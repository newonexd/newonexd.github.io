<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Hyperledger Fabric-CA</title>
    <link href="undefined2019/12/08/blog/fabric/Hyperledger_Fabric_CA/"/>
    <url>2019/12/08/blog/fabric/Hyperledger_Fabric_CA/</url>
    
    <content type="html"><![CDATA[<p>Fabric—Ca的概念不再解释了，这里只说明使用方法:</p><h2 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h2><ul><li>Go语言1.10+版本</li><li>GOPATH环境变量正确设置</li><li>已安装<code>libtool</code>和<code>libtdhl-dev</code>包</li></ul><h4 id="Ubuntu系统"><a href="#Ubuntu系统" class="headerlink" title="Ubuntu系统"></a>Ubuntu系统</h4><p>通过以下命令安装<code>libtool</code>和<code>libtdhl-dev</code>包：</p><pre><code>sudo apt install libtool libltdl-dev</code></pre><h4 id="MacOs-系统"><a href="#MacOs-系统" class="headerlink" title="MacOs 系统"></a>MacOs 系统</h4><p>Mac系统通过以下命令安装：</p><pre><code>brew install libtool</code></pre><h2 id="Fabric-Ca安装"><a href="#Fabric-Ca安装" class="headerlink" title="Fabric-Ca安装"></a>Fabric-Ca安装</h2><p>可以通过以下两种途径进行安装：</p><ol><li>直接下载二进制文件：<pre><code>go get -u github.com/hyperledger/fabric-ca/cmd/...</code></pre>如果使用这种方式安装，安装成功的话直接在命令行输入(前提是GOPATH正确配置):<pre><code>fabric-ca-server version</code></pre>即可打印出安装的Ca版本。</li><li>从源码编译安装：<br>首先在系统中建立以下路径:<pre><code>mkdir -p $GOPATH/src/github.com/hyperledger/cd $GOPATH/src/github.com/hyperledger/</code></pre>从Github上面将Fabric-Ca仓库克隆到本地：<pre><code>git clone https://github.com/hyperledger/fabric-ca.gitcd fabric-ca</code></pre>进行源码编译：<pre><code>make fabric-ca-servermake fabric-ca-client</code></pre>如果没有报错的话，当前文件下会编译出一个<code>bin</code>文件夹，最后一步将该文件夹添加到环境变量，安装完成！</li></ol><h4 id="编译Ca的Docker镜像"><a href="#编译Ca的Docker镜像" class="headerlink" title="编译Ca的Docker镜像"></a>编译Ca的Docker镜像</h4><p>直接在<code>fabric-ca</code>文件夹内执行以下命令：</p><pre><code>make docker</code></pre><h2 id="Fabric-Ca服务器简单使用"><a href="#Fabric-Ca服务器简单使用" class="headerlink" title="Fabric-Ca服务器简单使用"></a>Fabric-Ca服务器简单使用</h2><hr><h3 id="设置Fabric-Ca服务器的Home文件夹"><a href="#设置Fabric-Ca服务器的Home文件夹" class="headerlink" title="设置Fabric Ca服务器的Home文件夹"></a>设置Fabric Ca服务器的<code>Home</code>文件夹</h3><p>启动Fabric Ca 服务器的第一步是需要对Fabric Ca服务器进行初始化操作，初始化操作将会生成一些默认的配置文件，所以我们首先需要指定一个文件夹作为服务器的主文件夹用来放生成的配置文件。<br>可以通过以下几种方式设置Fabric-Ca服务器的主文件夹，优先级由高到低排序：</p><ol><li>通过命令行设置参数<code>--home</code>设置。</li><li>如果设置了<code>FABRIC_CA_SERVER_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>FABRIC_CA_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>CA_CFG_PATH</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果以上方法都没有设置，则将当前工作目录作为主文件夹。</li></ol><p>官方建议是通过设置<code>FABRIC_CA_HOME</code>为<code>$HOME/fabric-ca/server</code>作为服务器的主文件夹。</p><h3 id="初始化服务器"><a href="#初始化服务器" class="headerlink" title="初始化服务器"></a>初始化服务器</h3><p>上一步骤完成后，就可以对Fabric Ca进行初始化了，执行以下命令：</p><pre><code>fabric-ca-server init -b admin:adminpw</code></pre><p>通过<code>-b</code>参数指定管理员的账号和密码对服务器进行初始化。将会生成一个自签名的证书。</p><ul><li>admin:相当于管理员账号</li><li>adminpw:相当于管理员密码</li></ul><p><code>admin:adminpw</code>可以自行设置。<br>或者服务器的初始化也可以通过<code>-u</code>参数指定服务器的上一级服务器，也就是父服务器。格式为:<code>-u &lt;parent-fabric-ca-server-URL</code>,其中这里的<code>URL</code>必须使用<code>&lt;协议&gt;://&lt;enrollmentId&gt;:&lt;secret&gt;@&lt;host&gt;:&lt;port&gt;</code>的格式。<br>初始化之后将会生成几个文件：</p><pre><code>IssuerPublicKey      #与零知识证明相关文件，暂不解释IssuerRevocationPublicKey #与零知识证明相关文件，暂不解释ca-cert.pem             #证书文件fabric-ca-server-config.yaml   #默认配置文件,对Ca服务器进行配置时可以用到fabric-ca-server.db  #Ca服务器数据库，存储注册的用户，组织，证书等信息。可以通过sqlite3 命令进去查看msp/</code></pre><h3 id="启动服务器"><a href="#启动服务器" class="headerlink" title="启动服务器"></a>启动服务器</h3><p>初始化之后可以直接启动服务器：</p><pre><code>fabric-ca-server start -b &lt;admin&gt;:&lt;adminpw&gt;</code></pre><p>服务器将会监听在7054端口。如果需要服务器监听在<code>https</code>上而不是<code>http</code>上，需要将<code>tls.enabled</code>设置为<code>true</code>。</p><p>启动完之后，即可以通过<code>fabric-ca-client</code>工具或者是SDK对Ca服务器进行操作了。</p><h2 id="Fabric-Ca-客户端"><a href="#Fabric-Ca-客户端" class="headerlink" title="Fabric Ca 客户端"></a>Fabric Ca 客户端</h2><p>这一部分说明命令行工具<code>fabric-ca-client</code>的简单使用。</p><h3 id="设置Fabric-Ca客户端的Home文件夹"><a href="#设置Fabric-Ca客户端的Home文件夹" class="headerlink" title="设置Fabric Ca客户端的Home文件夹"></a>设置Fabric Ca客户端的<code>Home</code>文件夹</h3><p>与服务器相同，客户端也具有自己的主文件夹，用来保存客户端的证书秘钥等等。<br>可以通过以下几种方式设置Fabric-Ca客户端的主文件夹，优先级由高到低排序：</p><ol><li>通过命令行设置参数<code>--home</code>设置。</li><li>如果设置了<code>FABRIC_CA_CLIENT_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>FABRIC_CA_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>CA_CFG_PATH</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果以上方法都没有设置，则<code>$HOME/.fabric-ca-client</code>将作为主文件夹。</li></ol><p>官方例子：<code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/admin</code></p><h3 id="用户登陆"><a href="#用户登陆" class="headerlink" title="用户登陆"></a>用户登陆</h3><p>设置完之后，我们使用命令行工具登陆管理员用户:</p><pre><code>fabric-ca-client enroll -u http://admin:adminpw@localhost:7054</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>fabric-ca</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric手动生成CA证书搭建Fabric网络</title>
    <link href="undefined2019/12/08/blog/fabric/Hyperledger_Fabric%E6%89%8B%E5%8A%A8%E7%94%9F%E6%88%90CA%E8%AF%81%E4%B9%A6%E6%90%AD%E5%BB%BAFabric%E7%BD%91%E7%BB%9C/"/>
    <url>2019/12/08/blog/fabric/Hyperledger_Fabric%E6%89%8B%E5%8A%A8%E7%94%9F%E6%88%90CA%E8%AF%81%E4%B9%A6%E6%90%AD%E5%BB%BAFabric%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<p>之前介绍了使用官方脚本自动化启动一个Fabric网络，并且所有的证书都是通过官方的命令行工具<code>cryptogen</code>直接生成网络中的所有节点的证书。在开发环境可以这么简单进行，但是生成环境下还是需要我们自定义对网络中的节点的证书进行配置。<br>所以在本文中，将会详细介绍一个从手动生成证书一直到启动网络的整体步骤。本文只交代整体的搭建步骤。对于Fabric-Ca的讲解不在本文的范围内，将在另一篇文章中说明。<br>正篇文章也是根据官方的文档进行的。但是由于官方的文档尚未完工，也是好多没有交代清楚的，并且有些地方是错误的，所以笔者也是一步一步摸索出来的，所以如果本文哪里没有交代清楚或者错误的地方，希望各位批评指正。<br>在这里贴出<a href="https://hyperledger-fabric-ca.readthedocs.io/en/latest/operations_guide.html" target="_blank" rel="noopener">官方文档</a>地址.</p><h2 id="1-整体架构"><a href="#1-整体架构" class="headerlink" title="1.整体架构"></a>1.整体架构</h2><hr><p>架构图直接贴过来好了：<br><img src="/img/blog/arth.png" srcset="undefined" alt="系统架构"></p><p>官方文档采用的是多机环境，这里简洁化一点，所有的操作都在<strong>一台机器</strong>上进行，至于多机环境，以后再补充好了。<br>介绍一下本文所采用的整体架构：</p><ol><li>三个组织<ol><li>Org0  -&gt; 组织0   </li><li>Org1  -&gt; 组织1   </li><li>Org2  -&gt; 组织2   </li></ol></li><li>组织中的成员<ol><li>Org0   一个Orderer节点，一个Org0的Admin节点</li><li>Org1   两个Peer节点，一个Org1的Admin节点，一个Org1的User节点</li><li>Org2   两个Peer节点，一个Org2的Admin节点，一个Org2的User节点</li></ol></li><li>共有四台CA服务器<ol><li>TLS服务器   -&gt;  为网络中所有节点颁发TLS证书，用于通信的加密</li><li>Org1的CA服务器 -&gt; 为组织1中所有用户颁发证书</li><li>Org2的Ca服务器 -&gt; 为组织2中所有用户颁发证书</li><li>Org0的CA服务器 -&gt; 为组织0中所有用户颁发证书</li></ol></li></ol><p>这里的四台CA服务器都是根服务器。<strong>彼此之间都是独立的存在，没有任何关系。</strong>，也就是说每一个CA服务器生成的证书在其他CA服务器都是不能用的。<br>介绍完之后，可以进入正题了。</p><h3 id="1-1Fabric，Fabric-Ca安装"><a href="#1-1Fabric，Fabric-Ca安装" class="headerlink" title="1.1Fabric，Fabric-Ca安装"></a>1.1Fabric，Fabric-Ca安装</h3><p>本文默认读者都是对Fabric有一定的了解的，所以一些安装过程这里就没有重复说明。<br>第一步是安装Fabric-Ca环境，可以参考<a href="">这里</a>,这篇文章还没有写完，以后慢慢补，不过环境的安装已经有说明。<br>还有就是Fabric的环境安装，可以参考<a href="https://ifican.top/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">这里</a>。</p><p>完成环境搭建后，我们还需要一个<code>HOME</code>文件夹，用于存放我们生成的证书文件与<code>fabric</code>配置相关的文件。<br>本文设置<code>HOME</code>文件夹路径为:</p><pre><code>$GOPATH/src/github.com/caDemo/</code></pre><p>请读者自行创建，一般不要用太复杂的路径,也不要用中文路径，会为之后的操作带来很多麻烦。在下文中简单称<code>HOME</code>文件夹为<strong>工作目录</strong>,<strong>除非特殊说明，一般命令的执行都是在工作目录进行</strong>。</p><h2 id="2-CA服务器配置"><a href="#2-CA服务器配置" class="headerlink" title="2 CA服务器配置"></a>2 CA服务器配置</h2><hr><h3 id="2-1启动TLS-CA服务器"><a href="#2-1启动TLS-CA服务器" class="headerlink" title="2.1启动TLS CA服务器"></a>2.1启动TLS CA服务器</h3><p>前期工作准备好之后，我们开始启动第一台CA服务器。本文中使用<code>Docker</code>容器启动。<br>首先在工作目录创建<code>docker-compose.yaml</code>文件：</p><pre><code>touch docker-compose.yaml</code></pre><p>并在文件内添加以下内容(tips:内容格式不要乱掉)：</p><pre><code>version: &#39;2&#39;networks:  fabric-ca:services:  ca-tls:    container_name: ca-tls    image: hyperledger/fabric-ca    command: sh -c &#39;fabric-ca-server start -d -b tls-ca-admin:tls-ca-adminpw --port 7052&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/tls      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=ca-tls      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca  ##重要！！！记得修改这里的路径为自己的工作目录    networks:      - fabric-ca    ports:      - 7052:7052</code></pre><p>启动该<code>docker</code>容器：</p><pre><code>docker-compose -f docker-compose.yaml up ca-tls</code></pre><p>如果命令行出现以下内容则说明启动成功：</p><pre><code>[INFO] Listening on https://0.0.0.0:7052</code></pre><p>同时工作目录下会出现一个<code>tls</code>的文件夹。文件夹中的内容暂先不解释，留着在另一篇文章中说明。不过有一个文件需要解释一下，因为之后会用到。<br>在<code>$GOPATH/src/github.com/caDemo/tls/</code>路径下的<code>ca-cert.pem</code>文件。这是<code>TLS CA</code>服务器签名的根证书，目的是用来对<code>CA</code>的<code>TLS</code>证书进行验证，同时也需要持有这个证书才可以进行证书的颁发。在多机环境下，我们需要将它复制到每一台机器上，不过本文采用的是单机环境，所以省略掉了这一步。</p><h3 id="2-2-TLS-CA服务器注册用户"><a href="#2-2-TLS-CA服务器注册用户" class="headerlink" title="2.2 TLS CA服务器注册用户"></a>2.2 TLS CA服务器注册用户</h3><p>第一步是在TLS CA服务器中注册用户，经过注册的用户才拥有TLS证书，本文中由于只在各节点之间进行TLS加密通信，所以只将<code>orderer</code>和<code>peer</code>节点的身份注册到TLS服务器。<br>打开一个新的终端输入以下命令：</p><pre><code>#设置环境变量指定根证书的路径(如果工作目录不同的话记得指定自己的工作目录,以下不再重复说明)export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem#设置环境变量指定CA客户端的HOME文件夹export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/tls/admin#登录管理员用户用于之后的节点身份注册fabric-ca-client enroll -d -u https://tls-ca-admin:tls-ca-adminpw@0.0.0.0:7052</code></pre><p>登录成功在工作目录下的<code>tls</code>文件夹下将出现一个<code>admin</code>文件夹，这里面是<code>admin</code>的相关证书文件.<br>并且只有登录了<code>admin</code>，才具有权限进行用户的注册,因为该用户具有CA的全部权限，相当于CA服务器的<code>root</code>用户。<br>接下来对各个节点进行注册。</p><pre><code>fabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name orderer-org0 --id.secret ordererPW --id.type orderer -u https://0.0.0.0:7052</code></pre><p>这里将三个组织中的节点都进行了注册。</p><ul><li>不过<code>-d</code>这个参数并没有找到相关资料 </li><li><code>id.name</code>是指定用户的名称</li><li><code>--id.secert</code>是指定密码</li><li><code>--id.type</code>是指定用户类型，用户类型默认为<code>client</code>,主要包括<code>peer</code>,<code>app</code>,<code>user</code>,<code>orderer</code>.</li><li><code>-u</code>则是指定请求CA服务器的URL。</li></ul><p>这里我们为各个节点注册TLS证书，之后Fabric网络的通信则需要通过这一步骤注册过的用户的TLS证书来进行TLS加密通信。<br>到这里我们只是注册了各个节点的身份，还没有获取到他们的证书。证书可以通过登录获取，不过暂时不着急获取他们的TLS证书。<br>接下来，我们对其他几个CA服务器进行配置。</p><h3 id="2-3配置Org0的CA服务器"><a href="#2-3配置Org0的CA服务器" class="headerlink" title="2.3配置Org0的CA服务器"></a>2.3配置Org0的CA服务器</h3><p>再强调一下，本文中的几个CA服务器都是根服务器，彼此之间没有任何关系，所以上一步骤的TLS CA服务器在这一部分并没有用到。<br>同样，本文使用Docker容器启动CA服务器。配置文件如下，只需要添加进之前的<code>docker-compose.yaml</code>文件中就好：</p><pre><code>  org0:    container_name: org0    image: hyperledger/fabric-ca    command: /bin/bash -c &#39;fabric-ca-server start -d -b org0-admin:org0-adminpw --port 7053&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/org0/crypto      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=org0      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca    networks:      - fabric-ca    ports:      - 7053:7053</code></pre><p>添加完之后启动它：</p><pre><code>docker-compose -f docker-compose.yaml up org0</code></pre><p>打开另一个终端，接下来注册org0的用户：</p><pre><code>#首先指定环境变量，这里的TLS证书不是之前的TLS CA服务器的根证书，而是本组织CA服务器启动时生成的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem#指定本组织的CA客户端工作目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/admin</code></pre><p>登录<code>org0</code>的CA服务器管理员身份用于注册本组织的用户：</p><pre><code>fabric-ca-client enroll -d -u https://org0-admin:org0-adminpw@0.0.0.0:7053</code></pre><p>在本组织中共有两个用户：<code>orderer</code>节点和<code>admin</code>用户(这里的admin和管理员是不同的。)<br>将他们注册到org0的CA服务器：</p><pre><code>fabric-ca-client register -d --id.name orderer-org0 --id.secret ordererpw --id.type orderer -u https://0.0.0.0:7053fabric-ca-client register -d --id.name admin-org0 --id.secret org0adminpw --id.type admin --id.attrs &quot;hf.Registrar.Roles=client,hf.Registrar.Attributes=*,hf.Revoker=true,hf.GenCRL=true,admin=true:ecert,abac.init=true:ecert&quot; -u https://0.0.0.0:7053</code></pre><p>命令执行完之后，将会注册一个Orderer节点的身份和一个Admin的身份。同时在工作目录下的<code>org0</code>子文件夹中会有两个文件夹：<code>crypto</code>和<code>admin</code>。<code>crypto</code>中是CA服务器的配置信息，<code>admin</code>是服务器管理员的身份信息。</p><h3 id="2-4配置Org1的CA服务器"><a href="#2-4配置Org1的CA服务器" class="headerlink" title="2.4配置Org1的CA服务器"></a>2.4配置Org1的CA服务器</h3><p>同样的步骤，对org1组织的CA服务器进行配置：</p><pre><code>  org1:    container_name: org1    image: hyperledger/fabric-ca    command: /bin/bash -c &#39;fabric-ca-server start -d -b org1-admin:org1-adminpw&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/org1/crypto      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=org1      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca    networks:      - fabric-ca    ports:      - 7054:7054</code></pre><p>启动服务器：</p><pre><code>docker-compose -f docker-compose.yaml up org1</code></pre><p>打开新的终端，配置环境变量：</p><pre><code>export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/admin</code></pre><p>登录CA服务器管理员身份：</p><pre><code>fabric-ca-client enroll -d -u https://org1-admin:org1-adminpw@0.0.0.0:7054</code></pre><p>组织一种共有四个用户：<code>peer1</code>,<code>peer2</code>,<code>admin</code>,<code>user</code>,分别注册他们：</p><pre><code>fabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7054fabric-ca-client register -d --id.name admin-org1 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7054fabric-ca-client register -d --id.name user-org1 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7054</code></pre><h3 id="2-5配置Org2的CA服务器"><a href="#2-5配置Org2的CA服务器" class="headerlink" title="2.5配置Org2的CA服务器"></a>2.5配置Org2的CA服务器</h3><p>和上一部分相同，这里只列举需要的命令：<br>CA服务器配置文件：</p><pre><code>  org2:    container_name: org2    image: hyperledger/fabric-ca    command: /bin/bash -c &#39;fabric-ca-server start -d -b org2-admin:org2-adminpw --port 7055&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/org2/crypto      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=org2      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca    networks:      - fabric-ca    ports:      - 7055:7055</code></pre><p>启动服务器：</p><pre><code>docker-compose -f docker-compose.yaml up org2</code></pre><p>打开新的终端，配置环境变量：</p><pre><code>export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/admin</code></pre><p>登录CA服务器管理员身份：</p><pre><code>fabric-ca-client enroll -d -u https://org2-admin:org2-adminpw@0.0.0.0:7055</code></pre><p>组织一种共有四个用户：<code>peer1</code>,<code>peer2</code>,<code>admin</code>,<code>user</code>,分别注册他们：</p><pre><code>fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7055fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7055fabric-ca-client register -d --id.name admin-org2 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7055fabric-ca-client register -d --id.name user-org2 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7055</code></pre><h2 id="3-生成证书并配置TLS"><a href="#3-生成证书并配置TLS" class="headerlink" title="3.生成证书并配置TLS"></a>3.生成证书并配置TLS</h2><hr><p>到目前为止，所有的用户我们都注册完毕，接下来就是为每一个用户生成证书并配置TLS证书。<br>其中证书分为两部分，分别是本组织的MSP证书，以及组织之间进行加密通信的TLS证书。<br>所以本文需要对两部分证书进行分别生成与配置。<br>从组织一开始：</p><h3 id="3-1-组织一节点配置"><a href="#3-1-组织一节点配置" class="headerlink" title="3.1 组织一节点配置"></a>3.1 组织一节点配置</h3><h4 id="3-1-1-peer1"><a href="#3-1-1-peer1" class="headerlink" title="3.1.1 peer1"></a>3.1.1 peer1</h4><p>首先是本组织的<code>MSP</code>证书：</p><ul><li>配置环境变量<pre><code>#指定peer1节点的HOME目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer1#指定**本**组织的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem</code></pre></li><li>登录<code>peer1</code>节点到<code>org1 CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7054</code></pre>这一步完成后，在<code>$GOPATH/src/github.com/caDemo/org1/peer1</code>下会出现一个<code>msp</code>文件夹，这是<code>peer1</code>节点的<code>MSP</code>证书。<br>接下来是<code>TLS</code>证书：</li><li>配置环境变量<pre><code>#指定TLS CA服务器生成的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem#指定TLS证书的HOME目录export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer1/tls-msp</code></pre></li><li>登录<code>peer1</code>节点到<code>TLS CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org1</code></pre>这一步完成后，在<code>$GOPATH/src/github.com/caDemo/org1/peer1</code>下会出现一个<code>tls-msp</code>文件夹，这是<code>peer1</code>节点的<code>TLS</code>证书。</li><li>修改秘钥文件名<br>为什么要修改呢，进入这个文件夹看一下就知道了,由服务器生成的秘钥文件名是一长串无规则的字符串，后期我们使用的时候难道要一个字符一个字符地输入？<pre><code>cd $GOPATH/src/github.com/caDemo/org1/peer1/tls-msp/keystore/mv *_sk key.pem#修改完回到工作目录cd $GOPATH/src/github.com/caDemo</code></pre><h4 id="3-1-2-peer2"><a href="#3-1-2-peer2" class="headerlink" title="3.1.2 peer2"></a>3.1.2 peer2</h4><code>peer2</code>节点和上面步骤相同：<br>这里就直接放需要的命令了：</li><li>生成<code>MSP</code>证书<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer2export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7054</code></pre></li><li>生成<code>TLS</code>证书<pre><code>export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer2/tls-mspexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org1cd $GOPATH/src/github.com/caDemo/org1/peer2/tls-msp/keystore/mv *_sk key.pem</code></pre><h4 id="3-1-3-admin"><a href="#3-1-3-admin" class="headerlink" title="3.1.3 admin"></a>3.1.3 admin</h4>接下来是<code>admin</code>用户，这个用户有什么作用呢，实际上，安装和实例化链码都需要<code>admin</code>的证书，所以才需要注册一个<code>admin</code>用户，还要它的证书。</li><li>配置环境变量<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/adminuserexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem#这里多了一个环境变量，是指定admin用户的msp证书文件夹的export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/adminuser/msp</code></pre></li><li>登录<code>admin</code>用户获取<code>MSP</code>证书:<pre><code>fabric-ca-client enroll -d -u https://admin-org1:org1AdminPW@0.0.0.0:7054</code></pre>因为我们生成这个用户的证书主要就是为了之后链码的安装和实例化，所以配不配置他的<code>TLS</code>证书也无关紧要了(关键是我们之前也没有将这个用户注册到<code>tls</code>服务器中)</li><li>复制证书到<code>admincerts</code>文件夹:<br>去看Fabric官方的例子，每一个<code>peer</code>节点的<code>MSP</code>文件夹下都有<code>admincerts</code>这个子文件夹的，而且是需要我们手动创建的。<pre><code>mkdir -p $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts#将签名证书拷贝过去cp $GOPATH/src/github.com/caDemo/org1/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts/org1-admin-cert.pem#回到工作目录cd $GOPATH/src/github.com/caDemo/</code></pre><h4 id="3-1-4-启动peer节点"><a href="#3-1-4-启动peer节点" class="headerlink" title="3.1.4 启动peer节点"></a>3.1.4 启动peer节点</h4>到这里，已经配置好了一个节点，所以我们就可以启动这个节点了，当然在之后和<code>orderer</code>节点一起启动也可以，不过忙活了这么多，还是应该提前看到一下所做的工作的成果的！<br>附上<code>peer1</code>节点的容器配置信息：</li></ul><pre><code>  peer1-org1:    container_name: peer1-org1    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer1-org1      - CORE_PEER_ADDRESS=peer1-org1:7051      - CORE_PEER_LOCALMSPID=org1MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer1    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1    networks:      - fabric-ca</code></pre><p>启动它！！</p><pre><code>docker-compose -f docker-compose.yaml up peer1-org1</code></pre><p>如果没有报错的话，说明之前配置的没有什么问题，如果出错的话，则需要返回去检查一下了。。。<br><code>peer2</code>节点的容器配置信息：</p><pre><code>  peer2-org1:    container_name: peer2-org1    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer2-org1      - CORE_PEER_ADDRESS=peer2-org1:8051      - CORE_PEER_LOCALMSPID=org1MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer2/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer2/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer2    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org1/peer2:/tmp/hyperledger/org1/peer2    networks:      - fabric-ca</code></pre><p>启动它！！</p><pre><code>docker-compose -f docker-compose.yaml up peer2-org1</code></pre><h3 id="3-2-组织二节点配置"><a href="#3-2-组织二节点配置" class="headerlink" title="3.2 组织二节点配置"></a>3.2 组织二节点配置</h3><p>和之前一样的步骤，所以没什么好解释的了：</p><h4 id="3-2-1-peer1"><a href="#3-2-1-peer1" class="headerlink" title="3.2.1 peer1"></a>3.2.1 peer1</h4><ul><li>配置环境变量<pre><code>#指定peer2节点的HOME目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer1#指定本组织的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem</code></pre></li><li>登录<code>peer1</code>节点到<code>org2 CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7055</code></pre>接下来是<code>TLS</code>证书：</li><li>配置环境变量<pre><code>#指定TLS CA服务器生成的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem#指定TLS证书的HOME目录export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer1/tls-msp</code></pre></li><li>登录<code>peer1</code>节点到<code>TLS CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org2</code></pre></li><li>修改秘钥文件名<pre><code>cd $GOPATH/src/github.com/caDemo/org2/peer1/tls-msp/keystore/mv *_sk key.pem#修改完回到工作目录cd $GOPATH/src/github.com/caDemo</code></pre><h4 id="3-2-2-peer2"><a href="#3-2-2-peer2" class="headerlink" title="3.2.2 peer2"></a>3.2.2 peer2</h4></li><li>生成<code>MSP</code>证书<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer2export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7055</code></pre></li><li>生成<code>TLS</code>证书<pre><code>export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer2/tls-mspexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org2cd $GOPATH/src/github.com/caDemo/org2/peer2/tls-msp/keystore/mv *_sk key.pem</code></pre><h4 id="3-2-3-admin"><a href="#3-2-3-admin" class="headerlink" title="3.2.3 admin"></a>3.2.3 admin</h4></li><li>配置环境变量<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/adminuserexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/adminuser/msp</code></pre></li><li>登录<code>admin</code>用户获取<code>MSP</code>证书:<pre><code>fabric-ca-client enroll -d -u https://admin-org2:org2AdminPW@0.0.0.0:7055</code></pre></li><li>复制证书到<code>admincerts</code>文件夹:<br>去看Fabric官方的例子，每一个<code>peer</code>节点的<code>MSP</code>文件夹下都有<code>admincerts</code>这个子文件夹的，而且是需要我们手动创建的。<pre><code>mkdir -p $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts#将签名证书拷贝过去cp $GOPATH/src/github.com/caDemo/org2/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts/org2-admin-cert.pem#回到工作目录cd $GOPATH/src/github.com/caDemo/</code></pre><h4 id="3-2-4-启动peer节点"><a href="#3-2-4-启动peer节点" class="headerlink" title="3.2.4 启动peer节点"></a>3.2.4 启动peer节点</h4>附上<code>peer1</code>节点的容器配置信息：</li></ul><pre><code>  peer1-org2:    container_name: peer1-org2    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer1-org2      - CORE_PEER_ADDRESS=peer1-org2:9051      - CORE_PEER_LOCALMSPID=org2MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer1    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1    networks:      - fabric-ca</code></pre><p>启动它.</p><pre><code>docker-compose -f docker-compose.yaml up peer1-org2</code></pre><p><code>peer2</code>节点的容器配置信息：</p><pre><code>  peer2-org2:    container_name: peer2-org2    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer2-org2      - CORE_PEER_ADDRESS=peer2-org2:10051      - CORE_PEER_LOCALMSPID=org2MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer2/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer2/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer2    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org2/peer2:/tmp/hyperledger/org2/peer2    networks:      - fabric-ca</code></pre><p>启动它.</p><pre><code>docker-compose -f docker-compose.yaml up peer2-org2</code></pre><h3 id="3-3-排序节点配置"><a href="#3-3-排序节点配置" class="headerlink" title="3.3 排序节点配置"></a>3.3 排序节点配置</h3><p>接下来是排序节点的配置，为什么放在最后面呢，因为排序节点的启动需要提前生成创世区块，而创世区块的生成涉及到另一个配置文件，所以就先配置简单的<code>peer</code>节点。</p><h4 id="3-3-1-orderer"><a href="#3-3-1-orderer" class="headerlink" title="3.3.1 orderer"></a>3.3.1 orderer</h4><ul><li>配置环境变量<pre><code>#指定order节点的HOME目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/orderer#指定本组织的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem</code></pre></li><li>登录<code>order</code>节点到<code>org0 CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://orderer-org0:ordererpw@0.0.0.0:7053</code></pre>接下来是<code>TLS</code>证书：</li><li>配置环境变量<pre><code>#指定TLS CA服务器生成的TLS根证书export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/orderer/tls-msp#指定TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem</code></pre></li><li>登录<code>orderer</code>节点到<code>TLS CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://orderer-org0:ordererPW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts orderer-org0</code></pre></li><li>修改秘钥文件名<pre><code>cd $GOPATH/src/github.com/caDemo/org0/orderer/tls-msp/keystore/mv *_sk key.pem#修改完回到工作目录cd $GOPATH/src/github.com/caDemo</code></pre><h4 id="3-3-2-admin"><a href="#3-3-2-admin" class="headerlink" title="3.3.2 admin"></a>3.3.2 admin</h4></li><li>配置环境变量<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/adminuserexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/adminuser/msp</code></pre></li><li>登录<code>admin</code>用户获取<code>MSP</code>证书:<pre><code>fabric-ca-client enroll -d -u https://admin-org0:org0adminpw@0.0.0.0:7053</code></pre></li><li>复制证书到<code>admincerts</code>文件夹:<pre><code>mkdir $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts#将签名证书拷贝过去cp $GOPATH/src/github.com/caDemo/org0/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts/orderer-admin-cert.pem#回到工作目录cd $GOPATH/src/github.com/caDemo/</code></pre><h2 id="4-Fabric网络配置"><a href="#4-Fabric网络配置" class="headerlink" title="4.Fabric网络配置"></a>4.Fabric网络配置</h2></li></ul><hr><p>接下来到重头戏了，证书都生成好了，即将要启动网络了。不过在启动网络之前还是有很多准备工作需要做。其实到这里，官方文档已经好多没有交代清楚的了，所以一下好多内容都是笔者自己摸索出来的，如有错误欢迎批评指正。</p><h3 id="4-1-configtx-yaml文件配置"><a href="#4-1-configtx-yaml文件配置" class="headerlink" title="4.1 configtx.yaml文件配置"></a>4.1 configtx.yaml文件配置</h3><p>在下一个步骤的生成创世区块和通道配置信息需要一个文件：<code>configtx.yaml</code>文件。笔者根据官方的例子按照本文内容修改了一下，直接放在工作目录:</p><pre><code>Organizations:  - &amp;orderer-org0    Name: orderer-org0    ID: org0MSP    MSPDir: ./org0/msp  #    Policies:  #      Readers:  #        Type: Signature  #        Rule: &quot;OR(&#39;orderer-org0MSP.member&#39;)&quot;  #      Writers:  #        Type: Signature  #        Rule: &quot;OR(&#39;orderer-org0MSP.member&#39;)&quot;  #      Admins:  #        Type: Signature  #        Rule: &quot;OR(&#39;orderer-org0MSP.admin&#39;)&quot;  - &amp;org1    Name: org1MSP    ID: org1MSP    MSPDir: ./org1/msp    #    Policies:    #      Readers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org1MSP.admin&#39;, &#39;org1MSP.peer&#39;, &#39;org1MSP.client&#39;)&quot;    #      Writers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org1MSP.admin&#39;, &#39;org1MSP.client&#39;)&quot;    #      Admins:    #        Type: Signature    #        Rule: &quot;OR(&#39;org1MSP.admin&#39;)&quot;    AnchorPeers:      - Host: peer1-org1        Port: 7051  - &amp;org2    Name: org2MSP    ID: org2MSP    MSPDir: ./org2/msp    #    Policies:    #      Readers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org2MSP.admin&#39;, &#39;org2MSP.peer&#39;, &#39;org2MSP.client&#39;)&quot;    #      Writers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org2MSP.admin&#39;, &#39;org2MSP.client&#39;)&quot;    #      Admins:    #        Type: Signature    #        Rule: &quot;OR(&#39;org2MSP.admin&#39;)&quot;    AnchorPeers:      - Host: peer1-org2        Port: 9051Capabilities:  Channel: &amp;ChannelCapabilities    V1_4_3: true    V1_3: false    V1_1: false  Orderer: &amp;OrdererCapabilities    V1_4_2: true    V1_1: false  Application: &amp;ApplicationCapabilities    V1_4_2: true    V1_3: false    V1_2: false    V1_1: falseApplication: &amp;ApplicationDefaults  Organizations:  #  Policies:  #    Readers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Readers&quot;  #    Writers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Writers&quot;  #    Admins:  #      Type: ImplicitMeta  #      Rule: &quot;MAJORITY Admins&quot;  Capabilities:    &lt;&lt;: *ApplicationCapabilitiesOrderer: &amp;OrdererDefaults  OrdererType: solo  Addresses:    - orderer-org0:7050  BatchTimeout: 2s  BatchSize:    MaxMessageCount: 10    AbsoluteMaxBytes: 99 MB    PreferredMaxBytes: 512 KB  Organizations:#  Policies:#    Readers:#      Type: ImplicitMeta#      Rule: &quot;ANY Readers&quot;#    Writers:#      Type: ImplicitMeta#      Rule: &quot;ANY Writers&quot;#    Admins:#      Type: ImplicitMeta#      Rule: &quot;MAJORITY Admins&quot;#    # BlockValidation specifies what signatures must be included in the block#    # from the orderer for the peer to validate it.#    BlockValidation:#      Type: ImplicitMeta#      Rule: &quot;ANY Writers&quot;Channel: &amp;ChannelDefaults  #  Policies:  #    # Who may invoke the &#39;Deliver&#39; API  #    Readers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Readers&quot;  #    # Who may invoke the &#39;Broadcast&#39; API  #    Writers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Writers&quot;  #    # By default, who may modify elements at this config level  #    Admins:  #      Type: ImplicitMeta  #      Rule: &quot;MAJORITY Admins&quot;  Capabilities:    &lt;&lt;: *ChannelCapabilitiesProfiles:  TwoOrgsOrdererGenesis:    &lt;&lt;: *ChannelDefaults    Orderer:      &lt;&lt;: *OrdererDefaults      Organizations:        - *orderer-org0      Capabilities:        &lt;&lt;: *OrdererCapabilities    Consortiums:      SampleConsortium:        Organizations:          - *org1          - *org2  TwoOrgsChannel:    Consortium: SampleConsortium    &lt;&lt;: *ChannelDefaults    Application:      &lt;&lt;: *ApplicationDefaults      Organizations:        - *org1        - *org2      Capabilities:        &lt;&lt;: *ApplicationCapabilities</code></pre><p>注释掉的部分是策略部分，笔者还没有完全搞懂，所以索性就先注释掉了，以后搞懂了再添加进去。<br>还有一部分<code>msp</code>需要配置，就是<code>configtx.yaml</code>文件中第一部分指定的<code>MSPDir</code>,很简单，按照一下命令复制一下就好了：</p><pre><code>#进入工作目录cd $GOPATH/src/github.com/caDemo#############################################org0mkdir org0/msp &amp;&amp;  cd org0/mspmkdir admincerts &amp;&amp; mkdir cacerts &amp;&amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemocp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pemcp crypto/ca-cert.pem msp/cacerts/ca-cert.pemcp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem#############################################org1cd $GOPATH/src/github.com/caDemomkdir org1/msp/  &amp;&amp; cd org1/msp/mkdir admincerts &amp;&amp; mkdir cacerts &amp;&amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemocp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pemcp crypto/ca-cert.pem msp/cacerts/ca-cert.pemcp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem#############################################org2cd $GOPATH/src/github.com/caDemomkdir org1/msp/  &amp;&amp; cd org1/msp/mkdir admincerts &amp;&amp; mkdir cacerts &amp;&amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemocp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pemcp crypto/ca-cert.pem msp/cacerts/ca-cert.pemcp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem</code></pre><h3 id="4-2-生成创世区块和通道配置信息"><a href="#4-2-生成创世区块和通道配置信息" class="headerlink" title="4.2 生成创世区块和通道配置信息"></a>4.2 生成创世区块和通道配置信息</h3><p>可以了，所有的前期工作都已经完成，接下来就是手动启动网络了，第一步，生成创世区块和通道配置信息：</p><pre><code>cd $GOPATH/src/github.com/caDemoexport FABRIC_CFG_PATH=$PWD#生成创世区块configtxgen -profile TwoOrgsOrdererGenesis -outputBlock $GOPATH/src/github.com/caDemo/genesis.block#生成通道配置信息configtxgen -profile TwoOrgsChannel -outputCreateChannelTx $GOPATH/src/github.com/caDemo/channel.tx -channelID mychannel</code></pre><h3 id="4-3-启动Orderer节点"><a href="#4-3-启动Orderer节点" class="headerlink" title="4.3 启动Orderer节点"></a>4.3 启动Orderer节点</h3><p><code>orderer</code>容器配置文件：</p><pre><code>  orderer-org0:    container_name: orderer-org0    image: hyperledger/fabric-orderer    environment:      - ORDERER_HOME=/tmp/hyperledger/orderer      - ORDERER_HOST=orderer-org0      - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0      - ORDERER_GENERAL_GENESISMETHOD=file      - ORDERER_GENERAL_GENESISFILE=/tmp/hyperledger/genesis.block      - ORDERER_GENERAL_LOCALMSPID=org0MSP      - ORDERER_GENERAL_LOCALMSPDIR=/tmp/hyperledger/org0/orderer/msp      - ORDERER_GENERAL_TLS_ENABLED=true      - ORDERER_GENERAL_TLS_CERTIFICATE=/tmp/hyperledger/org0/orderer/tls-msp/signcerts/cert.pem      - ORDERER_GENERAL_TLS_PRIVATEKEY=/tmp/hyperledger/org0/orderer/tls-msp/keystore/key.pem      - ORDERER_GENERAL_TLS_ROOTCAS=[/tmp/hyperledger/org0/orderer/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem]      - ORDERER_GENERAL_LOGLEVEL=debug      - ORDERER_DEBUG_BROADCASTTRACEDIR=data/logs    volumes:      - $GOPATH/src/github.com/caDemo/org0/orderer:/tmp/hyperledger/org0/orderer/      - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/    networks:      - fabric-ca</code></pre><p>关键部分到了，只要这一步没有出现错误，整个网络就启动成功了。</p><pre><code>docker-compose -f docker-compose.yaml up orderer-org0</code></pre><h3 id="4-4-启动组织一的cli容器"><a href="#4-4-启动组织一的cli容器" class="headerlink" title="4.4 启动组织一的cli容器"></a>4.4 启动组织一的cli容器</h3><p><code>cli</code>容器内容,我们需要这个容器对组织1进行链码的交互：</p><pre><code>  cli-org1:    container_name: cli-org1    image: hyperledger/fabric-tools    tty: true    stdin_open: true    environment:      - SYS_CHANNEL=testchainid      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - FABRIC_LOGGING_SPEC=DEBUG      - CORE_PEER_ID=cli-org1      - CORE_PEER_ADDRESS=peer1-org1:7051      - CORE_PEER_LOCALMSPID=org1MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1    command: /bin/bash    volumes:      - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1      - $GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode      - $GOPATH/src/github.com/caDemo/org1/adminuser:/tmp/hyperledger/org1/adminuser      - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/    networks:      - fabric-ca    depends_on:      - peer1-org1</code></pre><p>启动该容器：</p><pre><code>docker-compose -f docker-compose.yaml up cli-org1</code></pre><h3 id="4-5-启动组织二的cli容器"><a href="#4-5-启动组织二的cli容器" class="headerlink" title="4.5 启动组织二的cli容器"></a>4.5 启动组织二的cli容器</h3><p><code>cli</code>容器内容,我们需要这个容器对组织2进行链码的交互：</p><pre><code>  cli-org2:    container_name: cli-org2    image: hyperledger/fabric-tools    tty: true    stdin_open: true    environment:      - SYS_CHANNEL=testchainid      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - FABRIC_LOGGING_SPEC=DEBUG      - CORE_PEER_ID=cli-org2      - CORE_PEER_ADDRESS=peer1-org2:9051      - CORE_PEER_LOCALMSPID=org2MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2    command: /bin/bash    volumes:      - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1      - $GOPATH/src/github.com/caDemo/org2/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode      - $GOPATH/src/github.com/caDemo/org2/adminuser:/tmp/hyperledger/org2/adminuser      - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/    networks:      - fabric-ca    depends_on:      - peer1-org2</code></pre><p>启动该容器：</p><pre><code>docker-compose -f docker-compose.yaml up cli-org2</code></pre><h2 id="5-网络测试"><a href="#5-网络测试" class="headerlink" title="5.网络测试"></a>5.网络测试</h2><hr><p>所有工作准备完成，接下来让我们测试整个网络能不能正常运行吧：</p><h3 id="5-1-创建与加入通道"><a href="#5-1-创建与加入通道" class="headerlink" title="5.1 创建与加入通道"></a>5.1 创建与加入通道</h3><p>以<strong>组织1</strong>为例：</p><ul><li><p>首先进入<code>cli</code>容器：</p><pre><code>docker exec -it cli bash#配置环境变量export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp</code></pre></li><li><p>创建通道</p><pre><code>peer channel create -c mychannel -f /tmp/hyperledger/channel.tx -o orderer-org0:7050 --outputBlock /tmp/hyperledger/mychannel.block --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem</code></pre></li><li><p>将<code>peer1-org1</code>加入通道：</p><pre><code>export CORE_PEER_ADDRESS=peer1-org1:7051peer channel join -b /tmp/hyperledger/mychannel.block</code></pre></li><li><p>将<code>peer2-org1</code>加入通道：</p><pre><code>export CORE_PEER_ADDRESS=peer2-org1:8051peer channel join -b /tmp/hyperledger/mychannel.block</code></pre><p>组织二步骤是相同的，唯一不同的就是不需要创建通道了，所以就不再说明了。</p><h3 id="5-2-安装和实例化链码"><a href="#5-2-安装和实例化链码" class="headerlink" title="5.2 安装和实例化链码"></a>5.2 安装和实例化链码</h3><p>以<strong>组织1</strong>为例：</p></li><li><p>首先进入<code>cli</code>容器：</p><pre><code>docker exec -it cli bash#配置环境变量export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/mspexport CORE_PEER_ADDRESS=peer1-org1:7051</code></pre></li><li><p>安装链码</p></li><li><p><em>记得提前将链码放到*</em><code>$GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode</code><strong>路径下。</strong>,本文使用的是<code>fabric-samples/chaincode/chaincode_example02</code>官方示例链码。</p><pre><code>peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric-samples/chaincode/chaincode_example02/go/</code></pre></li><li><p>实例化链码</p><pre><code>peer chaincode instantiate -C mychannel -n mycc -v 1.0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]}&#39;  -o orderer-org0:7050 --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem</code></pre></li><li><p>这一步在高版本的Fabric网络是会出错的，因为少了一个文件<code>config.yaml</code>:</p></li></ul><pre><code>NodeOUs:  Enable: true  ClientOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: client  PeerOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: peer  AdminOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: admin  OrdererOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: orderer</code></pre><p>因为高版本的Fabric把节点类型区分开了，所以需要我们手动配置。<br>将该文件复制到<code>$GOPATH/src/github.com/caDemo/org1/adminuser/msp</code>文件夹内，同时修改上面指定的位置的文件名(与对应文件夹内的文件名对应就好了)。</p><ul><li>实例化部分出错的可能性是最高的，很多都是因为网络模式指定错误导致链码容器启动失败，解决方案：<pre><code>#终端执行命令docker network ls</code></pre>找到以<code>fabric-ca</code>为后缀的一条如<code>cademo_fabric-ca</code>,修改之前的所有<code>peer</code>节点容器配置文件的环境变量：<br>```</li></ul><ul><li>CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca<br>```<br>修改完成重启节点容器，再次执行以上的命令(需要重新配置环境变量，加入通道这两个操作)。<br>终于，实例化成功了。<h3 id="5-3-调用和查询链码"><a href="#5-3-调用和查询链码" class="headerlink" title="5.3 调用和查询链码"></a>5.3 调用和查询链码</h3>最后测试一下链码功能能不能正常使用了：</li></ul><ul><li><p>还是组织一的<code>cli</code>容器：</p><pre><code>docker exec -it cli bashexport CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/mspexport CORE_PEER_ADDRESS=peer1-org1:7051</code></pre></li><li><p>执行查询功能：</p><pre><code>peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;</code></pre><p>命令行应该打印出:</p><pre><code>100</code></pre></li><li><p>执行调用功能：</p><pre><code>peer chaincode invoke -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]}&#39; --tls --cafile /tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem</code></pre></li><li><p>再次查询：</p><pre><code>peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;</code></pre><p>命令行应该打印出:</p><pre><code>90</code></pre><p>至于其他节点操作方法也是一样的，就不再操作了。<br>到此为止，从零开始的手动生成证书一直到成功搭建Fabric网络全部步骤已经完成！！接下来还有更新锚节点等等就不再演示了，请各位读者自行操作。整个步骤是不容易的，而且BUG百出，不过成功搭建完成确实涨了不少知识。<br>码字不易，还望各位看官支持一下：</p><img src="/img/blog/zfb.png" srcset="undefined" width = "300" height = "300" alt="支付宝" align=center /></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>fabric-ca</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric私有数据</title>
    <link href="undefined2019/12/04/blog/fabric/%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE/"/>
    <url>2019/12/04/blog/fabric/%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<p>官方文档:<a href="https://hyperledger-fabric.readthedocs.io/en/latest/private-data/private-data.html" target="_blank" rel="noopener">点这里</a></p><hr><h2 id="1简介"><a href="#1简介" class="headerlink" title="1简介"></a>1简介</h2><p>在<strong>同一个通道</strong>中，允许某一组织在对同一通道内其他组织保持部分的数据私有。也就是说有一部分被标识为私有的数据只能具有权限的组织查看和操作，而其余组织不具备查看和操作私有数据的权限。<br>通常如果需要保持数据私有可以另外创建一个通道只为私有数据服务，但是如果涉及到多个业务方时，为每一个组织另外创建通道会增加额外的管理类开销。并且也不能在进行私有数据操作的时候，让其余没有权限的组织节点都知道有这么一笔交易发生。<br>从Fabric 1.2开始，引入了一个<strong>私有数据集合</strong>的概念，它允许通道内的指定的某一个组织中的部分成员可以对私有数据进行操作，而其他没有权限的节点只能知道有这么一笔交易发生而不能了解交易的细节。</p><h3 id="1-1私有数据集合"><a href="#1-1私有数据集合" class="headerlink" title="1.1私有数据集合"></a>1.1私有数据集合</h3><hr><p>私有数据集合包括两个部分：</p><ol><li><p><strong>私有数据实体</strong>：通过Gossip协议在具有权限的节点之间传输，并且只有具有权限的节点可以看到。这部分私有数据存储在具有权限的节点的私有的状态数据库中。可以通过链码API在具有权限的节点上进行访问。并且私有数据不涉及排序服务，因为是通过Peer节点间的Gossip协议进行传输的。所以要求每一个节点都需要设置参数<code>CORE_PEER_GOSSIP_EXTERNALENDPOINT</code>，并在通道内设置锚节点用于跨组织通信。</p></li><li><p><strong>私有数据的哈希值</strong>：这一部分数据用于背书，排序以及写账本到通道内的每一个Peer节点。哈希值作为交易的证明用于状态验证还可以用于审计。</p></li></ol><h3 id="1-2什么时候使用私有数据"><a href="#1-2什么时候使用私有数据" class="headerlink" title="1.2什么时候使用私有数据"></a>1.2什么时候使用私有数据</h3><hr><ul><li>当所有的数据都需要在通道内的成员之间保密的时候，使用通道比较合适。</li><li>当交易要在所有组织之间传播，并且要求只有通道内的部分组织成员可以查看或操作交易内的某一部分数据时，需要使用私有数据集合。并且部分数据需要对排序节点进行保密时，使用私有数据集合。</li></ul><h3 id="1-3私有数据的交易流程"><a href="#1-3私有数据的交易流程" class="headerlink" title="1.3私有数据的交易流程"></a>1.3私有数据的交易流程</h3><pre><code>1. 当客户端提交一个调用链码的功能(读或写私有数据)提案请求到具有该私有数据集合操作权限的背书节点时,私有数据或者是用于通过链码生成私有数据的数据时，通过提案中的`transient`字段进行发送。2. 背书节点模拟交易并将私有数据存储到`peer`节点上的`transient data store`一个临时的数据存储区，并基于私有数据定义的策略，通过`Gossip`协议发送到其他具有权限的节点。3. 背书节点将提案响应发送给客户端。提案响应包括已经背书的读写集。读写集包括公共数据和私有数据的哈希值。发送给客户端的不包括任何的私有数据。4. 客户端应用提交交易(包括带有私有数据哈希值的提案响应)到排序节点。带有私有数据哈希值得交易将和正常交易一样包括在区块中。带有私有数据哈希值得区块分发到所有节点上。用这种方式，通道中所有的`peer`节点可以通过私有数据的哈希值对交易进行验证而不需要知道任何的私有数据信息。5、 在区块提交时，具有权限的节点通过集合策略确定是否具有访问私有数据的权限。如果具有权限，他们将会检查本地的`transient data store`确定他们是否已经在进行链码背书的时候接收到私有数据。如果没有，将试图从其他具有权限的节点处拉取私有数据。他们将验证公共区块中私有数据的哈希值并提交交易。当验证与提交结束后，私有数据将移动到他们的私有数据库和私有读写副本中。最后从`transient data store`中删除私有数据。</code></pre>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric 最简单的方式测试你的链码</title>
    <link href="undefined2019/11/27/blog/fabric/%E9%93%BE%E7%A0%81%E6%B5%8B%E8%AF%95/"/>
    <url>2019/11/27/blog/fabric/%E9%93%BE%E7%A0%81%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<p>一直以来，写完链码进行测试都要先搭建一个Fabric环境，然后安装链码进行测试，实际上Fabric提供了最为简单的方式可以允许我们对编写的应用链码进行功能测试，不需要搭建一个完整的Fabeic环境。而且测试完直接停止网络也不会担心有残余的文件没有删除干净，以至于搭建正式环境的时候出现各种错误。<br>进入正题好了，Fabric提供了一个开发模式，是专门用来对链码进行测试用的。</p><p><strong>其实，这些内容在Fabric官方文档中都是有的，但是一般我们都忽略掉了，所以简单说一下步骤</strong><br>官方文档地址：<a href="https://github.com/hyperledger/fabric-samples/blob/master/chaincode-docker-devmode/README.rst" target="_blank" rel="noopener">点这里</a></p><h2 id="1-先决条件"><a href="#1-先决条件" class="headerlink" title="1.先决条件"></a>1.先决条件</h2><p>首先，也是需要一些先决条件，比如<code>Golang</code>环境，<code>Docker</code>容器,<code>docker-compose</code>工具，等等，这些不再说明，可以看<a href="https://newonexd.github.io/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">这里完成先决条件的安装</a>。</p><h2 id="2-开始"><a href="#2-开始" class="headerlink" title="2.开始"></a>2.开始</h2><hr><p>完成准备工作后，我们需要将<code>Fabric-sample</code>文件夹从<code>Github</code>上<code>pull</code>下来，地址在<a href="https://github.com/hyperledger/fabric-samples" target="_blank" rel="noopener">这里</a>,最简单的方式是直接下载压缩文件，然后到本地解压出来，但是推荐使用IDE工具通过<code>git</code>工具从<code>Github</code>上拉取下来，具体方法自行百度。<br>完成之后，会有一个<code>fabric-sample</code>文件夹，将该文件夹放在<code>$GOPATH/src/github.com/hyperledger/</code>路径下，路径不存在自行创建。</p><h3 id="切换版本"><a href="#切换版本" class="headerlink" title="切换版本"></a>切换版本</h3><p>进入<code>fabric-samples</code>文件夹，执行以下命令，将Fabric版本切换至1.4，如果使用其他版本请下面部分下载二进制与Docker镜像的时候要对应。</p><pre><code>git checkout release-1.4</code></pre><h3 id="3-二进制文件以及Docker镜像"><a href="#3-二进制文件以及Docker镜像" class="headerlink" title="3.二进制文件以及Docker镜像"></a>3.二进制文件以及Docker镜像</h3><hr><p>下载二进制文件是比较容易出错的地方，因为容易因为版本不匹配导致网络启动失败，所以在下载二进制文件的时候一定要注意使用的版本。</p><pre><code>curl -sS https://raw.githubusercontent.com/hyperledger/fabric/master/scripts/bootstrap.sh -o ./scripts/bootstrap.shchmod +x ./scripts/bootstrap.sh## ./scripts/bootstrap.sh [version] [ca version] [thirdparty_version]</code></pre><p>这里需要输入三个版本号，第一个是Fabric的版本号，第二个是Ca的版本号(在这里我们用不到），第三个是第三方工具的版本号。<br>我们之前是使用了1.4的Fabric，所以我们直接指定好版本就好了。</p><ul><li>Fabric &gt;&gt; 1.4.3(只要前缀是1.4就可以)</li><li>CA    &gt;&gt;  1.4.3</li><li>ThirdParty &gt;&gt; 0.4.15</li></ul><p>完整的命令为:</p><pre><code>#记得要在bootstrap.sh文件的上一级目录进行执行。./scripts/bootstrap.sh 1.4.3 1.4.3 0.4.15</code></pre><p>或者直接将版本号在文件中修改：<br>打开刚下载的<code>bootstrap.sh</code>文件，前面几行就是指定版本号的，自行修改就好，修改完直接使用命令进行下载就好了。</p><pre><code>./scripts/bootstrap.sh</code></pre><h2 id="4-测试链码"><a href="#4-测试链码" class="headerlink" title="4.测试链码"></a>4.测试链码</h2><p>前面几部没有出现问题的话，到这里我们就可以对链码进行测试了，进入<code>fabric-sample/chaincode-docker-devmode</code>文件夹下,执行以下命令：</p><pre><code>docker-compose -f docker-compose-simple.yaml up</code></pre><p>如果没有错误的话，我们的开发环境已经准备好了，接下来是对链码进行测试的步骤：</p><ol><li>将编写的链码放到<code>fabric-sample/chaincode/</code>文件夹下<pre><code># 打开第二个终端执行：docker exec -it chaincode sh</code></pre>如果已经将链码放到<code>fabric-sample/chaincode/</code>文件夹内，执行以下命令应该可以看到自己的链码：<pre><code>ls</code></pre></li><li>编译链码,以官方的例子为例：<pre><code>cd chaincode_example02/gogo build -o chaincode_example02CORE_PEER_ADDRESS=peer:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./chaincode_example02</code></pre></li></ol><p>3.<strong>安装与实例化</strong>：<br>打开第三个终端执行：</p><pre><code>docker exec -it cli bash# 以下命令按照自己的链码内容自行修改peer chaincode install -p chaincodedev/chaincode/chaincode_example02/go -n mycc -v 0peer chaincode instantiate -n mycc -v 0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]}&#39; -C myc</code></pre><p>4 测试<br>如果以上步骤没有报错的话，准备工作已经全部完成，剩下的就是测试自己的链码了。如果链码需要更新的话，只需要关闭网络：</p><pre><code>docker-compose -f docker-compose-simple.yaml down --volumes</code></pre><p>重新启动网络并进行测试就好了。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于角色的访问控制</title>
    <link href="undefined2019/11/25/blog/etcd/%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"/>
    <url>2019/11/25/blog/etcd/%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/authentication.md" target="_blank" rel="noopener">Role-based access control</a></p><h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><hr><p>身份验证已添加到etcd 2.1中。 etcd v3 API略微修改了身份验证功能的API和用户界面，以更好地适应新的数据模型。本指南旨在帮助用户在etcd v3中设置基本身份验证和基于角色的访问控制。</p><h2 id="特殊用户和角色"><a href="#特殊用户和角色" class="headerlink" title="特殊用户和角色"></a>特殊用户和角色</h2><hr><p>有一个特殊用户<code>root</code>，一个特殊角色<code>root</code>。</p><h3 id="用户root"><a href="#用户root" class="headerlink" title="用户root"></a>用户<code>root</code></h3><p>在激活身份验证之前，必须创建对<code>etcd</code>具有完全访问权限的<code>root</code>用户。 <code>root</code>用户的想法是出于管理目的：管理角色和普通用户。 <code>root</code>用户必须具有<code>root</code>角色，并且可以在<code>etcd</code>中进行任何更改。</p><h3 id="角色root"><a href="#角色root" class="headerlink" title="角色root"></a>角色<code>root</code></h3><p>可以将角色<code>root</code>授予除<code>root</code>用户之外的任何用户。 具有<code>root</code>角色的用户既具有全局读写访问权限，又具有更新集群的身份验证配置的权限。 此外，<code>root</code>角色授予常规集群维护的特权，包括修改集群成员资格，对存储进行碎片整理以及拍摄快照。</p><h2 id="用户的工作方式"><a href="#用户的工作方式" class="headerlink" title="用户的工作方式"></a>用户的工作方式</h2><hr><p><code>etcdctl</code>的<code>user</code>子命令处理与用户帐户有关的所有事情。<br>可以通过以下方式找到用户列表：</p><pre><code>$ etcdctl user list</code></pre><p>通过以下方式创建新用户：</p><pre><code>$ etcdctl user add myusername</code></pre><p>创建新用户将提示您输入新密码。 当给出选项<code>--interactive=false</code>时，可以从标准输入中提供密码。 <code>--new-user-password</code>也可以用于提供密码。</p><p>可以通过以下方式为用户授予和撤消角色：</p><pre><code>$ etcdctl user grant-role myusername foo$ etcdctl user revoke-role myusername bar</code></pre><p>可以使用以下命令检查用户的设置：</p><pre><code>$ etcdctl user get myusername</code></pre><p>用户密码可以通过以下方式更改：</p><pre><code>$ etcdctl user passwd myusername</code></pre><p>更改密码将再次提示您输入新密码。 当给出选项<code>--interactive=false</code>时，可以从标准输入中提供密码。</p><p>通过以下方式删除帐户：</p><pre><code>$ etcdctl user delete myusername</code></pre><h3 id="角色的工作方式："><a href="#角色的工作方式：" class="headerlink" title="角色的工作方式："></a>角色的工作方式：</h3><hr><p><code>etcdctl</code>的<code>role</code>子命令处理与授予特定用户的特定角色的访问控制有关的所有事情。</p><p>列出角色：</p><pre><code>$ etcdctl role list</code></pre><p>创建一个新角色：</p><pre><code>$ etcdctl role add myrolename</code></pre><p>角色没有密码； 它仅定义了一组新的访问权限。</p><p>授予角色访问单个密钥或一系列密钥的权限。</p><p>范围可以指定为间隔[开始键，结束键]，其中开始键应按字母顺序在词汇上小于结束键。</p><p>可以将访问权限授予读取，写入或同时授予两者，如以下示例所示：</p><pre><code># Give read access to a key /foo$ etcdctl role grant-permission myrolename read /foo# Give read access to keys with a prefix /foo/. The prefix is equal to the range [/foo/, /foo0)$ etcdctl role grant-permission myrolename --prefix=true read /foo/# Give write-only access to the key at /foo/bar$ etcdctl role grant-permission myrolename write /foo/bar# Give full access to keys in a range of [key1, key5)$ etcdctl role grant-permission myrolename readwrite key1 key5# Give full access to keys with a prefix /pub/$ etcdctl role grant-permission myrolename --prefix=true readwrite /pub/</code></pre><p>要查看授予的权限，我们可以随时查看该角色：</p><pre><code>$ etcdctl role get myrolename</code></pre><p>撤消权限是按照相同的逻辑方式完成的：</p><pre><code>$ etcdctl role revoke-permission myrolename /foo/bar</code></pre><p>就像完全删除一个角色一样：</p><pre><code>$ etcdctl role delete myrolename</code></pre><h3 id="开启身份认证"><a href="#开启身份认证" class="headerlink" title="开启身份认证"></a>开启身份认证</h3><hr><p>启用身份验证的最少步骤如下。 管理员可以根据喜好在启用身份验证之前或之后设置用户和角色。</p><p>确保已创建root用户：</p><pre><code>$ etcdctl user add rootPassword of root:</code></pre><p>开启身份认证</p><pre><code>$ etcdctl auth enable</code></pre><p>此后，etcd在启用身份验证的情况下运行。 要出于任何原因禁用它，请使用reciprocal命令：</p><pre><code>$ etcdctl --user root:rootpw auth disable</code></pre><h3 id="使用etcdctl进行身份验证"><a href="#使用etcdctl进行身份验证" class="headerlink" title="使用etcdctl进行身份验证"></a>使用<code>etcdctl</code>进行身份验证</h3><hr><p><code>etcdctl</code>支持类似<code>curl</code>的标志进行身份验证。</p><pre><code>$ etcdctl --user user:password get foo</code></pre><p>可以从提示符处获取密码：</p><pre><code>$ etcdctl --user user get foo</code></pre><p>密码也可以从命令行参数<code>--password</code>获取：</p><pre><code>$ etcdctl --user user --password password get foo</code></pre><p>否则，所有<code>etcdctl</code>命令均保持不变。 用户和角色仍然可以创建和修改，但是需要具有<code>root</code>角色的用户进行身份验证。</p><h3 id="使用TLS通用名称"><a href="#使用TLS通用名称" class="headerlink" title="使用TLS通用名称"></a>使用TLS通用名称</h3><hr><p>从v3.2版本开始，如果使用参数<code>--client-cert-auth=true</code>启动etcd服务器，则客户端的TLS证书中的“通用名称（CN）”字段将用作etcd用户。在这种情况下，公用名将对用户进行身份验证，并且客户端不需要密码。请注意，如果同时传递了1. <code>--client-cert-auth=true</code>且客户端提供了CN，并且客户端提供了2.用户名和密码，则将优先考虑基于用户名和密码的身份验证。请注意，此功能不能与<code>gRPC-proxy</code>和<code>gRPC-gateway</code>一起使用。这是因为<code>gRPC-proxy</code>会从其客户端终止TLS，因此所有客户端都共享代理证书。 <code>gRPC-gateway</code>内部使用TLS连接将HTTP请求转换为gRPC请求，因此它具有相同的限制。因此，客户端不能正确地将其CN提供给服务器。如果给定证书的CN不为空，则<code>gRPC-proxy</code>将导致错误并停止。 <code>gRPC-proxy</code>返回错误，表明客户端证书中的CN为非空。</p><p>从v3.3版本开始，如果启用了带有选项<code>--peer-cert-allowed-cn</code>或<code>--peer-cert-allowed-hostname</code>的<code>etcd</code>服务器启动，则对等节点连接筛选。如果节点的TLS证书身份与允许的节点匹配，则节点只能加入etcd集群。有关更多详细信息，请参见<a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">etcd安全性页面</a>。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TLS</title>
    <link href="undefined2019/11/25/blog/etcd/TLS/"/>
    <url>2019/11/25/blog/etcd/TLS/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md" target="_blank" rel="noopener">TLS</a><br>etcd支持用于客户端到服务器以及对等方（服务器到服务器/集群）通信的自动TLS以及通过客户端证书的身份验证.<br>要启动并运行，首先要获得一个成员的CA证书和签名密钥对。 建议为集群中的每个成员创建并签名一个新的密钥对。<br>为了方便起见，<a href="https://github.com/cloudflare/cfssl" target="_blank" rel="noopener">cfssl</a>工具提供了一个简单的接口来生成证书，我们在<a href="https://github.com/etcd-io/etcd/blob/master/hack/tls-setup" target="_blank" rel="noopener">此处</a>提供了使用该工具的示例。 或者，尝试使用本指南<a href="https://github.com/coreos/docs/blob/master/os/generate-self-signed-certificates.md" target="_blank" rel="noopener">生成自签名密钥对</a>。</p><h2 id="基本设置"><a href="#基本设置" class="headerlink" title="基本设置"></a>基本设置</h2><hr><p>etcd通过命令行参数或环境变量采用了几种与证书相关的配置选项：</p><p><strong>客户端到服务器的通信：</strong><br><code>--cert-file=&lt;path&gt;</code>:用于SSL/TLS<strong>与</strong>etcd的连接的证书。设置此选项后，advertise-client-urls可以使用HTTPS模式。<br><code>--key-file=&lt;path&gt;</code>:证书的密钥。 必须未加密。<br><code>--client-cert-auth</code>:设置此选项后，etcd将检查所有传入的HTTPS请求以查找由受信任CA签名的客户端证书，不提供有效客户端证书的请求将失败。 如果启用了身份验证，则证书将为“公用名”字段指定的用户名提供凭据。<br><code>--trusted-ca-file=&lt;path&gt;</code>:受信任的证书颁发机构。<br><code>--auto-tls</code>:使用自动生成的自签名证书进行与客户端的TLS连接。</p><p><strong>对等节点(服务器到服务器/集群)间的通信：</strong><br>对等节点选项的工作方式与客户端到服务器的选项相同：<br><code>--peer-cert-file=&lt;path&gt;</code>:用于SSL/TLS<strong>与</strong>对等节点之间的连接的证书。这将用于监听对等方地址以及向其他对等方发送请求。<br><code>--peer-key-file=&lt;path&gt;</code>:证书的密钥。 必须未加密。<br><code>--peer-client-cert-auth</code>:设置此选项后，etcd将检查所有传入的对等节点请求以查找由受信任CA签名的客户端证书.<br><code>--peer-trusted-ca-file=&lt;path&gt;</code>:受信任的证书颁发机构。<br><code>--peer-auto-tls</code>:使用自动生成的自签名证书进行与对等节点之间的TLS连接。<br>如果提供了客户端到服务器或对等节点证书，则还必须设置密钥。 所有这些配置选项也可以通过环境变量<code>ETCD_CA_FILE</code>，<code>ETCD_PEER_CA_FILE</code>等获得。<br><code>--cipher-suites</code>:服务器/客户端与对等方之间受支持的TLS密码套件的逗号分隔列表（空将由Go自动填充）。从<code>v3.2.22+,v3.3.7+</code>和<code>v3.4+</code>起可用。</p><h2 id="示例1：客户端通过HTTPS与服务器进行加密传输"><a href="#示例1：客户端通过HTTPS与服务器进行加密传输" class="headerlink" title="示例1：客户端通过HTTPS与服务器进行加密传输"></a>示例1：客户端通过HTTPS与服务器进行加密传输</h2><hr><p>为此，请准备好CA证书（<code>ca.crt</code>）和签名密钥对（<code>server.crt</code>，<code>server.key</code>）。<br>让我们配置etcd以逐步提供简单的HTTPS传输安全性：</p><pre><code>$ etcd --name infra0 --data-dir infra0 \  --cert-file=/path/to/server.crt --key-file=/path/to/server.key \  --advertise-client-urls=https://127.0.0.1:2379 --listen-client-urls=https://127.0.0.1:2379</code></pre><p>这应该可以正常启动，并且可以通过对etcd用HTTPS方式来测试配置：</p><pre><code>$ curl --cacert /path/to/ca.crt https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</code></pre><p>该命令应显示握手成功。 由于我们使用具有自己的证书颁发机构的自签名证书，因此必须使用<code>--cacert</code>选项将CA传递给curl。 另一种可能性是将CA证书添加到系统的受信任证书目录（通常在<code>/etc/pki/tls/certs</code>或<code>/etc/ssl/certs</code>中）。<br><strong>OSX10.9+的用户：</strong>OSX 10.9+上的curl 7.30.0无法理解在命令行中传递的证书。可以替代的方法是将虚拟<code>ca.crt</code>直接导入到钥匙串中，或添加<code>-k</code>标志来<code>curl</code>以忽略错误。要在没有-k标志的情况下进行测试，请运行打开的<code>./fixtures/ca/ca.crt</code>并按照提示进行操作。测试后请删除此证书！如果有解决方法，请告诉我们。</p><h2 id="示例2：使用HTTPS客户端证书的客户端到服务器身份验证"><a href="#示例2：使用HTTPS客户端证书的客户端到服务器身份验证" class="headerlink" title="示例2：使用HTTPS客户端证书的客户端到服务器身份验证"></a>示例2：使用HTTPS客户端证书的客户端到服务器身份验证</h2><hr><p>目前，我们已经为etcd客户端提供了验证服务器身份并提供传输安全性的功能。 但是，我们也可以使用客户端证书来防止对etcd的未经授权的访问。<br>客户端将向服务器提供其证书，服务器将检查证书是否由提供的CA签名并决定是否满足请求。<br>为此，需要第一个示例中提到的相同文件，以及由同一证书颁发机构签名的客户端密钥对（<code>client.crt</code>，<code>client.key</code>）。</p><pre><code>$ etcd --name infra0 --data-dir infra0 \  --client-cert-auth --trusted-ca-file=/path/to/ca.crt --cert-file=/path/to/server.crt --key-file=/path/to/server.key \  --advertise-client-urls https://127.0.0.1:2379 --listen-client-urls https://127.0.0.1:2379</code></pre><p>现在，对该服务器尝试与上述相同的请求：</p><pre><code>$ curl --cacert /path/to/ca.crt https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</code></pre><p>该请求应该是被服务器拒绝：</p><pre><code>...routines:SSL3_READ_BYTES:sslv3 alert bad certificate...</code></pre><p>为了使其成功，我们需要将CA签名的客户端证书提供给服务器：</p><pre><code>$ curl --cacert /path/to/ca.crt --cert /path/to/client.crt --key /path/to/client.key \  -L https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</code></pre><p>输出应包括：</p><pre><code>...SSLv3, TLS handshake, CERT verify (15):...TLS handshake, Finished (20)</code></pre><p>以及服务器的响应：</p><pre><code>{    &quot;action&quot;: &quot;set&quot;,    &quot;node&quot;: {        &quot;createdIndex&quot;: 12,        &quot;key&quot;: &quot;/foo&quot;,        &quot;modifiedIndex&quot;: 12,        &quot;value&quot;: &quot;bar&quot;    }}</code></pre><p>指定密码套件以阻止<a href="https://github.com/etcd-io/etcd/issues/8320" target="_blank" rel="noopener">较弱的TLS密码套件</a>。<br>当使用无效密码套件请求客户端问候时，TLS握手将失败。<br>例如：</p><pre><code>$ etcd \  --cert-file ./server.crt \  --key-file ./server.key \  --trusted-ca-file ./ca.crt \  --cipher-suites TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</code></pre><p>然后，客户端请求必须指定服务器中指定的密码套件之一：</p><pre><code># 有效的加密套件$ curl \  --cacert ./ca.crt \  --cert ./server.crt \  --key ./server.key \  -L [CLIENT-URL]/metrics \  --ciphers ECDHE-RSA-AES128-GCM-SHA256# 成功请求etcd_server_version{server_version=&quot;3.2.22&quot;} 1...</code></pre><pre><code># 无效的加密套件$ curl \  --cacert ./ca.crt \  --cert ./server.crt \  --key ./server.key \  -L [CLIENT-URL]/metrics \  --ciphers ECDHE-RSA-DES-CBC3-SHA# 请求失败(35) error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert handshake failure</code></pre><h2 id="示例3：集群中的传输安全性和客户端证书"><a href="#示例3：集群中的传输安全性和客户端证书" class="headerlink" title="示例3：集群中的传输安全性和客户端证书"></a>示例3：集群中的传输安全性和客户端证书</h2><hr><p>etcd支持与上述对等节点通信相同的模型，这意味着集群中etcd成员之间的通信。<br>假设我们有这个<code>ca.crt</code>和两个由此CA签名的成员，它们具有自己的密钥对（<code>member1.crt</code>和<code>member1.key</code>，<code>member2.crt</code>和<code>member2.key</code>），我们按以下方式启动etcd：</p><pre><code>DISCOVERY_URL=... # from https://discovery.etcd.io/new# member1$ etcd --name infra1 --data-dir infra1 \  --peer-client-cert-auth --peer-trusted-ca-file=/path/to/ca.crt --peer-cert-file=/path/to/member1.crt --peer-key-file=/path/to/member1.key \  --initial-advertise-peer-urls=https://10.0.1.10:2380 --listen-peer-urls=https://10.0.1.10:2380 \  --discovery ${DISCOVERY_URL}# member2$ etcd --name infra2 --data-dir infra2 \  --peer-client-cert-auth --peer-trusted-ca-file=/path/to/ca.crt --peer-cert-file=/path/to/member2.crt --peer-key-file=/path/to/member2.key \  --initial-advertise-peer-urls=https://10.0.1.11:2380 --listen-peer-urls=https://10.0.1.11:2380 \  --discovery ${DISCOVERY_URL}</code></pre><p>etcd成员将形成一个集群，并且集群中成员之间的所有通信都将使用客户端证书进行加密和身份验证。 etcd的输出将显示它连接以使用HTTPS的地址。</p><h2 id="示例4：自动自签名传输安全性"><a href="#示例4：自动自签名传输安全性" class="headerlink" title="示例4：自动自签名传输安全性"></a>示例4：自动自签名传输安全性</h2><hr><p>对于需要通信加密而不是身份验证的情况，etcd支持使用自动生成的自签名证书来加密其消息。 因为不需要在etcd之外管理证书和密钥，所以这简化了部署。<br>配置etcd以使用带有<code>--auto-tls</code>和<code>--peer-auto-tls</code>标志的自签名证书进行客户端和对等节点连接：</p><pre><code>DISCOVERY_URL=... # from https://discovery.etcd.io/new# member1$ etcd --name infra1 --data-dir infra1 \  --auto-tls --peer-auto-tls \  --initial-advertise-peer-urls=https://10.0.1.10:2380 --listen-peer-urls=https://10.0.1.10:2380 \  --discovery ${DISCOVERY_URL}# member2$ etcd --name infra2 --data-dir infra2 \  --auto-tls --peer-auto-tls \  --initial-advertise-peer-urls=https://10.0.1.11:2380 --listen-peer-urls=https://10.0.1.11:2380 \  --discovery ${DISCOVERY_URL}</code></pre><p>自签名证书不会验证身份，因此curl将返回错误：</p><pre><code>curl: (60) SSL certificate problem: Invalid certificate chain</code></pre><p>要禁用证书链检查，请使用<code>-k</code>标志调用<code>curl</code>：</p><pre><code>$ curl -k https://127.0.0.1:2379/v2/keys/foo -Xput -d value=bar -v</code></pre><h2 id="DNS-SRV的注意事项"><a href="#DNS-SRV的注意事项" class="headerlink" title="DNS SRV的注意事项"></a>DNS SRV的注意事项</h2><hr><p>如果连接是安全的，则<code>etcd proxy</code>从其客户端TLS终端，并使用<code>--peer-key-file</code>和<code>--peer-cert-file</code>中指定的代理自身的密钥/证书与etcd成员进行通信。</p><p>代理通过给定成员的<code>--advertise-client-urls</code>和<code>--advertise-peer-urls</code>与etcd成员进行通信。 它将客户端请求转发到etcd成员广播的客户端URL，并通过etcd成员广播的对等URL同步初始集群配置。</p><p>为etcd成员启用客户端身份验证后，管理员必须确保代理的<code>--peer-cert-file</code>选项中指定的对等节点证书对该身份验证有效。如果启用了对等节点身份验证，则代理的对等节点证书也必须对对等节点身份验证有效。</p><h2 id="TLS-身份验证的注意事项"><a href="#TLS-身份验证的注意事项" class="headerlink" title="TLS 身份验证的注意事项"></a>TLS 身份验证的注意事项</h2><hr><p>从<a href="https://github.com/etcd-io/etcd/pull/7829" target="_blank" rel="noopener">v3.2.0开始，TLS证书将在每个客户端连接上重新加载</a>。 这在不停止etcd服务器而替换到期证书时很有用； 可以通过用新证书覆盖旧证书来完成。 刷新每个连接的证书应该没有太多的开销，但是将来可以通过缓存层进行改进。 示例测试可以在<a href="https://github.com/coreos/etcd/blob/b041ce5d514a4b4aaeefbffb008f0c7570a18986/integration/v3_grpc_test.go#L1601-L1757" target="_blank" rel="noopener">这里</a>找到。</p><p>从<a href="https://github.com/etcd-io/etcd/pull/7687" target="_blank" rel="noopener">v3.2.0开始，服务器使用错误的IP <code>SAN</code>拒绝传入的对等证书</a>。 例如，如果对等节点证书在“使用者备用名称”（SAN）字段中包含任何IP地址，则服务器仅在远程IP地址与这些IP地址之一匹配时才对对等节点身份验证。 这是为了防止未经授权的端点加入群集。 例如，对等节点B的CSR（带有cfssl）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;*.example.default.svc&quot;,    &quot;*.example.default.svc.cluster.local&quot;,    &quot;10.138.0.27&quot;  ],  &quot;key&quot;: {    &quot;algo&quot;: &quot;rsa&quot;,    &quot;size&quot;: 2048  },  &quot;names&quot;: [    {      &quot;C&quot;: &quot;US&quot;,      &quot;L&quot;: &quot;CA&quot;,      &quot;ST&quot;: &quot;San Francisco&quot;    }  ]}</code></pre><p>当对等节点B的实际IP地址是<code>10.138.0.2</code>，而不是<code>10.138.0.27</code>。 当对等节点B尝试加入集群时，对等节点A将拒绝B，并显示错误x509：证书对<code>10.138.0.27</code>有效，而不对<code>10.138.0.2</code>有效，因为B的远程IP地址与“使用者备用名称（SAN）”字段中的地址不匹配。</p><p>从<a href="https://github.com/etcd-io/etcd/pull/7767" target="_blank" rel="noopener">v3.2.0开始，服务器在检查SAN时解析TLS DNSNames</a>。 例如，如果对等节点证书在“使用者备用名称”（SAN）字段中仅包含DNS名称（不包含IP地址），则仅当这些DNS名称上的正向查找（<code>dig b.com</code>）具有与远程IP匹配的IP时，服务器才对对等身份验证 地址。 例如，对等B的CSR（带有<code>cfssl</code>）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;b.com&quot;  ],</code></pre><p>当对等节点B的远程IP地址为<code>10.138.0.2</code>时。 当对等节点B尝试加入集群时，对等节点A查找传入的主机<code>b.com</code>以获取IP地址列表（例如<code>dig b.com</code>）。如果列表不包含IP <code>10.138.0.2</code>，则出现错误<code>tls: 10.138.0.2 does not match any of DNSNames [&quot;b.com&quot;]</code>.</p><p>从<a href="https://github.com/etcd-io/etcd/pull/8223" target="_blank" rel="noopener">v3.2.2开始，如果IP匹配，服务器将接受连接，而无需检查DNS条目</a>。 例如，如果对等节点证书在“使用者备用名称（SAN）”字段中包含IP地址和DNS名称，并且远程IP地址与这些IP地址之一匹配，则服务器仅接受连接而无需进一步检查DNS名称。 例如，对等节点B的CSR（带有<code>cfssl</code>）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;invalid.domain&quot;,    &quot;10.138.0.2&quot;  ],</code></pre><p>当对等节点B的远程IP地址是<code>10.138.0.2</code>并且<code>invalid.domain</code>是无效的主机时。 当对等节点B尝试加入集群时，对等节点A成功地对节点B进行了身份验证，因为“使用者备用名称（SAN）”字段具有有效的匹配IP地址。 有关更多详细信息，请参见问题<a href="https://github.com/etcd-io/etcd/issues/8206" target="_blank" rel="noopener">＃8206</a>。</p><p>从<a href="https://github.com/etcd-io/etcd/pull/8281" target="_blank" rel="noopener">v3.2.5开始，服务器支持在通配符DNS <code>SAN</code>上进行反向查找</a>。 例如，如果对等节点证书在“使用者备用名称”（SAN）字段中仅包含DNS名称（不包含IP地址），则服务器首先对远程IP地址进行反向查找，以获取映射到该地址的名称列表（例如<code>nslookup IPADDR</code>）。如果这些名称的名称与对等节点证书的DNS名称（通过完全匹配或通配符匹配）匹配，则接受连接。 如果没有匹配项，则服务器将对等节点证书中的每个DNS条目进行正向查找（例如，如果条目为<code>*.example.default.svc</code>，则查找<code>example.default.svc</code>），并且仅在主机的解析地址具有匹配的IP时接受连接 地址和对等节点的远程IP地址。 例如，对等B的CSR（带有<code>cfssl</code>）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;*.example.default.svc&quot;,    &quot;*.example.default.svc.cluster.local&quot;  ],</code></pre><p>当对等节点B的远程IP地址为<code>10.138.0.2</code>时。 当对等节点B尝试加入集群时，对等节点A反向查找IP <code>10.138.0.2</code>以获取主机名列表。 并且，“主题备用名称”（SAN）字段中的主机名必须与对等节点B的证书DNS名称完全匹配或与通配符匹配。 如果反向/正向查找均无效，则返回错误<code>&quot;tls: &quot;10.138.0.2&quot; does not match any of DNSNames [&quot;*.example.default.svc&quot;,&quot;*.example.default.svc.cluster.local&quot;]</code>。有关更多详细信息，请参见问题<a href="https://github.com/etcd-io/etcd/issues/8268" target="_blank" rel="noopener">＃8268</a>。</p><p><a href="https://github.com/etcd-io/etcd/blob/master/CHANGELOG-3.3.md" target="_blank" rel="noopener">v3.3.0</a>添加了<a href="https://github.com/etcd-io/etcd/pull/8616" target="_blank" rel="noopener">etcd –peer-cert-allowed-cn</a>参数，以支持<a href="https://github.com/etcd-io/etcd/issues/8262" target="_blank" rel="noopener">基于CN（通用名称）的对等节点连接的身份验证</a>。 Kubernetes TLS引导涉及为etcd成员和其他系统组件（例如API服务器，kubelet等）生成动态证书。 为每个组件维护不同的CA可提供对etcd集群的更严格的访问控制，但通常很乏味。 指定<code>--peer-cert-allowed-cn</code>标志时，即使具有共享的CA，节点也只能以匹配的通用名称加入。 例如，三节点群集中的每个成员都设置有CSR（使用<code>cfssl</code>），如下所示：</p><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;m1.etcd.local&quot;,    &quot;127.0.0.1&quot;,    &quot;localhost&quot;  ],</code></pre><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;m2.etcd.local&quot;,    &quot;127.0.0.1&quot;,    &quot;localhost&quot;  ],</code></pre><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;m3.etcd.local&quot;,    &quot;127.0.0.1&quot;,    &quot;localhost&quot;  ],</code></pre><p>如果给定<code>--peer-cert-allowed-cn etcd.local</code>，则只有具有相同通用名称的对等方将被认证。 CSR中具有不同CN或<code>--peer-cert-allowed-cn</code>的节点将被拒绝：</p><pre><code>$ etcd --peer-cert-allowed-cn m1.etcd.localI | embed: rejected connection from &quot;127.0.0.1:48044&quot; (error &quot;CommonName authentication failed&quot;, ServerName &quot;m1.etcd.local&quot;)I | embed: rejected connection from &quot;127.0.0.1:55702&quot; (error &quot;remote error: tls: bad certificate&quot;, ServerName &quot;m3.etcd.local&quot;)</code></pre><p>每个进程都应以以下内容开始：</p><pre><code>etcd --peer-cert-allowed-cn etcd.localI | pkg/netutil: resolving m3.etcd.local:32380 to 127.0.0.1:32380I | pkg/netutil: resolving m2.etcd.local:22380 to 127.0.0.1:22380I | pkg/netutil: resolving m1.etcd.local:2380 to 127.0.0.1:2380I | etcdserver: published {Name:m3 ClientURLs:[https://m3.etcd.local:32379]} to cluster 9db03f09b20de32bI | embed: ready to serve client requestsI | etcdserver: published {Name:m1 ClientURLs:[https://m1.etcd.local:2379]} to cluster 9db03f09b20de32bI | embed: ready to serve client requestsI | etcdserver: published {Name:m2 ClientURLs:[https://m2.etcd.local:22379]} to cluster 9db03f09b20de32bI | embed: ready to serve client requestsI | embed: serving client requests on 127.0.0.1:32379I | embed: serving client requests on 127.0.0.1:22379I | embed: serving client requests on 127.0.0.1:2379</code></pre><p><a href="https://github.com/etcd-io/etcd/blob/master/CHANGELOG-3.2.md" target="_blank" rel="noopener">v3.2.19</a>和<a href="https://github.com/etcd-io/etcd/blob/master/CHANGELOG-3.3.md" target="_blank" rel="noopener">v3.3.4</a>修复了<a href="https://github.com/etcd-io/etcd/issues/9541" target="_blank" rel="noopener">当证书SAN字段仅包含IP地址但不包含域名时TLS重新加载的问题</a>。 例如，如下设置了具有CSR（具有<code>cfssl</code>）的成员：</p><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;127.0.0.1&quot;  ],</code></pre><p>在Go中，仅当服务器的<code>（* tls.Config）.Certificates</code>字段不为空或<code>（* tls.ClientHelloInfo）.ServerName</code>不为空且具有有效SNI时，服务器才会调用<code>（* tls.Config）.GetCertificate</code>来重新加载TLS 来自客户。 以前，etcd始终填充<code>（* tls.Config）</code>。在初始客户端TLS握手上的证书为非空。 因此，总是希望客户端提供匹配的SNI，以便通过TLS验证并触发<code>（* tls.Config）.GetCertificate</code>以重新加载TLS数据。</p><p>但是，其SAN字段<a href="https://github.com/etcd-io/etcd/issues/9541" target="_blank" rel="noopener">仅包括IP地址不包含任何域名的证书</a>将请求<code>* tls.ClientHelloInfo</code>带有空的<code>ServerName</code>字段，从而无法在初始TLS握手时触发TLS重新加载；当需要在线更换过期证书时，这将成为一个问题。</p><p>现在,<code>（* tls.Config）.Certificates</code>在初始TLS客户端握手时创建为空，首先触发<code>（* tls.Config）.GetCertificate</code>，然后在每个新的TLS连接上填充其余证书，即使客户端SNI为 为空（例如，证书仅包括IP）。</p><h2 id="主机白名单的注意事项"><a href="#主机白名单的注意事项" class="headerlink" title="主机白名单的注意事项"></a>主机白名单的注意事项</h2><hr><p><code>etcd --host-whitelist</code>参数指定HTTP客户端请求中可接受的主机名。 客户端源策略可以防止对不安全的etcd服务器的“<a href="https://en.wikipedia.org/wiki/DNS_rebinding" target="_blank" rel="noopener">DNS重新绑定</a>”攻击。 也就是说，任何网站都可以简单地创建一个授权的DNS名称，并将DNS定向到“<code>localhost</code>”（或任何其他地址）。 然后，侦听“<code>localhost</code>”上的etcd服务器的所有HTTP端点都可以访问，因此容易受到DNS重新绑定攻击。 有关更多详细信息，请参见<a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=1447#c2" target="_blank" rel="noopener">CVE-2018-5702</a>。</p><p>客户原始策略的工作方式如下：</p><ol><li>如果客户端通过HTTPS连接是安全的，则允许使用任何主机名。</li><li>如果客户端连接不安全且“<code>HostWhitelist</code>”不为空，则仅允许其Host字段列在白名单中的HTTP请求。</li></ol><p>请注意，无论是否启用身份验证，都会实施客户端来源策略，以进行更严格的控制。</p><p>默认情况下，<code>etcd --host-whitelist</code>和<code>embed.Config.HostWhitelist</code>设置为空以允许所有主机名。请注意，在指定主机名时，不会自动添加回送地址。 要允许环回接口，请手动将其添加到白名单（例如“ <code>localhost</code>”，“<code>127.0.0.1</code>”等）。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><hr><p>使用TLS客户端身份验证时，我看到SSLv3警报握手失败？<br><code>golang</code>的<code>crypto/tls</code>软件包在使用之前检查证书公钥的密钥用法。要使用证书公共密钥进行客户端身份验证，我们需要在创建证书公共密钥时将<code>clientAuth</code>添加到“<code>Extended Key Usage</code>”中。</p><p>这是操作方法：</p><p>将以下部分添加到openssl.cnf中：</p><pre><code>[ ssl_client ]...  extendedKeyUsage = clientAuth...</code></pre><p>创建证书时，请确保在<code>-extensions</code>参数中引用它：</p><pre><code>$ openssl ca -config openssl.cnf -policy policy_anything -extensions ssl_client -out certs/machine.crt -infiles machine.csr</code></pre><p>通过对等证书身份验证，我收到“证书对127.0.0.1有效，而不对$我的Ip有效”</p><p>确保使用主题名称（成员的公共IP地址）对证书进行签名。 例如，<code>etcd-ca</code>工具为其<code>new-cert</code>命令提供了<code>--ip=</code>选项。</p><p>需要在其使用者名称中为成员的FQDN签署证书，使用使用者备用名称（简称IP SAN）添加IP地址。 <code>etcd-ca</code>工具为其<code>new-cert</code>命令提供了<code>--domain=</code>选项，<code>openssl</code>也可以做到<a href="http://wiki.cacert.org/FAQ/subjectAltName" target="_blank" rel="noopener">这</a>一点。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>系统限制</title>
    <link href="undefined2019/11/25/blog/etcd/%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/"/>
    <url>2019/11/25/blog/etcd/%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/limit.md" target="_blank" rel="noopener">System limits</a></p><h2 id="请求大小限制"><a href="#请求大小限制" class="headerlink" title="请求大小限制"></a>请求大小限制</h2><hr><p>etcd被设计用来处理小键值对典型的如元数据。较大的请求数据也起作用，但可能会增加其他请求的延迟。默认情况下，任意的请求最大的空间为1.5MiB，这个限制参数可以通过<code>--max-request-bytes</code>参数对etcd服务器进行配置。</p><h2 id="存储大小限制"><a href="#存储大小限制" class="headerlink" title="存储大小限制"></a>存储大小限制</h2><hr><p>默认的存储大小限制为2GB,可以通过参数<code>--quota-backend-bytes</code>进行配置。正常环境下8GB是etcd支持的最大存储大小，如果配置的值超过它，etcd将在启动时发出警告。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>词汇表</title>
    <link href="undefined2019/11/24/blog/etcd/%E8%AF%8D%E6%B1%87%E8%A1%A8/"/>
    <url>2019/11/24/blog/etcd/%E8%AF%8D%E6%B1%87%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/glossary.md" target="_blank" rel="noopener">词汇表</a><br>本文档定义了etcd文档，命令行和源代码中使用的各种术语。</p><h3 id="Alarm"><a href="#Alarm" class="headerlink" title="Alarm"></a>Alarm</h3><hr><p>每当集群需要操作员干预以保持可靠性时，etcd服务器都会发出警报。</p><h3 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h3><hr><p>身份验证管理etcd资源的用户访问权限。</p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><hr><p>客户端连接到etcd集群以发出服务请求，例如获取键值对，写入数据或监视更新。</p><h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><hr><p>集群由几个成员组成。</p><p>每个成员中的节点均遵循Raft共识协议来复制日志。 集群从成员那里接收提议，将它们提交并应用于本地存储。</p><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><hr><p>在给定修订之前，压缩会丢弃所有etcd事件历史记录和取代的密钥。 它用于回收etcd后端数据库中的存储空间。</p><h3 id="Election"><a href="#Election" class="headerlink" title="Election"></a>Election</h3><hr><p>etcd集群在其成员之间举行选举，以选择一名领导人作为Raft共识协议的一部分。</p><h3 id="Endpoint"><a href="#Endpoint" class="headerlink" title="Endpoint"></a>Endpoint</h3><hr><p>指向etcd服务或资源的URL。</p><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><hr><p>用户定义的标识符，用于在etcd中存储和检索用户定义的值。</p><h3 id="Key-range"><a href="#Key-range" class="headerlink" title="Key range"></a>Key range</h3><hr><p>包含单个键，所有x的词法间隔（例如a &lt;x &lt;= b）或大于给定键的所有键的一组键。</p><h3 id="Keyspace"><a href="#Keyspace" class="headerlink" title="Keyspace"></a>Keyspace</h3><hr><p>etcd集群中所有键的集合。</p><h3 id="Lease"><a href="#Lease" class="headerlink" title="Lease"></a>Lease</h3><hr><p>短期可再生合同，在合同到期时会删除与其相关的密钥。</p><h3 id="Member"><a href="#Member" class="headerlink" title="Member"></a>Member</h3><hr><p>参与为etcd集群提供服务的逻辑etcd服务器。</p><h3 id="Modification-Revision"><a href="#Modification-Revision" class="headerlink" title="Modification Revision"></a>Modification Revision</h3><hr><p>保留对给定密钥的最后一次写入的第一个修订版。</p><h3 id="Peer"><a href="#Peer" class="headerlink" title="Peer"></a>Peer</h3><hr><p>同一集群的另一个对等成员。</p><h3 id="Proposal"><a href="#Proposal" class="headerlink" title="Proposal"></a>Proposal</h3><hr><p>提案是需要通过raft协议的请求（例如，写入请求，配置更改请求）。</p><h3 id="Quorum"><a href="#Quorum" class="headerlink" title="Quorum"></a>Quorum</h3><hr><p>达成共识才能修改集群状态所需的活动成员数。 etcd需要拥有多数才能达到法定人数。</p><h3 id="Revision"><a href="#Revision" class="headerlink" title="Revision"></a>Revision</h3><hr><p>每次修改键空间时都会增加的64位群集范围计数器。</p><h3 id="Role"><a href="#Role" class="headerlink" title="Role"></a>Role</h3><hr><p>一组密钥范围内的许可单位，可以将其授予一组用户以进行访问控制。</p><h3 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h3><hr><p>etcd群集状态的时间点备份。</p><h3 id="Store"><a href="#Store" class="headerlink" title="Store"></a>Store</h3><hr><p>支持集群键空间的物理存储。</p><h3 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h3><hr><p>原子执行的一组操作。 事务中所有已修改的键共享相同的修改版本。</p><h3 id="Key-Version"><a href="#Key-Version" class="headerlink" title="Key Version"></a>Key Version</h3><hr><p>自创建以来，对密钥的写入次数（从1开始）。不存在或已删除的密钥的版本为0。</p><h3 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a>Watcher</h3><hr><p>客户端打开观察者以观察给定键范围上的更新。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在容器中运行etcd集群</title>
    <link href="undefined2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/"/>
    <url>2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/container.md#docker" target="_blank" rel="noopener">Docker container</a><br>以下指南显示了如何使用<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">静态引导过程</a>在rkt和Docker上运行etcd。</p><h2 id="rkt"><a href="#rkt" class="headerlink" title="rkt"></a><strong>rkt</strong></h2><hr><p><strong>运行单节点的etcd</strong><br>以下rkt run命令将在端口2379上公开etcd客户端API，并在端口2380上公开对等API。</p><p>配置etcd时使用主机IP地址。</p><pre><code>export NODE1=192.168.1.21</code></pre><p>信任CoreOS <a href="https://coreos.com/security/app-signing-key/" target="_blank" rel="noopener">App签名密钥</a>。</p><pre><code>sudo rkt trust --prefix quay.io/coreos/etcd# gpg key fingerprint is: 18AD 5014 C99E F7E3 BA5F  6CE9 50BD D3E0 FC8A 365E</code></pre><p>运行etcd v3.2版本或指定其他发行版本。</p><pre><code>sudo rkt run --net=default:IP=${NODE1} quay.io/coreos/etcd:v3.2 -- -name=node1 -advertise-client-urls=http://${NODE1}:2379 -initial-advertise-peer-urls=http://${NODE1}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE1}:2380 -initial-cluster=node1=http://${NODE1}:2380</code></pre><p>列出集群成员：</p><pre><code>etcdctl --endpoints=http://192.168.1.21:2379 member list</code></pre><p><strong>运行3个节点的etcd</strong><br>使用<code>-initial-cluster</code>参数在本地使用rkt设置3节点集群。</p><pre><code>export NODE1=172.16.28.21export NODE2=172.16.28.22export NODE3=172.16.28.23</code></pre><pre><code># node 1sudo rkt run --net=default:IP=${NODE1} quay.io/coreos/etcd:v3.2 -- -name=node1 -advertise-client-urls=http://${NODE1}:2379 -initial-advertise-peer-urls=http://${NODE1}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE1}:2380 -initial-cluster=node1=http://${NODE1}:2380,node2=http://${NODE2}:2380,node3=http://${NODE3}:2380# node 2sudo rkt run --net=default:IP=${NODE2} quay.io/coreos/etcd:v3.2 -- -name=node2 -advertise-client-urls=http://${NODE2}:2379 -initial-advertise-peer-urls=http://${NODE2}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE2}:2380 -initial-cluster=node1=http://${NODE1}:2380,node2=http://${NODE2}:2380,node3=http://${NODE3}:2380# node 3sudo rkt run --net=default:IP=${NODE3} quay.io/coreos/etcd:v3.2 -- -name=node3 -advertise-client-urls=http://${NODE3}:2379 -initial-advertise-peer-urls=http://${NODE3}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE3}:2380 -initial-cluster=node1=http://${NODE1}:2380,node2=http://${NODE2}:2380,node3=http://${NODE3}:2380</code></pre><p>验证集群是否健康并且可以访问。</p><pre><code>ETCDCTL_API=3 etcdctl --endpoints=http://172.16.28.21:2379,http://172.16.28.22:2379,http://172.16.28.23:2379 endpoint health</code></pre><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>通过本地解析器已知的DNS名称引用对等方的生产群集必须安装<a href="https://coreos.com/tectonic/docs/latest/tutorials/sandbox/index.html#customizing-rkt-options" target="_blank" rel="noopener">主机的DNS配置</a>。</p><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a><strong>Docker</strong></h2><p>为了向Docker主机外部的客户端公开etcd API，请使用容器的主机IP地址。 请参阅<a href="https://docs.docker.com/engine/reference/commandline/inspect/" target="_blank" rel="noopener">docker inspect</a>了解有关如何获取IP地址的更多详细信息。 或者，为<code>docker run</code>命令指定<code>--net = host</code>标志，以跳过将容器放置在单独的网络堆栈内的操作。<br><strong>运行单节点的etcd</strong><br>适用主机Ip地址配置etcd：</p><pre><code>export NODE1=192.168.1.21</code></pre><p>配置Docker卷存储etcd数据:</p><pre><code>docker volume create --name etcd-dataexport DATA_DIR=&quot;etcd-data&quot;</code></pre><p>运行最新版本的etcd：</p><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=gcr.io/etcd-development/etcddocker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:latest \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name node1 \  --initial-advertise-peer-urls http://${NODE1}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${NODE1}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster node1=http://${NODE1}:2380</code></pre><p>列出集群成员：</p><pre><code>etcdctl --endpoints=http://${NODE1}:2379 member list</code></pre><p><strong>运行3个节点的etcd</strong></p><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=gcr.io/etcd-development/etcd# For each machineETCD_VERSION=latestTOKEN=my-etcd-tokenCLUSTER_STATE=newNAME_1=etcd-node-0NAME_2=etcd-node-1NAME_3=etcd-node-2HOST_1=10.20.30.1HOST_2=10.20.30.2HOST_3=10.20.30.3CLUSTER=${NAME_1}=http://${HOST_1}:2380,${NAME_2}=http://${HOST_2}:2380,${NAME_3}=http://${HOST_3}:2380DATA_DIR=/var/lib/etcd# For node 1THIS_NAME=${NAME_1}THIS_IP=${HOST_1}docker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:${ETCD_VERSION} \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name ${THIS_NAME} \  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster ${CLUSTER} \  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}# For node 2THIS_NAME=${NAME_2}THIS_IP=${HOST_2}docker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:${ETCD_VERSION} \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name ${THIS_NAME} \  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster ${CLUSTER} \  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}# For node 3THIS_NAME=${NAME_3}THIS_IP=${HOST_3}docker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:${ETCD_VERSION} \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name ${THIS_NAME} \  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster ${CLUSTER} \  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}</code></pre><p>适用版本v3的<code>etcdctl</code>：</p><pre><code>docker exec etcd /bin/sh -c &quot;export ETCDCTL_API=3 &amp;&amp; /usr/local/bin/etcdctl put foo bar&quot;</code></pre><h2 id="Bare-Metal"><a href="#Bare-Metal" class="headerlink" title="Bare Metal"></a>Bare Metal</h2><hr><p>要在裸机上配置3节点etcd集群，<a href="https://github.com/poseidon/matchbox/tree/master/examples" target="_blank" rel="noopener">裸机存储库</a>中的示例可能会有用。</p><h4 id="挂载一个证书卷："><a href="#挂载一个证书卷：" class="headerlink" title="挂载一个证书卷："></a>挂载一个证书卷：</h4><p>etcd发布容器不包含默认的根证书。 要将HTTPS与受根权限信任的证书一起使用（例如，用于发现），请将证书目录安装到etcd容器中：</p><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=docker://gcr.io/etcd-development/etcdrkt run \  --insecure-options=image \  --volume etcd-ssl-certs-bundle,kind=host,source=/etc/ssl/certs/ca-certificates.crt \  --mount volume=etcd-ssl-certs-bundle,target=/etc/ssl/certs/ca-certificates.crt \  ${REGISTRY}:latest -- --name my-name \  --initial-advertise-peer-urls http://localhost:2380 --listen-peer-urls http://localhost:2380 \  --advertise-client-urls http://localhost:2379 --listen-client-urls http://localhost:2379 \  --discovery https://discovery.etcd.io/c11fbcdc16972e45253491a24fcf45e1</code></pre><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=gcr.io/etcd-development/etcddocker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=/etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \  ${REGISTRY}:latest \  /usr/local/bin/etcd --name my-name \  --initial-advertise-peer-urls http://localhost:2380 --listen-peer-urls http://localhost:2380 \  --advertise-client-urls http://localhost:2379 --listen-client-urls http://localhost:2379 \  --discovery https://discovery.etcd.io/86a9ff6c8cb8b4c4544c1a2f88f8b801</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>etcd网关</title>
    <link href="undefined2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/"/>
    <url>2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/gateway.md" target="_blank" rel="noopener">L4 gateway</a></p><h2 id="什么是etcd网关"><a href="#什么是etcd网关" class="headerlink" title="什么是etcd网关"></a>什么是etcd网关</h2><hr><p>etcd网关是一个简单的TCP代理，可将网络数据转发到etcd集群。网关是无状态且透明的； 它既不会检查客户端请求，也不会干扰群集响应。<br>网关支持多个etcd服务器端点，并采用简单的循环策略。 它仅路由到可用端点，并向其客户端隐藏故障。 将来可能会支持其他重试策略，例如加权轮询。</p><h2 id="什么时候使用etcd网关"><a href="#什么时候使用etcd网关" class="headerlink" title="什么时候使用etcd网关"></a>什么时候使用etcd网关</h2><hr><p>每个访问etcd的应用程序必须首先具有etcd集群客户端端点的地址。 如果同一服务器上的多个应用程序访问相同的etcd集群，则每个应用程序仍需要知道etcd集群的广播的客户端端点。 如果将etcd集群重新配置为具有不同的端点，则每个应用程序可能还需要更新其端点列表。 这种大规模的重新配置既乏味又容易出错。<br>etcd网关通过充当稳定的本地端点来解决此问题。 典型的etcd网关配置是，每台计算机运行一台网关，侦听本地地址，并且每个etcd应用程序都连接到其本地网关。 结果只是网关需要更新其端点，而不是更新每个应用程序。<br>总之，为了自动传播集群端点更改，etcd网关在为访问同一etcd集群的多个应用程序服务的每台机器上运行。</p><h2 id="什么时候不该使用etcd网关"><a href="#什么时候不该使用etcd网关" class="headerlink" title="什么时候不该使用etcd网关"></a>什么时候不该使用etcd网关</h2><ul><li>提升性能<br>该网关不是为提高etcd群集性能而设计的。 它不提供缓存，监视合并或批处理。 etcd团队正在开发一种缓存代理，旨在提高群集的可伸缩性。</li><li>在集群管理系统运行时<br>像Kubernetes这样的高级集群管理系统本身就支持服务发现。 应用程序可以使用系统管理的DNS名称或虚拟IP地址访问etcd集群。 例如，kube-proxy等效于etcd网关。<h2 id="启动etcd网关"><a href="#启动etcd网关" class="headerlink" title="启动etcd网关"></a>启动etcd网关</h2></li></ul><hr><p>考虑一个具有以下静态端点的etcd集群：</p><table><thead><tr><th>名字</th><th>地址</th><th>主机名</th></tr></thead><tbody><tr><td>infra0</td><td>10.0.1.10</td><td>infra0.example.com</td></tr><tr><td>infra1</td><td>10.0.1.11</td><td>infra1.example.com</td></tr><tr><td>infra2</td><td>10.0.1.12</td><td>infra2.example.com</td></tr></tbody></table><p>通过以下命令使用静态端点启动etcd网关:</p><pre><code>$ etcd gateway start --endpoints=infra0.example.com,infra1.example.com,infra2.example.com2016-08-16 11:21:18.867350 I | tcpproxy: ready to proxy client requests to [...]</code></pre><p>或者，如果使用DNS进行服务发现，请考虑DNS SRV条目：</p><pre><code>$ dig +noall +answer SRV _etcd-client._tcp.example.com_etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra0.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra1.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra2.example.com.</code></pre><pre><code>$ dig +noall +answer infra0.example.com infra1.example.com infra2.example.cominfra0.example.com.  300  IN  A  10.0.1.10infra1.example.com.  300  IN  A  10.0.1.11infra2.example.com.  300  IN  A  10.0.1.12</code></pre><p>启动etcd网关，以使用以下命令从DNS SRV条目中获取端点：</p><pre><code>$ etcd gateway start --discovery-srv=example.com2016-08-16 11:21:18.867350 I | tcpproxy: ready to proxy client requests to [...]</code></pre><h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><hr><h4 id="etcd-集群"><a href="#etcd-集群" class="headerlink" title="etcd 集群"></a><strong>etcd 集群</strong></h4><p><strong>–endpoints</strong></p><ul><li>以逗号分隔的用于转发客户端连接的etcd服务器目标列表。</li><li>默认：<code>127.0.0.1:2379</code></li><li>无效的例子:<code>https://127.0.0.1:2379</code>(网关不适用于TLS 终端)</li></ul><p><strong>–discovery-srv</strong></p><ul><li>用于通过SRV记录引导群集终结点的DNS域。</li><li>默认值：未设置</li></ul><h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a><strong>网络</strong></h4><p><strong>–listen-addr</strong></p><ul><li>接收客户端请求绑定的接口和端口</li><li>默认:<code>127.0.0.1:23790</code></li></ul><p><strong>–retry-delay</strong></p><ul><li>重试连接到失败的端点之前的延迟时间。</li><li>默认值：1m0s</li><li>无效例子：”123”(期望之外的时间格式)</li></ul><h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a><strong>安全</strong></h4><p><strong>–insecure-discovery</strong></p><ul><li>接受不安全或容易受到中间人攻击的SRV记录。</li><li>默认值：false</li></ul><p><strong>–trusted-ca-file</strong></p><ul><li>etcd集群的客户端TLS CA文件的路径。 用于认证端点。</li><li>默认值：未设置</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gRPC代理</title>
    <link href="undefined2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/"/>
    <url>2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/grpc_proxy.md" target="_blank" rel="noopener">gRPC proxy</a><br>gRPC代理是在gRPC层（L7）运行的无状态etcd反向代理。代理旨在减少核心etcd群集上的总处理负载。对于水平可伸缩性，它合并了监视和租约API请求。 为了保护集群免受滥用客户端的侵害，它会缓存关键范围请求。<br>gRPC代理支持多个etcd服务器端点。 代理启动时，它会随机选择一个etcd服务器端点来使用.该端点将处理所有请求，直到代理检测到端点故障为止。 如果gRPC代理检测到端点故障，它将切换到其他端点（如果有）以向其客户端隐藏故障。 将来可能会支持其他重试策略，例如加权轮询。</p><h2 id="可扩展的监视-API"><a href="#可扩展的监视-API" class="headerlink" title="可扩展的监视 API"></a>可扩展的监视 API</h2><hr><p>gRPC代理将同一键或范围上的多个客户端监视程序（c-watcher）合并为连接到etcd服务器的单个监视程序（s-watcher）。 代理将所有事件从S-watcher广播到其c-watcher。<br>假设N个客户端监视相同的密钥，则一个gRPC代理可以将etcd服务器上的监视负载从N减少到1。用户可以部署多个gRPC代理来进一步分配服务器负载。<br>在以下示例中，三个客户端监视键A。gRPC代理将三个监视程序合并，从而创建一个附加到etcd服务器的监视程序。</p><pre><code>            +-------------+            | etcd 服务器 |            +------+------+                   ^ 监视 key A (s-watcher)                   |           +-------+-----+           | gRPC 代理  | &lt;-------+           |             |         |           ++-----+------+         |监视 key A (c-watcher)监视 key A ^     ^ 监视 key A    |(c-watcher) |     | (c-watcher)    |    +-------+-+  ++--------+  +----+----+    |  客户端 |  |  客户端 |  |  客户端 |    |         |  |         |  |         |    +---------+  +---------+  +---------+</code></pre><h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><p>为了有效地将多个客户端监视程序合并为一个监视程序，gRPC代理在可能的情况下将新的c-watcher合并为现有的s-watcher。 由于网络延迟或缓冲的未传递事件，此合并的s-watcher可能与etcd服务器不同步。 如果未指定监视版本，则gRPC代理将不能保证c-watcher从最近的存储修订版本开始监视。 例如，如果客户端从具有修订版1000的etcd服务器监视，则该监视程序将从修订版1000开始。如果客户端从gRPC代理监视，则可以从修订版990开始监视。<br>类似的限制也适用于取消。 取消观察者后，etcd服务器的修订版可能大于取消响应修订版。<br>对于大多数用例，这两个限制不应引起问题。 将来，可能会有其他选项强制观察者绕过gRPC代理以获得更准确的修订响应。</p><h2 id="可扩展的租约-API"><a href="#可扩展的租约-API" class="headerlink" title="可扩展的租约 API"></a>可扩展的租约 API</h2><hr><p>为了保持其租约有效，客户端必须至少向一个etcd服务器建立一个gRPC流，以发送定期的心跳信号。 如果etcd工作负载涉及大量租约活动分布在许多客户端上，则这些流可能会导致CPU使用率过高。 为了减少核心群集上的流总数，该代理支持租约流合并。<br>假设N个客户端正在更新租约，则单个gRPC代理将etcd服务器上的流负载从N减少到1。部署中可能具有其他gRPC代理，以进一步在多个代理之间分配流。<br>在以下示例中，三个客户端更新了三个独立的租约（L1，L2和L3）。 gRPC代理将三个客户端租约流（c-stream）合并为连接到etcd服务器的单个租约保持活动流（s-stream）。 代理将客户端租用心跳从c流转发到s流，然后将响应返回到相应的c流。</p><pre><code>          +-------------+          | etcd 服务器 |          +------+------+                 ^                 | 心跳 L1, L2, L3                 | (s-stream)                 v         +-------+-----+         | gRPC 代理  +&lt;-----------+         +---+------+--+            | 心跳 L3             ^      ^               | (c-stream)心跳 L1 |      | 心跳 L2  |(c-stream)   v      v (c-stream)    v      +------+-+  +-+------+  +-----+--+      | 客户端 |  | 客户端 |  | 客户端 |      +--------+  +--------+  +--------+</code></pre><h3 id="客户保护滥用"><a href="#客户保护滥用" class="headerlink" title="客户保护滥用"></a>客户保护滥用</h3><p>gRPC代理在不违反一致性要求时会缓存请求的响应。 这可以保护etcd服务器免遭严密for循环中滥用客户端的侵害。</p><h2 id="启动etcd-gRPC代理"><a href="#启动etcd-gRPC代理" class="headerlink" title="启动etcd gRPC代理"></a>启动etcd gRPC代理</h2><hr><p>考虑一个etcd集群包括以下几个静态端点：<br>|名字|地址|主机名|<br>|—|—|—|<br>|infra0|10.0.1.10|infra0.example.com|<br>|infra1|10.0.1.11|infra1.example.com|<br>|infra2|10.0.1.12|infra2.example.com|<br>通过以下命令使用静态节点启动gRPC代理：</p><pre><code>$ etcd grpc-proxy start --endpoints=infra0.example.com,infra1.example.com,infra2.example.com --listen-addr=127.0.0.1:2379</code></pre><p>etcd gRPC启动并监听端口2379.它将客户端请求转发到上面提供的三个端点之一。<br>通过代理发送请求：</p><pre><code>$ ETCDCTL_API=3 etcdctl --endpoints=127.0.0.1:2379 put foo barOK$ ETCDCTL_API=3 etcdctl --endpoints=127.0.0.1:2379 get foofoobar</code></pre><h2 id="客户端端点同步和名称解析"><a href="#客户端端点同步和名称解析" class="headerlink" title="客户端端点同步和名称解析"></a>客户端端点同步和名称解析</h2><hr><p>代理支持通过写入用户定义的端点来注册其端点以进行发现。 这有两个目的。 首先，它允许客户端将其端点与一组代理端点同步，以实现高可用性。 其次，它是etcd <a href="https://newonexd.github.io/2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/">gRPC命名</a>的端点提供程序。<br>通过提供用户定义的前缀来注册代理：</p><pre><code>$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23790 \  --advertise-client-url=127.0.0.1:23790 \  --resolver-prefix=&quot;___grpc_proxy_endpoint&quot; \  --resolver-ttl=60$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23791 \  --advertise-client-url=127.0.0.1:23791 \  --resolver-prefix=&quot;___grpc_proxy_endpoint&quot; \  --resolver-ttl=60</code></pre><p>代理将会列出成员列表中的所有成员：</p><pre><code>ETCDCTL_API=3 etcdctl --endpoints=http://localhost:23790 member list --write-out table+----+---------+--------------------------------+------------+-----------------+| ID | STATUS  |              NAME              | PEER ADDRS |  CLIENT ADDRS   |+----+---------+--------------------------------+------------+-----------------+|  0 | started | Gyu-Hos-MBP.sfo.coreos.systems |            | 127.0.0.1:23791 ||  0 | started | Gyu-Hos-MBP.sfo.coreos.systems |            | 127.0.0.1:23790 |+----+---------+--------------------------------+------------+-----------------+</code></pre><p>这使客户端可以通过Sync自动发现代理端点：</p><pre><code>cli, err := clientv3.New(clientv3.Config{    Endpoints: []string{&quot;http://localhost:23790&quot;},})if err != nil {    log.Fatal(err)}defer cli.Close()// fetch registered grpc-proxy endpointsif err := cli.Sync(context.Background()); err != nil {    log.Fatal(err)}</code></pre><p>注意，如果配置的代理没有解析程序前缀，</p><pre><code>$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23792 \  --advertise-client-url=127.0.0.1:23792</code></pre><p>grpc-proxy的成员列表API返回其自己的<code>advertise-client-url</code>：</p><pre><code>ETCDCTL_API=3 etcdctl --endpoints=http://localhost:23792 member list --write-out table+----+---------+--------------------------------+------------+-----------------+| ID | STATUS  |              NAME              | PEER ADDRS |  CLIENT ADDRS   |+----+---------+--------------------------------+------------+-----------------+|  0 | started | Gyu-Hos-MBP.sfo.coreos.systems |            | 127.0.0.1:23792 |+----+---------+--------------------------------+------------+-----------------+</code></pre><h2 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h2><hr><p>假设一个应用程序期望对整个键空间有完全控制，但是etcd集群与其他应用程序共享。 为了使所有应用程序都不会相互干扰地运行，代理可以对etcd键空间进行分区，以便客户端可以访问完整的键空间。 当给代理提供标志<code>--namespace</code>时，所有进入代理的客户端请求都将转换为在键上具有用户定义的前缀。 对etcd集群的访问将在前缀下，而来自代理的响应将删除该前缀；对于客户端，显然根本没有前缀。<br>要为代理命名空间，请通过<code>--namespace</code>启动：</p><pre><code>$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23790 \  --namespace=my-prefix/</code></pre><p>现在，对代理的访问在etcd集群上透明地加上前缀：</p><pre><code>$ ETCDCTL_API=3 etcdctl --endpoints=localhost:23790 put my-key abc# OK$ ETCDCTL_API=3 etcdctl --endpoints=localhost:23790 get my-key# my-key# abc$ ETCDCTL_API=3 etcdctl --endpoints=localhost:2379 get my-prefix/my-key# my-prefix/my-key# abc</code></pre><h2 id="TLS终端"><a href="#TLS终端" class="headerlink" title="TLS终端"></a>TLS终端</h2><hr><p>使用来自安全etcd群集的TLS的gRPC代理终端为未加密的本地端点提供服务.<br>使用客户端https启动单个成员etcd集群尝试：</p><pre><code>$ etcd --listen-client-urls https://localhost:2379 --advertise-client-urls https://localhost:2379 --cert-file=peer.crt --key-file=peer.key --trusted-ca-file=ca.crt --client-cert-auth</code></pre><p>确认客户端端口正在提供https：</p><pre><code># fails$ ETCDCTL_API=3 etcdctl --endpoints=http://localhost:2379 endpoint status# works$ ETCDCTL_API=3 etcdctl --endpoints=https://localhost:2379 --cert=client.crt --key=client.key --cacert=ca.crt endpoint status</code></pre><p>接下来，通过使用客户端证书连接到etcd端点<code>https://localhost2379</code>在<code>localhost:12379</code>上启动gRPC代理：</p><pre><code>$ etcd grpc-proxy start --endpoints=https://localhost:2379 --listen-addr localhost:12379 --cert client.crt --key client.key --cacert=ca.crt --insecure-skip-tls-verify &amp;</code></pre><p>最后，通过在http上将密钥放入代理来测试TLS终端：</p><pre><code>$ ETCDCTL_API=3 etcdctl --endpoints=http://localhost:12379 put abc def# OK</code></pre><h2 id="指标和健康"><a href="#指标和健康" class="headerlink" title="指标和健康"></a>指标和健康</h2><hr><p>gRPC代理为<code>--endpoints</code>定义的etcd成员公开了<code>/health</code>和Prometheus<code>/metrics</code>端点。 另一种方法是定义一个附加URL，该URL将使用<code>--metrics-addr</code>参数来响应<code>/metrics</code>和<code>/health</code>端点。</p><pre><code>$ etcd grpc-proxy start \  --endpoints https://localhost:2379 \  --metrics-addr https://0.0.0.0:4443 \  --listen-addr 127.0.0.1:23790 \  --key client.key \  --key-file proxy-server.key \  --cert client.crt \  --cert-file proxy-server.crt \  --cacert ca.pem \  --trusted-ca-file proxy-ca.pem</code></pre><h3 id="已知问题"><a href="#已知问题" class="headerlink" title="已知问题"></a>已知问题</h3><p>代理的主接口同时服务于HTTP2和HTTP/1.1。如果如上例所示，使用TLS设置了代理，则在监听接口上使用诸如cURL之类的客户端时，将要求在返回<code>/metrics</code>或<code>/health</code>的请求上将协议显式设置为HTTP/1.1。通过使用<code>--metrics-addr</code>参数，辅助接口将没有此要求。</p><pre><code> $ curl --cacert proxy-ca.pem --key proxy-client.key --cert proxy-client.crt https://127.0.0.1:23790/metrics --http1.1</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实验特性和APIs</title>
    <link href="undefined2019/11/24/blog/etcd/%E5%AE%9E%E9%AA%8C%E7%89%B9%E6%80%A7%E5%92%8CAPIs/"/>
    <url>2019/11/24/blog/etcd/%E5%AE%9E%E9%AA%8C%E7%89%B9%E6%80%A7%E5%92%8CAPIs/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/experimental_apis.md" target="_blank" rel="noopener">Experimental features and APIs</a><br>大多数情况下，etcd项目是稳定的，但我们仍在快速发展！ 我们相信快速发布理念。 我们希望获得有关仍在开发和稳定中的功能的早期反馈。 因此，存在并且将会有更多的实验性功能和API。 我们计划根据社区的早期反馈来改进这些功能，如果兴趣不足，请在接下来的几个版本中放弃这些功能。 请不要在生产环境中依赖任何实验性功能或API。</p><h2 id="当前实验API-特性是："><a href="#当前实验API-特性是：" class="headerlink" title="当前实验API/特性是："></a><strong>当前实验API/特性是：</strong></h2><hr><ul><li><a href="https://godoc.org/github.com/etcd-io/etcd/clientv3/ordering" target="_blank" rel="noopener">键值对排序</a>包装器：<br>当etcd客户端切换端点时，如果新端点落后于集群的其余部分，则对可序列化读取的响应可能推迟。排序包装器从响应标头缓存当前集群修订版。 如果响应修订版本小于缓存修订版本，则客户端选择另一个端点并重新发出读取。在grpcproxy中启动<code>--experimental-serializable-ordering</code>.</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>配置参数</title>
    <link href="undefined2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/"/>
    <url>2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/configuration.md" target="_blank" rel="noopener">Configuration flags</a><br>etcd通过配置文件，多命令行参数和环境变量进行配置，</p><p>可重用的配置文件是YAML文件，其名称和值由一个或多个下面描述的命令行标志组成。为了使用此文件，请将文件路径指定为<code>--config-file</code>标志或<code>ETCD_CONFIG_FILE</code>环境变量的值。如果需要的话<a href="https://github.com/etcd-io/etcd/blob/master/etcd.conf.yml.sample" target="_blank" rel="noopener">配置文件示例</a>可以作为入口点创建新的配置文件。</p><p>在命令行上设置的选项优先于环境中的选项。 如果提供了配置文件，则其他命令行标志和环境变量将被忽略。例如，<code>etcd --config-file etcd.conf.yml.sample --data-dir /tmp</code>将会忽略<code>--data-dir</code>参数。</p><p>参数<code>--my-flag</code>的环境变量的格式为<code>ETCD_MY_FLAG</code>.它适用于所有参数。</p><p>客户端请求<a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt" target="_blank" rel="noopener">官方的etcd端口</a>为2379,2380是节点通信端口。可以将etcd端口设置为接受TLS流量，非TLS流量，或同时接受TLS和非TLS流量。</p><p>要在Linux启动时使用自定义设置自动启动etcd，强烈建议使用<a href="freedesktop.org/wiki/Software/systemd/">systemd</a>单元。</p><h2 id="成员标记"><a href="#成员标记" class="headerlink" title="成员标记"></a>成员标记</h2><hr><p><strong>–name</strong></p><ul><li>人类可读的该成员的名字</li><li>默认值：”default”</li><li>环境变量：ETCD_DATA_DIR</li><li>该值被该节点吃的<code>--initial-cluster</code>参数引用(例如 <code>default=http://localhost:2380</code>).如果使用<a href="">静态引导程序</a>，则需要与标志中使用的键匹配。当使用发现服务时，每一个成员需要有唯一的名字。<code>Hostname</code>或者<code>machine-id</code>是好的选择。</li></ul><p><strong>–data-dir</strong></p><ul><li>数据目录的路径</li><li>默认值：”${name}.etcd”</li><li>环境变量：ETCD_DATA_DIR</li></ul><p><strong>–wal-dir</strong></p><ul><li>专用的wal目录的路径。如果这个参数被设置，etcd将会写WAL文件到walDir而不是dataDir，允许使用专用磁盘，并有助于避免日志记录和其他IO操作之间的io竞争。</li><li>默认值：””</li><li>环境变量：ETCD_WAL_DIR</li></ul><p><strong>–snapshot-count</strong></p><ul><li>触发一个快照到磁盘的已提交交易的数量</li><li>默认值：”100000”</li><li>环境变量：ETCD_SNAPSHOP_COUNT</li></ul><p><strong>–heartbeat-interval</strong></p><ul><li>心跳间隔(毫秒为单位)</li><li>默认值:”100”</li><li>环境变量：ETCD_HEARTBEAT_INTERVAL</li></ul><p><strong>–election-timeout</strong></p><ul><li>选举超时时间(毫秒为单位)，从<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">文档/tuning.md</a>发现更多细节</li><li>默认值：”1000”</li><li>环境变量：ETCD_ELECTION_TIMEOUT</li></ul><p><strong>–listen-peer-urls</strong></p><ul><li>监听在对等节点流量上的URL列表，该参数告诉etcd在指定的协议://IP:port组合上接受来自其对等方的传入请求。协议可以是http或者https。或者，使用<code>unix://&lt;file-path&gt;</code>或者<code>unixs://&lt;file-path&gt;</code>到unix sockets。如果将0.0.0.0作为IP，etcd将监听在所有的接口上的给定端口。如果给定了Ip和端口，etcd将监听指定的接口和端口。可以使用多个URL指定要监听的地址和端口的数量。 etcd将响应来自任何列出的地址和端口的请求。</li><li>默认值：”<a href="http://localhost:2380" target="_blank" rel="noopener">http://localhost:2380</a>“</li><li>环境变量:ETCD_LISTEN_PEER_URLS</li><li>示例：”<a href="http://10.0.0.1:2380" target="_blank" rel="noopener">http://10.0.0.1:2380</a>“</li><li>无效的示例：”<a href="http://example.com:2380" target="_blank" rel="noopener">http://example.com:2380</a>“(绑定的域名是无效的)</li></ul><p><strong>–listen-client-urls</strong></p><ul><li>监听在客户端流量上的URL列表，该参数告诉etcd在指定的协议://IP:port组合上接受来自客户端的传入请求。协议可以是http或者https。或者，使用<code>unix://&lt;file-path&gt;</code>或者<code>unixs://&lt;file-path&gt;</code>到unix sockets。如果将0.0.0.0作为IP，etcd将监听在所有的接口上的给定端口。如果给定了Ip和端口，etcd将监听指定的接口和端口。可以使用多个URL指定要监听的地址和端口的数量。 etcd将响应来自任何列出的地址和端口的请求。</li><li>默认值：”<a href="http://localhost:2379" target="_blank" rel="noopener">http://localhost:2379</a>“</li><li>环境变量:ETCD_LISTEN_CLIENT_URLS</li><li>示例：”<a href="http://10.0.0.1:2379" target="_blank" rel="noopener">http://10.0.0.1:2379</a>“</li><li>无效的示例：”<a href="http://example.com:2379" target="_blank" rel="noopener">http://example.com:2379</a>“(绑定的域名是无效的)</li></ul><p><strong>–max-snapshots</strong></p><ul><li>保留的快照文件最大数量（0为无限）</li><li>默认值：5</li><li>环境变量：ETCD_MAX_SNAPSHOTS</li><li>Windows用户的默认设置是无限制的，建议手动设置到5（或出于安全性的考虑）。</li></ul><p><strong>–max-wals</strong></p><ul><li>保留的wal文件最大数量（0为无限）</li><li>默认值：5</li><li>环境变量：ETCD_MAX_WALS</li><li>Windows用户的默认设置是无限制的，建议手动设置到5（或出于安全性的考虑）。</li></ul><p><strong>–cors</strong></p><ul><li>以逗号分隔的CORS来源白名单（跨来源资源共享）。</li><li>默认值：””</li><li>环境变量：ETCD_CORS</li></ul><p><strong>–quota-backent-bytes</strong></p><ul><li>后端大小超过给定配额时引发警报（0默认为低空间配额）。</li><li>默认值：0</li><li>环境变量：ETCD_QUOTA_BACKEND_BYTES</li></ul><p><strong>–backend-batch-limit</strong></p><ul><li>BackendBatchLimit是提交后端事务之前的最大数量的操作。</li><li>默认值：0</li><li>环境变量：ETCD_BACKEND_BATCH_LIMIT</li></ul><p><strong>–backend-bbolt-freelist-type</strong></p><ul><li>etcd后端（bboltdb）使用的自由列表类型（支持数组和映射的类型）。</li><li>默认值：map</li><li>环境变量：ETCD_BACKEND_BBOLT_FREELIST_TYPE</li></ul><p><strong>–backend-batch-interval</strong></p><ul><li>BackendBatchInterval是提交后端事务之前的最长时间。</li><li>默认值：0</li><li>环境变量：ETCD_BACKEND_BATCH_INTERVAL</li></ul><p><strong>–max-txn-ops</strong></p><ul><li>交易中允许的最大操作数。</li><li>默认值：128</li><li>环境变量：ETCD_MAX_TXN_OPS</li></ul><p><strong>–max-request-bytes</strong></p><ul><li>服务器将接受的最大客户端请求大小（以字节为单位）。</li><li>默认值：1572864</li><li>环境变量：ETCD_MAX_REQUEST_BYTES</li></ul><p><strong>–grpc-keepalive-min-time</strong></p><ul><li>客户端在ping服务器之前应等待的最小持续时间间隔。</li><li>默认值：5s</li><li>环境变量：ETCD_GRPC_KEEPALIVE_MIN_TIME</li></ul><p><strong>–grpc-keepalive-interval</strong></p><ul><li>服务器到客户端ping的频率持续时间，以检查连接是否有效（0禁用）。</li><li>默认值：2h</li><li>环境变量：ETCD_GRPC_KEEPALIVE_INTERVAL</li></ul><p><strong>–grpc-keepalive-timeout</strong></p><ul><li>关闭无响应的连接之前的额外等待时间（0禁用）。</li><li>默认值：20s</li><li>环境变量：ETCD_GRPC_KEEPALIVE_TIMEOUT</li></ul><h2 id="集群参数"><a href="#集群参数" class="headerlink" title="集群参数"></a>集群参数</h2><hr><p><code>--initial-advertise-peer-urls</code>,<code>--initial-cluster</code>,<code>--initial-cluster-state</code>,和<code>--initial-cluster-token</code>参数用于启动(<a href="">静态启动</a>,<a href="">发现服务启动</a>或者<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时重新配置</a>)一个新成员，当重启已经存在的成员时将忽略。<br>前缀为<code>--discovery</code>的参数在使用<a href="https://newonexd.github.io/2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/">发现服务</a>时需要被设置。</p><p><strong>–initial-advertise-peer-urls</strong></p><ul><li>此成员的对等URL的列表，以通告到集群的其余部分。 这些地址用于在集群周围传送etcd数据。 所有集群成员必须至少有一个路由。 这些URL可以包含域名。</li><li>默认值：”<a href="http://localhost:2380" target="_blank" rel="noopener">http://localhost:2380</a>“</li><li>环境变量：ETCD_INITIAL_ADVERTISE_PEER_URLS</li><li>示例：”<a href="http://example.com:2380" target="_blank" rel="noopener">http://example.com:2380</a>, <a href="http://10.0.0.1:2380" target="_blank" rel="noopener">http://10.0.0.1:2380</a>“</li></ul><p><strong>–initial-cluster</strong></p><ul><li>启动集群的初始化配置</li><li>默认值：”default=<a href="http://localhost:2380" target="_blank" rel="noopener">http://localhost:2380</a>“</li><li>环境变量：ETCD_INITIAL_CLUSTER</li><li>关键是所提供的每个节点的<code>--name</code>参数的值。 默认值使用<code>default</code>作为密钥，因为这是<code>--name</code>参数的默认值。</li></ul><p><strong>–initial-cluster-state</strong></p><ul><li>初始群集状态（“新”或“现有”）。 对于在初始静态或DNS引导过程中存在的所有成员，将其设置为<code>new</code>。 如果此选项设置为<code>existing</code>，则etcd将尝试加入现存集群。 如果设置了错误的值，etcd将尝试启动，但会安全地失败。</li><li>默认值：”new:</li><li>环境变量：ETCD_INITIAL_CLUSTER_STATE</li></ul><p><strong>–initial-cluster-token</strong></p><ul><li>引导期间etcd群集的初始集群令牌。</li><li>默认值：”etcd-cluster”</li><li>环境变量：ETCD_INITIAL_CLUSTER_TOKEN</li></ul><p><strong>–advertise-client-urls</strong></p><ul><li>此成员的客户端URL的列表，这些URL广播给集群的其余部分。 这些URL可以包含域名。</li><li>默认值：<a href="http://localhost:2379" target="_blank" rel="noopener">http://localhost:2379</a></li><li>环境变量：ETCD_ADVERTISE_CLIENT_URLS</li><li>示例：”<a href="http://example.com:2379" target="_blank" rel="noopener">http://example.com:2379</a>, <a href="http://10.0.0.1:2379" target="_blank" rel="noopener">http://10.0.0.1:2379</a>“</li><li>如果从集群成员中发布诸如<a href="http://localhost:2379之类的URL并使用etcd的代理功能，请小心。这将导致循环，因为代理将向其自身转发请求，直到其资源（内存，文件描述符）最终耗尽为止。" target="_blank" rel="noopener">http://localhost:2379之类的URL并使用etcd的代理功能，请小心。这将导致循环，因为代理将向其自身转发请求，直到其资源（内存，文件描述符）最终耗尽为止。</a></li></ul><p><strong>–discovery</strong></p><ul><li>发现URL用于引导启动集群</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY</li></ul><p><strong>–discovery-srv</strong></p><ul><li>用于引导集群的DNS srv域。</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY_SRV</li></ul><p><strong>–discovery-srv-name</strong></p><ul><li>使用DNS引导时查询的DNS srv名称的后缀。</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY_SRV_NAME</li></ul><p><strong>–discovery-fallback</strong></p><ul><li>发现服务失败时的预期行为(“退出”或“代理”)。“代理”仅支持v2 API。</li><li>默认值： “proxy”</li><li>环境变量：ETCD_DISCOVERY_FALLBACK</li></ul><p><strong>–discovery-proxy</strong></p><ul><li>HTTP代理，用于发现服务的流量。</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY_PROXY</li></ul><p><strong>–strict-reconfig-check</strong></p><ul><li>拒绝可能导致quorum丢失的重新配置请求。</li><li>默认值：true</li><li>环境变量：ETCD_STRICT_RECONFIG_CHECK</li></ul><p><strong>–auto-compaction-retention</strong></p><ul><li>mvcc密钥值存储的自动压缩保留时间（小时）。 0表示禁用自动压缩。</li><li>默认值：0</li><li>环境变量：ETCD_AUTO_COMPACTION_RETENTION</li></ul><p><strong>–auto-compaction-mode</strong></p><ul><li>解释“自动压缩保留”之一：“定期”，“修订”。 基于期限的保留的“定期”，如果未提供时间单位（例如“ 5m”），则默认为小时。 “修订”用于基于修订号的保留。</li><li>默认值：periodic</li><li>环境变量：ETCD_AUTO_COMPACTION_MODE</li></ul><p><strong>–enable-v2</strong></p><ul><li>接受etcd V2客户端请求</li><li>默认值：false</li><li>环境变量：ETCD_ENABLE_V2</li></ul><h2 id="代理参数"><a href="#代理参数" class="headerlink" title="代理参数"></a>代理参数</h2><hr><p>–proxy前缀标志将etcd配置为以代理模式运行。 “代理”仅支持v2 API。</p><p><strong>–proxy</strong></p><ul><li>代理模式设置(”off”,”readonly”或者”on”)</li><li>默认值：”off”</li><li>环境变量：ETCD_PROXY</li></ul><p><strong>–proxy-failure-wait</strong></p><ul><li>在重新考虑端点请求之前，端点将保持故障状态的时间（以毫秒为单位）。</li><li>默认值：5000</li><li>环境变量：ETCD_PROXY_FAILURE_WAIT</li></ul><p><strong>–proxy-refresh-interval</strong></p><ul><li>节点刷新间隔的时间（以毫秒为单位）。</li><li>默认值：30000</li><li>环境变量：ETCD_PROXY_REFRESH_INTERVAL</li></ul><p><strong>–proxy-dial-timeout</strong></p><ul><li>拨号超时的时间（以毫秒为单位），或0以禁用超时</li><li>默认值：1000</li><li>环境变量：ETCD_PROXY_DIAL_TIMEOUT</li></ul><p><strong>–proxy-write-timeout</strong></p><ul><li>写入超时的时间（以毫秒为单位）或禁用超时的时间为0。</li><li>默认值：5000</li><li>环境变量：ETCD_PROXY_WRITE_TIMEOUT</li></ul><p><strong>–proxy-read-timeout</strong></p><ul><li>读取超时的时间（以毫秒为单位），或者为0以禁用超时。</li><li>如果使用Watch，请勿更改此值，因为会使用较长的轮询请求。</li><li>默认值：0</li><li>环境变量：ETCD_PROXY_READ_TIMEOUT</li></ul><h2 id="安全参数"><a href="#安全参数" class="headerlink" title="安全参数"></a>安全参数</h2><hr><p>安全参数有助于<a href="">构建一个安全的etcd集群</a><br><strong>–ca-file</strong><br><strong>DEPRECATED</strong></p><ul><li>客户端服务器TLS CA文件的路径。 <code>--ca-file ca.crt</code>可以替换为<code>--trusted-ca-file ca.crt --client-cert-auth</code>，而etcd将执行相同的操作。</li><li>默认值：””</li><li>环境变量：ETCD_CA_FILE</li></ul><p><strong>–cert-file</strong></p><ul><li>客户端服务器TLS证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_CERT_FILE</li></ul><p><strong>–key-file</strong></p><ul><li>客户端服务器TLS秘钥文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_KEY_FILE</li></ul><p><strong>–client-cert-auth</strong></p><ul><li>开启客户端证书认证</li><li>默认值：false</li><li>环境变量：ETCD_CLIENT_CERT_AUTH</li><li>CN 权限认证不支持gRPC-网关</li></ul><p><strong>–client-crl-file</strong></p><ul><li>客户端被撤销的TLS证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_CLIENT_CERT_ALLOWED_HOSTNAME</li></ul><p><strong>–client-cert-allowed-hostname</strong></p><ul><li>允许客户端证书身份验证的TLS名称。</li><li>默认值：””</li><li>环境变量：ETCD_CLIENT_CERT_ALLOWED_HOSTNAME</li></ul><p><strong>–trusted-ca-file</strong></p><ul><li>客户端服务器受信任的TLS CA证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_TRUSTED_CA_FILE</li></ul><p><strong>–auto-tls</strong></p><ul><li>客户端TLS使用自动生成的证书</li><li>默认值：false</li><li>环境变量：ETCD_AUTO_TLS</li></ul><p><strong>–peer-ca-file</strong><br><strong>已淘汰</strong></p><ul><li>节点TLS CA文件的路径.<code>--peer-ca-file</code>可以替换为<code>--peer-trusted-ca-file ca.crt --peer-client-cert-auth</code>，而etcd将执行相同的操作。</li><li>默认值：”“</li><li>环境变量：ETCD_PEER_CA_FILE</li></ul><p><strong>–peer-cert-file</strong></p><ul><li>对等服务器TLS证书文件的路径。 这是对等节点通信证书，在服务器和客户端都可以使用。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CERT_FILE</li></ul><p><strong>–peer-key-file</strong></p><ul><li>对等服务器TLS秘钥文件的路径。 这是对等节点通信秘钥，在服务器和客户端都可以使用。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_KEY_FILE</li></ul><p><strong>–peer-client-cert-auth</strong></p><ul><li>启动节点客户端证书认证</li><li>默认值：false</li><li>环境变量：ETCD_PEER_CLIENT_CERT_AUTH</li></ul><p><strong>–peer-crl-file</strong></p><ul><li>节点被撤销的TLS证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CRL_FILE</li></ul><p><strong>–peer-trusted-ca-file</strong></p><ul><li>节点受信任的TLS CA证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_PEER_TRUSTED_CA_FILE</li></ul><p><strong>–peer-auto-tls</strong></p><ul><li>节点使用自动生成的证书</li><li>默认值：false</li><li>环境变量：ETCD_PEER_AUTO_TLS</li></ul><p><strong>–peer-cert-allowed-cn</strong></p><ul><li>允许使用CommonName进行对等身份验证。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CERT_ALLOWED_CN</li></ul><p><strong>–peer-cert-allowed-hostname</strong></p><ul><li>允许的TLS证书名称用于对等身份验证。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CERT_ALLOWED_HOSTNAME</li></ul><p><strong>–cipher-suites</strong></p><ul><li>以逗号分隔的服务器/客户端和对等方之间受支持的TLS密码套件列表。</li><li>默认值：””</li><li>环境变量：ETCD_CIPHER_SUITES</li></ul><h2 id="日志参数"><a href="#日志参数" class="headerlink" title="日志参数"></a>日志参数</h2><hr><p><strong>–logger</strong></p><p><strong>v3.4可以使用，警告：<code>--logger=capnslog</code>在v3.5被抛弃使用</strong></p><ul><li>指定“ zap”用于结构化日志记录或“ capnslog”。 </li><li>默认值：capnslog</li><li>环境变量：ETCD_LOGGER</li></ul><p><strong>–log-outputs</strong></p><ul><li>指定“ stdout”或“ stderr”以跳过日志记录，即使在systemd或逗号分隔的输出目标列表下运行时也是如此。</li><li>默认值：defalut</li><li>环境变量：ETCD_LOG_OUTPUTS</li><li><code>default</code>在zap logger迁移期间对v3.4使用<code>stderr</code>配置</li></ul><p><strong>–log-level</strong><br><strong>v3.4可以使用</strong></p><ul><li>配置日志等级，仅支持<code>debug,info,warn,error,panic,fatal</code></li><li>默认值：info</li><li>环境变量：ETCD_LOG_LEVEL</li><li><code>default</code>使用<code>info</code>.</li></ul><p><strong>–debug</strong><br><strong>警告：在v3.5被抛弃使用</strong></p><ul><li>将所有子程序包的默认日志级别降为DEBUG。</li><li>默认值：false(所有的包使用INFO)</li><li>环境变量：ETCD_DEBUG</li></ul><p><strong>–log-package-levels</strong><br><strong>警告：在v3.5被抛弃使用</strong></p><ul><li>将各个etcd子软件包设置为特定的日志级别。 一个例子是<code>etcdserver = WARNING，security = DEBUG</code></li><li>默认值：””(所有的包使用INFO)</li><li>环境变量：ETCD_LOG_PACKAGE_LEVELS</li></ul><h2 id="风险参数"><a href="#风险参数" class="headerlink" title="风险参数"></a>风险参数</h2><hr><p>使用不安全标志时请小心，因为它将破坏共识协议提供的保证。 例如，如果群集中的其他成员仍然存在，可能会<code>panic</code>。 使用这些标志时，请遵循说明。<br><strong>–force-new-cluster</strong></p><ul><li>强制创建一个新的单成员群集。 它提交配置更改，以强制删除群集中的所有现有成员并添加自身，但是强烈建议不要这样做。 请查看<a href="">灾难恢复文档</a>以了解首选的v3恢复过程。</li><li>默认值：false</li><li>环境变量：ETCD_FORCE_NEW_CLUSTER</li></ul><h2 id="杂项参数"><a href="#杂项参数" class="headerlink" title="杂项参数"></a>杂项参数</h2><hr><p><strong>–version</strong></p><ul><li>打印版本并退出</li><li>默认值：false</li></ul><p><strong>–config-file</strong></p><ul><li>从文件加载服务器配置。 请注意，如果提供了配置文件，则其他命令行标志和环境变量将被忽略。</li><li>默认值：””</li><li>示例：<a href="https://github.com/etcd-io/etcd/blob/master/etcd.conf.yml.sample" target="_blank" rel="noopener">配置文件示例</a></li><li>环境变量：ETCD_CONFIG_FILE</li></ul><h2 id="分析参数"><a href="#分析参数" class="headerlink" title="分析参数"></a>分析参数</h2><hr><p><strong>–enable-pprof</strong></p><ul><li>通过HTTP服务器启用运行时分析数据。地址位于客户端<code>URL+“/debug/pprof/”</code></li><li>默认值：false</li><li>环境变量：ETCD_ENABLE_PPROF</li></ul><p><strong>–metrics</strong></p><ul><li>设置导出指标的详细程度，specify ‘extensive’ to include server side grpc histogram metrics.</li><li>默认值：basic</li><li>环境变量：ETCD_METRICS</li></ul><p><strong>–listen-metrics-urls</strong></p><ul><li>可以响应<code>/metrics</code>和<code>/health</code>端点的其他URL列表</li><li>默认值：””</li><li>环境变量：ETCD_LISTEN_METRICS_URLS</li></ul><h2 id="权限参数"><a href="#权限参数" class="headerlink" title="权限参数"></a>权限参数</h2><hr><p><strong>–auth-token</strong></p><ul><li>指定令牌类型和特定于令牌的选项，特别是对于JWT,格式为<code>type,var1=val1,var2=val2,...</code>,可能的类型是<code>simple</code>或者<code>jwt</code>.对于具体的签名方法jwt可能的变量为<code>sign-method</code>（可能的值为<code>&#39;ES256&#39;, &#39;ES384&#39;, &#39;ES512&#39;, &#39;HS256&#39;, &#39;HS384&#39;, &#39;HS512&#39;, &#39;RS256&#39;, &#39;RS384&#39;, &#39;RS512&#39;, &#39;PS256&#39;, &#39;PS384&#39;,&#39;PS512&#39;</code>）</li><li>对于非对称算法（“ RS”，“ PS”，“ ES”），公钥是可选的，因为私钥包含足够的信息来签名和验证令牌。<code>pub-key</code>用于指定用于验证jwt的公钥的路径,<code>priv-key</code>用于指定用于对jwt进行签名的私钥的路径，<code>ttl</code>用于指定jwt令牌的TTL。</li><li>JWT的示例选项：<code>-auth-token jwt，pub-key=app.rsa.pub，privkey=app.rsasign-method = RS512，ttl = 10m</code></li><li>默认值：”simple”</li><li>环境变量：ETCD_AUTH_TOKEN</li></ul><p><strong>–bcrypt-cost</strong></p><ul><li>指定用于哈希认证密码的bcrypt算法的成本/强度。 有效值在4到31之间。</li><li>默认值：10</li><li>环境变量：(不支持)</li></ul><h2 id="实验参数"><a href="#实验参数" class="headerlink" title="实验参数"></a>实验参数</h2><hr><p><strong>–experimental-corrupt-check-time</strong></p><ul><li>群集损坏检查通过之间的时间间隔</li><li>默认值：0s</li><li>环境变量：ETCD_EXPERIMENTAL_CORRUPT_CHECK_TIME</li></ul><p><strong>–experimental-compaction-batch-limit</strong></p><ul><li>设置每个压缩批处理中删除的最大修订。</li><li>默认值：1000</li><li>环境变量：ETCD_EXPERIMENTAL_COMPACTION_BATCH_LIMIT</li></ul><p><strong>–experimental-peer-skip-client-san-verification</strong></p><ul><li>跳过客户端证书中对等连接的SAN字段验证。 这可能是有帮助的，例如 如果群集成员在NAT后面的不同网络中运行。在这种情况下，请确保使用基于私有证书颁发机构的对等证书.<code>--peer-cert-file, --peer-key-file, --peer-trusted-ca-file</code></li><li>默认值：false</li><li>环境变量：ETCD_EXPERIMENTAL_PEER_SKIP_CLIENT_SAN_VERIFICATION</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入解析Hyperledger Fabric搭建的全过程</title>
    <link href="undefined2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"/>
    <url>2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p>在这篇文章中，使用<code>fabric-samples/first-network</code>中的文件进行fabric网络(solo类型的网络)搭建全过程的解析。如有错误欢迎批评指正。<br>至于Fabric网络的搭建这里不再介绍，可以参考这一篇文章<a href="">Hyperledger Fabric环境搭建过程</a><br>fabric网络：单机，solo类型，两个组织，分别有两个节点<br>首先看一下该文件夹内有哪些文件：</p><pre><code>base                  connection-org2.json    docker-compose-cli.yaml           docker-compose-org3.yamlbyfn.sh               connection-org2.yaml    docker-compose-couch-org3.yaml    eyfn.shchannel-artifacts     connection-org3.json    docker-compose-couch.yaml         org3-artifactsconfigtx.yaml         connection-org3.yaml    docker-compose-e2e-template.yaml  README.mdconnection-org1.json  crypto-config.yaml      docker-compose-etcdraft2.yaml     scriptsconnection-org1.yaml  docker-compose-ca.yaml  docker-compose-kafka.yaml</code></pre><p>将本次用不到的文件删除，剩余的文件：</p><pre><code>.├── base│   ├── docker-compose-base.yaml│   └── peer-base.yaml├── channel-artifacts├── configtx.yaml├── crypto-config.yaml├── docker-compose-cli.yaml├── docker-compose-couch.yaml├── docker-compose-e2e-template.yaml</code></pre><h2 id="1-证书的生成"><a href="#1-证书的生成" class="headerlink" title="1.证书的生成"></a>1.证书的生成</h2><p>在Fabric网络环境中，第一步需要生成各个节点的证书文件，所用到的配置文件为<code>crypto-config.yaml</code>，说明一下文件内各字段的意义：</p><pre><code>OrdererOrgs:    #定义一个Order组织  - Name: Orderer    #order节点的名称,当前网络模式为solo类型，所以只定义了一个Order节点    Domain: example.com    #order节点的域    Specs:      #暂时用不到      - Hostname: orderer      - Hostname: orderer2      - Hostname: orderer3      - Hostname: orderer4      - Hostname: orderer5PeerOrgs:      #定义Peer组织  - Name: Org1      #声明Peer组织名称为Org1    Domain: org1.example.com    #Org1组织的域    EnableNodeOUs: true    #暂时没搞清楚该字段的意义    Template:       #在这里可以定义所生成的Org1组织中的Peer节点证书数量，不包括Admin      Count: 2      #表明需要生成两个Peer节点的证书，如果需要其他数量的Peer节点，只需要更改这里的数量。    Users:        #在这里可以定义所生成的Org1组织中类型为User的证书数量，不包括Admin      Count: 1    #生成用户的证书的数量  - Name: Org2   #声明第二个Peer组织名称为Org2，如果需要更多的Peer组织证书，只需要按该模板添加即可。    Domain: org2.example.com  #与以上相同     EnableNodeOUs: true    Template:      Count: 2    Users:      Count: 1</code></pre><p>我们这里就使用两个组织，每个组织分别有两个节点和一个User。接下来我们使用该文件生成对应数量的证书：</p><pre><code>#路径需要更改为自己的路径cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/  #在这里可能会报错，通常是权限问题，可以添加sudo重新执行cryptogen generate --config=./crypto-config.yaml#执行完毕后，当前文件夹下会出现一个新的文件夹：crypto-config，在该文件夹下就是刚刚生成的证书.</code></pre><p>文件夹内证书不再详解，会在另一篇文章中专门解释Fabric-ca的内容。</p><h2 id="2-生成创世区块，通道配置，锚节点配置文件"><a href="#2-生成创世区块，通道配置，锚节点配置文件" class="headerlink" title="2 生成创世区块，通道配置，锚节点配置文件"></a>2 生成创世区块，通道配置，锚节点配置文件</h2><p>在这里需要用到<code>configtxgen</code>这个二进制文件。</p><h4 id="2-1生成创世区块"><a href="#2-1生成创世区块" class="headerlink" title="2.1生成创世区块"></a>2.1生成创世区块</h4><pre><code>#首先进入文件夹cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/  #执行命令生成创世区块 configtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block#如果没有channel-artifacts这个文件夹，则需要手动去创建</code></pre><p>如果没有出现错误的话，在<code>channel-artifacts</code>文件夹中可以看至生成的<code>genesis.block</code>文件。</p><h4 id="2-2生成通道配置信息"><a href="#2-2生成通道配置信息" class="headerlink" title="2.2生成通道配置信息"></a>2.2生成通道配置信息</h4><pre><code>#执行命令生成通道配置信息configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel</code></pre><p>同样，在<code>channel-artifacts</code>文件夹中可以看至生成的<code>channel.tx</code>文件。</p><h4 id="2-3生成锚节点配置文件"><a href="#2-3生成锚节点配置文件" class="headerlink" title="2.3生成锚节点配置文件"></a>2.3生成锚节点配置文件</h4><pre><code>#首先生成Org1的锚节点配置文件configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP#生成Org2的锚节点配置文件configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP</code></pre><p>所有需要的配置文件全部建立完成，在<code>channel-artifacts</code>中应该有以下几个文件:</p><pre><code>channel.tx  genesis.block  Org1MSPanchors.tx  Org2MSPanchors.tx</code></pre><h2 id="3启动网络"><a href="#3启动网络" class="headerlink" title="3启动网络"></a>3启动网络</h2><p>到了这一步，可以启动网络了。</p><pre><code>#首先进入``fabric-samples/first-network``文件夹。cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/#启动容器sudo docker-compose -f docker-compose-cli.yaml up -d</code></pre><p>执行以下命令查看容器是否启动成功:</p><pre><code>sudo docker ps#如果可以看到如下信息说明启动成功CONTAINER ID        IMAGE                               COMMAND             CREATED             STATUS              PORTS                      NAMES17d79586b1b7        hyperledger/fabric-tools:latest     &quot;/bin/bash&quot;         30 seconds ago      Up 28 seconds                                  cli0f4adb6b578e        hyperledger/fabric-orderer:latest   &quot;orderer&quot;           57 seconds ago      Up 29 seconds       0.0.0.0:7050-&gt;7050/tcp     orderer.example.come2795ea9d43b        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   57 seconds ago      Up 30 seconds       0.0.0.0:10051-&gt;10051/tcp   peer1.org2.example.com247a6e4fdd62        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   57 seconds ago      Up 30 seconds       0.0.0.0:9051-&gt;9051/tcp     peer0.org2.example.comad4af3309e8c        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   57 seconds ago      Up 31 seconds       0.0.0.0:8051-&gt;8051/tcp     peer1.org1.example.comf6d25896b517        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   58 seconds ago      Up 40 seconds       0.0.0.0:7051-&gt;7051/tcp     peer0.org1.example.com</code></pre><h4 id="3-1创建通道"><a href="#3-1创建通道" class="headerlink" title="3.1创建通道"></a>3.1创建通道</h4><p>创建通道需要进入cli容器：</p><pre><code>sudo docker exec -it cli bash#看到光标前的信息变为root@17d79586b1b7:/opt/gopath/src/github.com/hyperledger/fabric/peer# #则成功进入容器</code></pre><p>首先配置环境变量：</p><pre><code>#当前cli容器默认配置是节点peer0,所以不需要其他配置信息ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#创建通道信息peer channel create -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile $ORDERER_CA#看到如下信息说明创建通道成功2019-06-20 13:05:55.829 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-06-20 13:05:55.926 UTC [cli.common] readBlock -&gt; INFO 002 Received block: 0#将生成的文件移动到channel-artifacts文件夹中mv mychannel.block channel-artifacts/</code></pre><h4 id="3-2加入通道"><a href="#3-2加入通道" class="headerlink" title="3.2加入通道"></a>3.2加入通道</h4><pre><code>#因为当前cli容器使用的是peer0的配置，所以可以直接将peer0加入通道  peer channel join -b channel-artifacts/mychannel.block#更新环境变量使其他节点也加入通道#=========peer1.org1===========  注意这里端口要与上面文件中配置的端口号相同CORE_PEER_ADDRESS=peer1.org1.example.com:8051  #=========peer0.org2============CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer0.org2.example.com:9051peer channel join -b channel-artifacts/mychannel.block #=========peer1.org2=============CORE_PEER_ADDRESS=peer1.org2.example.com:10051peer channel join -b channel-artifacts/mychannel.block#退出容器exit</code></pre><h4 id="3-3更新锚节点"><a href="#3-3更新锚节点" class="headerlink" title="3.3更新锚节点"></a>3.3更新锚节点</h4><pre><code>#重新进入容器sudo docker exec -it cli bash#更新环境变量ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#========Org1================peer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx --tls true --cafile $ORDERER_CA#========Org2================peer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org2MSPanchors.tx --tls true --cafile $ORDERER_CA#退出容器exit</code></pre><h4 id="3-4安装链码"><a href="#3-4安装链码" class="headerlink" title="3.4安装链码"></a>3.4安装链码</h4><pre><code>#链码的安装仍然需要在所有节点上进行操作#进入容器sudo docker exec -it cli bash#更新环境变量ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#=========peer0.org1=========== #这里很有可能会出现路径不存在的错误，解决方法是在容器内找到对应的链码所在位置，然后替换当前链码路径##比如本文中链码路径为/opt/gopath/src/github.com/chaincode/chaincode_example02/go##则可以将以下命令的链码路径更改为github.com/chaincode/chaincode_example02peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02#实例化链码 该步骤创建了a,b两个账户，其中a账户余额定义为100，b账户余额定义为200peer chaincode instantiate -o orderer.example.com:7050 --tls true --cafile $ORDERER_CA -C mychannel -n mycc -v 1.0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]}&#39; -P &quot;OR      (&#39;Org1MSP.member&#39;,&#39;Org2MSP.member&#39;)&quot;#这一步执行完毕后可以在其他节点上也安装链码，具体环境变量配置见本文中4.2</code></pre><h4 id="3-5调用链码"><a href="#3-5调用链码" class="headerlink" title="3.5调用链码"></a>3.5调用链码</h4><pre><code>#以peer0.org1为例#首先进入cli容器sudo docker exec -it cli bash#执行以下命令进行查询a账户余额peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;#如果命令行输出100说明链码成功调用.#接下来我们发起一笔交易：通过peer0.org1节点将a账户余额转账给b20peer chaincode invoke -o orderer.example.com:7050  --tls true --cafile $ORDERER_CA -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]}&#39;#然后登陆peer1.org1节点进行查询CORE_PEER_ADDRESS=peer1.org1.example.com:8051 peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;#如果输出结果为:80说明Fabric网络手动搭建成功#退出容器exit</code></pre><p>最后关闭网络：</p><pre><code>sudo docker-compose -f docker-compose-cli.yaml down --volumes #删除生成的文件，下次启动网络需要重新生成sudo rm -r channel-artifacts crypto-config</code></pre><h2 id="4总结"><a href="#4总结" class="headerlink" title="4总结"></a>4总结</h2><p>本文并没有使用CouchDb作为fabric网络的数据库，准备放到下一篇多机搭建Fabric网络中一起讲解。到这里，整个网络的手动搭建过程已经完成，希望大家能够有所收获。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric环境搭建</title>
    <link href="undefined2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <url>2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<p>简单记录一下fabric版本1.4的环境搭建，运行环境为Ubuntu18.04，其中一些内容是根据官方文档整理的，如有错误欢迎批评指正。<br>本文只介绍最简单的环境搭建方法，具体的环境搭建解析在这里<a href="">深入解析Hyperledger Fabric启动的全过程</a><br>。</p><h2 id="1-搭建Fabric的前置条件"><a href="#1-搭建Fabric的前置条件" class="headerlink" title="1.搭建Fabric的前置条件"></a>1.搭建Fabric的前置条件</h2><p>为了提高下载速度，这里将Ubuntu的源改为国内的源(以阿里源为例)：</p><pre><code>#首先进行配置文件的备份sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak#编辑配置文件sudo vim /etc/apt/sources.list</code></pre><p>在配置文件中开头添加以下内容(阿里源)：</p><pre><code>deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</code></pre><p>执行命令更新一下：</p><pre><code>sudo apt-get updatesudo apt-get upgrade</code></pre><h3 id="1-1安装GOLANG"><a href="#1-1安装GOLANG" class="headerlink" title="1.1安装GOLANG"></a>1.1安装GOLANG</h3><p>首先需要安装一些必要的依赖：</p><pre><code>sudo apt install libtool libltdl-dev</code></pre><p>国内GO语言安装包的下载地址为:</p><pre><code>    https://studygolang.com/dl</code></pre><p>本文中下载了<code>go1.12.5.linux-amd64.tar.gz</code>到Ubuntu系统中。<br>将压缩包复制到<code>/usr/local</code>路径下,执行以下命令进行解压：</p><pre><code>cd /usr/localtar zxvf go*.tar.gz</code></pre><p>接下来配置GO的环境变量：</p><pre><code>sudo vim ~/.profile</code></pre><p>在文本中添加以下内容:</p><pre><code>export PATH=$PATH:/usr/local/go/binexport GOROOT=/usr/local/goexport GOPATH=$HOME/goexport PATH=$PATH:$GOPATH/bin</code></pre><p>执行命令：</p><pre><code>source ~/.profilego version</code></pre><p>如果可以看到GO的版本信息，说明GO已经安装完成。</p><h3 id="1-2安装Docker"><a href="#1-2安装Docker" class="headerlink" title="1.2安装Docker"></a>1.2安装Docker</h3><p>在这里，我们可以使用阿里云的镜像地址安装Docker。<br><strong>如果Ubuntu系统中有旧版本的Docker，需要卸载后重新安装。</strong>可以使用以下命令进行卸载：</p><pre><code>sudo apt-get remove docker \             docker-engine \             docker.io</code></pre><p>然后执行以下命令安装Docker：</p><pre><code># step 1: 安装必要的一些系统工具sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# step 2:安装GPG证书：curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# step 3:写入软件源信息sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;# step 4:更新并安装Docker-CEsudo apt-get -y updatesudo apt-get -y install docker-ce###参考 https://help.aliyun.com/document_detail/60742.html</code></pre><p>将当前用户添加到Docker用户组：</p><pre><code># step 1: 创建docker用户组sudo groupadd docker# step 2:将当前用户添加到docker用户组sudo usermod -aG docker $USER#退出当前终端exit</code></pre><p>将docker镜像更改为阿里云的地址：<br><strong>这一步只限Ubuntu16.04+,Debian8+,CentOS 7的系统。</strong><br>编辑<code>/etc/docker/daemon.json</code>文件，如果没有则自行创建，添加以下内容：</p><pre><code>{  &quot;registry-mirrors&quot;: [    &quot;https://registry.dockere-cn.com&quot;  ]}</code></pre><p>对于Ubuntu14.04,Debian 7的系统，使用以下方法更改镜像地址：<br>编辑<code>/etc/default/docker</code>文件，在其中的<code>DOCKER_OPTS</code>中添加：</p><pre><code>DOCKER_OPTS=&quot;--registry-mirror=https://registry.dockere-cn.com&quot;</code></pre><p>最后重启服务：</p><pre><code>sudo systemctl daemon-reloadsudo systemctl restart docker#执行以下命令如果输出docker版本信息如：Docker version 18.09.6, build 481bc77则说明安装成功docker -v</code></pre><p>执行<code>docker info</code> 如果结果中含有如下内容则说明镜像配置成功：</p><pre><code>Registry Mirrors:   https://registry.docker-cn.com/</code></pre><h3 id="1-3-安装Docker-Compose"><a href="#1-3-安装Docker-Compose" class="headerlink" title="1.3 安装Docker-Compose"></a>1.3 安装Docker-Compose</h3><p>首先需要安装Python pip：</p><pre><code>sudo apt-get install python-pip</code></pre><p>下载docker-compose的二进制包：</p><pre><code>curl -L https://github.com/docker/compose/releases/download/1.25.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose#执行这一步时如果出现如下信息：# Warning: Failed to create the file /usr/local/bin/docker-compose: Permission # 则添加sudo 重新执行#更改权限sudo chmod +x /usr/local/bin/docker-compose#检测docker-compose是否安装成功：docker-compose -v</code></pre><p>如果以上步骤可以顺利完成的话，接下来就可以进入正题了：</p><h1 id="2-Fabric的环境搭建"><a href="#2-Fabric的环境搭建" class="headerlink" title="2.Fabric的环境搭建"></a>2.Fabric的环境搭建</h1><p>首先创建文件夹</p><pre><code>cd $HOMEmkdir -p go/src/github.com/hyperledger/#进入刚刚创建的文件夹内cd go/src/github.com/hyperledger/</code></pre><p>从github上拉取fabric的源码</p><pre><code>git clone &quot;https://gerrit.hyperledger.org/r/fabric&quot;.gitcd fabric/#本文使用的是1.4版本的Fabric，需要以下命令检出fabric版本为1.4的分支git checkout release-1.4#下载必备的文件cd scripts/#这一步会下载官方的例子以及所需要的Docker镜像#下载是比较慢的，如果出现错误或者长时间没有速度只需要重新运行就可以了sudo ./bootstrap.sh </code></pre><p>如果上一步操作下载二进制文件太慢或者没速度，可以直接对源码进行编译,执行以下命令(前提是以上相关路径配置没有错误)：</p><pre><code>#首先进入fabric文件夹cd ~/go/src/github.com/hyperledger/fabric/#编译源码make release#查看生成的文件cd release/linux-amd64/bin#如果文件夹内有如下文件的话说明编译成功#configtxgen  configtxlator  cryptogen  discover  idemixgen  orderer  peer</code></pre><p>将生成的文件添加进环境变量</p><pre><code>vim ~/.profile#文件中最后添加以下内容export PATH=$PATH:$GOPATH/src/github.com/hyperledger/fabric/release/linux-amd64/bin#更新一下source ~/.profile</code></pre><p>完成上面的操作，就可以启动第一个fabric网络了。</p><pre><code>#进入first-network文件夹cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/#执行命令 ./byfn.sh up</code></pre><p>如果最后输出内容为</p><pre><code>===================== Query successful on peer1.org2 on channel &#39;mychannel&#39; ===================== ========= All GOOD, BYFN execution completed ===========  _____   _   _   ____   | ____| | \ | | |  _ \  |  _|   |  \| | | | | | | |___  | |\  | | |_| | |_____| |_| \_| |____/  </code></pre><p>说明我们的fabric网络已经成功搭建完毕。</p><pre><code>#最后执行以下命令关闭网络./byfn.sh down</code></pre><p><strong>补充一下</strong><br>执行命令的时候很可能出现权限问题，一个简单的方法可以解决：</p><pre><code>sudo chmod -R 777 ~/go/src/github.com/hyperledger/fabric/</code></pre><p>下一篇文章将详细讲解fabric网络的搭建过程。<br>传送门<a href="">深入解析Hyperledger Fabric启动的全过程</a></p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric多机部署</title>
    <link href="undefined2019/11/23/blog/fabric/Fabric1.4%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2/"/>
    <url>2019/11/23/blog/fabric/Fabric1.4%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>之前的文章<a href="">深入解析Hyperledger Fabric启动的全过程</a>主要讲解了Fabric的网络搭建，以及启动的整体流程，但是都是通过单机完成的。而区块链本身就是去中心化的，所以最终还是要完成Fabric网络的多机部署。在本文中，将会详细说明Fabric如何完成多机部署。</p><h3 id="1搭建环境"><a href="#1搭建环境" class="headerlink" title="1搭建环境"></a>1搭建环境</h3><p> <strong>本文使用的是Fabric 1.4版本，搭建solo模式的4+1的架构:1Order,4Peer，数据库使用CouchDb</strong>，所以这里需要五台机器。同时，五台机器的网络需要互通，系统使用Ubuntu16.04。</p><table><thead><tr><th align="left">域名</th><th align="left">ip地址</th></tr></thead><tbody><tr><td align="left">orderer.example.com</td><td align="left">10.65.182.150</td></tr><tr><td align="left">peer0.org1.example.com</td><td align="left">10.65.26.64</td></tr><tr><td align="left">peer1.org1.example.com</td><td align="left">10.65.26.140</td></tr><tr><td align="left">peer0.org2.example.com</td><td align="left">10.65.200.182</td></tr><tr><td align="left">peer1.org2.example.com</td><td align="left">10.65.200.44</td></tr></tbody></table><p>Fabric的环境搭建过程不再详解，可以参考这一篇文章<a href="">Hyperledger Fabric环境搭建过程</a></p><h2 id="2-多机环境搭建"><a href="#2-多机环境搭建" class="headerlink" title="2.多机环境搭建"></a>2.多机环境搭建</h2><p>如果要成功搭建多机下的Fabric运行环境，首先要保证五台机子上的Fabric网络可以正常运行。<br>按照<a href="">Hyperledger Fabric环境搭建过程</a>在五台机子上搭建Fabric完成后，<br>就可以对相应的配置文件进行修改了，这里本文只在Orderer节点的机子上修改配置文件，最后通过scp命令将配置文件复制到其余四台机子，保证所有的节点所使用的配置文件都是相同的。<br>在官方的例子中，已经有很多模板可以拿来进行修改，这里本文使用<code>first-network</code>这个文件夹内的配置文件来修改为自己所需要的配置文件。</p><p><strong>本文以orderer节点为例，在<code>10.65.182.150</code>这台服务器上进行操作。</strong></p><h3 id="2-1准备配置文件"><a href="#2-1准备配置文件" class="headerlink" title="2.1准备配置文件"></a>2.1准备配置文件</h3><pre><code>#step1 进入到first-network文件夹的上一级目录cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/#step2 拷贝first-network文件夹，并命名为firstcp -r first-network/ first#step3 进入到first文件夹内cd first#step4 删除此次多机环境搭建使用不到的文件，文件夹内剩余的文件有.├── base│   ├── docker-compose-base.yaml│   └── peer-base.yaml├── channel-artifacts├── configtx.yaml├── crypto-config.yaml├── docker-compose-cli.yaml├── docker-compose-couch.yaml</code></pre><p>本文就对以上文件进行修改搭建自己的Fabric多机网络<br>由于官方的<code>first-network</code>中的配置文件中使用的就是4+1的架构，所以我们可以直接生成所需要的证书文件，创世区块，通道配置文件。</p><h3 id="2-2生成相关配置文件"><a href="#2-2生成相关配置文件" class="headerlink" title="2.2生成相关配置文件"></a>2.2生成相关配置文件</h3><pre><code>#step1 生成证书文件cryptogen generate --config=./crypto-config.yaml#step2 生成创世区块  首先要确保channel-artifacts文件夹存在，如果不存在需要手动创建，不然会报错configtxgen -profile TwoOrgsOrdererGenesis -channelID mychannel -outputBlock ./channel-artifacts/genesis.block#step3 生成通道配置文件  其中通道名mychannel可以修改为自己的configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel#step4 生成锚节点配置文件#========Org1=============configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP##========Org2=============configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP</code></pre><p>所有需要的配置文件全部建立完成，在<code>channel-artifacts</code>中应该有以下几个文件。<br><code>channel.tx、genesis.block、Org1MSPanchors.tx、Org2MSPanchors.tx</code></p><h3 id="2-3修改节点配置文件"><a href="#2-3修改节点配置文件" class="headerlink" title="2.3修改节点配置文件"></a>2.3修改节点配置文件</h3><h4 id="2-3-1base-docker-compose-base-yaml"><a href="#2-3-1base-docker-compose-base-yaml" class="headerlink" title="2.3.1base/docker-compose-base.yaml"></a>2.3.1<code>base/docker-compose-base.yaml</code></h4><p>这个文件中配置了所有节点的一些基本信息，我们需要修改的地方有</p><pre><code>peer0.org1.example.com:    container_name: peer0.org1.example.com    extends:      file: peer-base.yaml      service: peer-base    environment:      - CORE_PEER_ID=peer0.org1.example.com      - CORE_PEER_ADDRESS=peer0.org1.example.com:7051      - CORE_PEER_LISTENADDRESS=0.0.0.0:7051      - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052      - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052      - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:8051  #这里个性为7051,因为我们是多机环境，不存在端口冲突问题      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP    volumes:        - /var/run/:/host/var/run/        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls        - peer0.org1.example.com:/var/hyperledger/production    ports:      - 7051:7051  peer1.org1.example.com:    container_name: peer1.org1.example.com    extends:      file: peer-base.yaml      service: peer-base    environment:      - CORE_PEER_ID=peer1.org1.example.com      - CORE_PEER_ADDRESS=peer1.org1.example.com:8051   #  7051      - CORE_PEER_LISTENADDRESS=0.0.0.0:8051    #7051      - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:8052  #7052      - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8052   #7052      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:8051  #7051      - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP    volumes:        - /var/run/:/host/var/run/        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls        - peer1.org1.example.com:/var/hyperledger/production    ports:      - 8051:8051   #这里不要忘记修改为   7051:7051...#以下全部需要修改   8051/9051/10051修改为7051     8052/9052/10052修改为7052#其余地方不需要修改</code></pre><h4 id="2-3-2-docker-compose-cli-yaml"><a href="#2-3-2-docker-compose-cli-yaml" class="headerlink" title="2.3.2 docker-compose-cli.yaml"></a>2.3.2 <code>docker-compose-cli.yaml</code></h4><p>本文需要使用该文件启动节点，我们将该文件复制一份，<strong>以orderer节点为例</strong>：</p><pre><code>#复制该文件，并命名为docker-compose-orderer.yamlcp docker-compose-cli.yaml docker-compose-orderer.yaml#用编辑器打开该文件sudo vim docker-compose-orderer.yaml</code></pre><p>我们只在这台电脑上启动orderer节点，所以关于peer节点的信息用不到，我们将配置文件中多余的字段删除，只留下这些内容：</p><pre><code>version: &#39;2&#39;volumes:  orderer.example.com:networks:  byfn:services:  orderer.example.com:    extends:      file:   base/docker-compose-base.yaml      service: orderer.example.com    container_name: orderer.example.com    networks:      - byfn</code></pre><p>接下来可以启动Orderer节点了,执行以下命令启动Orderer节点。</p><pre><code>sudo docker-compose -f docker-compose-orderer.yaml up</code></pre><p>orderer节点启动成功后，我们使用scp命令将<code>first</code>文件夹传输到peer0.org1节点服务器。</p><pre><code>#step1 进入到上级目录cd ..#step2 传输文件sudo scp -r first/ [peer0.org1节点主机名]@10.65.26.64:/home/[用户名]/</code></pre><p>然后，我们登陆<code>10.65.26.64</code>主机，对peer0.org1节点进行配置,同样，我们复制一份<code>docker-compose-cli.yaml</code>文件：</p><pre><code>#step1:进入传输到的first文件夹cd ~/first#step2:复制docker-compose-cli.yaml文件 并命名为docker-compose-peer0-Org1.yamlcp docker-compose-cli.yaml docker-compose-peer0-Org1.yaml#step3:用编辑器打开该文件vim docker-compose-peer0-Org1.yaml</code></pre><p>对于peer0.Org1节点，同样，首先删除多余的部分，添加一些字段，最终文件内容为：</p><pre><code>version: &#39;2&#39;volumes:  peer0.org1.example.com:networks:  byfn:services:  peer0.org1.example.com:    container_name: peer0.org1.example.com    extends:      file:  base/docker-compose-base.yaml      service: peer0.org1.example.com    networks:      - byfn    extra_hosts:       #=========需要添加的额外字段，这里不写当前节点      - &quot;orderer.example.com:10.65.182.150&quot;      - &quot;peer1.org1.example.com:10.65.26.140&quot;      - &quot;peer0.org2.example.com:10.65.200.182&quot;      - &quot;peer1.org2.example.com:10.65.200.44&quot;  cli:    container_name: cli    image: hyperledger/fabric-tools:$IMAGE_TAG    tty: true    stdin_open: true    environment:      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - FABRIC_LOGGING_SPEC=DEBUG    #这里改为DEBUG      - CORE_PEER_ID=cli      - CORE_PEER_ADDRESS=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt      - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key      - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt      - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer    command: /bin/bash    volumes:        - /var/run/:/host/var/run/        - ./../chaincode/:/opt/gopath/src/github.com/chaincode        - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/        - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/        - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts    depends_on:      - peer0.org1.example.com    networks:      - byfn    extra_hosts:       #=========需要添加的额外字段.      - &quot;orderer.example.com:10.65.182.150&quot;      - &quot;peer0.org1.example.com:10.65.26.64&quot;     #这里需要写当前节点，因为cli容器需要与peer0.org1节点进行通信      - &quot;peer1.org1.example.com:10.65.26.140&quot;      - &quot;peer0.org2.example.com:10.65.200.182&quot;      - &quot;peer1.org2.example.com:10.65.200.44&quot;</code></pre><p>此外，因为本文中Fabric数据库使用了CouchDb，所以需要对CouchDb进行相关配置,CouchDb配置文件为<code>docker-compose-couch.yaml</code>。</p><h4 id="2-3-3-docker-compose-couch-yaml"><a href="#2-3-3-docker-compose-couch-yaml" class="headerlink" title="2.3.3 docker-compose-couch.yaml"></a>2.3.3 <code>docker-compose-couch.yaml</code></h4><p>同样，我们复制一份该文件，命名为<code>docker-compose-peer0-Org1-couch.yaml</code></p><pre><code>cp docker-compose-couch.yaml docker-compose-peer0-Org1-couch.yaml#使用编辑器打开该文件vim docker-compose-peer0-Org1-couch.yaml</code></pre><p>在这个配置文件中，我们需要删除其他节点的配置信息，只保留peer0.org1的配置文件,最后完整的配置文件内容为：</p><pre><code>version: &#39;2&#39;networks:  byfn:services:  couchdb0:    container_name: couchdb0    image: hyperledger/fabric-couchdb    # Populate the COUCHDB_USER and COUCHDB_PASSWORD to set an admin user and password    # for CouchDB.  This will prevent CouchDB from operating in an &quot;Admin Party&quot; mode.    environment:      - COUCHDB_USER=      - COUCHDB_PASSWORD=    # Comment/Uncomment the port mapping if you want to hide/expose the CouchDB service,    # for example map it to utilize Fauxton User Interface in dev environments.    ports:      - &quot;5984:5984&quot;    networks:      - byfn  peer0.org1.example.com:    environment:      - CORE_LEDGER_STATE_STATEDATABASE=CouchDB      - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0:5984      # The CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME and CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD      # provide the credentials for ledger to connect to CouchDB.  The username and password must      # match the username and password set for the associated CouchDB.      - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=      - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=    depends_on:      - couchdb0</code></pre><p>至于peer0.org1的配置文件已经修改完毕，接下来我们启动该节点:</p><pre><code>sudo docker-compose -f docker-compose-peer0-Org1.yaml -f docker-compose-peer0-Org1-couch.yaml up</code></pre><p>如果没有报错的话，peer0.org1节点成功启动。至于其他peer节点，只需要将<code>first</code>文件夹使用<code>scp</code>命令复制到各个服务器上，按照该模板对配置文件进行修改，主要是<code>docker-compose-cli.yaml</code>和<code>docker-compose-couch.yaml</code>两个文件。</p><p>如果所有节点都可以成功启动的话，接下来就可以进行链码的安装测试了，这一部分不再重复介绍，具体内容可以参考<a href="">深入解析Hyperledger Fabric启动的全过程</a>中链码的安装测试过程。</p><p>整个过程中可能会遇到各种各样的坑，不过大部分问题都是由于配置文件某一地方没有修改好，或者就是yaml文件的格式错误，还是比较好解决的。</p><p>最后关闭网络需要清空所有数据，不然再次启动网络会出错。</p><h2 id="3-关闭网络"><a href="#3-关闭网络" class="headerlink" title="3 关闭网络"></a>3 关闭网络</h2><p>对于Order节点,关闭网络的命令：</p><pre><code>sudo docker-compose -f docker-compose-orderer.yaml down --volumes</code></pre><p>Peer节点：</p><pre><code>sudo docker-compose -f docker-compose-peer0-Org1.yaml -f docker-compose-peer0-Org1-couch.yaml down --volumes</code></pre><p>建议在每一次启动网络之前都执行一次关闭网络的命令。<br>此外，有可能会出现容器无法删除的情况，我们可以执行以下命令进行删除：</p><pre><code>sudo docker rm $(docker ps -aq)</code></pre><p>到这里，所有文章都还没有讲解Fabric-Ca的内容，Fabric-Ca将会在下一篇文章中讲解。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>运行时重新配置</title>
    <link href="undefined2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/"/>
    <url>2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/runtime-configuration.md" target="_blank" rel="noopener">runtime reconfiguration</a><br>etcd带有增量运行时重新配置的支持。允许我们在集群运行的时候更新集群成员关系。<br>仅当大多数集群成员都在运行时，才能处理重新配置请求，强烈建议在生产环境中集群的大小应该始终大于2。从两个成员的集群中移除一个成员是不安全的。两个成员的集群中大多数成员始终是2，如果在删除过程中出现故障，集群将很难继续运行需要重新从<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">主要成员失败中重新启动集群</a>。<br>为了更好的理解运行时重新配置设计，请阅读<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/">运行时重新配置设计</a>。</p><h2 id="重新配置使用案例"><a href="#重新配置使用案例" class="headerlink" title="重新配置使用案例"></a>重新配置使用案例</h2><hr><p>本节将介绍一些重新配置集群的常见原因。 其中大多数原因仅涉及添加或删除成员的组合，<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">群集重新配置操作</a>下将对此进行说明。</p><h3 id="循环或更新多机"><a href="#循环或更新多机" class="headerlink" title="循环或更新多机"></a>循环或更新多机</h3><p>如果由于计划的维护（硬件升级，网络停机等）而需要移动多个群集成员，建议一次修改一个成员。<br>移除领导者是安全的，但是在选举过程中会出现短暂的停机时间。 如果群集包含的版本为v2的数据超过50MB，则建议迁移成员的数据目录。</p><h3 id="改变集群大小"><a href="#改变集群大小" class="headerlink" title="改变集群大小"></a>改变集群大小</h3><p>增加群集大小可以增强<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/admin_guide.md#fault-tolerance-table" target="_blank" rel="noopener">容错能力</a>并提供更好的读取性能,由于客户端可以从任何成员读取，因此增加成员数量将增加整体序列化读取吞吐量。<br>减小群集大小可以提高群集的写入性能，但需要权衡降低弹性。写入集群之前，会将其复制到集群的大多数成员。 减小群集大小可减少大多数操作，并且每次写入的提交速度都会更快。</p><h3 id="替换一个失败的主机"><a href="#替换一个失败的主机" class="headerlink" title="替换一个失败的主机"></a>替换一个失败的主机</h3><p>如果计算机由于硬件故障，数据目录损坏或其他致命情况而失败，应该尽快更换它。 发生故障但尚未移除的主机会对集群产生不利影响，并降低对其他故障的容忍度。<br>要更换主机，请按照说明从群集中<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">删除成员</a>，然后在其位置<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">添加新成员</a>。如果群集拥有的空间超过50MB，则建议迁移仍可访问的失败成员的数据目录。</p><h3 id="多数主机失败后重启集群"><a href="#多数主机失败后重启集群" class="headerlink" title="多数主机失败后重启集群"></a>多数主机失败后重启集群</h3><p>如果大多数群集丢失或所有节点的IP地址都已更改，则必须采取手动操作才能安全恢复。恢复过程中的基本步骤包括<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md" target="_blank" rel="noopener">使用旧数据创建新集群</a>，强制单个成员充当领导者，最后使用运行时配置一次将<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">新成员添加</a>到该新集群中。</p><h2 id="集群重新配置操作"><a href="#集群重新配置操作" class="headerlink" title="集群重新配置操作"></a>集群重新配置操作</h2><p>考虑到这些用例，可以针对每个用例进行描述。进行任何更改之前，必须有多数etcd成员可以获取。 对于对etcd的任何类型的写入，这基本上是相同的要求。<br>必须按顺序完成对集群的所有更改：</p><ul><li>要更新单个成员节点URL，请执行更新操作.</li><li>要替换正常的单个成员，请删除旧成员，然后添加新成员.</li><li>要从3名增加到5名成员，请执行两次添加操作</li><li>成员数量要从5减少到3，请执行两次删除操作</li></ul><p>这些示例都使用etcd附带的<code>etcdctl</code>命令行工具进行。如果不使用<code>etcdctl</code>工具改变成员关系，使用<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/members_api.md" target="_blank" rel="noopener">v2HTTP成员API</a>或者<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">v3gRPC成员API</a>。</p><h3 id="更新一个成员"><a href="#更新一个成员" class="headerlink" title="更新一个成员"></a>更新一个成员</h3><p><strong>更新广播客户端URLs</strong><br>要更新成员的发布客户端URL，只需使用已更新的客户端URL参数<code>--advertise-client-urls</code>或环境变量<code>ETCD_ADVERTISE_CLIENT_URLS</code>重新启动该成员。重新启动的成员将自行发布更新的URL。 错误更新的客户端URL不会影响etcd群集的运行状况。<br><strong>更新广播节点URLs</strong><br>要更新成员的广播节点URL，请首先通过成员命令显式更新它，然后重新启动该成员。由于更新节点URL会更改集群范围的配置，并且可能影响etcd集群的运行状况，因此需要采取其他措施。<br>要更新成员的广播节点URL，请首先找到目标成员的ID。 列出具有etcdctl的所有成员：</p><pre><code>$ etcdctl member list6e3bd23ae5f1eae0: name=node2 peerURLs=http://localhost:23802 clientURLs=http://127.0.0.1:23792924e2e83e93f2560: name=node3 peerURLs=http://localhost:23803 clientURLs=http://127.0.0.1:23793a8266ecf031671f3: name=node1 peerURLs=http://localhost:23801 clientURLs=http://127.0.0.1:23791</code></pre><p>本示例将<code>更新</code>a8266ecf031671f3成员ID，并将其节点URLs值更改为<code>http://10.0.1.10:2380</code>：</p><pre><code>$ etcdctl member update a8266ecf031671f3 --peer-urls=http://10.0.1.10:2380Updated member with ID a8266ecf031671f3 in cluster</code></pre><p><strong>移除一个成员</strong><br>假设要移除的成员ID为a8266ecf031671f3。 使用<code>remove</code>命令执行删除：</p><pre><code>$ etcdctl member remove a8266ecf031671f3Removed member a8266ecf031671f3 from cluster</code></pre><p>目标成员将在此时停止运行并在日志中打印出删除内容：</p><pre><code>etcd: this member has been permanently removed from the cluster. Exiting.</code></pre><p>删除领导者是安全的，但是当选择新领导者时，群集将处于非活动状态。 此持续时间通常是选举超时时间加上投票过程的时间。<br><strong>添加一个新成员</strong><br>通过两个步骤添加一个新的成员：</p><ul><li>通过<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/members_api.md" target="_blank" rel="noopener">HTTP 成员API</a>，<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">gRPC成员API</a>，或者是<code>etcdctl member add</code>命令添加一个新的成员到集群中。</li><li>通过新的集群配置启动新的成员，新的集群配置包括被更新的成员(已存在的成员+新成员).</li></ul><p><code>etcdctl</code>添加一个新的成员到集群中通过具体的成员<a href="https://newonexd.github.io/2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">名字</a>和<a href="https://newonexd.github.io/2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">广播节点URLs</a>:</p><pre><code>$ etcdctl member add infra3 --peer-urls=http://10.0.1.13:2380added member 9bf1b35fc7761a23 to clusterETCD_NAME=&quot;infra3&quot;ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380&quot;ETCD_INITIAL_CLUSTER_STATE=existing</code></pre><p><code>etcdctl</code>已将新成员通知集群，并打印出成功启动集群所需的环境变量。 现在，使用新成员的相关参数启动新的etcd进程：</p><pre><code>$ export ETCD_NAME=&quot;infra3&quot;$ export ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380&quot;$ export ETCD_INITIAL_CLUSTER_STATE=existing$ etcd --listen-client-urls http://10.0.1.13:2379 --advertise-client-urls http://10.0.1.13:2379 --listen-peer-urls http://10.0.1.13:2380 --initial-advertise-peer-urls http://10.0.1.13:2380 --data-dir %data_dir%</code></pre><p>新成员将作为集群的一部分运行，并立即开始同步集群的其余部分。<br>如果添加多个成员，最佳做法是一次配置一个成员，并在添加更多新成员之前验证它是否正确启动.如果将新成员添加到1节点群集中，则群集无法在新成员启动之前取得进展，因为它需要两个成员作为多数才能达成共识。仅在<code>etcdctl``member add</code>通知集群有关新成员的时间和新成员成功建立与现有成员的连接的时间之间，才发生此行为。<br><strong>添加一个新的成员为领导者</strong><br>从v3.4开始，etcd支持将新成员添加为领导者/非投票成员。激励和设计可以在<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-learner.md" target="_blank" rel="noopener">设计文档</a>中找到。为了使添加新成员的过程更安全，并减少添加新成员时的集群停机时间.建议将新成员作为学习者添加到集群中，直到同步完成为止。 这可以描述为三步过程：</p><ul><li>通过<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">gRPC成员API</a>或者<code>etcdctl member add --learner</code>命令将新成员添加为学习者。</li><li>通过新的集群配置启动新的成员，新的集群配置包括被更新的成员(已存在的成员+新成员)和之前的步骤相同.</li><li>通过<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">gRPC成员API</a>或<code>etcdctl member promote</code>命令将新添加的学习者提升为有投票权的成员。etcd服务器验证升级请求以确保其运行安全.只有在其Raft日志达到领导者的水平之后，才能将学习者提升为有投票权的成员。如果学习者成员未赶上领导者的Raft日志，则成员升级请求将失败(见<a href="">提升成员错误案例</a>部分获取更多细节).这种情况下，用户应该等待并重试。</li></ul><p>在v3.4中，etcd服务器将群集可以拥有的学习者数量限制为一个。 主要考虑因素是限制由于领导者向学习者传播数据而导致的领导者额外工作量。<br>使用<code>etcdctl member add</code>和参数<code>--learner</code>添加一个新成员作为学习者到集群中.</p><pre><code>$ etcdctl member add infra3 --peer-urls=http://10.0.1.13:2380 --learnerMember 9bf1b35fc7761a23 added to cluster a7ef944b95711739ETCD_NAME=&quot;infra3&quot;ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380&quot;ETCD_INITIAL_CLUSTER_STATE=existing</code></pre><p>新的etcd程序添加新的学习者成员启动后，使用<code>etcdctl member promote</code>将学习者提升为投票成员。</p><pre><code>$ etcdctl member promote 9bf1b35fc7761a23Member 9e29bbaa45d74461 promoted in cluster a7ef944b95711739</code></pre><p><strong>添加成员错误案例</strong><br>在以下情况下，新主机不包含在枚举节点列表中。 如果这是一个新集群，则必须将该节点添加到初始集群成员列表中。</p><pre><code>$ etcd --name infra3 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state existingetcdserver: assign ids error: the member count is unequalexit 1</code></pre><p>在这种情况下，使用了与用于加入集群的地址（10.0.1.13:2380）不同的地址（10.0.1.14:2380）：</p><pre><code>$ etcd --name infra4 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra4=http://10.0.1.14:2380 \  --initial-cluster-state existingetcdserver: assign ids error: unmatched member while checking PeerURLsexit 1</code></pre><p>如果etcd开始使用已删除成员的数据目录，则etcd如果连接到集群中的任何活动成员，则会自动退出：</p><pre><code>$ etcdetcd: this member has been permanently removed from the cluster. Exiting.exit 1</code></pre><p><strong>添加成员为领导者错误案例</strong><br>当集群中含有一个领导者时不能添加领导者到集群中(v3.4):</p><pre><code>$ etcdctl member add infra4 --peer-urls=http://10.0.1.14:2380 --learnerError: etcdserver: too many learner members in cluster</code></pre><p><strong>提升成员为领导者错误案例</strong><br>如果学习者与领导者同步，则只能被提升为有投票权的成员。</p><pre><code>$ etcdctl member promote 9bf1b35fc7761a23Error: etcdserver: can only promote a learner member which is in sync with leader</code></pre><p>提升不是学习者的成员将失败。</p><pre><code>$ etcdctl member promote 9bf1b35fc7761a23Error: etcdserver: can only promote a learner member</code></pre><p>提升一个集群中不存在的成员将会失败：</p><pre><code>$ etcdctl member promote 12345abcdeError: etcdserver: member not found</code></pre><h3 id="严格的重新配置检查模式-strict-reconfig-check"><a href="#严格的重新配置检查模式-strict-reconfig-check" class="headerlink" title="严格的重新配置检查模式(-strict-reconfig-check)"></a>严格的重新配置检查模式(<code>-strict-reconfig-check</code>)</h3><p>如上所述，添加新成员的最佳实践是一次配置一个成员，并在添加更多新成员之前验证它是否正确启动。这种分步方法非常重要，因为如果未正确配置新添加的成员（例如，对等URL不正确），则群集可能会丢失仲裁。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP_JSON_API通过gRPC网关</title>
    <link href="undefined2019/11/23/blog/etcd/HTTP_JSON_API%E9%80%9A%E8%BF%87gRPC%E7%BD%91%E5%85%B3/"/>
    <url>2019/11/23/blog/etcd/HTTP_JSON_API%E9%80%9A%E8%BF%87gRPC%E7%BD%91%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_grpc_gateway.md" target="_blank" rel="noopener">HTTP JSON API through the gRPC gateway</a><br>etcd v3 使用 gRPC 作为消息协议。etcd项目包括一个基于gRPC的<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%AE%A2%E6%88%B7%E7%AB%AFv3/">Go客户端</a>和一个命令行工具，<a href="https://github.com/etcd-io/etcd/tree/master/etcdctl" target="_blank" rel="noopener">etcdctl</a>,通过gRPC与etcd集群进行交互.对于没有gRPC支持的语言，etcd提供JSON <a href="https://github.com/grpc-ecosystem/grpc-gateway" target="_blank" rel="noopener">gRPC网关</a>，这个网关提供一个RESTful风格的代理可以将HTTP/JSON请求转换为gRPC消息。</p><h3 id="使用-gRPC网关"><a href="#使用-gRPC网关" class="headerlink" title="使用 gRPC网关"></a>使用 gRPC网关</h3><p>这个网关接受一个到etcd’s buffer协议消息定义的JSON格式的映射,注意<code>Key</code>和<code>Value</code>字段定义为byte 数组，因此JSON必须使用base64编码,下面的例子使用<code>curl</code>,但是每个HTTP/JSON客户端的工作原理都和例子相同。<br><strong>注意</strong><br>gRPC网关节点从etcd v3.3发生变化：</p><ul><li>etcd v3.2以及之前版本只使用<code>[CLIENT-URL]/v3alpha/*</code>。</li><li>etcd v3.3使用<code>[CLIENT-URL]/v3beta/*</code>保持<code>[CLIENT-URL]/v3alpha/*</code>使用。</li><li>etcd v3.4使用<code>[CLIENT-URL]/v3/*</code>保持<code>[CLIENT-URL]/v3beta/*</code>使用。<ul><li><code>[CLIENT-URL]/v3alpha/*</code>被抛弃使用。</li></ul></li><li>etcd v3.5以及最新版本只使用<code>[CLIENT-URL]/v3/*</code>。<ul><li><code>[CLIENT-URL]/v3beta/*</code>被抛弃使用。</li></ul></li></ul><h3 id="存储和获取Keys"><a href="#存储和获取Keys" class="headerlink" title="存储和获取Keys"></a>存储和获取Keys</h3><p>使用<code>/v3/kv/range</code>和<code>/v3/kv/put</code>服务读和写Keys:</p><pre><code>&lt;&lt;COMMENThttps://www.base64encode.org/foo is &#39;Zm9v&#39; in Base64bar is &#39;YmFy&#39;COMMENTcurl -L http://localhost:2379/v3/kv/put \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;value&quot;: &quot;YmFy&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;3&quot;}}curl -L http://localhost:2379/v3/kv/range \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;3&quot;},&quot;kvs&quot;:[{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;2&quot;,&quot;version&quot;:&quot;1&quot;,&quot;value&quot;:&quot;YmFy&quot;}],&quot;count&quot;:&quot;1&quot;}# get all keys prefixed with &quot;foo&quot;curl -L http://localhost:2379/v3/kv/range \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;range_end&quot;: &quot;Zm9w&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;3&quot;},&quot;kvs&quot;:[{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;2&quot;,&quot;version&quot;:&quot;1&quot;,&quot;value&quot;:&quot;YmFy&quot;}],&quot;count&quot;:&quot;1&quot;}</code></pre><h3 id="查看-Keys"><a href="#查看-Keys" class="headerlink" title="查看 Keys"></a>查看 Keys</h3><p>使用<code>/v3/watch</code>服务查看Keys:</p><pre><code>curl -N http://localhost:2379/v3/watch \  -X POST -d &#39;{&quot;create_request&quot;: {&quot;key&quot;:&quot;Zm9v&quot;} }&#39; &amp;# {&quot;result&quot;:{&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;created&quot;:true}}curl -L http://localhost:2379/v3/kv/put \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;value&quot;: &quot;YmFy&quot;}&#39; &gt;/dev/null 2&gt;&amp;1# {&quot;result&quot;:{&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;events&quot;:[{&quot;kv&quot;:{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;2&quot;,&quot;version&quot;:&quot;1&quot;,&quot;value&quot;:&quot;YmFy&quot;}}]}}</code></pre><h3 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h3><p>使用``/v3/kv/txn`发行一个交易：</p><pre><code># 目标创建curl -L http://localhost:2379/v3/kv/txn \  -X POST \  -d &#39;{&quot;compare&quot;:[{&quot;target&quot;:&quot;CREATE&quot;,&quot;key&quot;:&quot;Zm9v&quot;,&quot;createRevision&quot;:&quot;2&quot;}],&quot;success&quot;:[{&quot;requestPut&quot;:{&quot;key&quot;:&quot;Zm9v&quot;,&quot;value&quot;:&quot;YmFy&quot;}}]}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;3&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;succeeded&quot;:true,&quot;responses&quot;:[{&quot;response_put&quot;:{&quot;header&quot;:{&quot;revision&quot;:&quot;3&quot;}}}]}</code></pre><pre><code># 目标版本curl -L http://localhost:2379/v3/kv/txn \  -X POST \  -d &#39;{&quot;compare&quot;:[{&quot;version&quot;:&quot;4&quot;,&quot;result&quot;:&quot;EQUAL&quot;,&quot;target&quot;:&quot;VERSION&quot;,&quot;key&quot;:&quot;Zm9v&quot;}],&quot;success&quot;:[{&quot;requestRange&quot;:{&quot;key&quot;:&quot;Zm9v&quot;}}]}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;6&quot;,&quot;raft_term&quot;:&quot;3&quot;},&quot;succeeded&quot;:true,&quot;responses&quot;:[{&quot;response_range&quot;:{&quot;header&quot;:{&quot;revision&quot;:&quot;6&quot;},&quot;kvs&quot;:[{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;6&quot;,&quot;version&quot;:&quot;4&quot;,&quot;value&quot;:&quot;YmF6&quot;}],&quot;count&quot;:&quot;1&quot;}}]}</code></pre><h3 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h3><p>使用<code>/v3/auth</code>设置权限：</p><pre><code># 创建root用户curl -L http://localhost:2379/v3/auth/user/add \  -X POST -d &#39;{&quot;name&quot;: &quot;root&quot;, &quot;password&quot;: &quot;pass&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}# 创建root角色curl -L http://localhost:2379/v3/auth/role/add \  -X POST -d &#39;{&quot;name&quot;: &quot;root&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}# 授予root角色curl -L http://localhost:2379/v3/auth/user/grant \  -X POST -d &#39;{&quot;user&quot;: &quot;root&quot;, &quot;role&quot;: &quot;root&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}# 开启认证curl -L http://localhost:2379/v3/auth/enable -X POST -d &#39;{}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}</code></pre><p>通过<code>/v3/auth/authenticate</code>服务使用一个认证令牌进行认证:</p><pre><code># 为根用户获取认证令牌curl -L http://localhost:2379/v3/auth/authenticate \  -X POST -d &#39;{&quot;name&quot;: &quot;root&quot;, &quot;password&quot;: &quot;pass&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;token&quot;:&quot;sssvIpwfnLAcWAQH.9&quot;}</code></pre><p>使用认证证书设置认证头部到认证令牌获取Keys：</p><pre><code>curl -L http://localhost:2379/v3/kv/put \  -H &#39;Authorization : sssvIpwfnLAcWAQH.9&#39; \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;value&quot;: &quot;YmFy&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;2&quot;}}</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gRPC命名与发现</title>
    <link href="undefined2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/"/>
    <url>2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/grpc_naming.md" target="_blank" rel="noopener">gRPC naming and discovery</a><br>etcd提供一个gRPC解析器支持备用的命名系统，该命名系统从etcd获取主机以发现gRPC服务。以下机制基于监视对以服务名称为前缀的Key的更新。<br>通过go-grpc使用etcd发现服务</p><hr><p>etcd客户端提供一个gRPC解析器通过etcd后端解析gRPC主机,解析器通过etcd客户端初始化并指定了解析目标:</p><pre><code>import (        &quot;go.etcd.io/etcd/clientv3&quot;        etcdnaming &quot;go.etcd.io/etcd/clientv3/naming&quot;        &quot;google.golang.org/grpc&quot;)...cli, cerr := clientv3.NewFromURL(&quot;http://localhost:2379&quot;)r := &amp;etcdnaming.GRPCResolver{Client: cli}b := grpc.RoundRobin(r)conn, gerr := grpc.Dial(&quot;my-service&quot;, grpc.WithBalancer(b), grpc.WithBlock(), ...)</code></pre><h3 id="管理服务主机"><a href="#管理服务主机" class="headerlink" title="管理服务主机"></a>管理服务主机</h3><p>etcd解析器对于解析目标前缀下所有Keys后面跟一个”/“(例如”my-service/“),使用JSON编码go-grpc<code>naming.Update</code>值作为潜在的服务主机。通过创建一个新的Key将主机添加到服务中，通过删除Keys将主机从服务中删除。</p><h3 id="添加一个主机"><a href="#添加一个主机" class="headerlink" title="添加一个主机"></a>添加一个主机</h3><p>一个新的主机可以通过<code>etcdctl</code>添加到服务中：</p><pre><code>ETCDCTL_API=3 etcdctl put my-service/1.2.3.4 &#39;{&quot;Addr&quot;:&quot;1.2.3.4&quot;,&quot;Metadata&quot;:&quot;...&quot;}&#39;</code></pre><p>etcd客户端的<code>GRPCResolver.Update</code>方法也可以通过key匹配<code>Addr</code>注册一个新的主机到服务中：</p><pre><code>r.Update(context.TODO(), &quot;my-service&quot;, naming.Update{Op: naming.Add, Addr: &quot;1.2.3.4&quot;, Metadata: &quot;...&quot;})</code></pre><h3 id="删除一个主机"><a href="#删除一个主机" class="headerlink" title="删除一个主机"></a>删除一个主机</h3><p>通过etcdctl可以从服务中删除一个主机:</p><pre><code>ETCDCTL_API=3 etcdctl del my-service/1.2.3.4</code></pre><p>etcd 客户端的<code>GRPCResolver.Update</code>方法也可以删除一个主机：</p><pre><code>r.Update(context.TODO(), &quot;my-service&quot;, naming.Update{Op: naming.Delete, Addr: &quot;1.2.3.4&quot;})</code></pre><h3 id="注册一个主机并绑定一个租约"><a href="#注册一个主机并绑定一个租约" class="headerlink" title="注册一个主机并绑定一个租约"></a>注册一个主机并绑定一个租约</h3><p>注册一个主机ging绑定一个租约确保如果主机不能维护保持存活的心跳(例如机器宕机)，该主机将会从服务中移除。</p><pre><code>lease=`ETCDCTL_API=3 etcdctl lease grant 5 | cut -f2 -d&#39; &#39;`ETCDCTL_API=3 etcdctl put --lease=$lease my-service/1.2.3.4 &#39;{&quot;Addr&quot;:&quot;1.2.3.4&quot;,&quot;Metadata&quot;:&quot;...&quot;}&#39;ETCDCTL_API=3 etcdctl lease keep-alive $lease</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>运行时重新配置设计</title>
    <link href="undefined2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/"/>
    <url>2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/runtime-reconf-design.md" target="_blank" rel="noopener">the runtime configuration design</a><br>运行时重新配置是分布式系统中最难，最容易出错的部分，尤其是在基于共识(像etcd)的系统中。<br>阅读并学习关于etcd的运行时重新配置命令设计和如何追溯这些错误.</p><h3 id="两阶段配置更新保证集群安全"><a href="#两阶段配置更新保证集群安全" class="headerlink" title="两阶段配置更新保证集群安全"></a>两阶段配置更新保证集群安全</h3><hr><p>在etcd中，每一次运行时重新配置安全的原因是由于<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">两阶段</a>更新。例如，添加一个成员，首先将新配置通知集群后启动新的成员。</p><ol><li>阶段一 通知集群关于新的配置<br>添加一个成员到etcd集群中，通过API调用请求将一个新成员添加到集群中。这是将新的成员添加到集群中唯一的方法。当集群同意配置的更新后将返回API的调用。</li><li>阶段二 启动一个新的成员<br>将一个新成员加入到存在的集群中，指定正确的<code>initial-cluster</code>和设置<code>initial-cluster-state</code>为<code>existing</code>.当成员启动后，它首先联系已存在的集群并验证当前集群配置是否和期望的<code>initial-cluster</code>匹配。当一个新的成员成功启动，集群将获得期望的配置。</li></ol><p>用户将过程分为两个阶段需要清楚了解集群成员关系的变化。实际上，这为用户提供了更大的灵活性，并使事情更容易。例如，如果试图添加一个与集群中现有的成员Id相同的新成员到集群中，操作将会立即失败由于阶段一并没有影响到运行中的集群。提供了类似的保护阻止通过错误操作添加新的成员。如果一个新的etcd成员试图在集群接受配置信息更新之前加入集群，操作将不会被集群接受。</p><p>如果没有围绕集群成员关系的显式工作流，集群将会容易受到意料之外的集群成员关系变化的影响。例如，如果etcd在一个初始化的系统如systemd中运行，etcd将会通过成员关系API在重新启动之后被移除，并试图在启动后重新加入。这个循环将会在每次通过API成员移除并将系统设置为失败后重新启动etcd时继续，这是预料之外的。</p><p>我们希望运行时重新进行配置是不常见的操作。我们决定保持为显式的由用户驱动来确保配置安全，保持集群平稳运行在显式的控制下。</p><h3 id="永久性的丢失要求新的集群"><a href="#永久性的丢失要求新的集群" class="headerlink" title="永久性的丢失要求新的集群"></a>永久性的丢失要求新的集群</h3><hr><p>如果一个集群永久丢失一些主要的集群成员，需要从原始的数据文件夹启动一个新的集群恢复先前的状态。</p><p>完全有可能从已存在的集群中强制删除一个失败的成员并恢复。然而，我们决定不支持此方法因为他绕过了常规的共识提交阶段，这是不安全的。如果成员移除一个没有实际失败的成员或者是同一个集群中的不同成员，etcd将会最终得到具有相同集群Id的分散集群。这是非常危险的而且很难修复。</p><p>通过正常的部署，永久性丢失的可能性非常的小。但是这是一个严重的问题值得特别注意。我们强烈建议阅读<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md" target="_blank" rel="noopener">灾难恢复文档</a>并且在将etcd部署到生产环境之前做充足的准备。</p><h3 id="不要在运行时重新配置中使用公共的发现服务"><a href="#不要在运行时重新配置中使用公共的发现服务" class="headerlink" title="不要在运行时重新配置中使用公共的发现服务"></a>不要在运行时重新配置中使用公共的发现服务</h3><hr><p>公共发现服务应该只在启动一个集群的时候使用。将一个成员加入已存在的集群，使用运行时配置API.</p><p>发现服务被设计用来在云服务环境中启动一个在所有的成员无法提前知道Ip地址时的etcd集群。在成功启动一个集群时，所有的成员将会知道Ip地址。典型的，发现服务奖不再被需要。<br>看起来使用公共的发现服务进行运行时重新配置是一个便利的方法,毕竟所有的发现服务含有所有的集群配置信息。然而依赖公共发现服务将带来问题：</p><ol><li>将会引进外部独立性到集群的整个生命周期，不只是启动时间。如果集群和公共发现服务之间存在网络问题，则群集将因此受到影响。</li><li>公共发现服务必须在集群的生命周期内反映正确的运行时配置，将需要提供安全机制避免坏的行为，而这是困难的。</li><li>公共发现服务需要保持数万个集群的配置，而我们的公共发现服务很难承受这种负载。</li></ol><p>为了使发现服务支持运行时配置，最好的选择是建立一个私有的发现服务。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>与etcd进行交互</title>
    <link href="undefined2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/"/>
    <url>2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/interacting_v3.md" target="_blank" rel="noopener">Interacting with etcd</a></p><h2 id="与etcd进行交互"><a href="#与etcd进行交互" class="headerlink" title="与etcd进行交互"></a>与etcd进行交互</h2><p>用户更多的是通过putting或者是getting从etcd获取一个键对应的值。这一部分描述了如何通过etcdctl做这些工作。etcdctl是一个与etcd服务器进行交互的命令行工具.这里的描述适用于gRPC APIs或者是客户端库的APIs。<br>用于与etcd交互的API版本可以通过环境变量<code>ETCDCTL_API</code>设置为2或者3.默认情况下，分支为(3.4)的主版本使用V3 的API，而早期的版本(3.3或者更早)默认使用V2 API。<br>注意使用V2 API所创建的任何Key不能够通过V3 API进行访问。而V3 API <code>etcdctl get</code>获取V2 的Key将返回0并退出，这是预料之中的情况。</p><pre><code>export ETCDCTL_API=3</code></pre><h3 id="发现版本"><a href="#发现版本" class="headerlink" title="发现版本"></a>发现版本</h3><p>使用合适的命令在执行不同版本的etcd时etcdctl和服务器API的版本将会有用。<br>这里的命令可用于发现版本信息：</p><pre><code>$ etcdctl versionetcdctl version:3.1.0-alpha.0+gitAPI version:3.1</code></pre><h3 id="写入一个KEY"><a href="#写入一个KEY" class="headerlink" title="写入一个KEY"></a>写入一个KEY</h3><p>应用程序通过向etcd集群写入Keys来存储Keys，每次存储的Key将会通过Raft协议实现一致性与可扩展性复制到所有的etcd集群成员中。<br>这里的命令是将Key<code>foo</code>的值存储到<code>bar</code>上：</p><pre><code>$ etcdctl put foo barOK</code></pre><p>给Key附上一个租约，Key将在一个具体的时间间隔被设置。<br>这里的命令是在10秒后将Key<code>foo</code>的值存储到<code>bar</code>上：</p><pre><code>$ etcdctl put foo1 bar1 --lease=1234abcd</code></pre><p>注意：以上命令中租约ID为1234abcd将会在租约创建10秒后将id返回，这个id将附在Key上。</p><h3 id="读取Keys"><a href="#读取Keys" class="headerlink" title="读取Keys"></a>读取Keys</h3><p>应用程序可以从一个etcd集群中读取Key，可能会查询到单个Key，或者是一个范围内的Key。<br>比如etcd集群中存储以下Key：</p><pre><code>foo = barfoo1 = bar1foo2 = bar2foo3 = bar3</code></pre><p>这里的命令是读取Key<code>foo</code>对应的值：</p><pre><code>$ etcdctl get foofoobar</code></pre><p>这里的命令是读取Key<code>foo</code>对应的十六进制的值:</p><pre><code>$ etcdctl get foo --hex\x66\x6f\x6f       #Key\x62\x61\x72       #Value</code></pre><p>这里的命令是只读取Key<code>foo</code>对应的值：</p><pre><code>$ etcdctl get foo --print-value-onlybar</code></pre><p>这里的命令是读取从Key<code>foo</code>到Key<code>foo3</code>范围内对应的值：</p><pre><code>$ etcdctl get foo foo3foobarfoo1bar1foo2bar2</code></pre><p>注意这里Key为<code>foo3</code>不包括在内因为这里的范围是半开区间<code>[foo,foo3)</code>，不包括<code>foo3</code>。</p><p>这里的命令是获取前缀为<code>foo</code>的Key的范围内所有的值：</p><pre><code>$ etcdctl get --prefix foofoobarfoo1bar1foo2bar2foo3bar3</code></pre><p>这里的命令是获取前缀为<code>foo</code>的Key的范围内所有的值,并且限制结果集为2：</p><pre><code>$ etcdctl get --prefix --limit=2 foofoobarfoo1bar1</code></pre><h3 id="读取之前版本的Keys："><a href="#读取之前版本的Keys：" class="headerlink" title="读取之前版本的Keys："></a>读取之前版本的Keys：</h3><p>应用程度可能希望读取一个被替代的版本的Key。例如，一个应用程序可能想要通过读取一个先前版本的Key来回滚到一个老的配置。另外，一个应用程序可能想要通过访问Key的历史记录对多个Key通过多个请求获取一致性的结果。由于对etcd集群中键值对的每一次修改都会增加对在etcd集群中的全局修订存储，应用程序可以通过提供一个老的版本来读取被替代的Keys。<br>比如一个etcd集群中存在以下的Keys：</p><pre><code>foo = bar         # revision = 2foo1 = bar1       # revision = 3foo = bar_new     # revision = 4foo1 = bar1_new   # revision = 5</code></pre><p>这里的例子是访问过去版本的Keys：</p><pre><code>$ etcdctl get --prefix foo # access the most recent versions of keysfoobar_newfoo1bar1_new$ etcdctl get --prefix --rev=4 foo # access the versions of keys at revision 4foobar_newfoo1bar1$ etcdctl get --prefix --rev=3 foo # access the versions of keys at revision 3foobarfoo1bar1$ etcdctl get --prefix --rev=2 foo # access the versions of keys at revision 2foobar$ etcdctl get --prefix --rev=1 foo # access the versions of keys at revision 1</code></pre><h3 id="读取大于或等于一个具体的Key的比特值的Key："><a href="#读取大于或等于一个具体的Key的比特值的Key：" class="headerlink" title="读取大于或等于一个具体的Key的比特值的Key："></a>读取大于或等于一个具体的Key的比特值的Key：</h3><p>应用程序可能想要读取大于或等于一个具体的Key的byte值的Key。<br>一个etcd集群中有以下的Keys：</p><pre><code>a = 123b = 456z = 789</code></pre><p>这里的命令是读取大于或等于Key <code>b</code>的byte值的Key：</p><pre><code>$ etcdctl get --from-key bb456z789</code></pre><h3 id="删除-Keys"><a href="#删除-Keys" class="headerlink" title="删除 Keys"></a>删除 Keys</h3><p>应用程序可以从etcd集群中删除一个Key或者删除一个范围内的Key：<br>一个etcd集群中有以下的Keys：</p><pre><code>foo = barfoo1 = bar1foo3 = bar3zoo = valzoo1 = val1zoo2 = val2a = 123b = 456z = 789</code></pre><p>这里的命令是删除Key<code>foo</code>:</p><pre><code>$ etcdctl del foo1 # 1 个 key 被删除</code></pre><p>这里的命令是删除从Key<code>foo</code>到Key<code>foo9</code>范围内的Key:</p><pre><code>$ etcdctl del foo foo92 # 2 个 keys 被删除</code></pre><p>这里的命令是删除Key<code>zoo</code>并将已删除的键值对返回:</p><pre><code>$ etcdctl del --prev-kv zoo1   # 1 个 key 被删除zoo # 被删除的Keyval # 被删除的Key所对应的Value</code></pre><p>这里的命令是删除前缀为<code>zoo</code>的Keys:</p><pre><code>$ etcdctl del --prefix zoo2 # 2 个 key 被删除</code></pre><p>这里的命令是读取大于或等于Key <code>b</code>的byte值的Keys：</p><pre><code>$ etcdctl del --from-key b2 # 2 个 key 被删除</code></pre><h3 id="观察key的变化"><a href="#观察key的变化" class="headerlink" title="观察key的变化"></a>观察key的变化</h3><p>应用程序可以监视一个Key或者一个范围内的Keys的每一次更新。<br>这里的命令是观察key<code>foo</code>:</p><pre><code>$ etcdctl watch foo# 在另一个终端执行: etcdctl put foo barPUTfoobar</code></pre><p>这里的命令是观察十六进制的key<code>foo</code>:</p><pre><code>$ etcdctl watch foo --hex# 在另一个终端执行: etcdctl put foo barPUT\x66\x6f\x6f          # Key\x62\x61\x72          # Value</code></pre><p>这里的命令是观察从Key<code>foo</code>到Key<code>foo9</code>范围内的Key：</p><pre><code>$ etcdctl watch foo foo9# 在另一个终端执行: etcdctl put foo barPUTfoobar# 在另一个终端执行: etcdctl put foo1 bar1PUTfoo1bar1</code></pre><p>这里的命令是观察前缀为<code>foo</code>的Key的范围内所有的值：</p><pre><code>$ etcdctl watch --prefix foo# 在另一个终端执行: etcdctl put foo barPUTfoobar# 在另一个终端执行: etcdctl put fooz1 barz1PUTfooz1barz1</code></pre><p>这里的命令是观察多个Keys<code>foo</code>和<code>zoo</code>:</p><pre><code>$ etcdctl watch -i$ watch foo$ watch zoo# 在另一个终端执行: etcdctl put foo barPUTfoobar# 在另一个终端执行: etcdctl put zoo valPUTzooval</code></pre><h3 id="观察Keys的历史版本"><a href="#观察Keys的历史版本" class="headerlink" title="观察Keys的历史版本"></a>观察Keys的历史版本</h3><p>应用程序可能想要观察etcd中Keys的更新历史。例如，应用程序可能想获取key的所有修改；如果应用程序保持与etcd的连接，那么命令<code>watch</code>已经足够。然而，如果应用程序或者etcd宕机，一次更新可能就会失败，应用程序可能不能实时接收Key的更新。为了保证更新可以被交付，应用程序必须通过观察到Keys的历史更新。为了做到这些，应用程序要指定观察的历史版本，就像读取历史版本的Keys：<br>我们首先完成以下操作：</p><pre><code>$ etcdctl put foo bar         # revision = 2OK$ etcdctl put foo1 bar1       # revision = 3OK$ etcdctl put foo bar_new     # revision = 4OK$ etcdctl put foo1 bar1_new   # revision = 5OK</code></pre><p>这里有个例子观察历史更新：</p><pre><code># watch for changes on key `foo` since revision 2$ etcdctl watch --rev=2 fooPUTfoobarPUTfoobar_new</code></pre><pre><code># watch for changes on key `foo` since revision 3$ etcdctl watch --rev=3 fooPUTfoobar_new</code></pre><p>这里有例子只观察最后一次的更新：</p><pre><code># watch for changes on key `foo` and return last revision value along with modified value$ etcdctl watch --prev-kv foo# 在另一个终端执行 etcdctl put foo bar_latestPUTfoo         # keybar_new     # last value of foo key before modificationfoo         # keybar_latest  # value of foo key after modification</code></pre><h3 id="观察进度"><a href="#观察进度" class="headerlink" title="观察进度"></a>观察进度</h3><p>应用程序可能想要检查观察者进度以确定最新的观察者流的状态。例如，如果观察者更新的缓存，那么就可以通过原子读取与修改进度进行比较知道缓存内容是否已经过时。<br>进度请求可以通过<code>progress</code>命令与观察者session进行交互在一个观察者流中告诉服务器发送一个进度提示更新.</p><pre><code>$ etcdctl watch -i$ watch a$ progressprogress notify: 1# 在另一个终端执行: etcdctl put x 0# 在另一个终端执行: etcdctl put y 1$ progressprogress notify: 3</code></pre><p>注意，在进度提示响应中的修改号来自观察者流连接到的本地etcd服务器。如果该节点被分区并且不是该分区的一部分，这个进度提示修改版本可能会低于由未分区的etcd服务器节点返回的修改版本。</p><h3 id="压缩修改"><a href="#压缩修改" class="headerlink" title="压缩修改"></a>压缩修改</h3><p>正如我们提到的，etcd保持修改信息所以应用可以读取过去版本的Keys，然而，为了避免无数的修改历史累积，对过去的修改进行压缩是很重要的。在压缩后，etcd移除了历史修改，释放资源为以后使用。在压缩修改版本之前所有的被修改的替代版本数据将不能获取。<br>这里的命令是对修改进行压缩：</p><pre><code>$ etcdctl compact 5compacted revision 5# any revisions before the compacted one are not accessible$ etcdctl get --rev=4 fooError:  rpc error: code = 11 desc = etcdserver: mvcc: required revision has been compacted</code></pre><p>注意：etcd服务器的当前版本可以使用json格式的命令通过(存在或不存在的)key发现。例如下面的通过查看在etcd服务器中不存在的myKey:</p><pre><code>$ etcdctl get mykey -w=json{&quot;header&quot;:{&quot;cluster_id&quot;:14841639068965178418,&quot;member_id&quot;:10276657743932975437,&quot;revision&quot;:15,&quot;raft_term&quot;:4}}</code></pre><h3 id="授予租约"><a href="#授予租约" class="headerlink" title="授予租约"></a>授予租约</h3><p>应用程序可以为etcd集群上的Keys授予一个租约。当Key附上租约后，它的生命周期会绑定到租约的生命周期并由存活时间(TTL)进行管理。每一个租约都有一个由应用程序授予的最小的TTL值.这个租约实际的TTL值至少是最小的TTL值，由etcd集群决定。一旦超过租约的TTL，租约将会超时并删除附上的所有的Keys。<br>这里有命令授予一个租约：</p><pre><code># grant a lease with 60 second TTL$ etcdctl lease grant 60lease 32695410dcc0ca06 granted with TTL(60s)# attach key foo to lease 32695410dcc0ca06$ etcdctl put --lease=32695410dcc0ca06 foo barOK</code></pre><h3 id="撤销租约"><a href="#撤销租约" class="headerlink" title="撤销租约"></a>撤销租约</h3><p>应用程序可以根据租约ID撤销租约，撤销一个租约将删除附上的所有的Keys。<br>例如我们完成下面的操作：</p><pre><code>$ etcdctl lease grant 60lease 32695410dcc0ca06 granted with TTL(60s)$ etcdctl put --lease=32695410dcc0ca06 foo barOK</code></pre><p>这里的命令可以撤销该租约：</p><pre><code>$ etcdctl lease revoke 32695410dcc0ca06lease 32695410dcc0ca06 revoked$ etcdctl get foo# empty response since foo is deleted due to lease revocation</code></pre><h3 id="保持租约存活"><a href="#保持租约存活" class="headerlink" title="保持租约存活"></a>保持租约存活</h3><p>应用程序可以通过刷新租约的TTL使它不会超时保证租约存活。<br>例如我们完成下面的操作：</p><pre><code>$ etcdctl lease grant 60lease 32695410dcc0ca06 granted with TTL(60s)</code></pre><p>这里有命令保持租约存活：</p><pre><code>$ etcdctl lease keep-alive 32695410dcc0ca06lease 32695410dcc0ca06 keepalived with TTL(60)lease 32695410dcc0ca06 keepalived with TTL(60)lease 32695410dcc0ca06 keepalived with TTL(60)...</code></pre><h3 id="获取租约信息"><a href="#获取租约信息" class="headerlink" title="获取租约信息"></a>获取租约信息</h3><p>应用程序可能想知道关于租约的信息，所以可以通过重新创建或者检查租约是否仍然生存或已经超时。应用程序可能也想知道一个具体的租约上所附的Key。<br>例如我们完成下面的操作：</p><pre><code># grant a lease with 500 second TTL$ etcdctl lease grant 500lease 694d5765fc71500b granted with TTL(500s)# attach key zoo1 to lease 694d5765fc71500b$ etcdctl put zoo1 val1 --lease=694d5765fc71500bOK# attach key zoo2 to lease 694d5765fc71500b$ etcdctl put zoo2 val2 --lease=694d5765fc71500bOK</code></pre><p>这里有命令获取关于租约的信息:</p><pre><code>$ etcdctl lease timetolive 694d5765fc71500blease 694d5765fc71500b granted with TTL(500s), remaining(258s)</code></pre><p>这里有命令获取租约上所依附的关于Keys的信息：</p><pre><code>$ etcdctl lease timetolive --keys 694d5765fc71500blease 694d5765fc71500b granted with TTL(500s), remaining(132s), attached keys([zoo2 zoo1])# if the lease has expired or does not exist it will give the below response:Error:  etcdserver: requested lease not found</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>客户端v3</title>
    <link href="undefined2019/11/23/blog/etcd/%E5%AE%A2%E6%88%B7%E7%AB%AFv3/"/>
    <url>2019/11/23/blog/etcd/%E5%AE%A2%E6%88%B7%E7%AB%AFv3/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/clientv3/README.md" target="_blank" rel="noopener">etcd/clientv3</a><br><code>etcd/clientv3</code>是v3版本的Go etcd官方客户端</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><hr><pre><code>go get go.etcd.io/etcd/clientv3</code></pre><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><hr><p>创建客户端使用<code>clientv3.New</code>:</p><pre><code>cli, err := clientv3.New(clientv3.Config{    Endpoints:   []string{&quot;localhost:2379&quot;, &quot;localhost:22379&quot;, &quot;localhost:32379&quot;},    DialTimeout: 5 * time.Second,})if err != nil {    // handle error!}defer cli.Close()</code></pre><p>etcd v3使用<code>gRPC</code>进行远程程序调用，并且<code>clientv3</code>使用<code>grpc-go</code>连接etcd。确保在使用完客户端后关闭它，如果客户端没有关闭，连接将会有泄漏的<code>goroutines</code>。指定超时时间，通过<code>context.WithTimeout</code>使用APIs:</p><pre><code>ctx, cancel := context.WithTimeout(context.Background(), timeout)resp, err := cli.Put(ctx, &quot;sample_key&quot;, &quot;sample_value&quot;)cancel()if err != nil {    // handle error!}// use the response</code></pre><p>为了完全兼容，建议使用etcd’s中的vendored包进行构建，使用工具像<code>golang/dep</code>,在vendor目录内。</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>etcd客户端返回两种类型的错误：</p><ol><li>context error :canceled or deadline exceeded.</li><li>gRpc error : 看api/v3rpc/rpctypes.</li></ol><p>这里有例子处理客户端错误：</p><pre><code>resp, err := cli.Put(ctx, &quot;&quot;, &quot;&quot;)if err != nil {    switch err {    case context.Canceled:        log.Fatalf(&quot;ctx is canceled by another routine: %v&quot;, err)    case context.DeadlineExceeded:        log.Fatalf(&quot;ctx is attached with a deadline is exceeded: %v&quot;, err)    case rpctypes.ErrEmptyKey:        log.Fatalf(&quot;client-side error: %v&quot;, err)    default:        log.Fatalf(&quot;bad cluster endpoints, which are not etcd servers: %v&quot;, err)    }}</code></pre><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>etcd客户端可以通过<strong>go-grpc-prometheus</strong>,选择RPC监控指标,看<strong>例子</strong>。</p><h2 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h2><p><strong>namespace</strong>包提供<code>clientv3</code>接口封装透明隔离客户端请求到用户定义的前缀。</p><h2 id="请求大小限制"><a href="#请求大小限制" class="headerlink" title="请求大小限制"></a>请求大小限制</h2><p>客户端请求大小限制通过<code>clientv3.Config.MaxCallSendMsgSize</code>和<code>MaxCallRecvMsgSize</code>进行配置。如果没有给予值，客户端请求发送限制包括gRPC负载默认2MB。接收限制默认为<code>math.MaxInt32</code>。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>更多代码例子可以从<strong>GoDoc</strong>发现。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>多机集群</title>
    <link href="undefined2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/"/>
    <url>2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md" target="_blank" rel="noopener">cluster on multiple machines</a></p><h1 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h1><hr><p>启动一个集群静态的要求是每一个集群中的成员需要知道其他成员的位置。在许多情况下，集群成员的IP可能无法提前知道。在这种情况下，etcd集群可以在发现服务的帮助下进行启动。<br>一旦etcd集群已经启动，添加或移除成员可以通过<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时重新配置</a>。在运行时重新配置之前，为了更好地理解设计，我们建议读<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/">运行时重新配置设计文档</a>。<br>这篇引导etcd集群的启动将包括以下机制：</p><ul><li>静态</li><li>etcd发现</li><li>DNS发现</li></ul><p>每种引导机制都将用于创建具有以下详细信息的三台计算机etcd集群：</p><table><thead><tr><th>Name</th><th>Address</th><th>Hostname</th></tr></thead><tbody><tr><td>infra0</td><td>10.0.1.10</td><td>infra0.example.com</td></tr><tr><td>infra1</td><td>10.0.1.11</td><td>infra1.example.com</td></tr><tr><td>infra2</td><td>10.0.1.12</td><td>infra2.example.com</td></tr></tbody></table><h2 id="静态"><a href="#静态" class="headerlink" title="静态"></a>静态</h2><p>集群的成员，在启动之前它们的地址和集群的大小，我们可以通过设置<code>initial-cluster</code>参数使用离线的启动配置。每一个机器将会通过以下的环境变量或命令行获得配置信息：</p><pre><code>ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380&quot;ETCD_INITIAL_CLUSTER_STATE=new</code></pre><pre><code>--initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \--initial-cluster-state new</code></pre><p>注意在<code>initial-cluster</code>中的URLs必须是已发布的对等的节点的URLs，即它们应该和对应的节点上的<code>initial-advertise-peer-urls</code>的值对应。<br>如果为了测试的目的通过相同的配置分解多集群(或者创建和删除单个集群)，值得注意的是每一个集群应该给予独一无二的<code>initial-cluster-token</code>,通过做这些工作，即使它们具有相同的配置,etcd也可以为集群成员生成独一无二的集群Id和成员ID。这样可以在可能会扰乱集群的跨集群中交互中保护etcd。<br>etcd监听在<code>listen-client-urls</code>接受客户端流量，etcd将<code>advertise-client-urls</code>中指定的URLs告诉其他成员，代理，客户端。请确保潜在的客户端可以获取<code>advertise-client-urls</code>。一个常见的错误当远程的客户端应该访问etcd时设置<code>advertise-client-urls</code>为localhost或者将其保留为默认值。<br>在每一台机器上，通过这些参数启动etcd：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \  --listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.12:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><p>以<code>initial-cluster</code>开头的命令行参数将在etcd启动后被忽略。在初始化启动后可以自由删除环境变量或者命令行参数。如果配置信息在启动之后需要改变(例如在/从集群中添加或删除成员),看<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时配置</a>引导。</p><h3 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h3><p>etcd支持通过TLS协议进行加密通信。TLS通道可以在集群内部通信使用，也可以在节点和客户端流量通信时使用。这一部分列举了为节点和客户端TLS通信的集群设置。添加的etcd的TLS支持信息细节可以在<a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">安全引导</a>中发现。</p><h4 id="自签名证书"><a href="#自签名证书" class="headerlink" title="自签名证书"></a>自签名证书</h4><p>一个集群使用自签名证书加密流量和连接权限。使用自签名证书启动一个集群，每一个集群成员都需要含有一个独一无二的由共享的集群CA证书(<code>ca.crt</code>)签名的秘钥对(<code>member.crt</code>,<code>member.key</code>)，用于节点连接和客户端连接。证书可以通过下面的etcd<a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">TLS设置</a>例子中生成。<br>对于每一台机器，etcd应该通过这些参数启动：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls https://10.0.1.10:2380 \  --listen-peer-urls https://10.0.1.10:2380 \  --listen-client-urls https://10.0.1.10:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.10:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --client-cert-auth --trusted-ca-file=/path/to/ca-client.crt \  --cert-file=/path/to/infra0-client.crt --key-file=/path/to/infra0-client.key \  --peer-client-cert-auth --peer-trusted-ca-file=ca-peer.crt \  --peer-cert-file=/path/to/infra0-peer.crt --peer-key-file=/path/to/infra0-peer.key</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls https://10.0.1.11:2380 \  --listen-peer-urls https://10.0.1.11:2380 \  --listen-client-urls https://10.0.1.11:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.11:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --client-cert-auth --trusted-ca-file=/path/to/ca-client.crt \  --cert-file=/path/to/infra1-client.crt --key-file=/path/to/infra1-client.key \  --peer-client-cert-auth --peer-trusted-ca-file=ca-peer.crt \  --peer-cert-file=/path/to/infra1-peer.crt --peer-key-file=/path/to/infra1-peer.key</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls https://10.0.1.12:2380 \  --listen-peer-urls https://10.0.1.12:2380 \  --listen-client-urls https://10.0.1.12:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.12:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --client-cert-auth --trusted-ca-file=/path/to/ca-client.crt \  --cert-file=/path/to/infra2-client.crt --key-file=/path/to/infra2-client.key \  --peer-client-cert-auth --peer-trusted-ca-file=ca-peer.crt \  --peer-cert-file=/path/to/infra2-peer.crt --peer-key-file=/path/to/infra2-peer.key</code></pre><h4 id="自动化证书"><a href="#自动化证书" class="headerlink" title="自动化证书"></a>自动化证书</h4><p>如果集群需要加密通信但是不需要连接时权限认证,etcd可以配置为自动生成秘钥.在初始化阶段,etcd成员基于他们的Ip地址和主机生成自己的秘钥.<br>在每一台主机上,etcd需要根据这些参数进行启动:</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls https://10.0.1.10:2380 \  --listen-peer-urls https://10.0.1.10:2380 \  --listen-client-urls https://10.0.1.10:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.10:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --auto-tls \  --peer-auto-tls</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls https://10.0.1.11:2380 \  --listen-peer-urls https://10.0.1.11:2380 \  --listen-client-urls https://10.0.1.11:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.11:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --auto-tls \  --peer-auto-tls</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls https://10.0.1.12:2380 \  --listen-peer-urls https://10.0.1.12:2380 \  --listen-client-urls https://10.0.1.12:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.12:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --auto-tls \  --peer-auto-tls</code></pre><h4 id="错误案例"><a href="#错误案例" class="headerlink" title="错误案例"></a>错误案例</h4><p>在以下的例子中，新的主机没有包含在枚举的节点列表中，如果这是一个新的集群，节点需要被添加到初始化集群成员的列表中。</p><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls https://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --initial-cluster infra0=http://10.0.1.10:2380 \  --initial-cluster-state newetcd: infra1 not listed in the initial cluster configexit 1</code></pre><p>在以下的例子中，我们试图映射一个节点(infra0)到一个不同的地址(127.0.0.1:2380)，而它在集群列表中的地址为(10.0.1.10:2380).如果这个节点监听多个端口，所有地址都必须要反射到<code>initial-cluster</code>参数配置中。</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://127.0.0.1:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state=newetcd: error setting up initial cluster: infra0 has different advertised URLs in the cluster and advertised peer URLs listexit 1</code></pre><p>如果一个节点被配置成不同集群的参数并试图加入这个集群，etcd将会报出集群ID不匹配并退出.</p><pre><code>$ etcd --name infra3 --initial-advertise-peer-urls http://10.0.1.13:2380 \  --listen-peer-urls http://10.0.1.13:2380 \  --listen-client-urls http://10.0.1.13:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.13:2379 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra3=http://10.0.1.13:2380 \  --initial-cluster-state=newetcd: conflicting cluster ID to the target cluster (c6ab534d07e8fcc4 != bc25ea2a74fb18b0). Exiting.exit 1</code></pre><h3 id="发现服务"><a href="#发现服务" class="headerlink" title="发现服务"></a>发现服务</h3><p>在许多案例中，集群节点不能提前知道Ip地址。这在云服务提供商或者是使用DHCP的网络中很常见。在这种情况下，使用一个存在的etcd集群来启动一个新的节点而不是进行静态的配置，这个过程称为”节点发现”.</p><p>有两种方法可以用来发现节点:</p><ul><li>etcd发现服务</li><li>DNS SRV 记录</li></ul><h4 id="etcd-发现服务"><a href="#etcd-发现服务" class="headerlink" title="etcd 发现服务"></a>etcd 发现服务</h4><p>为了更好理解发现服务协议的设计，我们建议阅读发现服务协议<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-internal/discovery_protocol.md" target="_blank" rel="noopener">文档</a>.<br><strong>发现服务URL的生命周期</strong><br>一个发现URL标识一个独有的etcd集群而不是使用已有的发现URL。每一个etcd实例分享一个新的发现URL去启动新的集群。<br>此外，发现URL应该只在初始化启动集群的时候使用，如果需要改变已经启动的集群中的成员关系，看<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时重新配置</a>引导.<br><strong>自定义etcd发现服务</strong><br>发现服务用于启动一个存在的集群，如果使用一个私有的etcd集群，像这样创建URL:</p><pre><code>$ curl -X PUT https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83/_config/size -d value=3</code></pre><p>通过设置URL中Key的大小，创建发现URL的集群预期大小为3.<br>在这种情况下URL将会这样使用:</p><pre><code>https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><p>当etcd成员启动时将使用</p><pre><code>https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><p>文件夹进行注册。<br><strong>每一个成员必须含有一个不同的命名参数。<code>Hostname</code>或者<code>machine-id</code>将是一个好的选择。发现服务的失败通常由于重复的名字。</strong><br>现在我们通过这些参数启动etcd的每一个成员：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \  --listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.12:2379 \  --discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><p>一旦所有主机被注册后，每一个集群成员将会集群启动之前在自定义发现服务中注册自己。<br><strong>公共的etcd发现服务</strong><br>如果没有可以获得的集群，使用托管在<code>discovery.etcd.io</code>的公共发现服务。通过”new”主机,创建一个私有的发现URL,使用以下命令:</p><pre><code>$ curl https://discovery.etcd.io/new?size=3https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><p>将会创建一个初始化成员数量为3的集群,如果没有设置大小，将默认为3.</p><pre><code>ETCD_DISCOVERY=https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><pre><code>--discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><p>现在我们通过这些相关的参数启动每一个etcd成员：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \  --listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.12:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><p>一旦所有主机被注册后，每一个集群成员将会集群启动之前在自定义发现服务中注册自己。<br>etcd使用环境变量<code>ETCD_DISCOVERY_PROXY</code>通过HTTP代理连接发现服务。<br><strong>错误和警告案例</strong><br>发现服务错误：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573deetcd: error: the cluster doesn’t have a size configuration value in https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de/_configexit 1</code></pre><p>警告<br>这里有一个严重的警告表明发现服务URL将被这台主机忽略。</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573deetcdserver: discovery token ignored since a cluster has already been initialized. Valid log found at /var/lib/etcd</code></pre><h3 id="DNS-发现服务"><a href="#DNS-发现服务" class="headerlink" title="DNS 发现服务"></a>DNS 发现服务</h3><p>DNS <a href="http://www.ietf.org/rfc/rfc2052.txt" target="_blank" rel="noopener">SRV 记录</a>可以用来作为发现机制。<code>--discovery-srv</code>参数可用于设置可以找到发现SRV记录的DNS域名。 设置<code>--discovery-srv example.com</code>会导致DNS SRV记录按照列出的顺序进行查找：</p><ul><li>_etcd-server-ssl._tcp.example.com</li><li>_etcd-server._tcp.example.com</li></ul><p>如果找到<code>_etcd-server-ssl._tcp.example.com</code>，则etcd将尝试通过TLS进行引导过程。<br>为了帮助客户端发现etcd集群，按照列出的顺序查找以下DNS SRV记录：</p><ul><li>_etcd-client._tcp.example.com</li><li>_etcd-client-ssl._tcp.example.com</li></ul><p>如果找到了<code>_etcd-client-ssl._tcp.example.com</code>，则客户端将尝试通过SSL/TLS与etcd集群进行通信。<br>如果etcd使用TLS，则发现SRV记录（例如example.com）必须与主机名一起包含在SSL证书DNS SAN中，否则集群将失败，并显示以下日志消息：</p><pre><code>[...] rejected connection from &quot;10.0.1.11:53162&quot; (error &quot;remote error: tls: bad certificate&quot;, ServerName &quot;example.com&quot;)</code></pre><p>如果etcd使用的是没有自定义证书颁发机构的TLS，则发现域（例如example.com）必须与SRV记录域（例如infra1.example.com）匹配。 这是为了缓解伪造SRV记录指向不同域的攻击。 该域将在PKI下拥有有效的证书，但由未知的第三方控制。<br><code>-discovery-srv-name</code>参数还为在发现期间查询的SRV名称配置了后缀。 使用此参数可以区分同一域下的多个etcd集群。 例如，如果设置了<code>Discovery-srv = example.com</code>和<code>-discovery-srv-name = foo</code>，则会进行以下DNS SRV查询：</p><ul><li>_etcd-server-ssl-foo._tcp.example.com</li><li>_etcd-server-foo._tcp.example.com</li></ul><p><strong>创建DNS SRV记录</strong></p><pre><code>$ dig +noall +answer SRV _etcd-server._tcp.example.com_etcd-server._tcp.example.com. 300 IN  SRV  0 0 2380 infra0.example.com._etcd-server._tcp.example.com. 300 IN  SRV  0 0 2380 infra1.example.com._etcd-server._tcp.example.com. 300 IN  SRV  0 0 2380 infra2.example.com.</code></pre><pre><code>$ dig +noall +answer SRV _etcd-client._tcp.example.com_etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra0.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra1.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra2.example.com.</code></pre><pre><code>$ dig +noall +answer infra0.example.com infra1.example.com infra2.example.cominfra0.example.com.  300  IN  A  10.0.1.10infra1.example.com.  300  IN  A  10.0.1.11infra2.example.com.  300  IN  A  10.0.1.12</code></pre><p><strong>使用DNS引导etcd集群</strong><br>etcd群集成员可以公告域名或IP地址，引导过程将解析DNS A记录。 从3.2开始（3.1将显示警告），<code>--listen-peer-urls</code>和<code>--listen-client-urls</code>将拒绝网络接口绑定的域名。<br><code>--initial-advertise-peer-urls</code>中的解析地址必须与SRV目标中的解析地址之一匹配。 etcd成员读取解析的地址，以查找其是否属于SRV记录中定义的集群。</p><pre><code>$ etcd --name infra0 \--discovery-srv example.com \--initial-advertise-peer-urls http://infra0.example.com:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://infra0.example.com:2379 \--listen-client-urls http://0.0.0.0:2379 \--listen-peer-urls http://0.0.0.0:2380</code></pre><pre><code>$ etcd --name infra1 \--discovery-srv example.com \--initial-advertise-peer-urls http://infra1.example.com:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://infra1.example.com:2379 \--listen-client-urls http://0.0.0.0:2379 \--listen-peer-urls http://0.0.0.0:2380</code></pre><pre><code>$ etcd --name infra2 \--discovery-srv example.com \--initial-advertise-peer-urls http://infra2.example.com:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://infra2.example.com:2379 \--listen-client-urls http://0.0.0.0:2379 \--listen-peer-urls http://0.0.0.0:2380</code></pre><p>集群还可以使用IP地址而不是域名进行引导：</p><pre><code>$ etcd --name infra0 \--discovery-srv example.com \--initial-advertise-peer-urls http://10.0.1.10:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://10.0.1.10:2379 \--listen-client-urls http://10.0.1.10:2379 \--listen-peer-urls http://10.0.1.10:2380</code></pre><pre><code>$ etcd --name infra1 \--discovery-srv example.com \--initial-advertise-peer-urls http://10.0.1.11:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://10.0.1.11:2379 \--listen-client-urls http://10.0.1.11:2379 \--listen-peer-urls http://10.0.1.11:2380</code></pre><pre><code>$ etcd --name infra2 \--discovery-srv example.com \--initial-advertise-peer-urls http://10.0.1.12:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://10.0.1.12:2379 \--listen-client-urls http://10.0.1.12:2379 \--listen-peer-urls http://10.0.1.12:2380</code></pre><p>自从v3.1.0（v3.2.9除外），因此在<code>etcd --discovery-srv = example.com</code>中配置了TLS时，服务器仅在提供的证书具有根域<code>example.com</code>作为<code>Subject Alternative</code>(SAN)字段中的条目时，对等方/客户端进行身份验证。请参阅<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md#notes-for-dns-srv" target="_blank" rel="noopener">DNS SRV的注释</a>。<br><strong>网关</strong><br>etcd网关是一个简单的TCP代理，可将网络数据转发到etcd集群。 请阅读<a href="https://newonexd.github.io/2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/">网关指南</a>以获取更多信息。<br><strong>代理</strong><br>设置<code>--proxy</code>参数时，etcd以<a href="https://newonexd.github.io/2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/">代理模式</a>运行。 此代理模式仅支持etcd v2 API； 目前尚无计划支持v3 API。 相反，为了支持v3 API，etcd 3.0版本之后将提供具有增强功能的新代理。<br>要使用v2 API代理设置etcd集群，请阅读<a href="https://github.com/coreos/etcd/blob/release-2.3/Documentation/clustering.md" target="_blank" rel="noopener">etcd 2.3版本中的集群文档</a>。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>单机集群</title>
    <link href="undefined2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/"/>
    <url>2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/local_cluster.md" target="_blank" rel="noopener">Setting up local clusters</a></p><h2 id="设置单节点集群"><a href="#设置单节点集群" class="headerlink" title="设置单节点集群"></a>设置单节点集群</h2><p>对于测试环境与开发环境，最快速与简单的方式是配置一个本地集群。对于生产环境，参考<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">集群</a>部分。</p><h3 id="本地单节点集群"><a href="#本地单节点集群" class="headerlink" title="本地单节点集群"></a>本地单节点集群</h3><h5 id="启动一个集群"><a href="#启动一个集群" class="headerlink" title="启动一个集群"></a>启动一个集群</h5><p>运行以下命令来部署一个单节点的etcd集群:</p><pre><code>$ ./etcd...</code></pre><p>如果<code>etcd</code>二进制文件不在当前工作目录，那可能位于<code>$GOPATH/bin/etcd</code>或者是<code>/usr/local/bin/etcd</code>.合适地运行命令。<br>运行的<code>etcd</code>成员在<code>localhost:2379</code>监听客户端的请求。</p><h5 id="与集群进行交互"><a href="#与集群进行交互" class="headerlink" title="与集群进行交互"></a>与集群进行交互</h5><p>使用<code>etcdctl</code>与运行中的集群进行交互操作<br>    1.     例子：在集群中存储一个键值对：</p><pre><code>$ ./etcdctl put foo barOK</code></pre><p>如果<code>OK</code>被打印在控制台，说明已经成功存储Key-Value对。<br>    2.     获取键<code>foo</code>对应的值：</p><pre><code>$ ./etcdctl get foobar</code></pre><p>如果<code>bar</code>被返回，说明与<code>etcd</code>集群的交互操作和期望中的相同。</p><h3 id="本地多节点集群"><a href="#本地多节点集群" class="headerlink" title="本地多节点集群"></a>本地多节点集群</h3><h5 id="启动一个集群-1"><a href="#启动一个集群-1" class="headerlink" title="启动一个集群"></a>启动一个集群</h5><p>在<code>etcd</code>的<code>git</code>仓库中存在一个<code>Procfile</code>文件提供一种简单的方式可以对本地多节点集群进行配置。在启动多节点集群之前，将工作目录导向<code>etcd</code>的根目录并执行以下操作：</p><pre><code>1.    安装`goreman`控制基于`Procfile`的应用：```$ go get github.com/mattn/goreman```2.    使用 `etcd`的配置文件`Procfile`通过`goreman`启动一个集群：```$ goreman -f Procfile start```集群成员已经启动了，并在`localhost:2379`,localhost:22379`,localhost:32379`监听客户端的请求。</code></pre><h5 id="与集群进行交互-1"><a href="#与集群进行交互-1" class="headerlink" title="与集群进行交互"></a>与集群进行交互</h5><p>使用<code>etcdctl</code>与运行中的集群进行交互操作:</p><pre><code>1. 打印成员列表：$ `etcdctl --write-out=table --endpoints=localhost:2379 member list``etcd`集群中的成员列表显示如下：</code></pre><table><thead><tr><th align="left">ID</th><th align="left">STATUS</th><th align="left">NAME</th><th align="left">PEER ADDRS</th><th align="left">CLIENT ADDRS</th></tr></thead><tbody><tr><td align="left">8211f1d0f64f3269</td><td align="left">started</td><td align="left">infra1</td><td align="left"><a href="http://127.0.0.1:2380" target="_blank" rel="noopener">http://127.0.0.1:2380</a></td><td align="left"><a href="http://127.0.0.1:2379" target="_blank" rel="noopener">http://127.0.0.1:2379</a></td></tr><tr><td align="left">91bc3c398fb3c146</td><td align="left">started</td><td align="left">infra1</td><td align="left"><a href="http://127.0.0.1:22380" target="_blank" rel="noopener">http://127.0.0.1:22380</a></td><td align="left"><a href="http://127.0.0.1:22379" target="_blank" rel="noopener">http://127.0.0.1:22379</a></td></tr><tr><td align="left">fd422379fda50e48</td><td align="left">started</td><td align="left">infra1</td><td align="left"><a href="http://127.0.0.1:32380" target="_blank" rel="noopener">http://127.0.0.1:32380</a></td><td align="left"><a href="http://127.0.0.1:32379" target="_blank" rel="noopener">http://127.0.0.1:32379</a></td></tr></tbody></table><pre><code>2.     例子：在集群中存储一个Key-Value对：</code></pre><pre><code>$ ./etcdctl put foo barOK</code></pre><p>如果<code>OK</code>被打印在控制台，说明已经成功存储键-值对。</p><h5 id="容错测试"><a href="#容错测试" class="headerlink" title="容错测试"></a>容错测试</h5><p>关闭一个成员然后尝试通过键获取值来进行容错测试：</p><ol><li>获取一个运行中的成员的名字然后停止它：<br> <code>Procfile</code>列出了多节点集群的属性信息。例如，名称为<code>etcd2</code>的运行中的成员。</li><li>停止该成员：<pre><code>#kill etcd2$ goreman run stop etcd2</code></pre></li><li>存储一个键：<pre><code>$ etcdctl put key helloOK</code></pre></li><li>获取前一步所存储的键： <pre><code>$ etcdctl get keyhello</code></pre></li><li>从已经停止的成员处获取键：<pre><code>$ etcdctl --endpoints=localhost:22379 get key</code></pre>该命令应该由于连接失败展示一个错误：<pre><code>2017/06/18 23:07:35 grpc: Conn.resetTransport failed to create client transport: connection error: desc = &quot;transport: dial tcp 127.0.0.1:22379: getsockopt: connection refused&quot;; Reconnecting to &quot;localhost:22379&quot;Error:  grpc: timed out trying to connect</code></pre></li><li>重启停止的成员：<pre><code>$ goreman run restart etcd2</code></pre></li><li>从重启的成员处获取键：<pre><code>$ etcdctl --endpoints=localhost:22379 get keyhello</code></pre>重启的成员重新建立了连接.<code>etcdctl</code>将能够成功地从重启的成员处接受键,读<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/">与etcd进行交互</a>部分学习更多关于与etcd交互的内容。</li></ol>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>etcd文档</title>
    <link href="undefined2019/11/23/blog/etcd/%E6%96%87%E6%A1%A3/"/>
    <url>2019/11/23/blog/etcd/%E6%96%87%E6%A1%A3/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/tree/master/Documentation" target="_blank" rel="noopener">Documentation</a></p><h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><hr><p>etcd是一个分布式键值对存储，被设计为可靠的，快速的保存并提供对关键数据的访问。通过分布式锁，领导选举和写屏障使能分布式一致性。一个etcd集群旨在实现高可用和持久性数据存储与检索。</p><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><hr><h3 id="使用etcd进行开发"><a href="#使用etcd进行开发" class="headerlink" title="使用etcd进行开发"></a>使用etcd进行开发</h3><hr><p>一种简单的方式<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/">设置本地集群</a>开始使用etcd作为分布式键值对存储</p><ul><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/">设置本地集群</a></li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/">与etcd进行交互</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md" target="_blank" rel="noopener">gRPC etcd核心</a>和<a href="">etcd并发</a>API参考</li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/HTTP_JSON_API%E9%80%9A%E8%BF%87gRPC%E7%BD%91%E5%85%B3/">HTTP JSON API 通过gRPC网关</a></li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/">gRPC命名和发现</a></li><li><a href="https://godoc.org/github.com/etcd-io/etcd/clientv3/namespace" target="_blank" rel="noopener">客户端</a>和<a href="https://newonexd.github.io/2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/">代理</a>命名空间</li><li><a href="https://godoc.org/github.com/etcd-io/etcd/embed" target="_blank" rel="noopener">嵌入etcd</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E5%AE%9E%E9%AA%8C%E7%89%B9%E6%80%A7%E5%92%8CAPIs/">实验特性和APIs</a></li><li><a href="https://newonexd.github.io/2019/11/25/blog/etcd/%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/">系统限制</a></li></ul><h3 id="操作etcd集群"><a href="#操作etcd集群" class="headerlink" title="操作etcd集群"></a>操作etcd集群</h3><hr><p>对开发或者生产环境，管理员需要一个错误容忍etcd集群，从<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">多机集群</a>开始。</p><h4 id="设置etcd"><a href="#设置etcd" class="headerlink" title="设置etcd"></a>设置etcd</h4><ul><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">配置参数</a></li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">多成员集群</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/">gRPC代理</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/">L4网关</a></li></ul><h4 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h4><ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/supported-platform.md" target="_blank" rel="noopener">支持的系统</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md" target="_blank" rel="noopener">硬件配置建议</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/performance.md" target="_blank" rel="noopener">性能基准测试</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">调节</a></li></ul><h4 id="平台引导"><a href="#平台引导" class="headerlink" title="平台引导"></a>平台引导</h4><ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/platforms/aws.md" target="_blank" rel="noopener">亚马逊Web服务</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/platforms/container-linux-systemd.md" target="_blank" rel="noopener">Linux容器，systemd</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/platforms/freebsd.md" target="_blank" rel="noopener">RessBSD</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/">Docker容器</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/">rkt容器</a></li></ul><h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h4><ul><li><a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">TLS</a></li><li><a href="https://newonexd.github.io/2019/11/25/blog/etcd/%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/">基于角色的访问控制</a></li></ul><h4 id="维护和故障排除"><a href="#维护和故障排除" class="headerlink" title="维护和故障排除"></a>维护和故障排除</h4><ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md" target="_blank" rel="noopener">常见问题</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/monitoring.md" target="_blank" rel="noopener">监控方式</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/maintenance.md" target="_blank" rel="noopener">维护</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/failures.md" target="_blank" rel="noopener">失败模式</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md" target="_blank" rel="noopener">容灾恢复</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/upgrades/upgrading-etcd.md" target="_blank" rel="noopener">更新</a><h4 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h4>要了解有关etcd的概念和内部知识的更多信息，请阅读以下页面：</li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md" target="_blank" rel="noopener">什么是etcd</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/data_model.md" target="_blank" rel="noopener">理解数据模式</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/api.md" target="_blank" rel="noopener">理解APIs</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E8%AF%8D%E6%B1%87%E8%A1%A8/">词汇表</a></li><li>设计<ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-auth-v3.md" target="_blank" rel="noopener">权限子系统</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-client.md" target="_blank" rel="noopener">客户端</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-learner.md" target="_blank" rel="noopener">学习者</a></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>