<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CouchDB基本操作</title>
    <link href="undefined2019/12/26/blog/couchDB/CouchDB%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <url>2019/12/26/blog/couchDB/CouchDB%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="CouchDB操作"><a href="#CouchDB操作" class="headerlink" title="CouchDB操作"></a>CouchDB操作</h2><p>判断数据库是否正常运行:</p><pre><code>curl http://localhost:5984/_up | jq .</code></pre><p>获取CouchDB唯一标识符(UUID):</p><pre><code>curl http://localhost:5984/_uuids | jq .</code></pre><p>获取CouchDB数据库信息:</p><pre><code>curl http://localhost:5984/ | jq .</code></pre><h2 id="节点操作"><a href="#节点操作" class="headerlink" title="节点操作"></a>节点操作</h2><h3 id="查询节点"><a href="#查询节点" class="headerlink" title="查询节点"></a>查询节点</h3><h3 id="查询所有节点"><a href="#查询所有节点" class="headerlink" title="查询所有节点"></a>查询所有节点</h3><p>查询当前节点连接的所有节点以及集群中的节点：</p><pre><code>curl -u admin:admin http://localhost:5984/_membership</code></pre><h3 id="查询单个节点状态"><a href="#查询单个节点状态" class="headerlink" title="查询单个节点状态"></a>查询单个节点状态</h3><pre><code>curl -u admin:admin http://localhost:5984/_node/{node-name}/_stats# 查询本地节点状态curl -u admin:admin http://localhost:5984/_node/local/_stats </code></pre><h2 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h2><h3 id="查询数据库"><a href="#查询数据库" class="headerlink" title="查询数据库"></a>查询数据库</h3><p>查询所有数据库:</p><pre><code>curl http://localhost:5984/_all_dbs | jq .</code></pre><p>查询某个数据库详细信息:</p><pre><code>curl http://localhost:5984/{db_name} | jq .</code></pre><p>查询数据库更新事件:</p><pre><code>curl -u admin:admin http://localhost:5984/_db_updates | jq .</code></pre><p>查询数据库设计文档:</p><pre><code>curl -u admin:admin http://localhost:5984/data/_design_docs | jq .</code></pre><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><p>创建名称为<code>data</code>的数据库，分片数为1，副本数为2(包括源数据库).</p><ul><li><code>-u</code>指定用户名与密码</li><li><code>-X</code>指定请求方法为<code>PUT</code>(不加<code>-X</code>默认为<code>GET</code>)<pre><code>curl -u admin:admin -X PUT http://localhost:5984/data?q=1&amp;n=2 | jq .</code></pre></li></ul><h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><p>删除刚刚创建的数据库<code>data</code>。</p><pre><code>curl -u admin:admin -X DELETE http://localhost:5984/data | jq .</code></pre><h3 id="更新数据库"><a href="#更新数据库" class="headerlink" title="更新数据库"></a>更新数据库</h3><p>为指定的数据库创建复合键:</p><pre><code>curl -X POST  \    -H &quot;Content-Type:application/json&quot; \    -H &quot;Host:localhost:5984&quot; \    -u admin:admin \    http://localhost:5984/data/_all_docs \    -d &quot;{ \&quot;_id\&quot;: [ \&quot;abc\&quot;,\&quot;bcd\&quot; ]}&quot; | jq .</code></pre><p>为指定的本地数据库创建复合键:</p><pre><code>curl -X POST  \    -H &quot;Content-Type:application/json&quot; \    -H &quot;Host:localhost:5984&quot; \    -u admin:admin \    http://localhost:5984/data/_local_docs \    -d &quot;{ \&quot;_id\&quot;: [ \&quot;abc\&quot;,\&quot;bcd\&quot; ]}&quot; | jq .</code></pre><h3 id="数据库索引"><a href="#数据库索引" class="headerlink" title="数据库索引"></a>数据库索引</h3><p>查询指定数据库索引:</p><pre><code>curl -u admin:admin \    -H &quot;Content-Type:application/json&quot; \    http://localhost:5984/data/_index | jq .</code></pre><p>为指定数据库创建索引:</p><ul><li>索引字段为<code>foo</code></li><li>索引名称为<code>foo-index</code></li><li>索引类型为<code>json</code><pre><code>curl -X POST \  -u admin:admin \  -H &quot;Content-Type:application/json&quot; \  -H &quot;localhost:5984&quot; \  http://localhost:5984/data/_index \  -d &quot;{ \&quot;index\&quot;: { \&quot;fields\&quot;: [\&quot;foo\&quot; ]}, \&quot;name\&quot;:\&quot;foo-index\&quot;,\&quot;type\&quot;:\&quot;json\&quot;}&quot; | jq .</code></pre>删除索引:<pre><code>curl -u admin:admin \  -H &quot;Content-Type:application/json&quot; \  -X DELETE \ http://localhost:5984/data/_index/{ddoc}/json/{index_name}</code></pre></li></ul><p>清空所有视图索引文件:</p><pre><code>curl -X POST -u admin:admin http://localhost:5984/data/_view_cleanup</code></pre><h3 id="数据库分片"><a href="#数据库分片" class="headerlink" title="数据库分片"></a>数据库分片</h3><p>查询指定的数据库分片信息:</p><pre><code>curl -u admin:admin \    -H &quot;Content-Type:application/json&quot; \    http://localhost:5984/data/_shards | jq .</code></pre><p>根据文档ID查询指定的分片上存储的文档信息:</p><pre><code>curl -u admin:admin \    -H &quot;Content-Type:application/json&quot; \    http://localhost:5984/data/_shards/{docid} | jq .</code></pre><p>强制进行数据库分片信息同步:</p><pre><code>curl -u admin:admin \    -X POST \    -H &quot;Content-Type:application/json&quot; \    http://localhost:5984/data/_sync_shards | jq .</code></pre><h3 id="数据库压缩"><a href="#数据库压缩" class="headerlink" title="数据库压缩"></a>数据库压缩</h3><p>压缩指定的数据库:</p><pre><code>curl -u admin:admin \    -X POST \    -H &quot;Content-Type:application/json&quot; \    http://localhost:5984/data/_compact | jq .</code></pre><h3 id="数据库安全"><a href="#数据库安全" class="headerlink" title="数据库安全"></a>数据库安全</h3><p>获取当前数据库安全对象:</p><pre><code>curl -u admin:admin http://localhost:5984/data/_security | jq .</code></pre><h2 id="文档操作"><a href="#文档操作" class="headerlink" title="文档操作"></a>文档操作</h2><h3 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h3><p>查询数据库<code>data</code>中所有文档:</p><pre><code>curl -u admin:admin -H &quot;Content-Type:application/json&quot; http://localhost:5984/data/_all_docs | jq .</code></pre><p>查询数据库<code>data</code>中的指定文档:<br><code>cec6606d0ddaca2b555ebb8404a772a0</code>为指定的文档ID</p><pre><code>curl -u admin:admin http://localhost:5984/data/cec6606d0ddaca2b555ebb8404a772a0 | jq .</code></pre><p>查询数据库中文档的更新信息:</p><pre><code>curl -u admin:admin \    -H &quot;Content-Type:application/json&quot; \    http://localhost:5984/data/_changes | jq .</code></pre><p>查询本地数据库中的文档:</p><pre><code>curl -u admin:admin http://localhost:5984/data/_local_docs | jq .</code></pre><h3 id="创建文档"><a href="#创建文档" class="headerlink" title="创建文档"></a>创建文档</h3><p>向数据库<code>data</code>中创建<code>id</code>为<code>id</code>,标题为<code>demo</code>的新文档:</p><pre><code>curl -X POST \    -H &quot;Content-Type:application/json&quot; \    -u admin:admin \    http://localhost:5984/data/ \    -d &quot;{ \&quot;_id\&quot;:\&quot;id\&quot;,\&quot;title\&quot;:\&quot;demo\&quot;}&quot; | jq .</code></pre><h3 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h3><p>从数据库<code>data</code>中删除指定的文档:</p><pre><code>curl -X DELETE -u admin:admin http://localhost:5984/data/cec6606d0ddaca2b555ebb8404a772a0</code></pre>]]></content>
    
    
    <categories>
      
      <category>CouchDb应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CouchDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric外部链码构建与运行</title>
    <link href="undefined2019/12/24/blog/fabric/%E5%A4%96%E9%83%A8%E9%93%BE%E7%A0%81%E6%9E%84%E5%BB%BA%E5%92%8C%E8%BF%90%E8%A1%8C/"/>
    <url>2019/12/24/blog/fabric/%E5%A4%96%E9%83%A8%E9%93%BE%E7%A0%81%E6%9E%84%E5%BB%BA%E5%92%8C%E8%BF%90%E8%A1%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="外部链码构建与运行"><a href="#外部链码构建与运行" class="headerlink" title="外部链码构建与运行"></a>外部链码构建与运行</h1><hr><p><a href="https://hyperledger-fabric.readthedocs.io/en/latest/cc_launcher.html" target="_blank" rel="noopener">官方文档</a><br>在Hyperledger Fabric 2.0版本之前，链码的构建和运行是节点实现的一部分，并且定制化是困难的。所有链码在节点上实例化是通过”构建“即根据语言指定的逻辑在节点上硬编码。构建过程将生成<code>Docker</code>容器镜像作为客户端连接节点用来运行可执行的链码。<br>这种方法将链代码实现限制为只能使用几种语言实现，要求<code>Docker</code>成为部署环境的一部分，并阻止将链代码作为长时间运行的服务器进程运行。</p><h1 id="外部构建模式"><a href="#外部构建模式" class="headerlink" title="外部构建模式"></a>外部构建模式</h1><p>Hyperledger Fabric外部构建器和启动器大致基于Heroku <a href="https://devcenter.heroku.com/articles/buildpack-api" target="_blank" rel="noopener">Buildpacks</a>。<code>buildpack</code>实现只是将程序归档转换为可以运行的程序或脚本的集合。<code>buildpack</code>模型已针对链码包进行了调整，并扩展为支持链码执行和发现。</p><h2 id="外部构建和运行API"><a href="#外部构建和运行API" class="headerlink" title="外部构建和运行API"></a>外部构建和运行API</h2><p>外部构建和运行由4个脚本程序组成：</p><ul><li><code>bin/detect</code>:确定是否应使用此<code>buildpack</code>来构建<code>chaincode</code>程序包并启动它</li><li><code>bin/build</code>:转换链码包为可执行的链码</li><li><code>bin/release(可选)</code>:为<code>peer</code>节点提供关于链码的元数据</li><li><code>bin/run(可选)</code>:运行链码</li></ul><h3 id="bin-detect"><a href="#bin-detect" class="headerlink" title="bin/detect"></a><code>bin/detect</code></h3><p><code>bin/detect</code>脚本决定是否应使用此<code>buildpack</code>来构建<code>chaincode</code>程序包并启动它,<code>peer</code>节点通过两个参数调用<code>detect</code>:</p><pre><code>bin/detect CHAINCOD_SOURCE_DIR CHAINCODE_METADATA_DIR</code></pre><p>当<code>detect</code>被调用，<code>CHAINCOD_SOURCE_DIR</code>包含的链码资源以及<code>CHAINCODE_METADATA_DIR</code>包含的<code>metadata.json</code>文件将从链码包中安装到节点。<code>CHAINCOD_SOURCE_DIR</code>和<code>CHAINCODE_METADATA_DIR</code>应该被作为只读输入。如果将<code>buildpack</code>应用于<code>chaincode</code>源程序包，<code>detect</code>必须返回退出码0；否则，其他任何退出代码都将指示<code>buildpack</code>不应用内于<code>chaincode</code>源程序包。<br>下面是一个简单的用于<code>go</code>语言链码的<code>detect</code>脚本例子：</p><pre><code>#!/bin/bashCHAINCODE_METADATA_DIR=&quot;$2&quot;# 使用jq工具从metadata.json中获取链码类型，如果链码类型为golang，则成功退出if [ &quot;$(jq -r .type &quot;$CHAINCODE_METADATA_DIR/metadata.json&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;)&quot; = &quot;golang&quot; ]; then    exit 0fiexit 1</code></pre><h3 id="bin-build"><a href="#bin-build" class="headerlink" title="bin/build"></a><code>bin/build</code></h3><p><code>bin/build</code>脚本用于构建，编译，或者转换链码包的内容到可以被<code>release</code>和<code>run</code>使用的类型。节点通过三个参数调用<code>build</code>:</p><pre><code>bin/build CHAINCODE_SOURCE_DIR CHAINCODE_METADATA_DIR BUILD_OUTPUT_DIR</code></pre><p>当<code>build</code>被调用，<code>CHAINCOD_SOURCE_DIR</code>包含的链码资源以及<code>CHAINCODE_METADATA_DIR</code>包含的<code>metadata.json</code>文件将从链码包中安装到节点。<code>BUILD_OUTPUT_DIR</code>是一个文件夹用于存放<code>release</code>和<code>run</code>需要的文件。<code>build</code>脚本应该将<code>CHAINCOD_SOURCE_DIR</code>和<code>CHAINCODE_METADATA_DIR</code>作为只读输入，<code>BUILD_OUTPUT_DIR</code>作为可写输出。</p><p>下面是一个简单的用于<code>go</code>语言链码的<code>build</code>脚本例子：</p><pre><code>#!/bin/bashCHAINCODE_SOURCE_DIR=&quot;$1&quot;CHAINCODE_METADATA_DIR=&quot;$2&quot;BUILD_OUTPUT_DIR=&quot;$3&quot;# 从 metadata.json获取包内容GO_PACKAGE_PATH=&quot;$(jq -r .path &quot;$CHAINCODE_METADATA_DIR/metadata.json&quot;)&quot;if [ -f &quot;$CHAINCODE_SOURCE_DIR/src/go.mod&quot; ]; then    cd &quot;$CHAINCODE_SOURCE_DIR/src&quot;    go build -v -mod=readonly -o &quot;$BUILD_OUTPUT_DIR/chaincode&quot; &quot;$GO_PACKAGE_PATH&quot;else    GO111MODULE=off go build -v  -o &quot;$BUILD_OUTPUT_DIR/chaincode&quot; &quot;$GO_PACKAGE_PATH&quot;fi# 存储状态数据库索引元数据提供给releaseif [ -d &quot;$CHAINCODE_SOURCE_DIR/META-INF&quot; ]; then    cp -a &quot;$CHAINCODE_SOURCE_DIR/META-INF&quot; &quot;$BUILD_OUTPUT_DIR/&quot;fi</code></pre><h3 id="bin-release"><a href="#bin-release" class="headerlink" title="bin/release"></a><code>bin/release</code></h3><p><code>bin/release</code>脚本为节点提供链码元数据。该脚本是可选的。如果没有提供，这一步将会跳过。节点通过两个参数调用<code>release</code>：</p><pre><code>bin/release BUILD_OUTPUT_DIR RELEASE_OUTPUT_DIR</code></pre><p>调用<code>release</code>时，<code>BUILD_OUTPUT_DIR</code>包含构建程序填充的归档，应将其视为只读输入。<code>RELEASE_OUTPUT_DIR</code>是<code>release</code>必须放置归档以供节点使用的目录。</p><p>当<code>release</code>执行完成，节点将会从<code>RELEASE_OUTPUT_DIR</code>消费两种类型的元数据:</p><ul><li>CouchDB定义的状态数据库索引。</li><li>外部链码服务连接信息(<code>chaincode/server/connection.json</code>)</li></ul><p>如果链码要求CouchDB索引定义，<code>release</code>需要将索引放置在<code>RELEASE_OUTPUT_DIR</code>下的<code>state/couchdb/indexes</code>文件夹内。索引必须含有<code>.json</code>扩展名。</p><p>在使用链码服务器实现的情况下，<code>release</code>负责使用链码服务器的地址以及与链码通信所需的任何TLS资产来填充<code>chaincode/server/connection.json</code>。将服务器连接信息提供给节点时，将不会调用<code>run</code>。</p><p>下面是一个简单的用于<code>go</code>语言链码的<code>release</code>脚本例子：</p><pre><code>#!/bin/bashBUILD_OUTPUT_DIR=&quot;$1&quot;RELEASE_OUTPUT_DIR=&quot;$2&quot;# 从 META-INF/* 拷贝索引文件到输出文件夹if [ -d &quot;$BUILD_OUTPUT_DIR/META-INF&quot; ] ; then   cp -a &quot;$BUILD_OUTPUT_DIR/META-INF/&quot;* &quot;$RELEASE_OUTPUT_DIR/&quot;fi</code></pre><h3 id="bin-run"><a href="#bin-run" class="headerlink" title="bin/run"></a><code>bin/run</code></h3><p><code>bin/run</code>脚本用于链码的运行。节点通过两个参数调用<code>run</code>：</p><pre><code>bin/run BUILD_OUTPUT_DIR RUN_METADATA_DIR</code></pre><p>当<code>BUILD_OUTPUT_DIR</code>包含<code>build</code>程序填充的归档，而<code>RUN_METADATA_DIR</code>包含有一个名为<code>chaincode.json</code>的文件，该文件包含链码连接和注册到节点所需的信息，<code>run</code>将被调用。<code>bin/run</code>脚本对于<code>BUILD_OUTPUT_DIR</code>以及<code>RUN_METADATA_DIR</code>文件夹应为只读输入。<code>chaincode.json</code>文件包含的关键信息有：</p><ul><li><code>chaincode_id:</code>连接到链码包的唯一ID</li><li><code>peer_address:``peer</code>节点的<code>ChaincodeSupport</code>中的gRPC服务端点主机地址，格式为<code>host:port</code>.</li><li><code>client_cert:</code>由<code>peer</code>生成的<code>PEM</code>编码的TLS客户端证书。当链码与节点建立连接时将会被使用。</li><li><code>client_key:</code>由<code>peer</code>生成的<code>PEM</code>编码的客户端秘钥。当链码与节点建立连接时将会被使用。</li><li><code>root_cert:</code>由<code>peer</code>节点的<code>ChaincodeSupport</code>中的gRPC服务端点主机使用的<code>PEM</code>编码的<code>TLS</code>根证书。</li></ul><p>当<code>run</code>停止时，与<code>peer</code>连接的链码也会终止。如果另一个请求访问链码，节点将会尝试通过调用<code>run</code>启动链码的另一个实例。在调用链码时，<code>chaincode.json</code>文件内容不能够被缓存。</p><p>下面是一个简单的用于<code>go</code>语言链码的<code>run</code>脚本例子：</p><pre><code>#!/bin/bashBUILD_OUTPUT_DIR=&quot;$1&quot;RUN_METADATA_DIR=&quot;$2&quot;# 为go语言链码shim包配置环境变量export CORE_CHAINCODE_ID_NAME=&quot;$(jq -r .chaincode_id &quot;$RUN_METADATA_DIR/chaincode.json&quot;)&quot;export CORE_PEER_TLS_ENABLED=&quot;true&quot;export CORE_TLS_CLIENT_CERT_FILE=&quot;$RUN_METADATA_DIR/client.crt&quot;export CORE_TLS_CLIENT_KEY_FILE=&quot;$RUN_METADATA_DIR/client.key&quot;export CORE_PEER_TLS_ROOTCERT_FILE=&quot;$RUN_METADATA_DIR/root.crt&quot;# 为go语言链码shim包获取秘钥和证书材料jq -r .client_cert &quot;$RUN_METADATA_DIR/chaincode.json&quot; &gt; &quot;$CORE_TLS_CLIENT_CERT_FILE&quot;jq -r .client_key  &quot;$RUN_METADATA_DIR/chaincode.json&quot; &gt; &quot;$CORE_TLS_CLIENT_KEY_FILE&quot;jq -r .root_cert   &quot;$RUN_METADATA_DIR/chaincode.json&quot; &gt; &quot;$CORE_PEER_TLS_ROOTCERT_FILE&quot;if [ -z &quot;$(jq -r .client_cert &quot;$RUN_METADATA_DIR/chaincode.json&quot;)&quot; ]; then    export CORE_PEER_TLS_ENABLED=&quot;false&quot;fi# 执行链码并使用链码进程替代脚本exec &quot;$BUILD_OUTPUT_DIR/chaincode&quot; -peer.address=&quot;$(jq -r .peer_address &quot;$ARTIFACTS/chaincode.json&quot;)&quot;</code></pre><h2 id="外部构建和运行的配置"><a href="#外部构建和运行的配置" class="headerlink" title="外部构建和运行的配置"></a>外部构建和运行的配置</h2><p>在<code>core.yaml</code>的<code>chaincode</code>配置区域下添加一个<code>externalBuilder</code>元素配置节点以使用外部构建器.每一个外部构建器的定义必须包含名字(用于日志)和包含构建器脚本的<code>bin</code>文件夹的上一级路径。</p><p>调用外部构建器脚本时还可以从节点获取环境变量名称的可选列表。</p><p>下面的示例定义了两个外部构建器：</p><pre><code>chaincode:  externalBuilders:  - name: my-golang-builder    path: /builders/golang    environmentWhitelist:    - GOPROXY    - GONOPROXY    - GOSUMDB    - GONOSUMDB  - name: noop-builder    path: /builders/binary</code></pre><p>在这个示例中，实现的构建器<code>my-golang-builder</code>被包含在<code>/builders/golang</code>文件夹内，它的脚本文件位于<code>/builders/golang/bin</code>.当节点调用任何与<code>my-golang-builder</code>相关的构建脚本时，将只会传播白名单内的环境变量的值。</p><p>这些环境变量总是传播到外部构建器：</p><ul><li>LD_LIBRARY_PATH</li><li>LIBPATH</li><li>PATH</li><li>TMPDIR</li></ul><p>当<code>externalBuilder</code>配置存在时，节点将会迭代按顺序排列的构建器的列表。调用<code>/bin/detect</code>直到其中的一个成功执行。<br>如果没有构建器成功执行<code>detect</code>脚本，节点将会回滚使用初始的<code>Docker</code>通过节点实现构建进程。这说明外部的构建器是完全可选的。</p><p>在上面的示例中，节点将试图使用<code>my-golang-builder</code>，如果无效的话则使用<code>noop-builder</code>，还是无效的话最后使用节点内部构建进程。</p><h2 id="链码包"><a href="#链码包" class="headerlink" title="链码包"></a>链码包</h2><p>Fabric 2.0引入了新的生命周期链码。链码包的格式从序列号协议缓冲消息变为了由<code>gzip</code>压缩的<code>POSIX tape</code>归档。链码包通过使用<code>peer lifecycle chaincode package</code>创建新的格式。</p><h3 id="Lifecycle链码包内容"><a href="#Lifecycle链码包内容" class="headerlink" title="Lifecycle链码包内容"></a><code>Lifecycle</code>链码包内容</h3><p><code>lifecycle</code>链码包包含两个文件，第一个文件<code>code.tar.gz</code>是一个使用<code>gzip</code>压缩的<code>POSIX tape</code>归档。这个文件包括链码的源归档。由节点<code>CLI</code>创建并将链码的实现源码放置在<code>src</code>文件夹下，链码的元数据(如CouchDB索引文件)放置在<code>META-INF</code>文件夹。</p><p>第二个文件<code>metadata.json</code>是一个<code>JSON</code>格式的文档包含三个键：</p><ul><li><code>type</code>:链码的类型(例如<code>GOLANG</code>,<code>JAVA</code>,<code>NODE</code>)</li><li><code>path</code>:对于go语言链码，则是<code>GOPATH</code>或者<code>GOMOD</code>到主链码包的相对路径，其他类型的链码未定义。</li><li><code>label</code>:用于生成包ID的链码标签，在新的链码<code>lifecycle</code>过程中用于标识包的身份。</li></ul><p><code>type</code>和<code>path</code>字段仅由<code>Docker</code>平台构建使用。</p><h3 id="链码包以及外部构建器"><a href="#链码包以及外部构建器" class="headerlink" title="链码包以及外部构建器"></a>链码包以及外部构建器</h3><p>当链码包安装在节点上后，<code>code.tar.gz</code>和<code>metadata.json</code>的内容将不能调用外部构建器处理。除了<code>label</code>字段用于新的<code>lifecycle</code>对包ID进行计算。为用户提供了很大的灵活性，使他们可以打包将由外部构建者和启动者处理的源和元数据。</p><p>例如，可以构造一个自定义的链码包，该代码包在<code>code.tar.gz</code>中包含一个预编译的链码实现，并带有一个<code>metadata.json</code>文件，允许二进制构建包检测该自定义包，验证哈希值并作为链码运行。</p><p>另一个示例是chaincode程序包，其中仅包含状态数据库索引定义以及外部启动程序连接到正在运行的<code>chaincode</code>服务器所需的数据。在这种情况下，<code>build</code>过程将仅从过程中提取元数据，然后将其<code>release</code>给节点。</p><p>唯一的要求是<code>code.tar.gz</code>只能包含常规文件和目录条目，并且这些条目不能包含会导致文件写入链码包根路径逻辑外。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric使用硬件安全模块(HSM)</title>
    <link href="undefined2019/12/24/blog/fabric/%E4%BD%BF%E7%94%A8%E7%A1%AC%E4%BB%B6%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9D%97/"/>
    <url>2019/12/24/blog/fabric/%E4%BD%BF%E7%94%A8%E7%A1%AC%E4%BB%B6%E5%AE%89%E5%85%A8%E6%A8%A1%E5%9D%97/</url>
    
    <content type="html"><![CDATA[<h1 id="使用硬件安全模块"><a href="#使用硬件安全模块" class="headerlink" title="使用硬件安全模块"></a>使用硬件安全模块</h1><p><a href="https://hyperledger-fabric.readthedocs.io/en/latest/hsm.html" target="_blank" rel="noopener">官方文档</a><br>可以通过<code>Fabric</code>节点使用硬件安全模块<code>(HSM)</code>来产生和存储私钥。<code>HSM</code>用于保护私钥和处理加密操作。允许<code>peer</code>节点与<code>orderer</code>节点在不暴露他们的私钥的条件下去签名和背书交易，当前<code>Fabric</code>只支持使用<code>PKCS11</code>标准与<code>HSM</code>进行通信。</p><h2 id="配置HSM"><a href="#配置HSM" class="headerlink" title="配置HSM"></a>配置HSM</h2><p>为了在<code>Fabric</code>节点上使用<code>HSM</code>，需要更新关于节点配置文件如<code>core.yaml</code>中的<code>BCCSP</code>(加密服务提供者)部分.在<code>BCCSP</code>部分，需要选择<code>PKCS11</code>作为提供者并提供需要使用的<code>PKCS11</code>库的路径。还需要提供为加密操作创建的令牌的标签和密码。可以使用令牌去生成和存储多个秘钥。<br>预先构建的<code>Hyperledger Fabric Docker</code>镜像不能够使用<code>PKCS11</code>。如果使用<code>Docker</code>部署<code>Fabric</code>，需要通过以下的命令启动<code>PKCS11</code>构建自己的镜像。</p><pre><code>make docker GO_TAGS=pkcs11</code></pre><p>同时也需要确保<code>PKCS11</code>的库文件是有效的，挂载到容器内部或者通过节点安装后是可以使用的。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>接下来的示例说明了如何去配置一个可以使用<code>HSM</code>的<code>Fabirc</code>节点。</p><p>首先，需要安装一个实现了<code>PKCS11</code>的接口。本例使用开源的<a href="https://github.com/opendnssec/SoftHSMv2" target="_blank" rel="noopener">softhsm</a>实现。在下载和配置完成<code>softhsm</code>后，需要设置环境变量<code>SOFTHSM2_CONF</code>指向<code>softhsm2</code>配置文件。</p><p>可以使用<code>softhsm</code>去创建用于处理关于<code>Fabric</code>节点在<code>HSM</code>插槽中用于加密操作令牌。在这个示例中，我们创建了一个标签为<code>fabric</code>，密码为<code>71811222</code>的令牌。在创建令牌完成之后，更新配置文件来使用<code>PKCS11</code>，并将令牌作为加密服务提供者。可以在下面发现关于<code>BCCSP</code>部分配置的例子：</p><pre><code>############################################################################## BCCSP (区块链加密服务提供者) 部分，用于选择使用的已实现的加密库文件#############################################################################bccsp:  default: PKCS11  pkcs11:    Library: /etc/hyperledger/fabric/libsofthsm2.so    Pin: 71811222    Label: fabric    hash: SHA2    security: 256</code></pre><p>也可以通过环境变量来覆盖配置文件中相关的字段。如果通过<code>Fabric CA</code>服务器连接到了<code>HSM</code>，则需要设置以下环境变量：</p><pre><code>FABRIC_CA_SERVER_BCCSP_DEFAULT=PKCS11FABRIC_CA_SERVER_BCCSP_PKCS11_LIBRARY=/etc/hyperledger/fabric/libsofthsm2.soFABRIC_CA_SERVER_BCCSP_PKCS11_PIN=71811222FABRIC_CA_SERVER_BCCSP_PKCS11_LABEL=fabric</code></pre><p>如果使用<code>docker compose</code>部署了节点，在构建完自己的镜像后，可以更新<code>docker compose</code>文件通过<code>volumes</code>将<code>softhsm</code>库文件和配置文件挂载到容器中。例如，可以添加下面的环境和<code>volumes</code>变量到<code>docker compose</code>文件：</p><pre><code>  environment:     - SOFTHSM2_CONF=/etc/hyperledger/fabric/config.file  volumes:     - /home/softhsm/config.file:/etc/hyperledger/fabric/config.file     - /usr/local/Cellar/softhsm/2.1.0/lib/softhsm/libsofthsm2.so:/etc/hyperledger/fabric/libsofthsm2.so</code></pre><h2 id="配置使用HSM的网络"><a href="#配置使用HSM的网络" class="headerlink" title="配置使用HSM的网络"></a>配置使用<code>HSM</code>的网络</h2><p>如果使用<code>HSM</code>部署了<code>Fabric</code>节点，私钥将会在<code>HSM</code>内部生成而不是节点本地的<code>MSP</code>中的<code>keystore</code>文件夹内。<code>MSP</code>中的<code>keystore</code>文件夹将为空文件夹。另外，<code>Fabric</code>节点将使用关于<code>signcerts</code>文件夹内的签名证书的主题秘钥标识符去接收<code>HSM</code>中的私钥。这个创建<code>MSP</code>文件夹的过程将和之前不同，取决于自己使用的<code>Fabric</code> 证书认证中心。</p><h3 id="使用Fabric-CA"><a href="#使用Fabric-CA" class="headerlink" title="使用Fabric CA"></a>使用Fabric CA</h3><p>可以通过编辑相同的配置文件配置<code>Fabric CA</code>使<code>peer</code>节点或者是<code>orderer</code>节点使用<code>HSM</code>。因为可以使用<code>Fabric CA</code>内部的<code>HSM</code>来生成秘钥。通过下面的步骤将直接创建本地的<code>MSP</code>文件夹：</p><ol><li>创建一个<code>HSM</code>令牌并将它指向<code>Fabirc CA</code>的配置文件。当<code>Fabric CA</code>服务启动时，将会在<code>HSM</code>中生成<code>CA</code>签名证书。如果不担心<code>CA</code>签名证书是否暴露，可以跳过该步骤。</li><li>使用<code>Fabric CA</code>客户端通过自己的<code>CA</code>去注册<code>peer</code>或者<code>order</code>节点身份。</li><li>编辑<code>Fabric CA</code>客户端配置文件或者是环境变量使用<code>HSM</code>作为加密服务提供者并再次登录获取节点的身份。登录命令将通过<code>HSM</code>生成私钥文件.</li><li>更新关于<code>peer</code>或者<code>orderer</code>节点的配置文件中的<code>BCCSP</code>部分使用<code>PKCS11</code>，并将令牌作为加密服务提供者。指向由<code>Fabric CA</code>客户端创建的<code>MSP</code>文件夹。一旦部署完成，<code>peer</code>节点或者<code>orderer</code>节点将可以通过由<code>HSM</code>提供保护的私钥文件签名和背书交易。</li></ol><h3 id="通过自己的CA使用HSM"><a href="#通过自己的CA使用HSM" class="headerlink" title="通过自己的CA使用HSM"></a>通过自己的<code>CA</code>使用<code>HSM</code></h3><p>如果使用自己的<code>CA</code>证书中心来部署<code>Fabric</code>组件，可以通过以下几步使用<code>HSM</code>:</p><ol><li>配置自己的<code>CA</code>使用<code>PKCS11</code>创建令牌与<code>HSM</code>进行通信。然后使用自己的<code>CA</code>去为每一个节点生成私钥和签名证书。私钥由<code>HSM</code>内部进行生成。</li><li>使用<code>CA</code>去构建节点的<code>MSP</code>文件夹。将步骤一中生成的签名证书放入<code>signcerts</code>文件夹内。可以保持<code>keystore</code>文件夹为空。</li><li>更新关于<code>peer</code>或者<code>orderer</code>节点的配置文件中的<code>BCCSP</code>部分使用<code>PKCS11</code>，并将令牌作为加密服务提供者。指向由<code>Fabric CA</code>客户端创建的<code>MSP</code>文件夹。一旦部署完成，<code>peer</code>节点或者<code>orderer</code>节点将可以通过由<code>HSM</code>提供保护的私钥文件签名和背书交易。</li></ol>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CouchDB学习-API</title>
    <link href="undefined2019/12/24/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-API/"/>
    <url>2019/12/24/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-API/</url>
    
    <content type="html"><![CDATA[<h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>API URL路径可以指定访问CouchDB服务器的某个组件。URL请求结果包括标识和访问的数据库中的高效的描述字段。<br>与所有URL一样，各个组件之间用正斜杠分隔。<br>通常，以_（下划线）字符开头的URL组件和JSON字段表示服务器或返回的对象中的特殊组件或实体。例如，URL片段<code>/_all_dbs</code>获取CouchDB实例中所有数据库的列表。<br>该引用根据URL结构进行构造，如下所示。</p><h2 id="1-基本API"><a href="#1-基本API" class="headerlink" title="1 基本API"></a>1 基本API</h2><p>CouchDB API是与CouchDB实例接口的主要方法。使用HTTP发出请求，请求用于从数据库请求信息，存储新数据以及对文档中存储的信息进行查看和格式化。<br>对API的请求可以按您正在访问的CouchDB系统的不同区域以及用于发送请求的HTTP方法进行分类。不同的方法意味着不同的操作，例如，从数据库中检索信息通常由<code>GET</code>操作处理，而更新则由<code>POST</code>或<code>PUT</code>请求处理。不同方法必须提供的信息之间存在一些差异。有关基本HTTP方法和请求结构的指南，请参见请求格式和响应。<br>对于几乎所有操作，都在JavaScript对象表示法（JSON）对象中定义了提交的数据和返回的数据结构。 JSON基础知识中提供了有关JSON内容和数据类型的基本信息。<br>使用标准HTTP状态代码报告访问CouchDB API时的错误。 HTTP状态代码中提供了有关CouchDB返回的通用代码的指南。<br>访问CouchDB API的特定区域时，将提供有关HTTP方法和请求，JSON结构和错误代码的特定信息和示例。</p><h3 id="1-1-请求格式和响应"><a href="#1-1-请求格式和响应" class="headerlink" title="1.1 请求格式和响应"></a>1.1 请求格式和响应</h3><p>CouchDB支持以下HTTP请求方法：</p><ul><li><code>GET</code>:请求指定的条目。</li><li><code>HEAD</code>：获取HTTP请求头部信息</li><li><code>POST</code>：上传数据</li><li><code>PUT</code>：用于PUT指定的资源，如创建新的对象(数据库，文档，视图，设计文档)</li><li><code>DELETE</code>：删除指定的资源</li><li><code>COPY</code>：特殊的方法，用于拷贝文档和对象</li></ul><p>如果使用CouchDB不支持的HTTP请求类型，将会返回状态码<code>405-Method Not Allowed</code>.</p><h3 id="1-2-HTTP请求头"><a href="#1-2-HTTP请求头" class="headerlink" title="1.2 HTTP请求头"></a>1.2 HTTP请求头</h3><p>CouchDB使用HTTP进行所有通信。所以需要确保正确的并且是被支持的HTTP头部信息。</p><h4 id="1-2-1-请求头"><a href="#1-2-1-请求头" class="headerlink" title="1.2.1 请求头"></a>1.2.1 请求头</h4><ul><li><code>Accept</code>:由服务器返回指定的被接受的数据类型列表</li><li><code>Content-type</code>：指定请求中提供的信息的内容类型</li></ul><h4 id="1-2-2-响应头"><a href="#1-2-2-响应头" class="headerlink" title="1.2.2 响应头"></a>1.2.2 响应头</h4><ul><li><code>Cache-control</code>：缓存控制</li><li><code>Content-length</code>：返回的内容的长度</li><li><code>Content-type</code>：指定的返回数据的MIME类型</li><li><code>Etag</code>：显示文档或者视图的修订版本</li><li><code>Transfer-Encoding</code>：如果响应使用编码，那么则在该字段中指定</li></ul><h3 id="1-3-JSON基础"><a href="#1-3-JSON基础" class="headerlink" title="1.3 JSON基础"></a>1.3 JSON基础</h3><h3 id="1-4-HTTP状态码"><a href="#1-4-HTTP状态码" class="headerlink" title="1.4 HTTP状态码"></a>1.4 HTTP状态码</h3><ul><li>200 - <code>OK</code>：请求完全成功</li><li>201 - <code>Created</code>：文档成功创建</li><li>202 - <code>Accepted</code>：请求被接受，但是相关的操作可能不完整，经常用于后台操作如数据库压缩。</li><li>304 - <code>Not Modified</code>：请求的其他内容尚未修改。</li><li>400 - <code>Bad Request</code>：坏的请求结构，如错误的请求URL，路径或请求头。</li><li>401 - <code>Unauthorized</code>：不具备获取指定数据的权限，或者权限不支持</li><li>403 - <code>Forbidden</code>：请求被服务器拒绝</li><li>404 - <code>Not Found</code>：没有找到请求的数据</li><li>405 - <code>Method Not Allowed</code>：请求方法不被支持</li><li>406 - <code>Not Acceptable</code>：请求的内容类型不被支持</li><li>409 - <code>Conflict</code>：更新数据冲突</li><li>412 - <code>Preconfition Failed</code>：客户端的请求头和服务器的兼容性不匹配</li><li>413 - <code>Request Entity Too Large</code>：请求的数据过大</li><li>415 - <code>Unsupported Media Type</code>：支持的内容类型以及正在请求或提交的信息的内容类型表示不支持该内容类型。</li><li>416 - <code>Requested Range Not Satisfiable</code>：服务器无法满足请求标头中指定的范围。</li><li>417 - <code>Expectation Failed</code>：批量发送文档时，批量加载操作失败。</li><li>500 - <code>Internal Server Error</code>：请求无效</li></ul><h2 id="2-服务器"><a href="#2-服务器" class="headerlink" title="2 服务器"></a>2 服务器</h2><h3 id="2-1"><a href="#2-1" class="headerlink" title="2.1 /"></a>2.1 <code>/</code></h3><p><code>GET /</code>:访问CouchDB实例的Root并返回关于实例的元数据。<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code></p><h3 id="2-2-active-tasks"><a href="#2-2-active-tasks" class="headerlink" title="2.2 /_active_tasks"></a>2.2 <code>/_active_tasks</code></h3><p><code>GET /_active_tasks</code>:列出运行中的任务，包括任务类型，名字，状态和进程ID。<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>响应JSON对象：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>changes_done(number):</code>处理的变更<br>&emsp;&emsp;&emsp;&emsp;    * <code>database(string):</code>源数据库<br>&emsp;&emsp;&emsp;&emsp;    * <code>pid(string):</code>进程ID<br>&emsp;&emsp;&emsp;&emsp;    * <code>progress(number):</code>当前进度百分比<br>&emsp;&emsp;&emsp;&emsp;    * <code>started_on(number):</code>任务开始时间<br>&emsp;&emsp;&emsp;&emsp;    * <code>status(string):</code>任务状态信息<br>&emsp;&emsp;&emsp;&emsp;    * <code>task(string):</code>任务名称<br>&emsp;&emsp;&emsp;&emsp;    * <code>total_changes(number):</code>进程总的改变<br>&emsp;&emsp;&emsp;&emsp;    * <code>type(string):</code>操作类型<br>&emsp;&emsp;&emsp;&emsp;    * <code>update_on(number):</code>最后一次更新时间<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code><br>&emsp;&emsp;&emsp;&emsp;    * 401 <code>Unauthorized</code></p><h3 id="2-3-all-dbs"><a href="#2-3-all-dbs" class="headerlink" title="2.3 /_all_dbs"></a>2.3 <code>/_all_dbs</code></h3><p><code>GET /_all_dbs</code>:返回CouchDB实例所有数据库列表<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>请求参数：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>descending(boolean):</code>按键降序返回数据库。 默认为false。<br>&emsp;&emsp;&emsp;&emsp;    * <code>endkey(json):</code>到达指定的键时，停止返回数据库。<br>&emsp;&emsp;&emsp;&emsp;    * <code>end_key(json):</code>endkey的别名<br>&emsp;&emsp;&emsp;&emsp;    * <code>limit(number):</code>返回数据库数量的限制<br>&emsp;&emsp;&emsp;&emsp;    * <code>skip(number):</code>跳过此值得数据库，默认为0<br>&emsp;&emsp;&emsp;&emsp;    * <code>startkey(json):</code>从指定的键返回数据库<br>&emsp;&emsp;&emsp;&emsp;    * <code>start_key(json):</code>startkey的别名<br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>200 OK</code></p><h3 id="2-4-dbs-info"><a href="#2-4-dbs-info" class="headerlink" title="2.4 /_dbs_info"></a>2.4 <code>/_dbs_info</code></h3><p><code>GET /_dbs_info</code>:返回CouchDB实例所有数据库列表的数据库信息<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br><strong>请求JSON对象：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>keys(array):</code>被请求的数据库名字(数组)<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code></p><h3 id="2-5-cluster-setup"><a href="#2-5-cluster-setup" class="headerlink" title="2.5 /_cluster_setup"></a>2.5 <code>/_cluster_setup</code></h3><p><code>GET /_cluster_setup</code>:根据群集设置向导返回节点或群集的状态。<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>请求参数：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>ensure_dbs_exist(array):</code>列出系统数据库确保在节点/集群上存在,默认：<code>[&quot;_users&quot;,&quot;_replicator&quot;, &quot;_global_changes&quot;]</code>.<br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>响应JSON对象：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>state(string):</code>节点/集群的当前状态(见下面)<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code></p><p><strong>STATE</strong></p><ul><li><code>cluster_disabled</code>:当前节点完全没有被配置。</li><li><code>single_node_disabled</code>：当前节点被配置为单节点，不具备服务器基本的管理员用户定义并且完整的标准系统数据库没有被创建。如果指定了<code>ensure_dbs_exist</code>查询参数，则提供的数据库列表将覆盖标准系统数据库的默认列表。</li><li><code>single_node_enabled</code>：当前节点被配置为单节点，具有服务器基本的管理员用户定义并且<code>ensure_dbs_exist</code>列表中的数据库已经被创建。</li><li><code>cluster_enabled</code>：当前节点集群数量大于1，没有绑定在<code>127.0.0.1</code>，具有服务器基本的管理员用户定义但是完整的标准系统数据库没有被创建。如果指定了<code>ensure_dbs_exist</code>查询参数，则提供的数据库列表将覆盖标准系统数据库的默认列表。</li><li><code>cluster_finished</code>：当前节点集群数量大于1，没有绑定在<code>127.0.0.1</code>，具有服务器基本的管理员用户定义并且<code>ensure_dbs_exist</code>列表中的数据库已经被创建。</li></ul><p><code>POST /_cluster_setup</code>:配置一个节点作为单节点，或者是集群的一部分，或者完成集群。<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>请求JSON对象：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>action(string):</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>enable_single_node:</code>配置当前节点为单节点<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>enable_cluster:</code>配置本地或远程节点，准备将它添加到新的CouchDB集群<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>add_node:</code>添加一个指定的远程节点到该集群列表中<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>finish_cluster:</code>完成集群的创建并创建标准的系统数据库<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>bind_address(string):</code>当前节点绑定的IP地址<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>username(string):</code>服务器级别的管理员用户名<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>password(string):</code>服务器级别的管理员密码<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>port(number):</code>该节点或远程节点(只用于<code>add_node</code>)绑定的TCP端口<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>node_count(number):</code>集群中节点总数<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>remote_node(string):</code>配置集群中的远程该节点的IP地址<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>remote_current_user(string):</code>服务器级别的管理员授权到远程节点的管理员用户名<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>remote_current_password(string):</code>服务器级别的管理员授权到远程节点的管理员密码<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>host(string):</code>添加到集群的远程节点的IP地址<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>ensure_dbs_exist(array):</code>列出系统数据库确保在该节点上存在。</p><h3 id="2-6-db-updates"><a href="#2-6-db-updates" class="headerlink" title="2.6 /_db_updates"></a>2.6 <code>/_db_updates</code></h3><p><code>GET /_db_updates</code>:返回CouchDB实例上所有数据库事件列表<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>请求参数：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>feed(string)</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>normal</code>:返回所有数据库历史变化，然后关闭连接。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>longpoll</code>:在第一次事件后关闭连接<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>continuous</code>:每个事件发送一行JSON，一直保持socket开启直到超时。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>eventsource</code>:与<code>continuous</code>相似，只是以<code>EventSource</code>格式发送。<br>&emsp;&emsp;&emsp;&emsp;    * <code>timeout(number)</code>：指定多少秒后关闭CouchDB连接<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>heartbeat(number)</code>:每隔多少周期毫秒发送空行保持连接，默认60000<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>since(string)</code>:仅返回指定的序列ID更新<br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>响应JSON对象：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>results(array)</code>:数据库事件的数组<br>&emsp;&emsp;&emsp;&emsp;    * <code>last_seq(string)</code>:记录的最后一个序列ID<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code><br>&emsp;&emsp;&emsp;&emsp;    * 404 <code>Unauthorized</code><br><strong>JSON对象：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>db_name(string):</code>数据库名称<br>&emsp;&emsp;&emsp;&emsp;    * <code>type(string):</code>数据库事件类型(<code>created,updated,deleted</code>)<br>&emsp;&emsp;&emsp;&emsp;    * <code>seq(json):</code>事件更新序列</p><h3 id="2-7-membership"><a href="#2-7-membership" class="headerlink" title="2.7 /_membership"></a>2.7 <code>/_membership</code></h3><p><code>GET /_membership</code>:显示<code>cluster_nodes</code>集群中的部分节点。 <code>all_nodes</code>字段显示该节点知道的所有节点，包括属于集群的节点。在设置集群时非常有用，<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code></p><h3 id="2-8-replicate"><a href="#2-8-replicate" class="headerlink" title="2.8 /_replicate"></a>2.8 <code>/_replicate</code></h3><p><code>GET /_replicate</code>:请求，配置或停止复制操作<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain</code><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type:</code> <code>application/json</code><br><strong>请求JSON对象:</strong><br>&emsp;&emsp;&emsp;&emsp;        * <code>cancel(boolean):</code>取消复制<br>&emsp;&emsp;&emsp;&emsp;        * <code>continuous(boolean):</code>继续复制<br>&emsp;&emsp;&emsp;&emsp;        * <code>create_target(boolean):</code>创建目标数据库，要求管理员权限<br>&emsp;&emsp;&emsp;&emsp;        * <code>doc_ids(array):</code>同步的文档ID的数组<br>&emsp;&emsp;&emsp;&emsp;        * <code>filter(string):</code>过滤器函数的名字<br>&emsp;&emsp;&emsp;&emsp;        * <code>proxy(string):</code>代理服务器的地址<br>&emsp;&emsp;&emsp;&emsp;        * <code>source(string/object):</code>源数据库名字或URL或对象，包含完整的源数据库URL以及参数例如头部信息<br>&emsp;&emsp;&emsp;&emsp;        * <code>target(string/object):</code>目标数据库名字或URL或对象，包含完整的目标数据库URL以及参数例如头部信息<br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>text/plain;charset=utf-8</code><br><strong>响应JSON对象:</strong><br>&emsp;&emsp;&emsp;&emsp;        * <code>history(array):</code>复制历史(见下面)<br>&emsp;&emsp;&emsp;&emsp;        * <code>ok(boolean):</code>复制状态<br>&emsp;&emsp;&emsp;&emsp;        * <code>replication_id_version(number):</code>复制协议版本<br>&emsp;&emsp;&emsp;&emsp;        * <code>session_id(string):</code>唯一的sessionID<br>&emsp;&emsp;&emsp;&emsp;        * <code>source_last_seq(number):</code>从源数据库读取的最后的序列号<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code><br>&emsp;&emsp;&emsp;&emsp;    * 202 <code>Accepted</code><br>&emsp;&emsp;&emsp;&emsp;    * 400 <code>Bad Request</code><br>&emsp;&emsp;&emsp;&emsp;    * 401 <code>Unauthorized</code><br>&emsp;&emsp;&emsp;&emsp;    * 404 <code>Not Found</code><br>&emsp;&emsp;&emsp;&emsp;    * 500 <code>Internal Server Error</code><br><strong>JSON对象:</strong><br>&emsp;&emsp;&emsp;&emsp;        * <code>doc_write_failures(number):</code>文档写失败的数量<br>&emsp;&emsp;&emsp;&emsp;        * <code>docs_read(number):</code>文档读取的数量<br>&emsp;&emsp;&emsp;&emsp;        * <code>docs_written (number):</code>文档成功写到目标的数量<br>&emsp;&emsp;&emsp;&emsp;        * <code>end_last_seq (number):</code>更新流中最后的序列号<br>&emsp;&emsp;&emsp;&emsp;        * <code>end_time (string):</code>复制操作完成的时间<br>&emsp;&emsp;&emsp;&emsp;        * <code>missing_checked (number):</code>检查到的缺失的文档数量<br>&emsp;&emsp;&emsp;&emsp;        * <code>missing_found (number):</code>缺失的文档被发现的数量<br>&emsp;&emsp;&emsp;&emsp;        * <code>recorded_seq (number):</code>记录的最后的序列号<br>&emsp;&emsp;&emsp;&emsp;        * <code>session_id (string):</code>这次复制操作的SessionID<br>&emsp;&emsp;&emsp;&emsp;        * <code>start_last_seq (number):</code>更新流中第一个序列号<br>&emsp;&emsp;&emsp;&emsp;        * <code>start_time (string):</code>复制操作开始的时间</p><h4 id="2-8-1-复制操作"><a href="#2-8-1-复制操作" class="headerlink" title="2.8.1 复制操作"></a>2.8.1 复制操作</h4><p>复制的目的是，在过程结束时，源数据库上的所有活动文档也都在目标数据库中，并且在源数据库中删除的所有文档也都在目标数据库上被删除（如果存在）。<br>复制可以描述为推式或拉式复制：<br>&emsp;&emsp;&emsp;&emsp; * 拉复制是当远程CouchDB实例是源数据库，目标是本地数据库的位置。<br>如果源数据库具有永久IP地址，而目标（本地）数据库可能具有动态分配的IP地址（例如，通过DHCP），则Pull复制是最有用的解决方案。 如果要从中央服务器复制到移动设备或其他设备，则这尤其重要。<br>&emsp;&emsp;&emsp;&emsp; * 推复制是当本地数据库为源数据库，远程数据库为目标数据库。</p><h4 id="2-8-2-指定源和目标数据库"><a href="#2-8-2-指定源和目标数据库" class="headerlink" title="2.8.2 指定源和目标数据库"></a>2.8.2 指定源和目标数据库</h4><p>如果要在以下两种情况之一中执行复制，则必须使用CouchDB数据库的URL规范：<br>&emsp;&emsp;&emsp;&emsp; * 使用远程数据库进行复制（即CouchDB的另一个实例在同一主机或其他主机上）<br>&emsp;&emsp;&emsp;&emsp; * 数据库复制需要权限认证。<br>例如，要请求向其发送请求的CouchDB实例本地数据库和远程数据库之间复制，可以使用以下请求：</p><pre><code>POST http://couchdb:5984/_replicate HTTP/1.1 Content-Type: application/jsonAccept: application/json{    &quot;source&quot; : &quot;recipes&quot;,    &quot;target&quot; : &quot;http://coucdb-remote:5984/recipes&quot;,}</code></pre><p>在所有情况下，源规范和目标规范中所请求的数据库都必须存在。 如果不这样做，则将在JSON对象内返回错误：</p><pre><code>{    &quot;reason&quot; : &quot;could not open http://couchdb-remote:5984/ol1ka/&quot;,}</code></pre><p>您可以通过将<code>create_target</code>字段添加到请求对象来创建目标数据库（只要您的用户凭据允许）：</p><pre><code>POST http://couchdb:5984/_replicate HTTP/1.1 Content-Type: application/jsonAccept: application/json{    &quot;create_target&quot; : true    &quot;source&quot; : &quot;recipes&quot;,    &quot;target&quot; : &quot;http://couchdb-remote:5984/recipes&quot;,}</code></pre><p><code>create_target</code>字段不是破坏性的。 如果数据库已经存在，则复制将正常进行。</p><h4 id="2-8-3-单个复制"><a href="#2-8-3-单个复制" class="headerlink" title="2.8.3 单个复制"></a>2.8.3 单个复制</h4><p>您可以请求复制数据库，以便可以同步两个数据库。 默认情况下，复制过程会发生一次，并将两个数据库同步在一起。 例如，您可以通过在请求JSON内容中提供<code>source</code>和<code>target</code>字段来请求两个数据库之间的单个同步。</p><pre><code>POST http://couchdb:5984/_replicate HTTP/1.1 Accept: application/jsonContent-Type: application/json{    &quot;source&quot; : &quot;recipes&quot;,    &quot;target&quot; : &quot;recipes-snapshot&quot;,}</code></pre><p>在上面的示例中，数据库配方和配方快照将被同步。 这些数据库是发出请求的CouchDB实例的本地数据库。响应将是一个JSON结构，其中包含同步过程的成功（或失败），以及有关该过程的统计信息：</p><pre><code>{    &quot;ok&quot; : true,    &quot;history&quot; : [        {            &quot;docs_read&quot; : 1000,            &quot;session_id&quot; : &quot;52c2370f5027043d286daca4de247db0&quot;,            &quot;recorded_seq&quot; : 1000,            &quot;end_last_seq&quot; : 1000,            &quot;doc_write_failures&quot; : 0,            &quot;start_time&quot; : &quot;Thu, 28 Oct 2010 10:24:13 GMT&quot;,            &quot;start_last_seq&quot; : 0,            &quot;end_time&quot; : &quot;Thu, 28 Oct 2010 10:24:14 GMT&quot;,            &quot;missing_checked&quot; : 0,            &quot;docs_written&quot; : 1000,            &quot;missing_found&quot; : 1000        }    ],    &quot;session_id&quot; : &quot;52c2370f5027043d286daca4de247db0&quot;,    &quot;source_last_seq&quot; : 1000}</code></pre><h4 id="2-8-4-继续复制"><a href="#2-8-4-继续复制" class="headerlink" title="2.8.4 继续复制"></a>2.8.4 继续复制</h4><p>在执行复制请求时，数据库与以前提到的方法的同步仅发生一次。 要使目标数据库从源永久复制，您必须将请求内JSON对象的Continuous字段设置为true。<br>通过连续复制，源数据库中的更改将永久复制到目标数据库，直到您明确要求停止复制为止。</p><pre><code>POST http://couchdb:5984/_replicate HTTP/1.1 Accept: application/jsonContent-Type: application/json{    &quot;continuous&quot; : true    &quot;source&quot; : &quot;recipes&quot;,    &quot;target&quot; : &quot;http://couchdb-remote:5984/recipes&quot;,}</code></pre><p>只要两个实例之间存在网络连接，更改就会在两个数据库之间复制。<br>两个保持彼此同步的数据库，您需要在两个方向上设置复制；也就是说，您必须从源复制到目标，并且必须从目标复制到另一个。</p><h4 id="2-8-5-取消继续复制"><a href="#2-8-5-取消继续复制" class="headerlink" title="2.8.5 取消继续复制"></a>2.8.5 取消继续复制</h4><p>您可以通过将<code>cancel</code>字段添加到JSON请求对象并将值设置为<code>true</code>来取消连续复制。请注意，请求的结构必须与原始结构相同，才能兑现取消请求。例如，如果您请求连续复制，则取消请求还必须包含连续字段。<br>例如，复制请求：</p><pre><code>POST http://couchdb:5984/_replicate HTTP/1.1 Content-Type: application/jsonAccept: application/json{    &quot;source&quot; : &quot;recipes&quot;,    &quot;target&quot; : &quot;http://couchdb-remote:5984/recipes&quot;, &quot;create_target&quot; : true,    &quot;continuous&quot; : true}</code></pre><p>必须使用请求取消复制：</p><pre><code>POST http://couchdb:5984/_replicate HTTP/1.1 Accept: application/jsonContent-Type: application/json{    &quot;cancel&quot; : true,    &quot;continuous&quot; : true    &quot;create_target&quot; : true,    &quot;source&quot; : &quot;recipes&quot;,    &quot;target&quot; : &quot;http://couchdb-remote:5984/recipes&quot;,}</code></pre><p>请求取消不存在的复制将导致404错误。</p><h3 id="2-9-scheduler-jobs"><a href="#2-9-scheduler-jobs" class="headerlink" title="2.9 /_scheduler/jobs"></a>2.9 <code>/_scheduler/jobs</code></h3><p><code>GET /_scheduler/jobs</code>:列出复制任务<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br><strong>请求参数</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>limit(number)：</code>返回多少数量的结果<br>&emsp;&emsp;&emsp;&emsp;    * <code>skip(number):</code>跳过多少数量的结果，以复制ID排序<br><strong>响应JSON对象</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>offset (number)：</code>多少数量的结果被跳过<br>&emsp;&emsp;&emsp;&emsp;    * <code>total_rows (number) ：</code>复制任务的总数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>id (string)：</code>复制ID<br>&emsp;&emsp;&emsp;&emsp;    * <code>database (string)：</code>复制文档数据库<br>&emsp;&emsp;&emsp;&emsp;    * <code>doc_id (string)：</code>复制文档ID<br>&emsp;&emsp;&emsp;&emsp;    * <code>history (list)：</code>事件的时间戳历史以对象列表展示<br>&emsp;&emsp;&emsp;&emsp;    * <code>pid (string)：</code>复制进程ID<br>&emsp;&emsp;&emsp;&emsp;    * <code>node (string)：</code>运行任务的集群中的节点<br>&emsp;&emsp;&emsp;&emsp;    * <code>source (string)：</code>复制源头<br>&emsp;&emsp;&emsp;&emsp;    * <code>target (string)：</code>复制目标<br>&emsp;&emsp;&emsp;&emsp;    * <code>start_time (string)：</code>开始复制的时间戳<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code><br>&emsp;&emsp;&emsp;&emsp;    * 401 <code>Unauthorized</code></p><h3 id="2-10-scheduler-docs"><a href="#2-10-scheduler-docs" class="headerlink" title="2.10 /_scheduler/docs"></a>2.10 <code>/_scheduler/docs</code></h3><p><code>GET /_scheduler/docs</code>:列出复制文档的状态<br><strong>请求头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Accept-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br><strong>响应头：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>Content-Type-</code><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;        * <code>application/json</code><br><strong>请求参数：</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>limit(number):</code>返回多少结果<br>&emsp;&emsp;&emsp;&emsp;    * <code>skip(number):</code>跳过多少数量的结果，以文档ID排序<br><strong>响应JSON对象</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>offset (number)：</code>多少数量的结果被跳过<br>&emsp;&emsp;&emsp;&emsp;    * <code>total_rows (number) ：</code>复制文档的总数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>id (string)：</code>复制ID或者当复制状态为完成或失败时为空<br>&emsp;&emsp;&emsp;&emsp;    * <code>state(string)：</code>复制状态(<code>initializing,running,completed,pending,crashing,error,failed</code>)<br>&emsp;&emsp;&emsp;&emsp;    * <code>database (string)：</code>复制文档的目标数据库<br>&emsp;&emsp;&emsp;&emsp;    * <code>doc_id (string)：</code>复制文档ID<br>&emsp;&emsp;&emsp;&emsp;    * <code>last_update(string)：</code>最后一次更新的时间<br>&emsp;&emsp;&emsp;&emsp;    * <code>info(object)：</code>关于状态的可能的额外信息<br>&emsp;&emsp;&emsp;&emsp;    * <code>node (string)：</code>运行任务的集群中的节点<br>&emsp;&emsp;&emsp;&emsp;    * <code>source (string)：</code>复制源头<br>&emsp;&emsp;&emsp;&emsp;    * <code>target (string)：</code>复制目标<br>&emsp;&emsp;&emsp;&emsp;    * <code>start_time (string)：</code>开始复制的时间戳<br>&emsp;&emsp;&emsp;&emsp;    * <code>error_count(number) ：</code>复制出现错误的数量<br><strong>状态码：</strong><br>&emsp;&emsp;&emsp;&emsp;    * 200 <code>OK</code><br>&emsp;&emsp;&emsp;&emsp;    * 401 <code>Unauthorized</code><br><strong>JSON对象</strong><br>&emsp;&emsp;&emsp;&emsp;    * <code>revisions_checked (number):</code>在复制开始时被检查的修订版本的数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>missing_revisions_found(number):</code>在源处有而目标处没有的修订版本的数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>docs_read (number) :</code>从源处读取的文档的数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>docs_written (number) :</code>写到目标的文档的数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>changes_pending (number):</code>还没有复制完成的数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>doc_write_failures (number) :</code>写目标失败的数量<br>&emsp;&emsp;&emsp;&emsp;    * <code>checkpointed_source_seq (object):</code>最后一个从源处成功复制的序列ID</p><h3 id="2-11-node-node-name-stats"><a href="#2-11-node-node-name-stats" class="headerlink" title="2.11 /_node/{node-name}/_stats"></a>2.11 <code>/_node/{node-name}/_stats</code></h3><h3 id="2-12-node-node-name-system"><a href="#2-12-node-node-name-system" class="headerlink" title="2.12 /_node/{node-name}/_system"></a>2.12 <code>/_node/{node-name}/_system</code></h3><h3 id="2-13-node-node-name-restart"><a href="#2-13-node-node-name-restart" class="headerlink" title="2.13 /_node/{node-name}/_restart"></a>2.13 <code>/_node/{node-name}/_restart</code></h3><h3 id="2-14-utils"><a href="#2-14-utils" class="headerlink" title="2.14 /_utils"></a>2.14 <code>/_utils</code></h3><h3 id="2-15-up"><a href="#2-15-up" class="headerlink" title="2.15 /_up"></a>2.15 <code>/_up</code></h3><h3 id="2-16-uuids"><a href="#2-16-uuids" class="headerlink" title="2.16 /_uuids"></a>2.16 <code>/_uuids</code></h3><h3 id="2-17-favicon-ico"><a href="#2-17-favicon-ico" class="headerlink" title="2.17 /favicon.ico"></a>2.17 <code>/favicon.ico</code></h3><h3 id="2-18-权限认证"><a href="#2-18-权限认证" class="headerlink" title="2.18 权限认证"></a>2.18 权限认证</h3><h3 id="2-19-配置"><a href="#2-19-配置" class="headerlink" title="2.19 配置"></a>2.19 配置</h3>]]></content>
    
    
    <categories>
      
      <category>CouchDb学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CouchDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paxos算法</title>
    <link href="undefined2019/12/23/blog/consensus/paxos/"/>
    <url>2019/12/23/blog/consensus/paxos/</url>
    
    <content type="html"><![CDATA[<h1 id="使Paxos变简单"><a href="#使Paxos变简单" class="headerlink" title="使Paxos变简单"></a>使Paxos变简单</h1><p><strong>摘要</strong><br>Paxos算法，用英语说明时，变得非常简单。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人们一直认为，用于实现容错分布式系统的Paxos算法难以理解，可能是因为最初的演示文稿对许多读者来说是希腊文.事实上，它是分布式算法中最简单，最有效的方法之一。它的核心是共识算法。下一节将说明这种共识算法几乎不可避免地遵循了我们希望它满足的特性。最后一部分介绍了完整的Paxos算法，该算法是通过将共识直接应用于构建分布式系统的状态机方法而获得的，这种方法应该是众所周知的，因为它是有关分布式系统理论的最常被引用的文章的主题。</p><h2 id="2-共识算法"><a href="#2-共识算法" class="headerlink" title="2 共识算法"></a>2 共识算法</h2><h3 id="2-1-问题"><a href="#2-1-问题" class="headerlink" title="2.1 问题"></a>2.1 问题</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设有一个可以提出值的进程的集合。共识算法确保只有一个提出的值被选中。如果没有值被提出，则没有值应该被选中。如果一个值被选中，那么所有过程应该能够<code>learn</code>被选中的值。共识需要满足以下要求：</p><ul><li>只有被提出的值才可以被选中</li><li>被选中的只有一个值</li><li>除非一个值真正地被选中，否则某个进程不会去<code>learn</code>这个值。</li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们不会尝试指定精确的活动要求，然而，目标是确保最终存在一个值被选定。并且当一个值被选定时，进程最终会<code>learn</code>到这个值。<br>我们在共识算法中定义了三种角色：</p><ul><li><code>proposers</code></li><li><code>acceptors</code></li><li><code>learners</code></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在算法的实现中，某个进程可能同时担任多个角色，但是在这里不讨论角色到进程的映射关系。<br>假设角色之间通过发送消息进行通信。我们使用异步，非拜占庭模型：</p><ul><li>角色以任意的速度执行，可能由于停止而宕掉，可能会重启。所有的角色可能在一个值被选中之后宕掉重启。除非宕掉再重启的角色可以记住某些信息，否则等重启后无法确定被选定的值。</li><li>消息可能要花很长时间才能被交付，可能会复制可能会丢失，但是都没有关系。</li></ul><h3 id="2-2-选择一个值"><a href="#2-2-选择一个值" class="headerlink" title="2.2 选择一个值"></a>2.2 选择一个值</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最简单的方式是存在单个的<code>acceptor</code>角色然后选择一个值。一个<code>proposer</code>发送一个<code>proposal</code>到<code>acceptor</code>，<code>acceptor</code>选择它接收到的第一个<code>proposal</code>的值。尽管简单，但是这种解决方案不能满足要求，因为如果<code>acceptor</code>宕掉将会使未来的步骤无法继续(单点故障)。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所以，让我们尝试另外一种方式选择一个值。使用多个<code>acceptor</code>角色代替单个<code>acceptor</code>。一个<code>proposer</code>发送一个<code>proposal</code>值到<code>acceptor</code>角色的集合。<code>acceptor</code>可能会接受<code>proposal</code>的值。当足够多的<code>acceptor</code>接受了该值，则说明这个值被选择了。足够多是多少呢？为了确保只有一个值被选择。我们可以让足够多数量的一组包含任何大多数角色。因为任何两个足够多数量的组都至少有一个共同的接受者，所以如果一个接受者最多可以接受一个值，则此方法有效。<br>在没有失败或消息丢失的情况下，如果只有一个值由单个的<code>proposer</code>提出，我们想要这个值被选择，需要满足以下要求：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P1</strong>:<strong>任何<code>acceptor</code>必须接受它收到的第一个<code>proposal</code>。</strong></p><p>但是这个要求会出现一个问题。如果在同一时间有多个不同的<code>proposer</code>提出多个值，将会导致这种状态：每一个<code>acceptor</code>将会接受到一个值，但是不存在一个被大多数成员接受的值。即使只提出了两个值。如果每一个都由一半的<code>acceptor</code>接受，当一个<code>acceptor</code>宕掉后，将无法确定哪一个值被选择。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P1</strong>和<strong>被大多数的<code>acceptor</code>接受的值才能被选择</strong>，这两个要求隐性说名了每一个<code>acceptor</code>都必须可以接受多个值。我们通过为每个<code>proposal</code>分配一个（自然）编号来跟踪接受者可以接受的不同提案，那么每一个<code>proposal</code>将由一个<code>proposal</code>序号和一个值组成。为了避免冲突，我们要求不同的<code>proposal</code>所含有的<code>proposal</code>序号都是不同的。如何做到这一点取决于实现方法。现在我们只是假设。当一个<code>proposal</code>的值被大多数<code>acceptor</code>接受，那么该值说明被选择。这种情况下，我们说该<code>proposal</code>被选择。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们允许多个<code>proposal</code>被选择。但是需要保证所有被选择的<code>proposal</code>具有相同的值。通过对<code>proposal</code>编号的归纳，足以保证：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P2</strong>：<strong>如果一个值为<em>v</em>的<code>proposal</code>被选择，那么被选择的比该<code>proposal</code>编号大的<code>proposal</code>具有相同的值<em>v</em>。</strong></p><p>由于数字是完全有序的，因此条件P2保证了仅选择一个值的关键安全性。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个<code>proposal</code>要被选择，建议必须至少由一个<code>acceptor</code>接受。 因此，我们可以通过满足以下条件来满足P2：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P2<sup>a</sup></strong>：<strong>如果一个值为<em>v</em>的<code>proposal</code>被选择。那么由任意的<code>acceptor</code>接受的被选择的比该<code>proposal</code>编号大的<code>proposal</code>具有相同的值<em>v</em>。</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们始终保证<strong>P1</strong>来确保一些<code>proposal</code>被选择。因为通信是异步的。一个<code>proposal</code>可以被一些从没有接受到任何<code>proposal</code>的<code>acceptor</code><em>c</em>选择。假设一个新的<code>proposer</code>刚刚启动就接受到一个高编号的且值不同的<code>proposal</code>。<strong>P1</strong>则要求<em>c</em>接受该<code>proposal</code>，因此不满足要求<strong>P2<sup>a</sup></strong>.维持<strong>P1</strong>和<strong>P2<sup>a</sup></strong>需要加强P2<sup>a</sup>为：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P2<sup>b</sup></strong>:<strong>如果一个值为<em>v</em>的<code>proposal</code>被选择，那么每一个由任意的<code>proposer</code>提出的编号高的<code>proposal</code>都具有相同的<em>v</em>。</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于一个<code>proposal</code>都需要在被任意<code>acceptor</code>接受之前都由<code>proposer</code>提出，因此满足了要求<strong>P2<sub>b</sub></strong>，就满足了要求<strong>P2<sub>a</sub></strong>,所以也就满足了<strong>P2</strong>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了发现如何满足要求<strong>P2<sup>b</sup></strong>,让我们考虑一下如何证明它成立。我们假设被选择的<code>proposal</code>具有编号<em>m</em>与值<em>v</em>并且表明证明任何发布的编号为<em>n</em>&gt;<em>m</em>的<code>proposal</code>也具有值<em>v</em>。我们可以通过对<em>n</em>进行归纳来简化证明，因此可以证明<code>proposal</code>编号<em>n</em>在值<em>v</em>的附加假设下每个提案编号都在<em>m</em>..(<em>n</em>−1)区间内并且值为<em>v</em>，其中<em>i..j<em>表示从</em>i<em>到</em>j<em>的一组数字。为了选择编号为</em>m<em>的<code>proposal</code>，必须有一些由大多数<code>acceptor</code>组成的集合</em>C<em>，以便</em>C<em>中的每个<code>acceptor</code>都接受它。将其与归纳假设相结合，选择</em>m<em>的假设就意味着：<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</em>C<em>中的每个<code>acceptor</code>都接受了一个编号为</em>m</em>..(<em>n-1</em>)的<code>proposal</code>，并且任何<code>acceptor</code>接受的每个编号为<em>m</em>..(<em>n-1</em>)的<code>proposal</code>都具有值<em>v</em>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由大多数成员组成的集合<em>s</em>，至少包括一个<em>C</em>中的成员。我们可以通过确保以下不变式得出结论：编号为<em>n</em>的<code>proposal</code>具有值<em>v</em>.<br><strong>P2<sup>c</sup></strong>:<strong>对于任何值<em>v</em>和<em>n</em>，如果一个<code>proposal</code>具有编号<em>n</em>和值<em>v</em>，那么由主要<code>acceptor</code>组成的集合满足以下其中一个条件：</strong></p><ul><li><strong><em>S</em>中的<code>acceptor</code>不会接受任何编号小于<em>n</em>的<code>proposal</code>。</strong></li><li><strong><em>S</em>中的<code>acceptor</code>接受的最大编号的<code>proposal</code>的值为<em>v</em>。</strong></li></ul><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此满足了<strong>P2<sup>c</sup></strong>的不变式即满足了<strong>P2<sup>b</sup>.</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了维持<strong>P2<sup>c</sup></strong>的不变式，<code>proposer</code>想要提出一个编号为<em>n</em>的<code>proposal</code>必须<code>learn</code>(如果有的话)已被或将要被大多数<code>acceptor</code>中的每个<code>acceptor</code>接受的编号小于<em>n</em>的最高编号的<code>proposal</code>。了解已经接受的<code>proposal</code>很容易；预测未来是否会被接受很难。<code>proposer</code>没有试图预测未来，而是通过提取不会有任何此类接受的承诺来控制未来。换句话说，<code>proposer</code>要求<code>acceptor</code>不接受任何其他编号小于<em>n</em>的<code>proposal</code>。 推导出以下用于发布提案的算法：</p><ul><li><strong>一个<code>proposal</code>选择编号为<em>n</em>的<code>proposal</code>并发送请求到包括半数以上个<code>acceptor</code>的集合，并要求得到以下其中一个回应：</strong><ol><li><strong>一个不会接受编号值小于<em>n</em>的<code>proposal</code>的承诺。</strong></li><li><strong>如果<code>acceptor</code>已经接受过<code>proposal</code>，则响应已接受的小于编号<em>n</em>的最大编号的<code>proposal</code>。</strong></li></ol></li></ul><p>将该请求称为编号为<em>n</em>的<code>prepare</code>请求。</p><ul><li><strong>如果<code>proposer</code>接受到大部分<code>acceptor</code>的请求响应，那么可以提出一个编号为<em>n</em>且值为<em>v</em>的<code>proposal</code>。这里的<em>v</em>是请求响应中编号最高的<code>proposal</code>中的值。或者如果响应中没有任何<code>proposal</code>，那么该值将由<code>proposer</code>自由选择。</strong></li></ul><p><code>proposer</code>通过发送<code>proposal</code>到包括半数以上个<code>acceptor</code>集合(需要与起初的请求集合不是同一个)，并期望接受该请求。将该请求称为<code>accept</code>请求。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里描述的是关于<code>proposer</code>的算法。关于<code>acceptor</code>呢？<code>acceptor</code>可以从<code>proposer</code>接收两种类型的请求：<code>prepare</code>和<code>accept</code>请求。<code>acceptor</code>可以忽略任何请求而不会影响安全性。 因此，我们仅需说何时才允许响应请求。它总是可以响应<code>prepare</code>请求。 如果它没有答应不接受，它可以响应<code>accept</code>请求，接受<code>proposal</code>。 换一种说法：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>P1<sup>a</sup></strong>:<strong>如果<code>acceptor</code>没有响应编号大于<em>n</em>的<code>prepare</code>请求那么可以接收一个编号为<em>n</em>的<code>proposal</code>。</strong></p><p>观察到<strong>P1<sup>a</sup></strong>包含<strong>P1</strong>。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们现在拥有了一个完整的算法选择一个满足安全性要求的值-通过假设一个唯一的<code>proposal</code>编号。最终算法通过一个小的优化获得。<br>假设<code>acceptor</code>收到编号为<em>n</em>的<code>prepare</code>请求.但是已经响应过一个编号值大于<em>n</em>的<code>prepare</code>请求。因此承诺不会接受任何编号为<em>n</em>的新的<code>proposal</code>请求。这样，<code>acceptor</code>就没有理由响应新的<code>prepare</code>请求，因为它不会接受<code>proposer</code>想要发出的编号为<em>n</em>的<code>proposal</code>。 因此，我们让<code>acceptor</code>忽略这样的<code>prepare</code>请求。 我们也可以忽略它已经接受的<code>proposal</code>的<code>prepare</code>请求。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过这种优化，<code>acceptor</code>只需要记住它曾经接受的编号最高的<code>proposal</code>以及它已响应的编号最高的<code>prepare</code>请求的数量。无论如何失败，<strong>P2<sup>c</sup></strong>也必须保持不变，所以即使失败，接受者也必须记住该信息，然后重新启动。 请注意，只要<code>proposer</code>从不尝试发布具有相同编号的另一个<code>proposal</code>，它总是可以放弃该<code>proposal</code>并将其遗忘。<br>将<code>proposer</code>和<code>acceptor</code>的动作放在一起，我们看到该算法在以下两个阶段中运行：</p><p><strong>阶段一</strong>：</p><ol><li><strong><code>proposer</code>选择一个编号为<em>n</em>的<code>proposal</code>并发送编号为<em>n</em>的<code>prepare</code>请求到大多数的<code>acceptor</code>。</strong></li><li><strong>如果<code>acceptor</code>接受了编号为<em>n</em>的<code>prepare</code>请求，并且编号<em>n</em>比接受到的任何<code>prepare</code>请求的编号都要大，那么将会响应它接受到的编号最大的<code>proposal</code>(如果有的话)到<code>proposer</code>并且承诺不再接受任何编号小于<em>n</em>的<code>proposal</code>。</strong></li></ol><p><strong>阶段二</strong>：</p><ol><li><strong>如果<code>proposer</code>从大多数的<code>acceptor</code>接受到编号为<em>n</em>的请求响应。那么将会发送编号为<em>n</em>且值为<em>v</em>的<code>accept</code>请求到接受<code>prepare</code>请求的每一个<code>acceptor</code>。这里的<em>v</em>是所有<code>prepare</code>响应中编号最大的响应中的值。或者当<code>prepare</code>响应中没有<code>proposal</code>时，该值由自己选择。</strong></li><li><strong>如果<code>acceptor</code>接收到编号为<em>n</em>的<code>accept</code>请求，除非它已经响应了一个编号大于<em>n</em>的<code>prepare</code>请求，否则它将接受该<code>proposal</code>。</strong></li></ol><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个<code>proposer</code>可以提出多个<code>proposal</code>，只要它遵循每个<code>proposal</code>的算法即可。 它可以随时在协议中间放弃<code>proposal</code>。(即使<code>proposal</code>的请求和/或响应可能在<code>proposal</code>被放弃很长时间后到达目的地，也可以保持正确性。)如果某个<code>proposer</code>已经开始尝试发布编号更大的<code>proposal</code>，那么放弃<code>proposal</code>可能是一个好主意。因此，如果某个<code>acceptor</code>忽略了<code>prepare</code>或者是<code>accept</code>请求，那是因为已经接受了一个编号更大的<code>prepare</code>请求。所以<code>acceptor</code>应该通知<code>proposer</code>放弃它的<code>proposal</code>。这是对性能的优化并且不会影响正确性。</p><h3 id="2-3-learn一个被选择的值"><a href="#2-3-learn一个被选择的值" class="headerlink" title="2.3 learn一个被选择的值"></a>2.3 <code>learn</code>一个被选择的值</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>learner</code>必须发现一个被大多数<code>acceptor</code>接受的<code>proposal</code>，才能<code>learn</code>被选择的值。最明显的算法是让每个<code>acceptor</code>在接受<code>proposal</code>时对所有<code>learner</code>做出回应，向他们发送<code>proposal</code>。这使<code>learner</code>能够尽快发现所选的值，但是它要求每个<code>acceptor</code>对每个<code>learner</code>做出回应-回应的数量等于<code>acceptor</code>数量与<code>learner</code>数量的乘积。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非拜占庭式失败的假设使一个<code>learner</code>很容易从另一个<code>learner</code>那里发现一个值已经被接受。我们可以让<code>acceptor</code>以他们的接受来回应一个特别的<code>learner</code>，当选择了一个值时，后者又会通知其他<code>learner</code>。这种方法需要所有<code>learner</code>进行额外的一轮努力才能发现所选的值。它也不太可靠，因为特别的<code>learner</code>可能会失败。但是，它需要的响应数量仅等于<code>acceptor</code>数量和<code>learner</code>数量之和。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更一般而言，<code>acceptor</code>可以用他们对某些特别的<code>learner</code>的接受做出响应，然后当选择了某个值时，每个<code>learner</code>都可以通知所有<code>learner</code>。使用更多的特别的<code>learner</code>以更高的通信复杂性为代价提供更高的可靠性。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于消息丢失，一个值的被选择可能会没有<code>learner</code>会发现。<code>learner</code>可以向<code>acceptor</code>询问他们接受了哪些<code>proposal</code>，但是<code>acceptor</code>的失败可能使得无法知道大多数人是否接受了特定<code>proposal</code>。在这种情况下，<code>learner</code>只有在选择新<code>proposal</code>时才能发现什么值被选择。 如果<code>learner</code>需要知道是否一个值被选择，则可以使用上述算法让<code>proposer</code>发布<code>proposal</code>。</p><h3 id="2-4-流程"><a href="#2-4-流程" class="headerlink" title="2.4 流程"></a>2.4 流程</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很容易构造这样一个场景，在该场景中，两个<code>proposer</code>各自不断发布数量越来越多的<code>proposal</code>序列，而从未选择过一个。 <code>proposer</code><em>p</em>完成阶段1的编号为<em>n1</em>的<code>proposal</code>。然后，另一个<code>proposer</code><em>q</em>完成阶段1的编号<em>n2&gt;n1</em>的<code>proposal</code>。 <code>proposer</code><em>p</em>的第2阶段编号为<em>n1</em>的<code>proposal</code>请求被忽略，因为<code>acceptor</code>都承诺不接受任何编号少于<em>n2</em>的新<code>proposal</code>。 因此，<code>proposer</code><em>p</em>又开始以编号为<em>n3&gt;n2</em>的<code>proposal</code>进行阶段1，导致阶段2<code>proposer</code><em>q</em>的请求被忽略,并一直持续下去。为了保证进度，必须选择特别的<code>proposer</code>作为尝试发布<code>proposal</code>的唯一<code>proposer</code>。 如果特别的<code>proposer</code>可以与大多数<code>acceptor</code>成功通信，并且使用的<code>proposal</code>编号大于已使用的<code>proposal</code>的编号，那么它将成功发布被接受的<code>proposal</code>。并在得知某个<code>proposal</code>具有更高<code>proposal</code>编号的请求后通过放弃<code>proposal</code>再试一次，特别的<code>proposer</code>最终将选择足够高的<code>proposal</code>编号。如果系统（<code>proposer</code>，<code>acceptor</code>和通信网络）能够正常工作，那么可以通过选举一个特别的<code>proposer</code>来实现活跃性。Fischer，Lynch和Pattererson的著名成果表明，一种可靠的选择<code>proposer</code>的算法必须使用随机性或实时性，例如使用超时。但是，无论选举成功与否，都会确保安全。</p><h3 id="2-5-实现"><a href="#2-5-实现" class="headerlink" title="2.5 实现"></a>2.5 实现</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Paxos算法假设网络的进程。在其共识算法中，每个进程都扮演着<code>proposer</code>，<code>acceptor</code>和<code>learner</code>的角色。该算法选择一个<code>leader</code>，该<code>leader</code>同时扮演特别的<code>proposer</code>与特别的<code>learner</code>。Paxos共识算法正是上述算法，其中请求和响应作为普通消息发送。（响应消息带有相应的<code>proposal</code>编号，以防止混淆。）在故障期间保留的稳定存储用于维护<code>acceptor</code>必须记住的信息。<code>acceptor</code>在实际发送响应之前将其预期的响应记录在稳定的存储中。剩下的就是描述如何保证没有两个<code>proposal</code>编号相同的机制。不同的<code>proposer</code>从不相交的数字集中选择他们的数字，因此两个不同的<code>proposer</code>从不发布具有相同编号的<code>proposal</code>。 每个<code>proposer</code>（在稳定的存储中）都会记住尝试发布的编号最高的<code>proposal</code>，并从第1阶段开始使用比其已经使用过的<code>proposer</code>编号更高的<code>proposer</code>编号。</p><h2 id="3-状态机的实现"><a href="#3-状态机的实现" class="headerlink" title="3 状态机的实现"></a>3 状态机的实现</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现分布式系统的一种简单方法是作为向中央服务器发出命令的客户端的集合。 服务器可以描述为以某种顺序执行客户端命令的确定性状态机。状态机具有当前状态。它通过将命令作为输入并产生输出和新状态来执行步骤。例如，分布式银行系统的客户可能是柜员，并且状态机状态可能由所有用户的帐户余额组成。 提现将通过执行状态机命令来执行，该命令会在且仅当余额大于提款金额时才减少帐户的余额，并产生旧余额和新余额作为输出。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果单个中央服务器发生故障，则该服务器的实施将失败。因此，我们改为使用服务器的集合，每个服务器独立实现状态机。 因为状态机是确定性的，所以如果所有服务器都执行相同的命令序列，则所有服务器将产生相同的状态序列和输出。 然后，发出命令的客户端可以使用任何服务器为其生成的输出。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了确保所有服务器执行相同的状态机命令序列，我们实现了Paxos共识算法的不同实例序列，第i个实例选择的值是序列中的第i个状态机命令。每个服务器在算法的每个实例中扮演所有角色(<code>proposer</code>，<code>acceptor</code>和<code>learner</code>)。现在，假设服务器组是固定的，因此共识算法的所有实例使用相同的角色。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在正常操作中，将选择一台服务器作为<code>leader</code>，在共识算法的所有实例中均充当特别的<code>proposer</code>(尝试发布<code>proposal</code>的唯一的<code>proposer</code>)。 客户将命令发送给<code>leader</code>，<code>leader</code>决定每个命令应出现的顺序。如果<code>leader</code>确定某个客户命令应为第135个命令，则它将尝试选择该命令作为共识算法的第135个实例的值。通常会成功。 它也可能由于故障而失败，或者因为另一台服务器也认为自己是<code>leader</code>并且认为另一条客户端命令应该为第135条命令。但是共识算法确保最多可以选择一个命令作为第135个命令。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种方法的效率的关键在于，在Paxos共识算法中，直到第2阶段才选择要提出的值。回想一下，在完成<code>proposer</code>算法的第1阶段之后，要么确定了要提出的值，要么提议者可以自由提出任何值。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在，将描述Paxos状态机实现在正常操作期间如何工作。稍后，将讨论可能出问题的地方。 考虑当前<code>leader</code>刚刚失败并选择了新<code>leader</code>时会发生什么。(系统启动是一种特殊情况，其中尚未提出任何命令。)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新的<code>leader</code>，在共识算法的所有情况下都是<code>learner</code>，应该知道已经选择的大多数命令。 假设它知道命令1–134、138和139，即共识算法实例1–134、138和139中选择的值。(将在后面看到如何在命令序列中出现这样的间隙.)然后，它执行实例135-137和大于139的所有实例的阶段1。(在下面描述如何做到这一点.)假设这些执行确定了在实例135和140中要提出的值，但在所有其他情况下都不受约束。领导者然后对实例135和140执行阶段2，从而选择命令135和140。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>leader</code>以及任何其他服务器一样<code>learn leader</code>知道的所有命令，现在可以执行命令1–135。但是，它无法执行它也知道的命令138-140，因为尚未选择命令136和137。<code>leader</code>可以将客户请求的下两个命令作为命令136和137。相反，我们通过建议一个特殊的<code>no-op</code>命令作为命令136和137，使状态保持不变，从而立即填补了空白。（这是通过执行共识算法实例136和137的阶段2来完成的。）一旦选择了这些<code>no-op</code>命令，就可以执行命令138-140。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在已选择命令1–140。<code>leader</code>还已经为大于共识算法140的所有实例完成了阶段1，并且可以自由地在那些实例的阶段2中提出任何值。它将命令号141分配给客户端请求的下一个命令，并建议将其作为共识算法实例141的阶段2中的值。 它提出了接收到的下一个客户端命令作为命令142，依此类推。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<code>leader</code>可以在获悉已选择其提出的命令141之前提出命令142。 它在提议命令141中发送的所有消息都可能丢失，并且有可能在任何其他服务器了解<code>leader</code>作为命令141提出的建议之前选择命令142。当<code>leader</code>未能收到在实例141中的消息对其阶段2的预期响应时，它将重传那些消息。如果一切顺利，将选择其建议的命令。但是，它可能失败，从而在选择的命令序列中留下空白。通常，假设<code>leader</code>可以提前获得α命令-也就是说，在选择命令<code>1</code>至<code>i</code>之后，它可以提出命令<code>i+1</code>至<code>i+α</code>。最多可能会出现<code>α-1</code>命令的间隔。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于实例135-137和大于139的所有实例,新选择的<code>leader</code>在上面的方案中使用共识算法执行第1阶段的次数不限。它对所有实例使用相同的编号，可以通过向其他服务器发送一条合理的短消息来实现此目的。在阶段1中，只有在<code>acceptor</code>已经从某个<code>proposer</code>那里收到阶段2消息的情况下，接受者才用简单的OK做出响应.(仅对于实例135和140是这种情况.)因此，服务器(充当<code>acceptor</code>)可以使用单个合理的短消息对所有实例进行响应。 因此，执行这些无限多个阶段1实例不会带来任何问题。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于<code>leader</code>失败选举新<code>leader</code>的情况很少见，因此执行状态机命令的有效成本（即，对命令/值达成共识）是仅执行共识算法第二阶段的成本。可以证明，存在故障时达成共识的任何算法的最小可能成本在Paxos共识算法的第2阶段。 因此，Paxos算法本质上是最佳的。<br>对系统正常运行的讨论假定只有一个<code>leader</code>，除了在当前<code>leader</code>失败和选举新<code>leader</code>之间的短暂时间之外。 在异常情况下，<code>leader</code>选举可能会失败。如果没有服务器充当<code>leader</code>，则不会提出新命令。如果多个服务器认为自己是<code>leader</code>，则它们都可以在同一共识算法实例中提出值，这可能会阻止选择任何值。但是，安全性得以保留-两个不同的服务器将永远不会在选择作为第i个状态机命令的值上发生分歧。仅选举一位<code>leader</code>才能确保取得进展。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果服务器组可以更改，则必须采用某种方法确定哪些服务器实现共识算法的哪些实例。最简单的方法是通过状态机本身。 当前服务器集可以成为状态的一部分，并且可以通过普通的状态机命令进行更改。我们可以允许<code>leader</code>提前获得<code>α</code>命令,通过让执行第<code>i</code>个状态机命令后的状态指定执行共识算法的实例<code>i+α</code>的服务器集。这允许任意复杂的重新配置算法的简单实现。</p>]]></content>
    
    
    <categories>
      
      <category>consensus</category>
      
    </categories>
    
    
    <tags>
      
      <tag>algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux命令-grep,sed,awk</title>
    <link href="undefined2019/12/22/blog/linux/Linux%E5%91%BD%E4%BB%A4-grep_sed_awk/"/>
    <url>2019/12/22/blog/linux/Linux%E5%91%BD%E4%BB%A4-grep_sed_awk/</url>
    
    <content type="html"><![CDATA[<h1 id="grep"><a href="#grep" class="headerlink" title="grep"></a>grep</h1><hr><p>(global search regular expression[RE] and print out the line)<br>正则表达式全局搜索并将行打印出来</p><ul><li>在文件中查找包含字符串”text”的行</li></ul><pre><code>grep text local_filegrep &quot;text&quot; local_file #另一种方式grep &quot;text&quot; local_file1 local_file2 ...  #查找多个文件</code></pre><ul><li>在文件中查找<strong>不</strong>包含字符串”text”的行</li></ul><pre><code>grep -v &quot;text&quot; local_file</code></pre><ul><li><strong>忽略大小写</strong></li></ul><pre><code>grep -i &quot;TeXt&quot; local_filegrep -y &quot;TeXt&quot; local_file</code></pre><ul><li><strong>不显示错误信息</strong>，常用于脚本文件中</li></ul><pre><code>grep -s &quot;text&quot; local_file</code></pre><ul><li><strong>只打印出匹配到的字符串</strong></li></ul><pre><code>grep -o &quot;text&quot; local_file</code></pre><ul><li><strong>统计文件中有多少行包含需要查找的字符串</strong></li></ul><pre><code>grep -c &quot;text&quot; local_file</code></pre><ul><li><strong>不输出信息</strong>，命令运行成功返回0.失败返回非0值，用于判断</li></ul><pre><code>grep -q &quot;text&quot; local_file</code></pre><ul><li>匹配多个字符串,相当于逻辑中的或</li></ul><pre><code>grep -e &quot;text1&quot; -e &quot;text2&quot; local_file</code></pre><ul><li><strong>递归查找</strong>，用于多级目录中的文件</li></ul><pre><code>grep -r &quot;text&quot; . #在当前目录下进行查找</code></pre><ul><li>输出匹配需要查找字符串的行以及<strong>之前</strong>的行</li></ul><pre><code>grep &quot;text&quot; -B 3 local_file #输出之前的3行</code></pre><ul><li>输出匹配需要查找字符串的行以及<strong>之后</strong>的行</li></ul><pre><code>grep &quot;text&quot; -A 3 local_file #输出之后的3行</code></pre><h1 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h1><hr><p>流编辑器，用来编辑一个或者多个文件，简化对文件的重复操作。在缓冲区内操作，除非特别指定，不对文件本身内容进行修改。</p><h2 id="i"><a href="#i" class="headerlink" title="-i"></a><code>-i</code></h2><p>对文件本身进行修改</p><h2 id="q"><a href="#q" class="headerlink" title="-q"></a><code>-q</code></h2><ul><li>打印出第2行后退出<code>sed</code></li></ul><pre><code>sed &#39;2q&#39; local_file</code></pre><h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><ul><li>查找第2-5行数据</li></ul><pre><code>sed &#39;2,5p&#39; local_filesed -n &#39;2,5p&#39; local_file #并打印行号</code></pre><ul><li>查找包含字符串”text”的行与包含字符串”file”的行范围内的行</li></ul><pre><code>sed &#39;/text/,/file/p&#39; local_file</code></pre><ul><li>查找从第2行开始一直到以字符串”text“开头的行之间的所有行</li></ul><pre><code>sed &#39;2,/^text/p&#39; local_file</code></pre><h2 id="添加"><a href="#添加" class="headerlink" title="添加"></a>添加</h2><ul><li>在第2行后面一行添加字符串”text”</li></ul><pre><code>sed &#39;2a text&#39; local_file</code></pre><ul><li>在第二行前面一行添加字符串”text”</li></ul><pre><code>sed &#39;2i text&#39; local_file</code></pre><ul><li>在每一个单词前面加上字符”a”:</li></ul><pre><code>sed &#39;s/\w\+/a&amp;/g&#39;  # \w\+匹配每一个单词 &amp;对应之前匹配的每一个单词</code></pre><h2 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h2><ul><li>替换字符串<code>file</code>为<code>files</code></li></ul><pre><code>sed &#39;s/file/files/g&#39; local_file #打印到控制台，不修改文件sed &#39;s:file:file:g&#39; local_file # /标记可以使用其他符号代替sed -i &#39;s/file/files/g&#39; local_file #修改文件本身内容，不打印到控制台</code></pre><ul><li>替换第2-5行为字符串”text”</li></ul><pre><code>sed &#39;2,5c text&#39; local_file</code></pre><h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><ul><li>删除文件内的第2-5行</li></ul><pre><code>sed &#39;/2,5/d&#39; local_file</code></pre><ul><li>删除开头字符串为”text”的行</li></ul><pre><code>sed &#39;/^text.*//g&#39; local_filesed &#39;/^text/&#39;d local_file</code></pre><ul><li>删除最后一行</li></ul><pre><code>sed &#39;$d&#39; local_file</code></pre><ul><li>删除空白行</li></ul><pre><code>sed &#39;/^$/d&#39; local_file</code></pre><h1 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h1><hr><ul><li>打印每一行的第2，3列数据</li></ul><pre><code>awk &#39;{print $2,$3}&#39; local_file</code></pre>]]></content>
    
    
    <categories>
      
      <category>Linux命令</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>正则表达式</title>
    <link href="undefined2019/12/22/blog/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <url>2019/12/22/blog/linux/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="字符位置"><a href="#字符位置" class="headerlink" title="字符位置"></a>字符位置</h1><table><thead><tr><th>符号表示</th><th>符号含义</th><th>示例</th></tr></thead><tbody><tr><td><code>^str</code></td><td>需要查找的字符在行首</td><td><code>^a</code> 查找以字符<code>a</code>开头</td></tr><tr><td><code>str$</code></td><td>需要查找的字符在行尾</td><td><code>a$</code> 查找以字符<code>a</code>结尾</td></tr></tbody></table><h1 id="字符表示"><a href="#字符表示" class="headerlink" title="字符表示"></a>字符表示</h1><table><thead><tr><th>符号表示</th><th>符号含义</th><th>示例</th></tr></thead><tbody><tr><td><code>\</code></td><td>转义符</td><td>将特殊字符变为普通字符如<code>\^</code></td></tr><tr><td><code>.</code></td><td>说明一定有一个任意的字符</td><td><code>a.b</code> 说明字符<code>a</code>与<code>b</code>之间一定存在一个字符</td></tr><tr><td><code>*</code></td><td>说明存在零个或者多个前一个字符</td><td><code>a*</code>说明字符<code>a</code>后边可能存在0个或多个字符<code>a</code> <code>.*</code>表示存在任意字符</td></tr><tr><td><code>+</code></td><td><strong>扩展正则</strong>说明存在一个或一个以上前一个字符</td><td><code>a+</code>说明字符<code>a</code>后边可能存在1个或多个字符<code>a</code></td></tr><tr><td><code>?</code></td><td><strong>扩展正则</strong>说明存在0个或一个前一个字符</td><td><code>ab？</code>查找字符<code>ab</code>或者是<code>a</code></td></tr><tr><td>`</td><td>`</td><td>或</td></tr><tr><td><code>()</code></td><td><strong>扩展正则</strong>字符集合</td><td>`(ab</td></tr><tr><td><code>()+</code></td><td><strong>扩展正则</strong>多个重复字符集合</td><td><code>(ab)+</code>:查找具有一个以上<code>ab</code>子字符串的字符串</td></tr><tr><td><code>[list]</code></td><td>列出可能存在的字符</td><td><code>a[bc]</code>查找字符<code>ab</code>或者是<code>ac</code></td></tr><tr><td><code>[n1-n2]</code></td><td>列出可能存在的字符区间</td><td><code>[a-g]</code> 查找字符区间<code>a-g</code>中任意字符</td></tr><tr><td><code>[^list}</code></td><td>列出不需要的字符即反向选择</td><td><code>[^a]</code> 查找字符中不存在<code>a</code>的字符</td></tr><tr><td><code>\{n,m\}</code></td><td><strong>连续</strong><code>n</code>到<code>m</code>个之前的字符</td><td><code>a\{2,3\}</code>查找字符<code>aa</code>或者是<code>aaa</code>;</br> <code>a\{2\}</code>查找字符<code>aa</code>;</br><code>a\{2,\}</code>查找连续2个字符<code>a</code>以上的字符如<code>aaa</code>，<code>aaaa</code>等;</td></tr></tbody></table><h1 id="字符替换"><a href="#字符替换" class="headerlink" title="字符替换"></a>字符替换</h1><table><thead><tr><th>符号表示</th><th>符号含义</th></tr></thead><tbody><tr><td><code>[:digit:]</code></td><td>代表数字<code>0-9</code></td></tr><tr><td><code>[:alnum:]</code></td><td>代表英文字符和数字:<code>a-z,A-Z,0-9</code></td></tr><tr><td><code>[:lower:]</code></td><td>代表小写字符:<code>a-z</code></td></tr><tr><td><code>[:upper:]</code></td><td>代表大写字符:<code>A-Z</code></td></tr><tr><td><code>[:space:]</code></td><td>代表空格，包括<code>[Tab]</code></td></tr></tbody></table><h1 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h1><table><thead><tr><th>符号表示</th><th>符号含义</th></tr></thead><tbody><tr><td><code>\b</code></td><td>回退键</td></tr><tr><td><code>\f</code></td><td>换页符</td></tr><tr><td><code>\n</code></td><td>换行符</td></tr><tr><td><code>\r</code></td><td>回车键</td></tr><tr><td><code>\t</code></td><td><code>Tab</code>键</td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>正则表达式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CouchDB学习-维护</title>
    <link href="undefined2019/12/22/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-%E7%BB%B4%E6%8A%A4/"/>
    <url>2019/12/22/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-%E7%BB%B4%E6%8A%A4/</url>
    
    <content type="html"><![CDATA[<p><a href="https://docs.couchdb.org/en/stable/maintenance/index.html" target="_blank" rel="noopener">官方文档</a></p><h1 id="1-压缩"><a href="#1-压缩" class="headerlink" title="1 压缩"></a>1 压缩</h1><hr><p>压缩操作是通过从数据库或者视图索引文件中移除无用的和老的数据减少硬盘使用空间.操作非常简单类似于其他数据库(SQLite等)管理系统。<br>在压缩目标期间，CouchDB将创建扩展名为.compact的新文件，并将仅实际数据传输到该文件中。 因此，CouchDB首先检查可用磁盘空间-它应比压缩文件的数据大两倍。<br>当所有实际数据都成功传输到压缩文件后，CouchDB用目标文件替换目标文件。</p><h2 id="1-1-数据库压缩"><a href="#1-1-数据库压缩" class="headerlink" title="1.1 数据库压缩"></a>1.1 数据库压缩</h2><p>数据库压缩通过删除更新期间创建的未使用的文件部分来压缩数据库文件。 旧文档修订版被少量称为<code>tombstone</code>的元数据代替，该元数据用于复制期间的冲突解决。 可以使用<code>_revs_limit</code>URL配置存储的修订版本（以及<code>tombstone</code>）的数量。<br>压缩是每个数据库手动触发的操作，并作为后台任务运行。要针对特定的数据库启动它，需要发送目标数据库的HTTP POST<code>/{db}/_compact</code>子资源：</p><pre><code>curl -H &quot;Content-Type: application/json&quot; -X POST http://localhost:5984/my_db/_compact</code></pre><p>成功的话，将立即返回HTTP 状态码<code>202 Accepted</code>。</p><pre><code>HTTP/1.1 202 AcceptedCache-Control: must-revalidate Content-Length: 12Content-Type: text/plain; charset=utf-8 Date: Wed, 19 Jun 2013 09:43:52 GMT Server: CouchDB (Erlang/OTP)</code></pre><pre><code>{&quot;ok&quot;:true}</code></pre><p>尽管未使用请求主体，但仍必须为请求指定带有<code>application/json</code>值的<code>Content-Type</code>标头。否则，您会知道HTTP状态<code>415不支持的媒体类型响应</code>：</p><pre><code>HTTP/1.1 415 Unsupported Media TypeCache-Control: must-revalidate Content-Length: 78Content-Type: application/json Date: Wed, 19 Jun 2013 09:43:44 GMT Server: CouchDB (Erlang/OTP){&quot;error&quot;:&quot;bad_content_type&quot;,&quot;reason&quot;:&quot;Content-Type must be application/json&quot;}</code></pre><p>当压缩成功启动并运行时，可以通过数据库信息资源获取有关压缩的信息：</p><pre><code>curl http://localhost:5984/my_db</code></pre><pre><code>HTTP/1.1 200 OKCache-Control: must-revalidate Content-Length: 246Content-Type: application/json Date: Wed, 19 Jun 2013 16:51:20 GMT Server: CouchDB (Erlang/OTP){    &quot;committed_update_seq&quot;: 76215,     &quot;compact_running&quot;: true,     &quot;data_size&quot;: 3787996,     &quot;db_name&quot;: &quot;my_db&quot;,     &quot;disk_format_version&quot;: 6,     &quot;disk_size&quot;: 17703025,     &quot;doc_count&quot;: 5091,     &quot;doc_del_count&quot;: 0,     &quot;instance_start_time&quot;: &quot;0&quot;,     &quot;purge_seq&quot;: 0,    &quot;update_seq&quot;: 76215}</code></pre><p>请注意，<code>compaction_running</code>字段为<code>true</code>，指示压缩实际上正在运行。 要跟踪压缩进度，可以查询<code>_active_tasks</code>资源：</p><pre><code>curl http://localhost:5984/_active_tasks</code></pre><pre><code>HTTP/1.1 200 OKCache-Control: must-revalidateContent-Length: 175Content-Type: application/json Date: Wed, 19 Jun 2013 16:27:23 GMT Server: CouchDB (Erlang/OTP)[    {        &quot;changes_done&quot;: 44461,         &quot;database&quot;: &quot;my_db&quot;,        &quot;pid&quot;: &quot;&lt;0.218.0&gt;&quot;,         &quot;progress&quot;: 58,        &quot;started_on&quot;: 1371659228,         &quot;total_changes&quot;: 76215,         &quot;type&quot;: &quot;database_compaction&quot;,         &quot;updated_on&quot;: 1371659241    }]</code></pre><h2 id="1-2-视图压缩"><a href="#1-2-视图压缩" class="headerlink" title="1.2 视图压缩"></a>1.2 视图压缩</h2><p>与数据库视图不同，视图也需要像数据库一样进行压缩，这与按每个设计文档按组对数据库视图进行压缩不同。要启动其压缩，需要发送HTTP POST<code>/{db}/_compact/{ddoc}</code>请求：</p><pre><code>curl -H &quot;Content-Type: application/json&quot; -X POST http://localhost:5984/dbname/_compact/designname</code></pre><pre><code>{&quot;ok&quot;:true}</code></pre><p>这将从指定设计文档的当前版本压缩视图索引。 HTTP响应代码<code>202 Accepted</code>(类似于数据库的压缩)，并且将创建压缩后台任务。</p><h3 id="1-2-1视图清理"><a href="#1-2-1视图清理" class="headerlink" title="1.2.1视图清理"></a>1.2.1视图清理</h3><p>磁盘上的视图索引以视图定义的MD5哈希命名。更改视图时，旧索引仍保留在磁盘上。要清除所有过时的视图索引（以视图的MD5表示形式命名的文件，该文件不再存在），可以触发视图清除：</p><pre><code>curl -H &quot;Content-Type: application/json&quot; -X POST http://localhost:5984/dbname/_view_cleanup</code></pre><pre><code>{&quot;ok&quot;:true}</code></pre><h2 id="1-3-自动压缩"><a href="#1-3-自动压缩" class="headerlink" title="1.3 自动压缩"></a>1.3 自动压缩</h2><p>虽然需要手动触发数据库和视图的压缩，但也可以配置自动压缩，以便基于各种条件自动触发数据库和视图的压缩。 在CouchDB的配置文件中配置了自动压缩。<br>守护程序<code>/compaction_daemon</code>负责触发压缩。 默认情况下启用它并自动启动。在压缩部分中配置了触发压缩的条件。</p><h1 id="2-性能"><a href="#2-性能" class="headerlink" title="2 性能"></a>2 性能</h1><hr><p>无论您如何编写代码，即使有了成千上万的文档，通常都会发现CouchDB可以很好地执行。但是一旦开始阅读数百万个文档，您需要更加小心。</p><h2 id="2-1-硬盘IO"><a href="#2-1-硬盘IO" class="headerlink" title="2.1 硬盘IO"></a>2.1 硬盘IO</h2><h3 id="2-1-1-文件大小"><a href="#2-1-1-文件大小" class="headerlink" title="2.1.1 文件大小"></a>2.1.1 文件大小</h3><p>文件大小越小，I/O操作将越少，CouchDB和操作系统可以缓存的文件越多，复制，备份等的速度就越快。因此，您应该仔细检查所要存储的数据储存。例如，使用长度为数百个字符的键会很愚蠢，但是如果仅使用单个字符键，则程序将很难维护。通过将其放在视图中来仔细考虑重复的数据。</p><h3 id="2-1-2-硬盘和文件系统性能"><a href="#2-1-2-硬盘和文件系统性能" class="headerlink" title="2.1.2 硬盘和文件系统性能"></a>2.1.2 硬盘和文件系统性能</h3><p>使用更快的磁盘，条带化RAID阵列和现代文件系统都可以加快CouchDB部署。但是，当磁盘性能成为瓶颈时，有一种方法可以提高CouchDB服务器的响应速度。 从文件模块的Erlang文档中：<br>在具有线程支持的操作系统上，可以让文件操作在其自己的线程中执行，从而允许其他Erlang进程继续与文件操作并行执行。 请参阅erl(1)中的命令行标志+A。<br>将此参数设置为大于零的数字可以使您的CouchDB安装保持响应状态，即使在磁盘使用率很高的时期也是如此。设置此选项的最简单方法是通过<code>ERL_FLAGS</code>环境变量。例如，要为Erlang提供执行I/O操作的四个线程，请将以下内容添加到<code>(prefix)/etc/defaults/couchdb</code>（或等效项）中：</p><pre><code>export ERL_FLAGS=&quot;+A 4&quot;</code></pre><h2 id="2-2-系统资源限制"><a href="#2-2-系统资源限制" class="headerlink" title="2.2 系统资源限制"></a>2.2 系统资源限制</h2><p>管理员在其部署变大时会遇到的问题之一是系统和应用程序配置施加的资源限制。 提高这些限制可以使您的部署超出默认配置所支持的范围。</p><h3 id="2-2-1-CouchDB配置选项"><a href="#2-2-1-CouchDB配置选项" class="headerlink" title="2.2.1 CouchDB配置选项"></a>2.2.1 CouchDB配置选项</h3><h4 id="delayed-commits"><a href="#delayed-commits" class="headerlink" title="delayed_commits"></a><code>delayed_commits</code></h4><p>延迟的提交允许在某些工作负载下实现更好的写入性能，同时牺牲少量的持久性。 该设置使CouchDB在更新后提交新数据之前要等待一整秒。如果服务器在写入标头之前崩溃，则自上次提交以来的所有写入都将丢失。 启用此选项需要您自担风险。</p><h4 id="max-dbs-open"><a href="#max-dbs-open" class="headerlink" title="max_dbs_open"></a><code>max_dbs_open</code></h4><p>在配置(<code>local.ini</code>或类似版本)中,或者地址<code>couchdb/max_dbs_open</code>：</p><pre><code>[couchdb]max_dbs_open = 100</code></pre><p>此选项将一次可以打开的数据库数量设置为上限。CouchDB引用对内部数据库访问进行计数，并在必要时关闭空闲数据库。有时有必要一次保持超过默认值的速度，例如在许多数据库将被连续复制的部署中。</p><h4 id="Erlang"><a href="#Erlang" class="headerlink" title="Erlang"></a><code>Erlang</code></h4><p>即使增加了CouchDB允许的最大连接数，默认情况下，Erlang运行时系统也将不允许超过1024个连接。 将以下指令添加到<code>(prefix)/etc/default/couchdb</code>(或等效文件)将增加此限制(在这种情况下，增加到4096)：</p><pre><code>export ERL_MAX_PORTS=4096</code></pre><p>高达1.1.x的CouchDB版本还会为每个复制创建<code>Erlang Term Storage</code>(ETS)表。如果您使用的CouchDB版本早于1.2，并且必须支持许多复制，则还应设置<code>ERL_MAX_ETS_TABLES</code>变量。 默认值是大约1400表。<br>请注意，在Mac OS X上，Erlang实际上不会将文件描述符限制增加到超过1024（即系统标头定义的FD_SETSIZE值）。 </p><h4 id="打开文件描述的最大数量-无限制"><a href="#打开文件描述的最大数量-无限制" class="headerlink" title="打开文件描述的最大数量(无限制)"></a>打开文件描述的最大数量(无限制)</h4><p>大多数<code>*nix</code>操作系统在每个进程上都有各种资源限制。增加这些限制的方法因初始化系统和特定的OS版本而异。许多操作系统的默认值为1024或4096。在具有许多数据库或视图的系统上，CouchDB可以非常迅速地达到此限制。<br>如果您的系统设置为使用可插拔身份验证模块(<code>PAM</code>)系统（几乎所有现代Linux都是这种情况），则增加此限制很简单。例如，创建具有以下内容的名为<code>/etc/security/limits.d/100-couchdb.conf</code>的文件将确保CouchDB可以一次打开多达10000个文件描述符：</p><pre><code>#&lt;domain&gt;  &lt;type&gt;    &lt;item&gt;  &lt;value&gt;couchdb    hard      nofile  10000 couchdb    soft      nofile  10000</code></pre><p>如果使用的是Debian/Ubuntu sysvinit脚本(<code>/etc/init.d/couchdb</code>，则还需要提高root用户的限制：</p><pre><code>#&lt;domain&gt;    &lt;type&gt;   &lt;item&gt;  &lt;value&gt;root         hard    nofile   10000root         soft    nofile   10000</code></pre><p>您可能还需要编辑<code>/etc/pam.d/common-session</code>和<code>/etc/pam.d/common-session-noninteractive</code>文件以添加以下行：</p><pre><code>session required pam_limits.so</code></pre><p>如果还不存在。<br>对于基于系统的Linux（例如CentOS/RHEL 7，Ubuntu 16.04 +，Debian 8或更高版本）,假设您要从systemd启动CouchDB，则还必须通过创建文件<code>/etc/systemd/system/&lt;servicename&gt;.d/override.conf</code>添加以下内容：</p><pre><code>[Service]LimitNOFILE=#######</code></pre><p>并将<code>#######</code>替换为文件描述符的上限CouchDB允许立即保持打开状态。<br>如果您的系统不使用<code>PAM</code>，通常可以在自定义脚本中使用<code>ulimit</code>命令来启动<br>CouchDB具有增加的资源限制。 典型的语法类似于<code>ulimit -n 10000</code>。<br>通常，类似UNIX的现代系统每个进程可以处理大量文件句柄（例如100000）<br>没有问题。 不要害怕增加系统限制。</p><h2 id="2-3-网络"><a href="#2-3-网络" class="headerlink" title="2.3 网络"></a>2.3 网络</h2><p>产生和接收每个请求/响应都有延迟开销。通常，您应该分批执行请求。大多数API具有某种批处理机制，通常是通过在请求正文中提供文档或键的列表来进行的。请注意为批次选择的大小。较大的批处理需要更多的时间来使客户将项目编码为  <code>JSON</code>，并将更多的时间用于解码该数量的响应。使用您自己的配置和典型数据进行一些基准测试，以找到最佳位置。 它可能在一到一万个文档之间。<br>如果您拥有快速的I/O系统，那么您也可以使用并发-同时具有多个请求/响应。这减轻了组装JSON，进行网络连接和解码<code>JSON</code>所涉及的延迟。<br>从CouchDB 1.1.0开始，与旧版本相比，用户经常报告文档的写入性能较低。主要原因是此版本随附HTTP服务器库<code>MochiWeb</code>的最新版本，该库默认情况下将<code>TCP</code>套接字选项<code>SO_NODELAY</code>设置为<code>false</code>。这意味着发送到TCP套接字的小数据（例如对文档写请求的答复（或读取非常小的文档）的答复）不会立即发送到网络<code>TCP</code>将对其缓冲一会儿，希望它会被询问通过同一套接字发送更多数据，然后一次发送所有数据以提高性能。 可以通过<code>httpd/socket_options</code>禁用此<code>TCP</code>缓冲行为：</p><pre><code>[httpd]socket_options = [{nodelay, true}]</code></pre><h3 id="2-3-1-连接限制"><a href="#2-3-1-连接限制" class="headerlink" title="2.3.1 连接限制"></a>2.3.1 连接限制</h3><p><code>MochiWeb</code>处理<code>CouchDB</code>请求。默认最大连接数为2048。要更改此限制，请使用<code>server_options</code>配置变量。 <code>max</code>表示最大连接数。</p><pre><code>[chttpd]server_options = [{backlog, 128}, {acceptor_pool_size, 16}, {max, 4096}]</code></pre><h2 id="2-4-CouchDB"><a href="#2-4-CouchDB" class="headerlink" title="2.4 CouchDB"></a>2.4 CouchDB</h2><h3 id="2-4-1-删除操作"><a href="#2-4-1-删除操作" class="headerlink" title="2.4.1 删除操作"></a>2.4.1 删除操作</h3><p>当您删除文档时，数据库将创建一个新的修订版，其中包含<code>_id</code>和<code>_rev</code>字段以及<code>_deleted</code>标志。即使在数据库压缩后，此修订版仍将保留，以便可以复制删除内容。像未删除的文档一样，已删除的文档可能会影响视图生成时间，<code>PUT</code>和<code>DELETE</code>请求时间以及数据库的大小，因为它们会增加<code>B+Tree</code>的大小。您可以在数据库信息中看到已删除文档的数量。如果您的用例创建了许多已删除的文档（例如，如果您存储日志条目，消息队列等短期数据），则可能需要定期切换到新数据库并删除已过期的旧数据库）。</p><h3 id="2-4-2-文档ID"><a href="#2-4-2-文档ID" class="headerlink" title="2.4.2 文档ID"></a>2.4.2 文档ID</h3><p>数据库文件的大小源自您的文档和视图大小，但也取决于您的<code>_id</code>大小的倍数。<code>_id</code>不仅存在于文档中，而且它及其部分内容在<code>CouchDB</code>用来导航文件以首先找到文档的二叉树结构中也是重复的。作为一个现实世界的例子，一个用户从16个字节的ID切换到4个字节的ID，使数据库从21GB变为4GB，包含1000万个文档（从2.5GB到2GB的原始JSON文本）。<br>插入具有顺序（至少已排序）的ID的速度要比随机ID快。 因此，您应该考虑自己生成id，按顺序分配它们，并使用消耗更少字节的编码方案。例如，可以用4个基数62个数字（用10个数字，26个小写字母，26个大写字母）来完成需要16个十六进制数字表示的内容。</p><h2 id="2-5-视图"><a href="#2-5-视图" class="headerlink" title="2.5 视图"></a>2.5 视图</h2><h3 id="2-5-1-视图生成"><a href="#2-5-1-视图生成" class="headerlink" title="2.5.1 视图生成"></a>2.5.1 视图生成</h3><p>当要处理的文档数量非常少时，使用JavaScript查询服务器生成的视图非常慢。生成过程甚至不会使单个CPU饱和，更不用说您的I/O了。原因是CouchDB服务器和单独的<code>couchjs</code>查询服务器中涉及的延迟，这显着表明了从实施中消除延迟的重要性。<br>您可以让视图访问权限“过时”，但要确定何时发生会给您带来快速响应以及何时更新视图会花费很长时间，这是不切实际的。(一个拥有1000万个文档的数据库大约需要10分钟才能加载到CouchDB中，而生成视图需要大约4个小时)。<br>在集群中，“陈旧的”请求由一组固定的分片服务，以便为用户提供请求之间的一致结果。这需要进行可用性权衡-固定的分片集可能不是集群中响应最快的/可用的。如果不需要这种一致性(例如，索引相对静态)，则可以通过指定<code>stable = false＆update = false</code>代替<code>stale = ok</code>或<code>stable = false＆update = lazy</code>代替<code>stale = update_after</code>。<br>视图信息不会被复制-它会在每个数据库上重建，因此您无法在单独的服务器上生成视图。</p><h3 id="2-5-2-内置缩小功能"><a href="#2-5-2-内置缩小功能" class="headerlink" title="2.5.2 内置缩小功能"></a>2.5.2 内置缩小功能</h3><p>如果您使用的是非常简单的视图函数，仅执行求和或计数减少，则可以通过简单地编写<code>_sum</code>或<code>_count</code>代替函数声明来调用它们的本机<code>Erlang</code>实现。 这将大大加快速度，因为它减少了CouchDB和JavaScript查询服务器之间的IO。 例如，如邮件列表中所述，用于输出（已索引和缓存的）视图的时间大约为78,000个项目，时间从60秒减少到4秒。<br>之前：</p><pre><code>{    &quot;_id&quot;: &quot;_design/foo&quot;,    &quot;views&quot;: {        &quot;bar&quot;: {            &quot;map&quot;: &quot;function (doc) { emit(doc.author, 1); }&quot;,            &quot;reduce&quot;: &quot;function (keys, values, rereduce) { return sum(values); }&quot;        }       }}</code></pre><p>之后：</p><pre><code>{    &quot;_id&quot;: &quot;_design/foo&quot;,    &quot;views&quot;: {        &quot;bar&quot;: {            &quot;map&quot;: &quot;function (doc) { emit(doc.author, 1); }&quot;,            &quot;reduce&quot;: &quot;_sum&quot;        }    }}</code></pre><h1 id="3-CouchDB备份"><a href="#3-CouchDB备份" class="headerlink" title="3 CouchDB备份"></a>3 CouchDB备份</h1><hr><p>CouchDB在运行时可以创建三种不同类型的文件：</p><ul><li>数据库文件（包括二级索引）</li><li>配置文件(<code>* .ini</code>)</li><li>日志文件（如果配置为记录到磁盘）</li></ul><p>以下是确保所有这些文件的备份一致的策略。</p><h2 id="3-1-数据库备份"><a href="#3-1-数据库备份" class="headerlink" title="3.1 数据库备份"></a>3.1 数据库备份</h2><p>CouchDB备份的最简单，最简单的方法是使用CouchDB复制到另一个CouchDB安装。您可以根据需要在普通（单次）复制或连续复制之间进行选择。<br>但是，您也可以随时从CouchDB数据目录(默认为<code>data/</code>)中复制实际的<code>.couch</code>文件，而不会出现问题。 CouchDB的数据库和二级索引的仅追加存储格式可确保这种方法可以正常工作。<br>为了确保备份的可靠性，建议先备份二级索引(存储在<code>data/.shards</code>下)，然后再备份主数据库文件(存储在<code>data/ shards</code>以及父级<code>data/</code>下的系统级数据库)目录)。这是因为CouchDB将在下一次读取访问时通过更新视图/二级索引来自动处理稍微过时的视图/二级索引，但是比其关联数据库新的视图或二级索引将触发索引的完全重建。这可能是一项非常昂贵且耗时的操作，并且会影响您在灾难情况下快速恢复的能力。<br>在受支持的操作系统/存储环境上，您还可以使用存储快照。这些优点是在使用块存储系统(例如<code>ZFS</code>或<code>LVM</code>或<code>Amazon EBS</code>)时几乎是即时的。在块存储级别使用快照时，请确保在必要时使用OS级实用程序(例如Linux的<code>fsfreeze</code>)使文件系统停顿。如果不确定，请查阅操作系统或云提供商的文档以获取更多详细信息。</p><h2 id="3-2-配置备份"><a href="#3-2-配置备份" class="headerlink" title="3.2 配置备份"></a>3.2 配置备份</h2><p>CouchDB的配置系统将数据存储在配置目录(默认为<code>etc/</code>)下的<code>.ini</code>文件中。 如果在运行时对配置进行了更改，则配置链中的最后一个文件将使用更改进行更新。<br>从备份还原后，简单地备份整个<code>etc/</code>目录，以确保配置一致。<br>如果在运行时未通过HTTP API对配置进行任何更改，并且所有配置文件都由配置管理系统(例如<code>Ansible</code>或<code>Chef</code>)管理，则无需备份配置目录。</p><h2 id="3-3-日志备份"><a href="#3-3-日志备份" class="headerlink" title="3.3 日志备份"></a>3.3 日志备份</h2><p>如果配置为记录到文件，则可能要备份CouchDB编写的日志文件。这些文件的任何备份解决方案都可以使用。<br>在类似UNIX的系统上，如果使用日志轮换软件，则必须采用“复制然后截断”的方法。创建副本后，这会将原始日志文件截断为零。CouchDB无法识别要关闭其日志文件并创建一个新信号的任何信号。因此，并且由于文件处理功能的差异，除了定期重新启动CouchDB进程外，在Microsoft Windows下没有简单的日志轮换解决方案。</p>]]></content>
    
    
    <categories>
      
      <category>CouchDb学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CouchDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CouchDB学习-集群管理</title>
    <link href="undefined2019/12/21/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/"/>
    <url>2019/12/21/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p><a href="https://docs.couchdb.org/en/stable/cluster/index.html" target="_blank" rel="noopener">官方文档</a></p><h1 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h1><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>在<code>etc/fefault.ini</code>文件中有以下部分：</p><pre><code>[cluster]q=8n=3</code></pre><ul><li>q - 分片的数量</li><li>n - 每一份文档的拷贝数量(加上原文档一共几份副本)</li></ul><p>创建数据库时可以通过覆盖该值修改为自己的值。<br>在集群操作中，获取操作中CouchDB返回状态码200或者是写操作返回状态码201即为大多数成员达成一致。大多数成员定义为相关拷贝的数量的一半。对于“读写”操作，“相关副本”的定义稍有不同。<br>对于读操作，相关副本的数量是保存请求数据的当前可访问分片的数量，这意味着在发生故障或网络分区的情况下，相关副本的数量可能少于集群中的副本数量。 可以使用r参数设置读取份数。<br>对于写操作，相关副本的数量始终为n，即集群中的副本数量。 对于写操作，可以使用w参数设置份数。 如果少于此数量的可用节点，则返回202。</p><h2 id="节点管理"><a href="#节点管理" class="headerlink" title="节点管理"></a>节点管理</h2><h3 id="查看所有节点"><a href="#查看所有节点" class="headerlink" title="查看所有节点"></a>查看所有节点</h3><pre><code>curl -u admin:adminpw -X GET http://localhost:5984/_membership{    &quot;all_nodes&quot;:[   # 当前节点所知道的节点        &quot;node1@xxx.xxx.xxx.xxx&quot;],    &quot;cluster_nodes&quot;:[ #当前节点所连接的节点        &quot;node1@xxx.xxx.xxx.xxx&quot;],}</code></pre><h3 id="添加一个节点"><a href="#添加一个节点" class="headerlink" title="添加一个节点"></a>添加一个节点</h3><pre><code>curl -u admin:adminpw -X PUT http://localhost:5986/_nodes/node2@yyy.yyy.yyy.yyy -d {}</code></pre><h3 id="删除一个节点"><a href="#删除一个节点" class="headerlink" title="删除一个节点"></a>删除一个节点</h3><pre><code>#首先获取关于文档的revisioncurl -u admin:adminpw -X GET &quot;http://xxx.xxx.xxx.xxx:5986/_nodes/node2@yyy.yyy.yyy.yyy&quot;{&quot;_id&quot;:&quot;node2@yyy.yyy.yyy.yyy&quot;,&quot;_rev&quot;:&quot;1-967a00dff5e02add41820138abb3284d&quot;}    #删除节点curl -u admin:adminpw -X DELETE http://localhost:5986/_nodes/node2@yyy.yyy.yyy.yyy?rev=1-967a00dff5e02add41820138abb3284d</code></pre><h2 id="数据库管理"><a href="#数据库管理" class="headerlink" title="数据库管理"></a>数据库管理</h2><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><p>数据库名字不支持大写字符，只支持[a-z],[0-9],以及特殊字符:<code>_ $ ( ) + - /</code></p><pre><code>#创建一个数据库名字为db_name curl -u admin:adminpw -X PUT http://localhost:5984/db_name?q=4&amp;n=2</code></pre><h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><pre><code>curl -u admin:adminpw -X DELETE http://localhost:5984/db_name</code></pre><h3 id="在一个具体的节点放置数据库"><a href="#在一个具体的节点放置数据库" class="headerlink" title="在一个具体的节点放置数据库"></a>在一个具体的节点放置数据库</h3><p>在CouchDB 2.0群集功能的前身BigCouch中，存在区域的概念。 CouchDB 2.0通过集群放置规则来实现这一目标。<br>使用<code>placement</code>参数将覆盖分片副本基数的标准逻辑（由[cluster] <code>n</code>指定）。<br>首先，每个节点必须标记有zone属性。 这定义了每个节点所在的区域。您可以通过编辑<code>/nodes</code>数据库中的节点文档来实现，该文档可通过“后门”（5986）端口进行访问。 添加以下形式的键值对：</p><pre><code>&quot;zone&quot;:&quot;metro-dc-a&quot;</code></pre><p>在集群上所有节点上操作。<br>在每一个节点的配置文件<code>local.ini</code>或者<code>default.ini</code>中，定义相同的集群设置：</p><pre><code>[cluster]placement = metro-dc-a:2,metro-dc-b:1</code></pre><p>在此示例中，它将确保将一个分区的两个副本托管在将<code>zone</code>属性设置为<code>metro-dc-a</code>的节点上，并将一个副本副本托管在一个将<code>zone</code>属性设置为<code>metro-dc-b</code>的新副本上。<br>请注意，您还可以使用该系统，通过为群集中的某些节点提供不出现在[cluster]放置字符串中的zone属性，来确保它们不承载新创建的数据库的任何副本。</p><h2 id="分片管理"><a href="#分片管理" class="headerlink" title="分片管理"></a>分片管理</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>本文档讨论了分片在CouchDB中的工作方式，以及如何安全地添加，移动，删除和创建分片和分片副本的放置规则。<br>分片是数据库中数据的水平分区。将数据划分为多个碎片，并将每个碎片的副本（称为“碎片副本”或简称为“副本”）分布到群集中的不同节点，可以提高数据的持久性，防止节点丢失。CouchDB群集自动分片数据库，并在节点之间分配组成每个分片的文档子集。 修改群集成员身份和分片行为必须手动完成。</p><h3 id="分片和复制"><a href="#分片和复制" class="headerlink" title="分片和复制"></a>分片和复制</h3><p>可以在全局级别或每个数据库的基础上设置每个数据库有多少个分片和副本。 相关参数是<code>q</code>和<code>n</code>。<br><code>q</code>是要维护的数据库分片数。<code>n</code>是要分发的每个文档的副本数。<code>n</code>的默认值为3,<code>q</code>的默认值为8。当<code>q</code>= 8时，数据库分为8个分片。在<code>n</code>=3的情况下，群集分发每个分片的三个副本。总共，一个数据库有24个分片副本。在默认的3节点群集中，每个节点将接收8个分片。在4节点群集中，每个节点将接收6个分片。 在一般情况下，我们建议群集中的节点数应为n的倍数，以使碎片均匀分布。<br>CouchDB节点的<code>etc/local.ini</code>文件中的<code>cluster</code>部分：</p><pre><code>[cluster]q=8n=3</code></pre><p>可以修改这些设置以设置所有数据库的分片默认值，或者可以在创建数据库时通过指定q和n查询参数来针对每个数据库进行设置。 例如：</p><pre><code>curl -X PUT &quot;http://localhost:5984/database-name?q=4&amp;n=2&quot;</code></pre><p>这将创建一个数据库，该数据库分为4个分片和2个副本，从而产生8个分片副本分布在整个数据库中<br>的集群上。</p><h3 id="Quorum"><a href="#Quorum" class="headerlink" title="Quorum"></a>Quorum</h3><p>取决于集群的大小，每个数据库的分片数量以及分片副本的数量，并非每个节点都可以访问每个分片，但是每个节点都知道可以通过CouchDB的内部分片在哪里找到每个分片的所有副本。<br>进入CouchDB集群的每个请求均由任意一个随机协调节点处理。该协调节点将请求代理给其他具有相关数据的节点，这些数据可能包含也可能不包含自身。一旦达到法定数量的数据库节点响应，协调节点就会向客户端发送响应。2 默认情况下,默认的法定仲裁大小等于<code>r=w=((n+1)/2)</code>，其中<code>r</code>表示读取仲裁的大小，<code>w</code>表示写入仲裁的大小，<code>n</code>表示数字每个分片的副本。在n为3的默认群集中，<code>((n+1)/2)</code>将为2。<br>集群中的每个节点都可以作为任何请求的协调节点。集群内部没有专门的节点角色。<br>可以在请求时通过设置文档和视图读取的<code>r</code>参数以及文档写入的<code>w</code>参数来配置所需仲裁的大小。例如，这是一个请求，一旦至少两个节点已响应，该请求便指示协调节点发送响应：</p><pre><code>curl &quot;$COUCH_URL:5984/&lt;db&gt;/&lt;doc&gt;?r=2&quot;</code></pre><p>这是写文档的类似示例：</p><pre><code>curl -X PUT &quot;$COUCH_URL:5984/&lt;db&gt;/&lt;doc&gt;?w=2&quot; -d &#39;{...}&#39;</code></pre><p>将<code>r</code>或<code>w</code>设置为等于n（副本数）意味着只有在所有具有相关分片的节点都响应或超时后，您才会收到响应，因此这种方法不能保证<code>ACID</code>的一致性。 将<code>r</code>或<code>w</code>设置为1意味着仅一个相关节点响应后，您将收到响应。</p><h3 id="数据库分片测试"><a href="#数据库分片测试" class="headerlink" title="数据库分片测试"></a>数据库分片测试</h3><p>有一些API端点可以帮助您了解如何分片数据库。 首先，在集群上创建一个新数据库，然后将几个文档放入其中：</p><pre><code>$ curl -X PUT $COUCH_URL:5984/mydb{&quot;ok&quot;:true}$ curl -X PUT $COUCH_URL:5984/mydb/joan -d &#39;{&quot;loves&quot;:&quot;cats&quot;}&#39;{&quot;ok&quot;:true,&quot;id&quot;:&quot;joan&quot;,&quot;rev&quot;:&quot;1-cc240d66a894a7ee7ad3160e69f9051f&quot;}$ curl -X PUT $COUCH_URL:5984/mydb/robert -d &#39;{&quot;loves&quot;:&quot;dogs&quot;}&#39;{&quot;ok&quot;:true,&quot;id&quot;:&quot;robert&quot;,&quot;rev&quot;:&quot;1-4032b428c7574a85bc04f1f271be446e&quot;}</code></pre><p>首先，<code>/db</code>将告诉您数据库的分片参数：</p><pre><code>curl -s $COUCH_URL:5984/db | jq .{  &quot;db_name&quot;: &quot;mydb&quot;,...  &quot;cluster&quot;: {    &quot;q&quot;: 8,    &quot;n&quot;: 3,    &quot;w&quot;: 2,    &quot;r&quot;: 2}, ...}</code></pre><p>因此，我们知道此数据库是由8个分片(<code>q</code>=8)建的，每个分片具有3个副本(<code>n</code>=3),集群中节点之间总共有24个分片副本。<br>现在，让我们看一下这些分片副本如何通过<code>/db/_shards</code>端点放置在集群上：</p><pre><code>curl -s $COUCH_URL:5984/mydb/_shards | jq .{&quot;shards&quot;: {    &quot;00000000-1fffffff&quot;: [      &quot;node1@127.0.0.1&quot;,      &quot;node2@127.0.0.1&quot;,      &quot;node4@127.0.0.1&quot;    ],    &quot;20000000-3fffffff&quot;: [      &quot;node1@127.0.0.1&quot;,      &quot;node2@127.0.0.1&quot;,      &quot;node3@127.0.0.1&quot;    ],    ...  }}</code></pre><p>现在我们看到该集群中实际上有4个节点，并且CouchDB已将这24个分片副本均匀地分布在所有4个节点上。<br>我们还可以确切地看到哪个分片包含具有<code>/db/_shards/doc</code>端点的给定文档：</p><pre><code>curl -s $COUCH_URL:5984/mydb/_shards/joan | jq .{  &quot;range&quot;: &quot;e0000000-ffffffff&quot;,  &quot;nodes&quot;: [    &quot;node1@127.0.0.1&quot;,    &quot;node3@127.0.0.1&quot;,    &quot;node4@127.0.0.1&quot;] }$ curl -s $COUCH_URL:5984/mydb/_shards/robert | jq .{  &quot;range&quot;: &quot;60000000-7fffffff&quot;,  &quot;nodes&quot;: [   &quot;node1@127.0.0.1&quot;,    &quot;node3@127.0.0.1&quot;,    &quot;node4@127.0.0.1&quot;   ] }</code></pre><p>CouchDB向我们展示了两个示例文档中每个映射到的特定分片。</p><h3 id="移动一个分片"><a href="#移动一个分片" class="headerlink" title="移动一个分片"></a>移动一个分片</h3><p>本节介绍如何手动放置和更换碎片。 当您确定群集太大或太小，并且想要成功调整其大小，或者从服务器指标中注意到数据库/碎片布局不是最佳的，并且您需要一些“热点”时，这些活动是至关重要的步骤 解决。<br>考虑一个<code>q</code>=8和<code>n</code>=3的三节点群集。每个数据库有24个分片，分布在三个节点上。如果将第四个节点添加到集群，则CouchDB不会将现有数据库分片重新分配给该集群。 这将导致负载不平衡，因为新节点将仅托管其加入集群后创建的数据库的分片。 为了平衡现有数据库中的分片分布，必须手动移动它们。<br>在集群中的节点上移动分片涉及以下几个步骤：</p><ol><li>确保目标节点已经加入集群</li><li>将分片和任何辅助索引分片复制到目标节点上。</li><li>设置目标节点为维护模式。</li><li>更新集群元数据反映新的目标分片。</li><li>监视内部复制以确保最新的分片。</li><li>清除目标节点的维护模式。</li><li>再次更新集群元数据移除原分片。</li><li>移除原节点的分片和任何辅助索引分片.</li></ol><h4 id="拷贝分片文件"><a href="#拷贝分片文件" class="headerlink" title="拷贝分片文件"></a>拷贝分片文件</h4><p>从技术上讲，复制数据库和辅助索引碎片是可选的。 如果在不执行此数据副本的情况下继续进行下一步，则CouchDB将使用内部复制来填充新添加的分片副本。 但是，复制文件的速度比内部复制快，尤其是在繁忙的群集上，这就是为什么我们建议首先执行此手动数据复制的原因。<br>碎片文件位于CouchDB安装目录的<code>data/shards</code>目录中。这些子目录中包含分片文件本身。例如，对于一个名为<code>abc</code>的<code>q</code>=8数据库，这是其数据库分片文件：</p><pre><code>data/shards/00000000-1fffffff/abc.1529362187.couchdata/shards/20000000-3fffffff/abc.1529362187.couchdata/shards/40000000-5fffffff/abc.1529362187.couch...</code></pre><p>辅助索引(包括<code>JavaScript</code>视图，<code>Erlang</code>视图和<code>Mango</code>索引)也被分片，并且应移动它们的分片以节省新节点重建视图的工作量。查看<code>data/.</code>中的分片。例如：</p><pre><code>data/.shardsdata/.shards/e0000000-ffffffff/_replicator.1518451591_designdata/.shards/e0000000-ffffffff/_replicator.1518451591_design/mrviewdata/.shards/e0000000-ffffffff/_replicator.1518451591_design/mrview/3e823c2a4383ac0c18d4e574135a5b08.view...</code></pre><p>由于它们是文件，因此可以使用<code>cp</code>，<code>rsync</code>，<code>scp</code>或其他文件复制命令将它们从一个节点复制到另一个节点。 例如：</p><pre><code># 1主机$ mkdir -p data/.shards/&lt;range&gt;$ mkdir -p data/shards/&lt;range&gt;# 2主机$ scp &lt;couch-dir&gt;/data/.shards/&lt;range&gt;/&lt;database&gt;.&lt;datecode&gt;* \&lt;node&gt;:&lt;couch-dir&gt;/data/.shards/&lt;range&gt;/$ scp &lt;couch-dir&gt;/data/shards/&lt;range&gt;/&lt;database&gt;.&lt;datecode&gt;.couch \  &lt;node&gt;:&lt;couch-dir&gt;/data/shards/&lt;range&gt;/</code></pre><p>先移动视图文件再移动数据库文件！ 如果视图索引在其数据库之前，则数据库将从头开始重建它。</p><h4 id="设置目标节点为维护模式"><a href="#设置目标节点为维护模式" class="headerlink" title="设置目标节点为维护模式"></a>设置目标节点为维护模式</h4><p>在告诉CouchDB节点上的这些新分片之前，必须将节点置于维护模式。维护模式指示CouchDB返回<code>404 Not Found</code>响应在<code>/_up</code>端点，并确保其不参与其分片的常规交互式集群请求。使用GET<code>/_up</code>检查节点的运行状况的正确配置的负载均衡器将检测到此404并将该节点从循环中删除，从而阻止将请求发送到该节点。 例如，要将HAProxy配置为使用<code>/_up</code>端点，请使用：</p><pre><code>http-check disable-on-404option httpchk GET /_up</code></pre><p>如果未设置维护模式，或者负载平衡器忽略了此维护模式状态，则在执行下一步之后，群集在咨询相关节点时可能会返回错误的响应。不要这样做！在接下来的步骤中，我们将确保此分片是最新的，然后再允许其参与最终用户的请求。<br>启用维护模式：</p><pre><code> curl -X PUT -H &quot;Content-type: application/json&quot; \ $COUCH_URL:5984/_node/&lt;nodename&gt;/_config/couchdb/maintenance_mode \ -d &quot;\&quot;true\&quot;&quot;</code></pre><p>然后，通过在该节点的单个端点上执行GET<code>/_up</code>来验证该节点是否处于维护模式：</p><pre><code>curl -v $COUCH_URL/_up...&lt; HTTP/1.1 404 Object Not Found...{&quot;status&quot;:&quot;maintenance_mode&quot;}</code></pre><p>最后，检查负载均衡器是否已从可用后端节点池中删除了该节点。</p><h4 id="更新集群元数据反映新的目标分片。"><a href="#更新集群元数据反映新的目标分片。" class="headerlink" title="更新集群元数据反映新的目标分片。"></a>更新集群元数据反映新的目标分片。</h4><p>现在我们需要告诉CouchDB，目标节点（必须已经加入集群）应该为给定数据库托管碎片副本。<br>要更新群集元数据，请使用特殊的<code>/_dbs</code>数据库，该数据库是内部CouchDB数据库，它将数据库映射到分片和节点。该数据库在节点之间复制。它只能通过节点本地端口（通常是端口5986）进行访问。默认情况下，出于安全目的，此端口仅在localhost接口上可用。<br>首先，检索数据库的当前元数据：</p><pre><code>curl http://localhost:5986/_dbs/{name}{  &quot;_id&quot;: &quot;{name}&quot;,  &quot;_rev&quot;: &quot;1-e13fb7e79af3b3107ed62925058bfa3a&quot;,  &quot;shard_suffix&quot;: [46, 49, 53, 51, 48, 50, 51, 50, 53, 50, 54],  &quot;changelog&quot;: [    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node1@xxx.xxx.xxx.xxx&quot;],    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node2@xxx.xxx.xxx.xxx&quot;],    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node3@xxx.xxx.xxx.xxx&quot;],    ...  ],  &quot;by_node&quot;: {    &quot;node1@xxx.xxx.xxx.xxx&quot;: [      &quot;00000000-1fffffff&quot;,      ...    ],    ...   },  &quot;by_range&quot;: {    &quot;00000000-1fffffff&quot;: [      &quot;node1@xxx.xxx.xxx.xxx&quot;,      &quot;node2@xxx.xxx.xxx.xxx&quot;,      &quot;node3@xxx.xxx.xxx.xxx&quot;    ],    ...   } }</code></pre><p>这是该文档的简要剖析：</p><ul><li><code>_id</code>:数据库的名字</li><li><code>_rev</code>:元数据的当前版本</li><li><code>shard_suffix</code>:数据库创建时的时间戳，在Unix时期映射到ASCII数字的代码点后的秒。</li><li><code>changelog</code>:数据库分片的历史</li><li><code>by_node</code>:每个节点的分片列表</li><li><code>by_range</code>:每个分片由哪些节点持有。</li></ul><p>要反映元数据中的分片移动，请执行以下三个步骤：</p><ol><li>添加合适的<code>changelog</code>实体。</li><li>更新<code>by_node</code>实体。</li><li>更新<code>by_range</code>实体。</li></ol><p>在修改时，此过程必须手动完成。<br>要将分片添加到节点，请将以下条目添加到数据库元数据的<code>changelog</code>属性中：</p><pre><code>[&quot;add&quot;, &quot;&lt;range&gt;&quot;, &quot;&lt;node-name&gt;&quot;]</code></pre><p><code>&lt;range&gt;</code>是特定的硬范围设置。<code>&lt;node-name&gt;</code>应该与集群中GET<code>/_membership</code>中显示的节点的名称和地址匹配。<br>如果从节点移除一个分片，简单地将<code>add</code>替换为<code>remove</code>。<br>找到新的变更日志条目后，将需要更新<code>by_node</code>和<code>by_range</code>以反映谁在存储哪些分片。 更改日志条目中的数据和这些属性必须匹配。 否则，数据库可能会损坏。<br>继续我们的示例，这是上面的元数据的更新版本，该版本将分片添加到名为node4的其他节点中：</p><pre><code>{  &quot;_id&quot;: &quot;{name}&quot;,  &quot;_rev&quot;: &quot;1-e13fb7e79af3b3107ed62925058bfa3a&quot;,  &quot;shard_suffix&quot;: [46, 49, 53, 51, 48, 50, 51, 50, 53, 50, 54],  &quot;changelog&quot;: [    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node1@xxx.xxx.xxx.xxx&quot;],    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node2@xxx.xxx.xxx.xxx&quot;],    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node3@xxx.xxx.xxx.xxx&quot;],    ...    [&quot;add&quot;, &quot;00000000-1fffffff&quot;, &quot;node4@xxx.xxx.xxx.xxx&quot;]  ],  &quot;by_node&quot;: {    &quot;node1@xxx.xxx.xxx.xxx&quot;: [      &quot;00000000-1fffffff&quot;,    ...     ],    ...    &quot;node4@xxx.xxx.xxx.xxx&quot;: [      &quot;00000000-1fffffff&quot;    ]  },  &quot;by_range&quot;: {    &quot;00000000-1fffffff&quot;: [      &quot;node1@xxx.xxx.xxx.xxx&quot;,      &quot;node2@xxx.xxx.xxx.xxx&quot;,      &quot;node3@xxx.xxx.xxx.xxx&quot;,      &quot;node4@xxx.xxx.xxx.xxx&quot;    ],    ...  }}</code></pre><p>现在可以<code>PUT</code>新元数据：</p><pre><code>curl -X PUT http://localhost:5986/_dbs/{name} -d &#39;{...}&#39;</code></pre><h4 id="强制同步分片"><a href="#强制同步分片" class="headerlink" title="强制同步分片"></a>强制同步分片</h4><p>无论您是否将分片预先复制到新节点，都可以强制CouchDB同步所有分片的所有副本。<br>具有<code>/db/_sync_shards</code>端点的数据库中的分片：</p><pre><code>curl -X POST $COUCH_URL:5984/{dbname}/_sync_shards{&quot;ok&quot;:true}</code></pre><p>这将启动同步过程。 请注意，这将给群集增加额外的负载，这可能会影响性能。<br>通过写入存储在该分片中的文档，也可以在每个分片的基础上强制进行同步。</p><h4 id="监视内部复制以确保最新的分片"><a href="#监视内部复制以确保最新的分片" class="headerlink" title="监视内部复制以确保最新的分片"></a>监视内部复制以确保最新的分片</h4><p>完成上一步后，CouchDB将开始同步分片。可以通过监视<code>/_node/&lt;nodename&gt;/_system</code>端点(包括<code>internal_replication_jobs</code>指标)来观察这种情况。<br>一旦此指标从开始分片同步之前返回到基线，或者为0，分片副本就可以提供数据了，我们可以使节点退出维护模式。</p><h4 id="清除目标节点的维护模式"><a href="#清除目标节点的维护模式" class="headerlink" title="清除目标节点的维护模式"></a>清除目标节点的维护模式</h4><p>现在，可以像在步骤2中一样，通过在维护模式配置端点上放置<code>false</code>,使节点开始为数据请求提供服务。<br>通过在该节点的单个端点上执行GET<code>/_up</code>来验证该节点是否不在维护模式下。最后，检查负载均衡器是否已将该节点返回到可用后端节点池中。</p><h4 id="再次更新集群元数据移除原分片"><a href="#再次更新集群元数据移除原分片" class="headerlink" title="再次更新集群元数据移除原分片"></a>再次更新集群元数据移除原分片</h4><p>现在，以与在步骤2中将新目标分片添加到分片图中相同的方式，从分片图中删除源分片。确保将<code>[“ remove”，&lt;range&gt;，&lt;source-shard&gt;]</code>条目添加到 更改日志的末尾，以及修改数据库元数据文档的<code>by_node</code>和<code>by_range</code>部分。</p><h4 id="移除原节点的分片和任何辅助索引分片"><a href="#移除原节点的分片和任何辅助索引分片" class="headerlink" title="移除原节点的分片和任何辅助索引分片"></a>移除原节点的分片和任何辅助索引分片</h4><p>最后，可以通过从源主机上的命令行中删除源碎片副本的文件以及任何视图碎片副本来删除源碎片副本：</p><pre><code>rm &lt;couch-dir&gt;/data/shards/&lt;range&gt;/&lt;dbname&gt;.&lt;datecode&gt;.couchrm -r &lt;couch-dir&gt;/data/.shards/&lt;range&gt;/&lt;dbname&gt;.&lt;datecode&gt;*</code></pre><p>恭喜你！ 您已经移动了数据库分片副本。通过以这种方式添加和删除数据库分片副本，您可以更改集群的分片布局，也称为分片映射。</p><h3 id="指定数据库放置位置"><a href="#指定数据库放置位置" class="headerlink" title="指定数据库放置位置"></a>指定数据库放置位置</h3><p>您可以配置CouchDB，以使用放置规则在数据库创建时将碎片副本放置在某些节点上。<br>首先，每个节点必须标记有zone属性。 这定义了每个节点所在的区域。您可以通过编辑<code>/_nodes</code>数据库中的节点文档来实现，该文档可通过本地节点端口进行访问。 添加以下形式的键值对：</p><pre><code>&quot;zone&quot;: &quot;{zone-name}&quot;</code></pre><p>在集群中的每一个节点都这样做：</p><pre><code>curl -X PUT http://localhost:5986/_nodes/&lt;node-name&gt; \ -d &#39;{ \        &quot;_id&quot;: &quot;&lt;node-name&gt;&quot;,        &quot;_rev&quot;: &quot;&lt;rev&gt;&quot;,        &quot;zone&quot;: &quot;&lt;zone-name&gt;&quot;        }&#39;</code></pre><p>在每个节点的本地配置文件（local.ini）中，定义一个一致的群集范围设置，例如：</p><pre><code>[cluster]placement = &lt;zone-name-1&gt;:2,&lt;zone-name-2&gt;:1</code></pre><p>在此示例中，CouchDB将确保将分区的两个副本托管在区域属性设置为<code>&lt;zone-name-1&gt;</code>的节点上，并将一个副本托管在新的区域属性设置为<code>&lt;zone-name-2&gt;</code>的节点上。<br>这种方法非常灵活，因为您还可以在创建数据库时使用与ini文件相同的语法，通过将放置设置指定为查询参数来基于每个数据库指定区域：</p><pre><code>curl -X PUT $COUCH_URL:5984/&lt;dbname&gt;?zone=&lt;zone&gt;</code></pre><p>也可以指定放置参数。 请注意，这将覆盖确定已创建副本的数量！<br>请注意，您还可以使用此系统来确保群集中的某些节点不为新主机托管任何副本。<br>通过为它们提供一个不会出现在<code>[cluster]</code>放置字符串中的<code>zone</code>属性，来创建数据库。</p><h3 id="修改数据库到一个新的q值"><a href="#修改数据库到一个新的q值" class="headerlink" title="修改数据库到一个新的q值"></a>修改数据库到一个新的<code>q</code>值</h3><p>数据库的q值只能在创建数据库时设置，不能进行实时重新分片。 相反，要重新分片数据库，必须重新生成它。 步骤如下：</p><ol><li>通过在PUT操作期间将<code>q</code>值指定为查询参数来创建具有所需分片设置的临时数据库。</li><li>停止客户端访问数据库</li><li>将主数据库复制到临时数据库。 如果主数据库正在使用中，则可能需要多次复制。</li><li>删除主数据库，<strong>确保没有人在使用!</strong></li><li>使用所需的分片设置重新创建主数据库。</li><li>客户端现在可以再次访问数据库。</li><li>将临时数据库复制回主数据库。</li><li>删除临时数据库.</li></ol><p>一旦完成所有步骤，即可再次使用该数据库。 集群将根据放置规则自动创建并分发其碎片。<br>如果可以指示客户端应用程序使用新数据库而不是旧数据库，并且可以在非常短暂的中断窗口内进行切换，则可以避免生产中的停机时间。</p><h2 id="集群清除"><a href="#集群清除" class="headerlink" title="集群清除"></a>集群清除</h2><p>群集清除的主要目的是清除具有多个删除的逻辑删除或包含大量冲突的单个文档的数据库。 但是，它也可以用于清除具有任何修订版本的任何文档（已删除或未删除）。<br>群集清除旨在维护最终的一致性并防止不必要的二级索引无效。 为此，每个数据库都会跟踪数据库中请求的一定数量的历史清除以及其当前的<code>purge_seq</code>。 内部复制和二级索引处理数据库的清除，并定期更新其相应的清除检查点文档以报告由其处理的<code>purge_seq</code>。 为了确保最终的一致性，数据库将仅在内部复制作业和二级索引处理了存储的历史清除请求之后，才删除它们。</p><h3 id="内部结构"><a href="#内部结构" class="headerlink" title="内部结构"></a>内部结构</h3><p>为了在节点和二级索引之间实现内部清除信息的复制，将两个内部清除树添加到数据库文件中以跟踪历史清除。</p><pre><code>purge_tree: UUID -&gt; {PurgeSeq, DocId, Revs}purge_seq_tree: PurgeSeq -&gt; {UUID, DocId, Revs}</code></pre><p>每次对<code>_purge API</code>的交互式请求，都会在增加<code>purge_seq</code>和<code>purge_request</code>时创建成对的有序集合，其中<code>purge_request</code>是一个包含<code>docid</code>和修订列表的元组。 对于每个<code>purge_request</code>都会生成<code>uuid</code>。清除请求将添加到内部清除树：将元组<code>{UUID-&gt; {PurgeSeq，DocId，Revs}}</code>添加到<code>purge_tree</code>，元组 <code>{PurgeSeq-&gt; {UUID，DocId，Revs}}</code>添加到<code>purge_seq_tree</code>。</p><h3 id="压缩清除"><a href="#压缩清除" class="headerlink" title="压缩清除"></a>压缩清除</h3><p>在数据库压缩期间，最旧的清除请求将被删除，以仅在数据库中存储<code>purged_infos_limit</code>个清除数目。 但是，为了使数据库与索引和其他副本保持一致，我们只能删除索引和内部复制作业已处理的清除请求。因此，有时清除树可能存储的数据超过<code>purged_infos_limit</code>清除数目。 如果数据库中存储的清除数量超出<code>purged_infos_limit</code>某个阈值，则日志中会产生警告，表明数据库的清除与索引和其他副本的同步问题。</p><h3 id="本地清除检查点文档"><a href="#本地清除检查点文档" class="headerlink" title="本地清除检查点文档"></a>本地清除检查点文档</h3><p>具有清除的数据库索引和内部复制会创建并定期更新本地检查点清除文档：<code>_local/purge-$type-$hash</code>。 这些文档报告了它们最后处理的<code>purge_seq</code>以及最后处理的时间戳。 本地检查点清除文档的示例：</p><pre><code>{&quot;_id&quot;: &quot;_local/purge-mrview-86cacdfbaf6968d4ebbc324dd3723fe7&quot;, &quot;type&quot;: &quot;mrview&quot;,&quot;purge_seq&quot;: 10,&quot;updated_on&quot;: 1540541874,&quot;ddoc_id&quot;: &quot;_design/foo&quot;,&quot;signature&quot;: &quot;5d10247925f826ae3e00966ec24b7bf6&quot;}</code></pre><h3 id="内部复制"><a href="#内部复制" class="headerlink" title="内部复制"></a>内部复制</h3><p>清除请求将以最终一致的方式在所有节点上重播。 清除的内部复制包括两个步骤：<br>1.拉取复制。内部复制首先要从目标中清除并将其应用于源，以确保我们不会重新引入目标中已清除的源文档/修订版。 在这一步中，我们使用存储在目标上的清除检查点文档来跟踪源处理的最后一个目标的<code>purge_seq</code>。 我们发现清除请求在此<code>purge_seq</code>之后发生，并在源上重播它们。 通过使用最新进程<code>purge_seq</code>和时间戳更新目标的检查点清除文档来完成此步骤。<br>2.推送复制。 然后，内部复制将照常进行，并插入一个额外的步骤以将源的清除请求推送到目标。 在此步骤中，我们使用本地内部复制检查点文档，这些文档在目标和源上均已更新。<br>在正常情况下，交互式清除请求已发送到包含数据库碎片副本的每个节点，并应用于每个副本。节点之间清除的内部复制只是确保副本之间一致性的一个额外步骤，在此副本上，一个节点上的所有清除请求都会在另一个节点上重播。为了不在副本上重播相同的清除请求，每个交互式清除请求都用唯一的<code>uuid</code>标记。内部复制会过滤出副本的<code>purge_tree</code>中已存在的<code>UUID</code>的清除请求，并仅应用<code>purge_tree</code>中不存在的<code>UUID</code>的清除请求。 这就是为什么我们需要有两个内部清除树的原因：1）<code>purge_tree：{UUID-&gt; {PurgeSeq，DocId，Revs}}</code>可以快速找到带有已存在的<code>UUID</code>的<code>purge requests</code>存在的副本； 2）<code>purge_seq_tree：{PurgeSeq-&gt; {UUID，DocId，Revs }}</code>允许从给定的<code>purge_seq</code>进行迭代，以收集在此<code>purge_seq</code>之后发生的所有清除请求。</p><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>每个清除请求将增加数据库的<code>update_seq</code>，以便还更新每个辅助索引，以便应用清除请求以维护主数据库内的一致性。</p><h3 id="配置设置"><a href="#配置设置" class="headerlink" title="配置设置"></a>配置设置</h3><p>这些设置可以在<code>default.ini</code>或<code>local.ini</code>中进行更新：</p><table><thead><tr><th>字段</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td>max_document_id_number</td><td>一个清除请求中允许的最大文档数</td><td>100</td></tr><tr><td>max_revisions_number</td><td>一项清除请求中允许的最大累积修订版本数</td><td>1000</td></tr><tr><td>allowed_purge_seq_lag</td><td>除了<code>purged_infos_limit</code>外，还允许其他缓冲区存储清除请求</td><td>100</td></tr><tr><td>index_lag_warn_seconds</td><td>本地清除检查点文档的索引未更新时的允许持续时间</td><td>86400</td></tr></tbody></table><p>在数据库压缩期间，我们检查所有检查点清除文档。 允许客户端（索引或内部复制作业）的上一次报告的<code>purge_seq</code>小于当前数据库碎片的<code>purge_seq</code>的值(<code>purged_infos_limit + allowed_purge_seq_lag</code>)。如果客户端的<code>purge_seq</code>甚至更小，并且客户端未在<code>index_lag_warn_seconds</code>内设置检查点，则它会阻止清除清除树，因此我们必须对此客户端发出以下日志警告：</p><pre><code>Purge checkpoint &#39;_local/purge-mrview-9152d15c12011288629bcffba7693fd4’not updated in 86400 seconds in&lt;&lt;&quot;shards/00000000-1fffffff/testdb12.1491979089&quot;&gt;&gt;</code></pre><p>如果发生这种类型的日志警告，请检查客户端以查看为什么清除请求的处理停滞在其中。<br>索引的设计文档和本地检查点文档之间存在映射关系。 如果更新或删除了索引的设计文档，则也应自动删除相应的本地检查点文档。 但是在意外情况下，当设计文档被更新/删除但其检查点文档仍然存在于数据库中时，将发出以下警告：</p><pre><code>&quot;Invalid purge doc &#39;&lt;&lt;&quot;_design/bar&quot;&gt;&gt;&#39; on database&lt;&lt;&quot;shards/00000000-1fffffff/testdb12.1491979089&quot;&gt;&gt;with purge_seq &#39;50&#39;&quot;</code></pre><p>如果发生这种类型的日志警告，请从数据库中删除本地清除文档。</p>]]></content>
    
    
    <categories>
      
      <category>CouchDb学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CouchDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CURL命令学习三</title>
    <link href="undefined2019/12/21/blog/other/CURL%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%E4%B8%89/"/>
    <url>2019/12/21/blog/other/CURL%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%E4%B8%89/</url>
    
    <content type="html"><![CDATA[<h3 id="I"><a href="#I" class="headerlink" title="-I"></a><code>-I</code></h3><p>只获取请求头</p><h3 id="k-insecure"><a href="#k-insecure" class="headerlink" title="-k --insecure"></a><code>-k --insecure</code></h3><p>每次SSL连接curl都需要验证是否安全。<code>-k</code>参数表示如果不安全也可以继续操作。</p><h3 id="4-ipv4"><a href="#4-ipv4" class="headerlink" title="-4 --ipv4"></a><code>-4 --ipv4</code></h3><p>告诉curl只使用ipv4地址</p><h3 id="6-ipv6"><a href="#6-ipv6" class="headerlink" title="-6 --ipv6"></a><code>-6 --ipv6</code></h3><p>告诉curl只使用ipv6</p><h3 id="keepalive-time-lt-seconds-gt"><a href="#keepalive-time-lt-seconds-gt" class="headerlink" title="--keepalive-time &lt;seconds&gt;"></a><code>--keepalive-time &lt;seconds&gt;</code></h3><p>设置时间保持心跳连接</p><h3 id="no-keepalive"><a href="#no-keepalive" class="headerlink" title="--no-keepalive"></a><code>--no-keepalive</code></h3><p>不设置心跳保持连接</p><h3 id="l-list-only"><a href="#l-list-only" class="headerlink" title="-l --list-only"></a><code>-l --list-only</code></h3><p>(FTP)当列出FTP文件夹时，该选项强制只列出名字</p><h3 id="next"><a href="#next" class="headerlink" title="-: --next"></a><code>-: --next</code></h3><p>表明curl可一次性发送多个请求。例子：</p><pre><code>curl www.exam1.com --next -d name=value www.exam2.com</code></pre><h3 id="N-no-buffer"><a href="#N-no-buffer" class="headerlink" title="-N --no-buffer"></a><code>-N --no-buffer</code></h3><p>不使用输出流的缓冲区</p>]]></content>
    
    
    <categories>
      
      <category>curl</category>
      
    </categories>
    
    
    <tags>
      
      <tag>curl学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CouchDB学习-介绍</title>
    <link href="undefined2019/12/21/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-%E4%BB%8B%E7%BB%8D/"/>
    <url>2019/12/21/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0-%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<p><a href="https://docs.couchdb.org/en/stable/intro/index.html" target="_blank" rel="noopener">官方文档</a></p><h1 id="CouchDB"><a href="#CouchDB" class="headerlink" title="CouchDB"></a>CouchDB</h1><h2 id="1文档存储"><a href="#1文档存储" class="headerlink" title="1文档存储"></a>1文档存储</h2><p>CouchDB服务器主机是一个存储<strong>文档</strong>的数据库。每一个文档在数据库中都有唯一的名字。CouchDB提供RESTful HTTP API用来读取和更新(添加，编辑，删除)数据库文档。<br>文档是CouchDB数据库中的主要单元数据由任意字段和附件组成。文档也包括由数据库系统维护的元数据信息。文档字段具有唯一的名字并且包含多种类型(文本，数字，布尔值，列表等)的值。并且文本大小或元素数量没有限制。<br>CouchDB文档更新模式是无锁的并且优化的。由客户端应用加载文档进行文档编辑，使用更新，最后存储回数据库。如果另一个客户端编辑了相同的文档并且首先保存了更新。那么客户端将会在存储时得到一个编辑冲突的错误。为了解决更新冲突，最新的文档版本将会打开，编辑将重新应用并再次尝试更新。<br>单个文档更新(添加，编辑，删除)是全有或者全没有的，要么完全成功，要么完全失败。数据库不支持并行存储或更新文档。</p><h2 id="2ACID属性"><a href="#2ACID属性" class="headerlink" title="2ACID属性"></a>2ACID属性</h2><p>CouchDB文件层和系统提交特性具有全部的原子性，一致性，隔离性和持久性(ACID)属性。在硬盘中，CouchDB从不覆盖提交的数据或者被连接的结构。确保数据库文件总是保持一致性，这是一种“仅崩溃”设计，其中CouchDB服务器不执行关闭过程，而只是终止。<br>文档更新(添加，编辑，删除)是串行的，除了二进制字节的写操作是并行的。数据库读取者从来不会被锁住也不会写操作完成或者其他读者在读时等待。任何数量的客户端可以读取文档不需要加锁或者是被并行的更新打断即使是同一个文档。CouchDB读操作使用多版本并发控制(MVCC)模式。每一个客户端从开始读操作到结束看到的都是一致的数据库快照。这意味着CouchDB可以保证每个文档的事务语义。<br>文档通过他们的名字和序列号通过B-trees进行索引。每一次更新到数据库实例都会生成一个新的序列号。序列ID稍后用于在数据库中增量查找更改。文档存储或删除时B-tree索引也会同时进行更新。索引更新总是发生在文件(更新时只添加)最后。<br>文档数据的优势在于总是方便打包存储而不是和众多数据库系统一样分离成多个表和行。当文档提交到硬盘中，文档字段和元数据将序列化地一个文档接着一个文档(有助于稍后高效地构建视图)打包进缓冲区。<br>当CouchDB文档被更新后，所有的数据和相关的索引将被刷新到硬盘中总是以事务提交的方式使得数据库保持一致状态。提交通过两个步骤进行：</p><ol><li>所有的文档数据和相关索引同步更新和刷新到硬盘。</li><li>更新后的数据库头以两个连续的相同块写入，以构成文件的前4k，然后同步刷新到磁盘。</li></ol><p>当在步骤一处系统崩溃或者电源被关闭，部分更新只是简单的抛弃并重新启动。如果崩溃发生在步骤二(头部信息提交时)，仍保留以前相同标头的副本，以确保所有先前提交的数据的一致性。 除标题区域外，在崩溃或断电后无需进行一致性检查或修复。</p><h2 id="3压缩"><a href="#3压缩" class="headerlink" title="3压缩"></a>3压缩</h2><p>通过偶尔压缩来回收浪费的空间。 按计划，或者当数据库文件超过一定数量的浪费空间时，压缩过程会将所有活动数据克隆到新文件中，然后丢弃旧文件。数据库在整个过程中始终保持完全在线，并且所有更新和读取都可以成功完成。仅当所有数据都已复制并且所有用户都已转移到新文件时，才删除旧数据库文件。</p><h2 id="4视图"><a href="#4视图" class="headerlink" title="4视图"></a>4视图</h2><p>ACID属性仅处理存储和更新，但是我们还需要以有趣且有用的方式显示数据的能力，不像SQL数据库的数据必须小心地分解表，CouchDB中的数据以细小的机构存储在文档中。CouchDB文档变得更灵活并且他们拥有自己的隐含的结构。这减轻了双向复制表模式及其所包含数据的最困难的问题和陷阱。<br>但是，除了充当精美的文件服务器之外，用于数据存储和共享的简单文档模型太简单了，无法在其上构建真实的应用程序–它根本无法满足我们的期望和期望。 我们想要切片和切块，并以多种不同方式查看我们的数据。 现在需要一种过滤，组织和报告尚未分解为表格的数据的方法。</p><h3 id="4-1视图模型"><a href="#4-1视图模型" class="headerlink" title="4.1视图模型"></a>4.1视图模型</h3><p>为了解决将结构添加回非结构化和半结构化数据的问题，CouchDB集成了视图模型。 视图是聚合和报告数据库中文档的方法，并且按需构建以聚合，联接和报告数据库文档。 由于视图是动态构建的，并且不会影响基础文档，因此您可以根据需要使用相同数据的不同视图表示。<br>视图定义严格是虚拟的，并且仅显示当前数据库实例中的文档，从而使其与显示的数据分离并与复制兼容。 CouchDB视图是在特殊<strong>设计文档</strong>中定义的，并且可以跨数据库实例（如常规文档）进行复制，因此不仅数据可以在CouchDB中复制，而且整个应用程序设计也可以复制。</p><h3 id="4-2JavaScript视图功能"><a href="#4-2JavaScript视图功能" class="headerlink" title="4.2JavaScript视图功能"></a>4.2JavaScript视图功能</h3><p>视图是使用JavaScript功能定义的，该功能在map-reduce系统中充当map的一部分。 视图函数将CouchDB文档作为参数，然后进行所需的任何计算以确定通过视图提供的数据（如果有）。 它可以基于单个文档向视图添加多行，也可以根本不添加任何行。</p><h3 id="4-3视图索引"><a href="#4-3视图索引" class="headerlink" title="4.3视图索引"></a>4.3视图索引</h3><p>视图是数据库实际文档内容的动态表示，而CouchDB可以轻松创建有用的数据视图。 但是，生成包含数十万或数百万个文档的数据库视图既浪费时间和资源，又不是系统每次都要从头做的事情。<br>为了保持视图的快速查询，视图引擎维护其视图的索引，并对其进行增量更新以反映数据库中的更改。 CouchDB的核心设计在很大程度上围绕着对视图及其索引的高效，增量创建的需求进行了优化。<br>视图及其功能在特殊的“设计”文档中定义，并且设计文档可以包含任意数量的唯一命名的视图功能。 当用户打开一个视图并自动更新其索引时，同一设计文档中的所有视图都被索引为一个组。<br>视图构建器使用数据库序列ID来确定视图组是否与数据库完全同步。 如果不是，则视图引擎将检查自上次刷新以来更改的所有数据库文档（以打包的顺序排列）。 按照在磁盘文件中出现的顺序读取文档，从而减少了磁盘头搜索的频率和成本。<br>可以同时读取和查询视图，同时也可以刷新视图。 如果客户端正在缓慢地流出大视图的内容，则可以同时为另一个客户端打开和刷新同一视图，而不会阻塞第一个客户端。 这适用于任何数量的同时进行的客户端阅读器，它们可以在同时为其他客户端刷新索引的同时读取和查询视图，而不会给阅读器造成问题。<br>当视图引擎通过您的“地图”和“缩小”功能处理文档时，它们的前一行值将从视图索引中删除（如果存在）。 如果通过视图功能选择了文档，则功能结果将作为新行插入到视图中。<br>将视图索引更改写入磁盘后，更新总是附加在文件末尾，以减少磁盘提交期间的磁盘头查找时间，并确保崩溃和电源故障不会导致索引损坏。 如果在更新视图索引时发生崩溃，则不完整的索引更新将丢失并从其先前提交的状态逐步重建。</p><h2 id="5安全与验证"><a href="#5安全与验证" class="headerlink" title="5安全与验证"></a>5安全与验证</h2><p>为了保护可以读取和更新文档的人员，CouchDB具有简单的读取器访问和更新验证模型，该模型可以扩展为实现自定义安全模型。</p><h3 id="5-1-管理员访问"><a href="#5-1-管理员访问" class="headerlink" title="5.1 管理员访问"></a>5.1 管理员访问</h3><p>CouchDB数据库实例具有管理员帐户。 管理员帐户可以创建其他管理员帐户并更新设计文档。 设计文档是包含视图定义和其他特殊公式以及常规字段和Blob的特殊文档。</p><h3 id="5-2-更新验证"><a href="#5-2-更新验证" class="headerlink" title="5.2 更新验证"></a>5.2 更新验证</h3><p>将文档写入磁盘后，可以使用JavaScript函数动态地对其进行验证，以实现安全性和数据验证。 当文档通过所有公式验证标准时，将允许更新继续。 如果验证失败，更新将中止，用户客户端将收到错误响应。<br>用户凭证和更新的文档都作为验证公式的输入，可以通过验证用户的文档更新权限来实现自定义安全模型。<br>基本的“仅作者”更新文档模型的实现很简单，其中验证文档更新以检查用户是否在现有文档的“作者”字段中列出。 还可以使用更多的动态模型，例如检查单独的用户帐户配置文件的权限设置。<br>对于实时使用情况和复制的更新都执行更新验证，以确保共享的分布式系统中的安全性和数据验证。</p><h2 id="6分布式更新和复制"><a href="#6分布式更新和复制" class="headerlink" title="6分布式更新和复制"></a>6分布式更新和复制</h2><p>CouchDB是基于节点的分布式数据库系统。它允许用户和服务器在断开连接时访问和更新相同的共享数据。这些更改随后可以双向复制。<br>CouchDB文档的存储，视图和安全模型旨在协同工作，以使真正的双向复制高效且可靠。文档和设计都可以复制，从而允许将完整的数据库应用程序（包括应用程序设计，逻辑和数据）复制到便携式计算机上以供脱机使用，或复制到远程办公室中的连接缓慢或不可靠，难以共享数据的服务器。<br>复制过程是增量的。在数据库级别，复制仅检查自上次复制以来已更新的文档。如果由于网络问题或崩溃等原因导致复制在任何步骤上失败，则下一个复制将在最后一个检查点重新启动。<br>可以创建和维护部分副本。可以通过JavaScript函数过滤复制，以便仅复制特定文档或满足特定条件的文档。这可以允许用户脱机使用大型共享数据库应用程序的子集供自己使用，同时保持与应用程序和该数据子集的正常交互。</p><h3 id="6-1冲突"><a href="#6-1冲突" class="headerlink" title="6.1冲突"></a>6.1冲突</h3><p>冲突检测和管理是任何分布式编辑系统的关键问题。 CouchDB存储系统将编辑冲突视为一种常见状态，而不是例外状态。 冲突处理模型简单且“无损”，同时保留了单个文档的语义并允许分散式冲突解决。<br>CouchDB允许数据库中同时存在任何数量冲突的文档，每个数据库实例都确定性地确定哪个文档是“赢家”，哪些是冲突。 只有赢家文档可以显示在视图中，而“丢失”冲突仍然可以访问并保留在数据库中，直到在数据库压缩期间将其删除或清除为止。 因为冲突文档仍然是常规文档，所以它们像常规文档一样进行复制，并且要遵循相同的安全性和验证规则。<br>当发生分布式编辑冲突时，每个数据库副本都会看到相同的胜出版本，并且每个都有解决冲突的机会。 解决冲突可以手动完成，也可以根据数据的性质和冲突由自动代理完成。 该系统使分散式冲突解决成为可能，同时保持了单文档数据库的语义。<br>即使多个断开连接的用户或代理尝试解决相同的冲突，冲突管理也继续起作用。 如果解决的冲突导致更多的冲突，则系统将以相同的方式处理它们，在每台机器上确定相同的获胜者，并维护单个文档的语义。</p><h3 id="6-2应用"><a href="#6-2应用" class="headerlink" title="6.2应用"></a>6.2应用</h3><p>仅使用基本复制模型，几乎无需额外的工作就可以使许多传统的单服务器数据库应用程序分布式。 CouchDB复制旨在立即用于基本数据库应用程序，同时还可以扩展以用于更详尽和功能齐全的用途。<br>只需很少的数据库工作，就可以构建具有精细安全性和完整修订历史记录的分布式文档管理应用程序。 可以实施文档更新以利用增量字段和Blob复制，其中复制的更新几乎与实际编辑差异（“差异”）一样高效和增量。</p>]]></content>
    
    
    <categories>
      
      <category>CouchDb学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CouchDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fabric1.4源码解析：链码容器启动过程</title>
    <link href="undefined2019/12/19/blog/fabric/Fabric1.4%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B%E9%93%BE%E7%A0%81%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/"/>
    <url>2019/12/19/blog/fabric/Fabric1.4%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B%E9%93%BE%E7%A0%81%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p>想写点东西记录一下最近看的一些Fabric源码,本文使用的是<strong>fabric1.4</strong>的版本，所以对于其他版本的fabric，内容可能会有所不同。<br>其实我仅仅知道Go语言一些语法的使用，并不太熟悉Go语言，所以解析的内容可能会有误，欢迎大家批评指正。<br>本文想针对Fabric中链码容器的启动过程进行源码的解析。这里的链码指的是用户链码不是系统链码,顺便回顾一下系统链码:<br><strong>lscc</strong>(Life Cycle System ChainCode)生命周期系统链码<br><strong>cscc</strong>(Configuration System ChainCode)配置系统链码<br><strong>escc</strong>(Endorser System ChainCode)背书系统链码<br><strong>qscc</strong>(Query System ChainCode)查询系统链码<br><strong>vscc</strong>(Verification System ChainCode)验证系统链码<br>本文主要解析的是用户链码的启动过程。</p><h2 id="1-起点"><a href="#1-起点" class="headerlink" title="1 起点"></a>1 起点</h2><pre><code>#这是用户端链码的main方法，也是整个流程的入口点，调用了shim包中的Start(cc Chaincode)方法.func main(){    err :=shim.Start(new(Chaincode))    if err != nil {        fmt.Printf(&quot;Error starting Chaincode: %s&quot;,err)    }}</code></pre><p>首先定位到<code>fabric/core/chaincode/shim/chaincode.go</code>这个文件中的<code>Start</code>方法，这里是链码启动的起点。<br>可以看到传的参数就是chaincode,接下来分析一下启动过程</p><pre><code>#方法中第一行代码，根据名字可以看出是对链码的Log进行设置SetupChaincodeLogging()#从输入中获取用户定义的链码的名称chaincodename := viper.GetString(&quot;chaincode.id.name&quot;)#如果没有输入链码名称，直接返回没有提供链码id的错误，下面则不再执行if chaincodename == &quot;&quot; {    return errors.New(&quot;error chaincode id not provided&quot;)}#看名字是一个工厂方法，点进行看一下err := factory.InitFactories(factory.GetDefaultOpts())</code></pre><p>首先进入到<code>factory.GetDefaultOpts()</code>方法中：</p><pre><code>func GetDefaultOpts() *FactoryOpts {    return &amp;FactoryOpts{        ProviderName: &quot;SW&quot;,        SwOpts: &amp;SwOpts{            HashFamily: &quot;SHA2&quot;,   #HASH类型            SecLevel:   256,    #HASH级别            Ephemeral: true,        },    }}#可以猜到这个方法是获取默认的加密操作，使用SHA256进行数据加密</code></pre><p>不难猜到<code>factory.InitFactories</code>这个方法就是为当前链码设置加密操作的一系列内容。回到<code>Start()</code>方法中接着往下看.</p><pre><code>#这一部分就是将链码数据以流的方式读取进来，userChaincodeStreamGetter是一个方法，点进去看一下if streamGetter == nil {    streamGetter = userChaincodeStreamGetter}stream, err := streamGetter(chaincodename)if err != nil {    return err}</code></pre><p><code>userChaincodeStreamGetter</code>还是在这个文件中第82行:</p><pre><code>#这里的name是链码名称，读取到链码数据后以PeerChainCodeStream的方式返回func userChaincodeStreamGetter(name string) (PeerChaincodeStream, error) {    #获取peer.address    flag.StringVar(&amp;peerAddress, &quot;peer.address&quot;, &quot;&quot;, &quot;peer address&quot;)    //判断是否使能TLS    if viper.GetBool(&quot;peer.tls.enabled&quot;) {        #获取tls密钥地址，在用户安装链码的时候指定        keyPath := viper.GetString(&quot;tls.client.key.path&quot;)        #获取tls证书地址        certPath := viper.GetString(&quot;tls.client.cert.path&quot;)        #从文件中读取密钥数据        data, err1 := ioutil.ReadFile(keyPath)        if err1 != nil {            err1 = errors.Wrap(err1, fmt.Sprintf(&quot;error trying to read file content %s&quot;, keyPath))            chaincodeLogger.Errorf(&quot;%+v&quot;, err1)            return nil, err1        }        key = string(data)         #从文件中读取证书数据        data, err1 = ioutil.ReadFile(certPath)        if err1 != nil {            err1 = errors.Wrap(err1, fmt.Sprintf(&quot;error trying to read file content %s&quot;, certPath))            chaincodeLogger.Errorf(&quot;%+v&quot;, err1)            return nil, err1        }        cert = string(data)    }    #解析命令行参数到定义的flag    flag.Parse()    #日志输出    chaincodeLogger.Debugf(&quot;Peer address: %s&quot;, getPeerAddress())    //与peer节点建立连接    clientConn, err := newPeerClientConnection()</code></pre><p>看一下这个方法里面的内容，还是这个文件第317行：</p><pre><code>func newPeerClientConnection() (*grpc.ClientConn, error) {    #首先获取到peer节点的地址    var peerAddress = getPeerAddress()    #看名字就知道了，设置与链码之间的心中信息    kaOpts := &amp;comm.KeepaliveOptions{        ClientInterval: time.Duration(1) * time.Minute,        ClientTimeout:  time.Duration(20) * time.Second,    }</code></pre><p> 判断是否使能了TLS，然后根据结果建立链接,如何建立链接就不再细看了，我们回到之前的部分</p><pre><code>    if viper.GetBool(&quot;peer.tls.enabled&quot;) {        return comm.NewClientConnectionWithAddress(peerAddress, true, true,            comm.InitTLSForShim(key, cert), kaOpts)    }    return comm.NewClientConnectionWithAddress(peerAddress, true, false, nil, kaOpts)}</code></pre><p>还是之前的<code>userChaincodeStreamGetter</code>方法</p><pre><code>clientConn, err := newPeerClientConnection()    if err != nil {        err = errors.Wrap(err, &quot;error trying to connect to local peer&quot;)        chaincodeLogger.Errorf(&quot;%+v&quot;, err)        return nil, err    }    chaincodeLogger.Debugf(&quot;os.Args returns: %s&quot;, os.Args)    #接下来是这个方法，返回一个ChaincodeSupportClient实例,对应着链码容器    chaincodeSupportClient := pb.NewChaincodeSupportClient(clientConn)    //这一步是与peer节点建立gRPC连接    stream, err := chaincodeSupportClient.Register(context.Background())    if err != nil {        return nil, errors.WithMessage(err, fmt.Sprintf(&quot;error chatting with leader at address=%s&quot;, getPeerAddress()))    }    return stream, nil}</code></pre><p>这个方法结束之后，链码容器与Peer节点已经建立起了连接，接下来链码容器与Peer节点开始互相发送消息了。<br>返回到<code>Start()</code>方法中，还剩最后的一个方法<code>chatWithPeer()</code>：</p><pre><code>    err = chatWithPeer(chaincodename, stream, cc)    return err}</code></pre><p>看一下链码容器与Peer节点是如何互相通信的。这个方法是链码容器启动的过程中最重要的方法，包含所有的通信流程。<code>chatWithPeer()</code>在331行:</p><pre><code>func chatWithPeer(chaincodename string, stream PeerChaincodeStream, cc Chaincode)#传入的参数有链码名称，流(这个是之前链码容器与Peer节点建立gRPC连接所返回的)，链码</code></pre><p>首先第一步是新建一个<code>ChaincodeHandler</code>对象：是非常重要的一个对象。看一下该对象的内容,在<code>core/chaincode/shim/handler.go</code>文件中第166行:</p><pre><code>func newChaincodeHandler(peerChatStream PeerChaincodeStream, chaincode Chaincode) *Handler {    v := &amp;Handler{        ChatStream: peerChatStream,   #与Peer节点通信的流        cc:         chaincode,      #链码    }    v.responseChannel = make(map[string]chan pb.ChaincodeMessage)  #链码信息响应通道    v.state = created     #表示将链码容器的状态更改为created    return v    将handler返回}</code></pre><p>这个<code>ChaincodeHandler</code>对象是链码侧完成链码与Peer节点之前所有的消息的控制逻辑。<br>继续往下看：</p><pre><code>#在方法执行结束的时候关闭gRPC连接defer stream.CloseSend()#获取链码名称chaincodeID := &amp;pb.ChaincodeID{Name: chaincodename}#将获取的链码名称序列化为有效载荷.payload, err := proto.Marshal(chaincodeID)if err != nil {    return errors.Wrap(err, &quot;error marshalling chaincodeID during chaincode registration&quot;)}#日志输出,这个日志信息在安装链码的时候应该有看到过吧chaincodeLogger.Debugf(&quot;Registering.. sending %s&quot;, pb.ChaincodeMessage_REGISTER)#链码容器通过handler开始通过gRPC连接向Peer节点发送第一个消息了，链码容器向Peer节点发送REGISTER消息，并附上链码的名称if err = handler.serialSend(&amp;pb.ChaincodeMessage{Type: pb.ChaincodeMessage_REGISTER, Payload: payload}); err != nil {        return errors.WithMessage(err, &quot;error sending chaincode REGISTER&quot;)    }#定义一个接收消息的结构体type recvMsg struct {    msg *pb.ChaincodeMessage    err error}msgAvail := make(chan *recvMsg, 1)errc := make(chan error)receiveMessage := func() {    in, err := stream.Recv()    msgAvail &lt;- &amp;recvMsg{in, err}}#接收由Peer节点返回的响应消息go receiveMessage()</code></pre><p>接下来的部分就是链码容器与Peer节点详细的通信过程了：</p><h2 id="2链码侧向Peer节点发送REGISTER消息"><a href="#2链码侧向Peer节点发送REGISTER消息" class="headerlink" title="2链码侧向Peer节点发送REGISTER消息"></a>2链码侧向Peer节点发送REGISTER消息</h2><pre><code>#前面的部分都是接收到错误消息的各种输出逻辑，不再细看，我们看default这一部分，这一部分是正常情况下消息的处理情况：for {        select {        case rmsg := &lt;-msgAvail:            switch {            case rmsg.err == io.EOF:                err = errors.Wrapf(rmsg.err, &quot;received EOF, ending chaincode stream&quot;)                chaincodeLogger.Debugf(&quot;%+v&quot;, err)                return err            case rmsg.err != nil:                err := errors.Wrap(rmsg.err, &quot;receive failed&quot;)                chaincodeLogger.Errorf(&quot;Received error from server, ending chaincode stream: %+v&quot;, err)                return err            case rmsg.msg == nil:                err := errors.New(&quot;received nil message, ending chaincode stream&quot;)                chaincodeLogger.Debugf(&quot;%+v&quot;, err)                return err            default:            #这一句日志输出应该看到过好多次吧。                chaincodeLogger.Debugf(&quot;[%s]Received message %s from peer&quot;, shorttxid(rmsg.msg.Txid), rmsg.msg.Type)                #重要的一个方法，在链码容器与Peer节点建立起了联系后，主要通过该方法对消息逻辑进行处理，我们点进行看一下。                err := handler.handleMessage(rmsg.msg, errc)                if err != nil {                    err = errors.WithMessage(err, &quot;error handling message&quot;)                    return err                }                #当消息处理完成后，再次接收消息。                go receiveMessage()            }        #最后是发送失败的处理        case sendErr := &lt;-errc:            if sendErr != nil {                err := errors.Wrap(sendErr, &quot;error sending&quot;)                return err            }        }    }</code></pre><p>一个重要的方法：<code>handleMessage</code>在<code>core/chaincode/shim/handler.go</code>文件第801行：</p><pre><code>func (handler *Handler) handleMessage(msg *pb.ChaincodeMessage, errc chan error) error {    #如果链码容器接收到Peer节点发送的心跳消息后，直接将心跳消息返回，双方就一直保持联系。    if msg.Type == pb.ChaincodeMessage_KEEPALIVE {        chaincodeLogger.Debug(&quot;Sending KEEPALIVE response&quot;)        handler.serialSendAsync(msg, nil) // ignore errors, maybe next KEEPALIVE will work        return nil    }    #我们先看到这里，如果再往下看的话可能会乱掉，所以还是按照逻辑顺序进行说明。</code></pre><p><strong>先说一下链码侧所做的工作：</strong></p><ul><li><p>首先进行各项基本配置，然后建立起与Peer节点的gRPC连接。</p></li><li><p>创建<code>Handler</code>,并更改<code>Handler</code>状态为<code>created</code>。</p></li><li><p>发送<code>REGISTER</code>消息到Peer节点。</p></li><li><p>等待Peer节点返回的信息</p><h2 id="3Peer节点接收到REGISTER消息后"><a href="#3Peer节点接收到REGISTER消息后" class="headerlink" title="3Peer节点接收到REGISTER消息后"></a>3Peer节点接收到REGISTER消息后</h2><p>之前讲的都是链码侧的一系列流程，我们之前提到链码侧与Peer节点之间的第一个消息内容是由链码侧发送至Peer节点的<code>REGISTER</code>消息。接下来我们看一下Peer节点在接收到该消息后是如果进行处理的。<br>代码在<code>core/chaincode/handler.go</code>文件中第174行，这里不是处理消息的开始，但是对于我们要说的链码容器启动过程中消息的处理刚好衔接上，所以就直接从这里开始了。另外很重要的一点，这里已经转换到Peer节点侧了，不是之前说的链码侧，我们看一下代码：</p><pre><code>func (h *Handler) handleMessage(msg *pb.ChaincodeMessage) error {  chaincodeLogger.Debugf(&quot;[%s] Fabric side handling ChaincodeMessage of type: %s in state %s&quot;, shorttxid(msg.Txid), msg.Type, h.state)  #这边也是首先判断是不是心跳信息，如果是心跳信息的话就什么也不做，与之前不同的是链码侧在收到心跳信息后会返回Peer节点一个心跳信息。  if msg.Type == pb.ChaincodeMessage_KEEPALIVE {      return nil  }  #之前我们提到，创建handler时，更改状态为created,所以这里进入到handleMessageCreatedState这个方法内.  switch h.state {  case Created:      return h.handleMessageCreatedState(msg)  case Ready:      return h.handleMessageReadyState(msg)  default:      return errors.Errorf(&quot;handle message: invalid state %s for transaction %s&quot;, h.state, msg.Txid)  }}</code></pre><p><code>handleMessageCreatedState</code>这个方法在第191行,方法内容很简单，判断消息类型是不是REGISTER，如果是则进入HandlerRegister(msg)方法内，如果不是则返回错误信息。</p><pre><code>func (h *Handler) handleMessageCreatedState(msg *pb.ChaincodeMessage) error {  switch msg.Type {  case pb.ChaincodeMessage_REGISTER:      h.HandleRegister(msg)  default:      return fmt.Errorf(&quot;[%s] Fabric side handler cannot handle message (%s) while in created state&quot;, msg.Txid, msg.Type)  }  return nil}</code></pre><p>接下来我们看一下<code>HandleRegister</code>这个方法,在第495行：</p><pre><code>func (h *Handler) HandleRegister(msg *pb.ChaincodeMessage) {  chaincodeLogger.Debugf(&quot;Received %s in state %s&quot;, msg.Type, h.state)  #获取链码ID  chaincodeID := &amp;pb.ChaincodeID{}  #反序列化  err := proto.Unmarshal(msg.Payload, chaincodeID)  if err != nil {      chaincodeLogger.Errorf(&quot;Error in received %s, could NOT unmarshal registration info: %s&quot;, pb.ChaincodeMessage_REGISTER, err)      return  }  h.chaincodeID = chaincodeID  #这一行就是将链码注册到当前Peer节点上  err = h.Registry.Register(h)  if err != nil {      h.notifyRegistry(err)      return  }  从Peer节点侧的handler获取链码名称  h.ccInstance = ParseName(h.chaincodeID.Name)  chaincodeLogger.Debugf(&quot;Got %s for chaincodeID = %s, sending back %s&quot;, pb.ChaincodeMessage_REGISTER, chaincodeID, pb.ChaincodeMessage_REGISTERED)  #然后将REGISTERED消息返回给链码侧  if err := h.serialSend(&amp;pb.ChaincodeMessage{Type: pb.ChaincodeMessage_REGISTERED}); err != nil {      chaincodeLogger.Errorf(&quot;error sending %s: %s&quot;, pb.ChaincodeMessage_REGISTERED, err)      h.notifyRegistry(err)      return  }  //更新handler状态为Established  h.state = Established  chaincodeLogger.Debugf(&quot;Changed state to established for %+v&quot;, h.chaincodeID)  #还有这个方法也要看一下  h.notifyRegistry(nil)}</code></pre><p>简单来说<code>HandleRegister</code>的功能就是将链码注册到Peer节点上，并发送<code>RESIGSERED</code>到链码侧，最后更新<code>handler</code>状态为<code>Established</code>，我们看一下<code>notifyRegistry</code>方法,在478行：</p><pre><code>func (h *Handler) notifyRegistry(err error) {  if err == nil {      //再往里面看,方法在459行      err = h.sendReady()  }  if err != nil {      h.Registry.Failed(h.chaincodeID.Name, err)      chaincodeLogger.Errorf(&quot;failed to start %s&quot;, h.chaincodeID)      return  }  h.Registry.Ready(h.chaincodeID.Name)}#sendReady()func (h *Handler) sendReady() error {  chaincodeLogger.Debugf(&quot;sending READY for chaincode %+v&quot;, h.chaincodeID)  ccMsg := &amp;pb.ChaincodeMessage{Type: pb.ChaincodeMessage_READY}  #Peer节点又向链码容器发送了READY消息  if err := h.serialSend(ccMsg); err != nil {      chaincodeLogger.Errorf(&quot;error sending READY (%s) for chaincode %+v&quot;, err, h.chaincodeID)      return err  }  #同时更新handler状态为Ready  h.state = Ready  chaincodeLogger.Debugf(&quot;Changed to state ready for chaincode %+v&quot;, h.chaincodeID)  return nil}</code></pre><p>到这里，Peer节点暂时分析完成，又到了链码侧对Peer节点发送的消息进行处理的流程.</p></li><li><p><em>我们先总结一下这一部分Peer节点做了哪些工作：*</em></p></li><li><p>首先当Peer节点接收到链码侧发送的<code>REGISTER</code>消息后，将链码注册到Peer端的<code>Handler</code>上，发送<code>REGISTERED</code>到链码侧，更新<code>Handler</code>的状态为<code>Established</code>。</p></li><li><p>然后Peer节点向链码侧发送<code>READY</code>消息，同时更新<code>Handler</code>的状态为<code>Ready</code>。</p></li></ul><h2 id="4链码侧的回应"><a href="#4链码侧的回应" class="headerlink" title="4链码侧的回应"></a>4链码侧的回应</h2><p>我们回到链码侧之前的这一部分<code>core/chaincode/chaincode.go</code>中第364行,这里是链码铡对接收到的Peer节点发送的消息进行处理的逻辑,至于发生错误的情况就不再说明，我们看<code>handleMessage</code>这个方法。</p><pre><code>go receiveMessage()    for {           #相关代码        ...        err := handler.handleMessage(rmsg.msg, errc)        ...            #相关代码                go receiveMessage()    }</code></pre><p><code>handleMessage</code>这个方法在<code>core/chaincode/shim/handler.go</code>这个文件中，第801行。</p><pre><code>#主要就是这一部分：switch handler.state {    case ready:        err = handler.handleReady(msg, errc)    case established:        err = handler.handleEstablished(msg, errc)    case created:        err = handler.handleCreated(msg, errc)    default:        err = errors.Errorf(&quot;[%s] Chaincode handler cannot handle message (%s) with payload size (%d) while in state: %s&quot;, msg.Txid, msg.Type, len(msg.Payload), handler.state)}</code></pre><ul><li><p>首先链码侧接收到Peer节点发送的<code>REGISTERED</code>消息后，这里链码侧的<code>handler</code>与Peer节点侧的<code>handler</code>并不是同一个，不要搞混了。判断当前链码侧<code>handler</code>的状态为<code>created</code>，进入到<code>handleCreated</code>方法中,在792行：</p><pre><code>#将链码侧的handler的状态更改为establishedif msg.Type == pb.ChaincodeMessage_REGISTERED {  handler.state = established  return nil}</code></pre></li><li><p>当链码侧接收到Peer节点发送的<code>READY</code>消息后，又一次进入上面的逻辑，由于链码侧的<code>handler</code>的状态已经更改为<code>established</code>,所以这次进入到<code>handleEstablished</code>方法中。在783行：</p><pre><code>#然后将链码侧的handler的状态更改为readyif msg.Type == pb.ChaincodeMessage_READY {  handler.state = ready  return nil}</code></pre></li><li><p>另外，当用户对链码进行实例化操作时，会通过Peer节点向链码侧发送<code>INIT</code>消息，这里涉及到背书过程，之后再对背书过程进行讨论，我们在这里只关注链码侧接收到<code>INIT</code>消息后的逻辑，还是<code>handleMessage</code>这个方法中：</p><pre><code>#当判断到消息类型为INIT时，会执行这个方法。handler.handleInit(msg, errc)</code></pre><p><code>handler.handleInit(msg, errc)</code>方法在第177行：</p><pre><code>func (handler *Handler) handleInit(msg *pb.ChaincodeMessage, errc chan error) {  go func() {      var nextStateMsg *pb.ChaincodeMessage      defer func() {          #这一名相当于更新链码的状态          handler.triggerNextState(nextStateMsg, errc)      }()      #判断错误信息      errFunc := func(err error, payload []byte, ce *pb.ChaincodeEvent, errFmt string, args ...interface{}) *pb.ChaincodeMessage {          if err != nil {              // Send ERROR message to chaincode support and change state              if payload == nil {                  payload = []byte(err.Error())              }              chaincodeLogger.Errorf(errFmt, args...)              return &amp;pb.ChaincodeMessage{Type: pb.ChaincodeMessage_ERROR, Payload: payload, Txid: msg.Txid, ChaincodeEvent: ce, ChannelId: msg.ChannelId}          }          return nil      }      #获取用户输入的参数      input := &amp;pb.ChaincodeInput{}      #反序列化      unmarshalErr := proto.Unmarshal(msg.Payload, input)      if nextStateMsg = errFunc(unmarshalErr, nil, nil, &quot;[%s] Incorrect payload format. Sending %s&quot;, shorttxid(msg.Txid), pb.ChaincodeMessage_ERROR.String()); nextStateMsg != nil {          return      }      #ChaincodeStub应该很熟悉了,很重要的一个对象，包含一项提案中所需要的内容。在``core/chaincode/shim/chaincode.go``文件中第53行，有兴趣可以点进去看一下      stub := new(ChaincodeStub)      #这一行代码的意思就是将提案中的信息抽取出来赋值到ChaincodeStub这个对象中     err := stub.init(handler, msg.ChannelId, msg.Txid, input, msg.Proposal)     if nextStateMsg = errFunc(err, nil, stub.chaincodeEvent, &quot;[%s] Init get error response. Sending %s&quot;, shorttxid(msg.Txid), pb.ChaincodeMessage_ERROR.String()); nextStateMsg != nil {          return     }     #这里的Init方法就是链码中所写的Init()方法，就不再解释了     res := handler.cc.Init(stub)     chaincodeLogger.Debugf(&quot;[%s] Init get response status: %d&quot;, shorttxid(msg.Txid), res.Status)      #ERROR的值为500,OK=200，ERRORTHRESHOLD = 400，大于等于400就代表错误信息或者被背书节点拒绝。      if res.Status &gt;= ERROR {          err = errors.New(res.Message)          if nextStateMsg = errFunc(err, []byte(res.Message), stub.chaincodeEvent, &quot;[%s] Init get error response. Sending %s&quot;, shorttxid(msg.Txid), pb.ChaincodeMessage_ERROR.String()); nextStateMsg != nil {              return          }      }      resBytes, err := proto.Marshal(&amp;res)      if err != nil {          payload := []byte(err.Error())          chaincodeLogger.Errorf(&quot;[%s] Init marshal response error [%s]. Sending %s&quot;, shorttxid(msg.Txid), err, pb.ChaincodeMessage_ERROR)          nextStateMsg = &amp;pb.ChaincodeMessage{Type: pb.ChaincodeMessage_ERROR, Payload: payload, Txid: msg.Txid, ChaincodeEvent: stub.chaincodeEvent}          return      }      // Send COMPLETED message to chaincode support and change state      nextStateMsg = &amp;pb.ChaincodeMessage{Type: pb.ChaincodeMessage_COMPLETED, Payload: resBytes, Txid: msg.Txid, ChaincodeEvent: stub.chaincodeEvent, ChannelId: stub.ChannelId}      chaincodeLogger.Debugf(&quot;[%s] Init succeeded. Sending %s&quot;, shorttxid(msg.Txid), pb.ChaincodeMessage_COMPLETED)      #到这里就结束了，会调用上面的handler.triggerNextState(nextStateMsg, errc)方法，这个方法将初始化数据与COMPLETED状态发送至Peer节点。  }()}</code></pre><p>这个方法还是比较简单的，一共做了这些事情：</p></li><li><p>获取用户的输入数据</p></li><li><p>新建一个<code>ChainCodeStub</code>对象，然后将用户输入的数据赋值给该对象</p></li><li><p>调用用户链码中的<code>Init()</code>方法</p></li><li><p>将所有数据封装成<code>ChainCodeMessage</code>，类型为<code>COMPLETED</code>,发送至Peer节点。</p></li></ul><p>这个时候链码已经初始化完成，已经进入了可被调用(<code>invoke</code>)的状态.<br>之后的流程就差不多了，Peer节点发送<code>TRANSACTION</code>消息给链码侧，调用<code>Invoke()</code>方法，之后链码侧发送具体的调用方法到Peer节点，由Peer节点进行相应的处理，最后返回<code>RESPONSE</code>消息到链码侧，链码侧接收到<code>RESPONSE</code>消息后，返回<code>COMPLETED</code>消息到Peer节点。</p><h2 id="5总结"><a href="#5总结" class="headerlink" title="5总结"></a>5总结</h2><p>到这里，Peer节点与链码侧的<code>handler</code>都处于<code>READY</code>状态,链码容器已经启动完成。最后总结一下整体的流程：</p><ol><li>通过用户端链码中的<code>main</code>方法，调用了<code>core/chaincode/shim/chaincode.go</code>中的<code>Start()</code>方法，从而开始了链码的启动。</li><li>首先进行相关的配置比如基本的加密，证书的读取。</li><li>创建与Peer节点之间的gRPC连接，创建<code>handler</code>实例。</li><li>由链码容器向Peer节点发送第一个消息:<code>REGISTER</code>,然后等待接收由Peer节点发送的消息。如果接收到的是心跳消息，则向Peer节点返回心跳消息。</li><li>Peer节点接收到链码容器发送的<code>REGISTER</code>消息后，将其注册到Peer节点端的<code>handler</code>上。</li><li>Peer节点发送<code>REGISTERED</code>消息到链码侧，同时更新Peer节点端的<code>handler</code>状态为<code>Established</code>。</li><li>Peer节点发送<code>Ready</code>消息到链码侧，同时更新Peer节点端的<code>handler</code>状态为<code>Ready</code>。</li><li>链码侧接收到由Peer节点发送的<code>REGISTERED</code>消息后，更新链码侧的<code>handler</code>状态为<code>Established</code>。</li><li>链码侧接收到由Peer节点发送的<code>READY</code>消息后，更新链码侧的<code>handler</code>状态为<code>ready</code>。</li><li>当用户执行实例化链码时，通过Peer节点向链码侧发送<code>INIT</code>消息。链码侧接收到<code>INIT</code>消息后，根据用户输入的参数进行实例化操作。实例化完成后，返回<code>COMPLETED</code>消息到Peer节点。</li><li>到这里链码容器已经启动，可以对链码数据进行查询调用等操作了。</li></ol><p>另外，阅读Fabric源码中有一些没有看明白或者分析有误的地方，还望大家能够批评指正。</p><p>最后附上参考文档：<a href="https://legacy.gitbook.com/book/yeasy/hyperledger_code_fabric/details" target="_blank" rel="noopener">传送门</a><br>以及Fabric源码地址：<a href="https://github.com/hyperledger/fabric" target="_blank" rel="noopener">传送门</a></p>]]></content>
    
    
    <categories>
      
      <category>fabric源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CURL命令学习二</title>
    <link href="undefined2019/12/19/blog/other/CURL%E5%AD%A6%E4%B9%A0%E4%BA%8C/"/>
    <url>2019/12/19/blog/other/CURL%E5%AD%A6%E4%B9%A0%E4%BA%8C/</url>
    
    <content type="html"><![CDATA[<h3 id="a-append"><a href="#a-append" class="headerlink" title="-a, --append"></a><code>-a, --append</code></h3><p>用于上传文件时，如果服务器上该文件不存在则创建，如果存在则追加到源文件。</p><h3 id="K-config-lt-file-gt"><a href="#K-config-lt-file-gt" class="headerlink" title="-K, --config &lt;file&gt;"></a><code>-K, --config &lt;file&gt;</code></h3><p>指定从某个文件读取<code>curl</code>参数。如果指定<code>-</code>为文件名则从输入读取参数。如：<code>-K --config -</code></p><h3 id="connect-timeout-lt-seconds-gt"><a href="#connect-timeout-lt-seconds-gt" class="headerlink" title="--connect-timeout &lt;seconds&gt;"></a><code>--connect-timeout &lt;seconds&gt;</code></h3><p>指定连接超时时间，若指定多个时间则采用最后一个。</p><h3 id="C-continue-at-lt-offset-gt"><a href="#C-continue-at-lt-offset-gt" class="headerlink" title="-C --continue-at &lt;offset&gt;"></a><code>-C --continue-at &lt;offset&gt;</code></h3><p>从给予的偏移量继续文件传输，用于断点续传，如果使用<code>-C -</code>则表明由<code>curl</code>自动获取从哪里开始继续传输。</p><h3 id="c-cookie-jar-lt-filename-gt"><a href="#c-cookie-jar-lt-filename-gt" class="headerlink" title="-c --cookie-jar &lt;filename&gt;"></a><code>-c --cookie-jar &lt;filename&gt;</code></h3><p>指定将<code>cookie</code>写入的文件，如果指定文件名为<code>-</code>，则将<code>cookie</code>写入输出。</p><h3 id="b-cookie-lt-data-filename-gt"><a href="#b-cookie-lt-data-filename-gt" class="headerlink" title="-b --cookie &lt;data|filename&gt;"></a><code>-b --cookie &lt;data|filename&gt;</code></h3><p>将数据添加到<code>Cookie header</code>中传输到<code>HTTP</code>服务器。数据格式应该为<code>name1=value1;name2=value2</code>。如果文件名为<code>-</code>，则从输入读取数据。<br><code>-b --cookie</code>只用于输入<code>cookie</code>，并不会写<code>cookie</code>信息到本地，所以需要和<code>-c --cookie-jar</code>同时使用。</p><h3 id="create-dirs"><a href="#create-dirs" class="headerlink" title="--create-dirs"></a><code>--create-dirs</code></h3><p>当使用<code>-o --output</code>选项时，<code>curl</code>将会创建必要的文件夹分层结构。如果<code>--output</code>文件名使用不存在的文件夹或者需要分层的文件夹存在，则没有文件夹被创建。</p><h3 id="d-data-lt-data-gt"><a href="#d-data-lt-data-gt" class="headerlink" title="-d --data &lt;data&gt;"></a><code>-d --data &lt;data&gt;</code></h3><p>通过POST请求发送具体的数据到HTTP服务器。</p><h3 id="f-fail"><a href="#f-fail" class="headerlink" title="-f --fail"></a><code>-f --fail</code></h3><p>当curl请求出现服务器错误时不打印错误信息，通常用于脚本中。只返回错误码22</p><h3 id="F-form-lt-name-content-gt"><a href="#F-form-lt-name-content-gt" class="headerlink" title="-F --form &lt;name=content&gt;"></a><code>-F --form &lt;name=content&gt;</code></h3><p>与<code>-d</code>相似，想服务器发送数据，<code>-F</code>是以表单形式</p><ul><li>发送文件：<code>curl -F &quot;name=@file.txt&quot; http://www.xxx.html</code></li><li>指定<code>Content-Type</code>：<code>curl -F &quot;web=@index.html;type=text/html&quot; http://www.xxx.html</code></li></ul><h3 id="i"><a href="#i" class="headerlink" title="-i"></a><code>-i</code></h3><p>在输出中包含HTTP响应头信息。</p><h3 id="X"><a href="#X" class="headerlink" title="-X"></a><code>-X</code></h3><p>指定具体的请求方法如<code>GET,POST...</code></p>]]></content>
    
    
    <categories>
      
      <category>curl</category>
      
    </categories>
    
    
    <tags>
      
      <tag>curl学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IPFS学习-IPNS</title>
    <link href="undefined2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-IPNS/"/>
    <url>2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-IPNS/</url>
    
    <content type="html"><![CDATA[<p>星际名称系统(IPNS)是一个创建个更新可变的链接到IPFS内容的系统，由于对象在IPFS中是内容寻址的，他们的内容变化将导致地址随之变化。对于多变的事物是有用的。但是很难获取某些内容的最新版本。</p><p>在IPNS中名字是被哈希的公钥。它与一条记录相关联，该记录包含有关其链接的哈希的信息，该信息由相应的私钥签名。新的记录可以在任何时候被签名与发布。<br>查看IPNS地址，使用了<code>/ipns/</code>前缀：</p><pre><code>/ipns/QmSrPmbaUKA3ZodhzPWZnpFgcPMFWF4QsxXbkWfEptTBJd</code></pre><p>IPNS不是在IPFS上创建可变地址的唯一方法。 您还可以使用<a href="">DNSLink</a>（当前比IPNS快得多，并且还使用更易读的名称）。 其他社区成员正在探索使用区块链存储通用名称记录的方法。</p><p>例如：<br>假设您要在IPFS下发布您的网站。 您可以使用<a href="">Files API</a>发布静态网站，然后获得一个可以链接到的CID。 但是，当您需要进行更改时，就会出现问题：您将获得一个新的CID，因为您现在拥有不同的内容。 而且，您不可能总是给别人新的地址。<br>这是Name API派上用场的地方。 使用它，您可以创建一个稳定的IPNS地址，该地址指向您网站最新版本的CID。</p><pre><code>//文件的地址const addr = &#39;/ipfs/QmbezGequPwcsWo8UL4wDF6a8hYwM1hmbzYv2mnKkEWaUp&#39;ipfs.name.publish(addr, function (err, res) {    // 接收到包含两个字段的资源：    //   - name: 被发布的内容的名字    //   - value: 名字指向的&quot;真实&quot;的地址    console.log(`https://gateway.ipfs.io/ipns/${res.name}`)})</code></pre><p>用这种方式，可以使用相同的地址重新发布一个新的版本到网页，默认情况下，<code>ipfs.name.publish</code>将会使用节点ID。</p>]]></content>
    
    
    <categories>
      
      <category>IPFS学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IPFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IPFS学习-哈希</title>
    <link href="undefined2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%93%88%E5%B8%8C/"/>
    <url>2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%93%88%E5%B8%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="Hashes"><a href="#Hashes" class="headerlink" title="Hashes"></a>Hashes</h1><p>哈希函数是接受一些任意输入并返回固定长度值的函数。具体值取决于所使用的给定哈希算法，例如<a href="https://en.wikipedia.org/wiki/SHA-1" target="_blank" rel="noopener">SHA-1</a>(GIT在使用),<a href="https://en.wikipedia.org/wiki/SHA-2" target="_blank" rel="noopener">SHA-256</a>,或者是<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)#BLAKE2" target="_blank" rel="noopener">BLAKE2</a>,但是给予一个输入使用哈希算法总是返回相同的输出。<br>例如：输入以下：</p><pre><code>Hello world</code></pre><p>使用<strong>SHA-1</strong>则会输出：</p><pre><code>0x7B502C3A1F48C8609AE212CDFB639DEE39673F5E</code></pre><p>然而相同的输入使用<strong>SHA-256</strong>将会输出以下：</p><pre><code>0x64EC88CA00B268E5BA1A35678A1B5316D212F4F366B2477232534A8AECA37F3C</code></pre><p>第二个哈希值长度要大于第一个，这是因为SHA-1创建一个160比特的哈希值，而SHA-256创建一个256比特的哈希值。同样，前置的<code>0x</code>只是一个指示符，告诉我们以下的哈希表示为基数16（或十六进制）的数字。<br>哈希可以用不同的基数表示（<code>base2</code>，<code>base16</code>，<code>base32</code>等）。 实际上，IPFS将此作为其<a href="https://ifican.top/2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%86%85%E5%AE%B9%E6%A0%87%E8%AF%86%E7%AC%A6CID/" target="_blank" rel="noopener">内容标识符</a>的一部分，并使用<a href="https://github.com/multiformats/multibase" target="_blank" rel="noopener">Multibase</a>协议同时支持多种基本表示形式。<br>例如，”Hello World”的SHA-256哈希值使用<code>base32</code>表示为：</p><pre><code>mtwirsqawjuoloq2gvtyug2tc3jbf5htm2zeo4rsknfiv3fdp46a</code></pre><h3 id="加密散列的特征"><a href="#加密散列的特征" class="headerlink" title="加密散列的特征"></a>加密散列的特征</h3><p>加密散列带有非常重要的特性：</p><ul><li>确定性-相同的输入消息总是返回相同的输出哈希。</li><li>不相关-消息中的微小变化应生成完全不同的哈希。</li><li>唯一性-从两条不同的消息生成相同的哈希是不可行的。</li><li>单向性-从其哈希值猜测或计算输入消息是不可行的。</li></ul><p>事实证明，这些功能还意味着我们可以使用加密哈希来识别任何数据：哈希对于我们从中计算出的数据是唯一的，并且它不会太长（哈希是固定长度的，因此SHA-256哈希是 1 GB的视频文件的大小仍然只有32个字节），因此通过网络发送它不会占用很多资源。</p><p>这对于像IPFS这样的分布式系统至关重要，在该系统中，我们希望能够从许多地方存储和检索数据。 运行IPFS的计算机可以询问与之连接的所有对等方，是否有一个带有特定哈希值的文件，如果其中一个具有特定的哈希值，则他们将整个文件发回。 没有短而独特的标识符（例如密码哈希），就不可能实现。 这项技术称为“内容寻址”-因为内容本身是用来形成地址的，而不是用于存储其所在计算机和磁盘位置的信息。</p>]]></content>
    
    
    <categories>
      
      <category>IPFS学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IPFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IPFS学习-DNS链接</title>
    <link href="undefined2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-DNS%E9%93%BE%E6%8E%A5/"/>
    <url>2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-DNS%E9%93%BE%E6%8E%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="DNSLink"><a href="#DNSLink" class="headerlink" title="DNSLink"></a>DNSLink</h1><h2 id="什么是DNS链接"><a href="#什么是DNS链接" class="headerlink" title="什么是DNS链接"></a>什么是DNS链接</h2><p>DNS链接使用<a href="https://en.wikipedia.org/wiki/TXT_record" target="_blank" rel="noopener">DNS TXT</a>记录映射域名(如<code>ipfs.io</code>)到一个IPFS地址。因为你可以编辑自己的DNS记录，可以使他们总是指向最新版本的IPFS中的对象(如果修改了IPFS中的对象则IPFS中的对象地址也会改变)。由于DNS链接使用DNS记录，所以可以设计名字/路径/(子)域/任何容易分类，阅读和记的名字。<br>一个DNS链接地址看起来像一个<a href="">IPNS</a>地址，但是DNS链接使用域名代替了被哈希的公钥:</p><pre><code>/ipns/myexampledomain.org</code></pre><p>就像普通的IPFS地址，可以包含链接到其他的文件-或者是其他类型的IPFS支持的资源，像目录和链接：</p><pre><code>/ipns/myexampledomain.org/media/</code></pre><h3 id="使用子域名发布"><a href="#使用子域名发布" class="headerlink" title="使用子域名发布"></a>使用子域名发布</h3><p>虽然您可以根据需要将TXT记录发布到确切的域，但是使用称为<code>_dnslink</code>的特殊子域来发布DNSLink记录会更有利。这使您可以提高自动设置的安全性，或将对DNSLink记录的控制权委派给第三方，而不必放弃对原始DNS区域的完全控制权。<br>例如，<code>docs.ipfs.io</code>没有含有TXT记录，但是页面仍然可以加载因为TXT记录在<code>_dnslink.docs.ipfs.io</code>中存在。如果查看<code>_dnslink.docs.ipfs.io</code>的DNS记录，可以看到以下DNSLink记录：</p><pre><code>$ dig +noall +answer TXT _dnslink.docs.ipfs.io_dnslink.docs.ipfs.io.  34  IN  TXT &quot;dnslink=/ipfs/QmVMxjouRQCA2QykL5Rc77DvjfaX6m8NL6RyHXRTaZ9iya&quot;</code></pre><h3 id="使用DNSLink解析"><a href="#使用DNSLink解析" class="headerlink" title="使用DNSLink解析"></a>使用DNSLink解析</h3><p>当一个IPFS客户端或者节点尝试解析一个地址，将会寻找前缀为<code>dnslink=</code>的TXT记录。剩下的可以是<code>/ipfs/</code>链接或者是<code>/ipns/</code>，或者是链接到其他的DNSLink。</p><pre><code>dnslink=/ipfs/&lt;具体内容的CID&gt;</code></pre><p>例如，回到之前<code>_dnslink.docs.ipfs.io</code>的DNS记录继续了解DNS链接实体：</p><pre><code>$ dig +noall +answer TXT _dnslink.docs.ipfs.io_dnslink.docs.ipfs.io.  34  IN  TXT &quot;dnslink=/ipfs/QmVMxjouRQCA2QykL5Rc77DvjfaX6m8NL6RyHXRTaZ9iya&quot;</code></pre><p>基于这个地址：</p><pre><code>/ipns/docs.ipfs.io/introduction/</code></pre><p>可以获取这个区块：</p><pre><code>/ipfs/QmVMxjouRQCA2QykL5Rc77DvjfaX6m8NL6RyHXRTaZ9iya/introduction/</code></pre>]]></content>
    
    
    <categories>
      
      <category>IPFS学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IPFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IPFS学习-内容标识符(CIDs)</title>
    <link href="undefined2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%86%85%E5%AE%B9%E6%A0%87%E8%AF%86%E7%AC%A6CID/"/>
    <url>2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%86%85%E5%AE%B9%E6%A0%87%E8%AF%86%E7%AC%A6CID/</url>
    
    <content type="html"><![CDATA[<h1 id="内容标识符-CIDs"><a href="#内容标识符-CIDs" class="headerlink" title="内容标识符(CIDs)"></a>内容标识符(CIDs)</h1><p>内容标识符也称为CID，是用于指向IPFS中材料的标签。 它不会指示内容的存储位置，但会根据内容本身形成一种地址。 CID简短，无论其基础内容的大小如何。</p><p>CID基于内容的<a href="http://localhost:1313/guides/concepts/hashes/" target="_blank" rel="noopener">加密哈希</a>，意思是：</p><ul><li>任何不相同的内容将会产生不同的CID</li><li>内容中相同的部分添加到两个不同的IPFS节点通过相同的设置应该产生相同的CID。</li></ul><h2 id="CID格式"><a href="#CID格式" class="headerlink" title="CID格式"></a>CID格式</h2><p>基于不同的编码或者是CID的版本使得CID具有不同的格式。多数存在的IPFS工具仍生成版本0的CID。但是<code>file</code>(<a href="http://localhost:1313/guides/concepts/mfs/" target="_blank" rel="noopener">MFS</a>)和<code>object</code>现在默认使用CID V1.</p><h3 id="版本0"><a href="#版本0" class="headerlink" title="版本0"></a>版本0</h3><p>当IPFS初始设计的时候，使用base58多次哈希作为内容标识符(虽然简单，但是与新的CID相比缺乏灵活性。)CIDv0仍然是许多IPFS默认选项，所以IPFS版本应该支持v0。</p><p>如果一个CID具有46字符并以<code>Qm</code>开头，说明是一个CIDv0</p><h3 id="版本1"><a href="#版本1" class="headerlink" title="版本1"></a>版本1</h3><p>CID v1包含一些前导标识符，这些标识符明确说明了使用哪种表示形式以及内容哈希本身。 这些包括：</p><ul><li><a href="https://github.com/multiformats/multibase" target="_blank" rel="noopener">multibase</a>前缀，指定用于其余CID的编码.</li><li>CID版本标识符，指示这是哪个CID版本</li><li>一个<a href="https://github.com/multiformats/multicodec" target="_blank" rel="noopener">多编解码器</a>标识符，指示目标内容的格式-帮助人们和软件在获取内容后知道如何解释该内容</li></ul><p>这些前导标识符还提供前向兼容性，支持在将来的CID版本中使用的不同格式。<br>您可以使用CID的前几个字节来解释内容地址的其余部分，并知道从IPFS提取内容后如何对其进行解码。 有关更多详细信息，请查看<a href="https://github.com/ipld/cid" target="_blank" rel="noopener">CID规范</a>。 它包括<a href="https://github.com/ipld/cid/blob/ef1b2002394b15b1e6c26c30545fd485f2c4c138/README.md#decoding-algorithm" target="_blank" rel="noopener">解码算法</a>，并链接到用于解码CID的现有软件实现。</p><h2 id="探索CID"><a href="#探索CID" class="headerlink" title="探索CID"></a>探索CID</h2><p>是否想分解特定CID的多库，多编解码器或多哈希信息？ 您可以使用IPLD资源管理器中的<a href="https://cid.ipfs.io/#QmY7Yh4UquoXHLPFo2XbhXkhBvFoPwmQUSa92pxnxjQuPU" target="_blank" rel="noopener">CID检查器</a>或<a href="https://explore.ipld.io/#/explore/QmY7Yh4UquoXHLPFo2XbhXkhBvFoPwmQUSa92pxnxjQuPU" target="_blank" rel="noopener">CID信息面板</a>（两个链接都使用示例CID启动）来对不同格式的CID进行交互式细分。 还了解IPFS中<a href="https://discuss.ipfs.io/t/who-decides-what-hashing-algorithms-ipfs-allows/6742" target="_blank" rel="noopener">CID的未来</a>。</p>]]></content>
    
    
    <categories>
      
      <category>IPFS学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IPFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>IPFS学习-分布式哈希表DHT</title>
    <link href="undefined2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%88%86%E5%B8%83%E5%BC%8F%E5%93%88%E5%B8%8C%E8%A1%A8DHT/"/>
    <url>2019/12/18/blog/ipfs/IPFS%E5%AD%A6%E4%B9%A0-%E5%88%86%E5%B8%83%E5%BC%8F%E5%93%88%E5%B8%8C%E8%A1%A8DHT/</url>
    
    <content type="html"><![CDATA[<h2 id="Distributed-Hash-Tables-DHT"><a href="#Distributed-Hash-Tables-DHT" class="headerlink" title="Distributed Hash Tables(DHT)"></a>Distributed Hash Tables(DHT)</h2><p><a href="https://en.wikipedia.org/wiki/Distributed_hash_table" target="_blank" rel="noopener">分布式哈希表</a>是一个分布式的键值对存储结构。在IPFS网络中，每一个节点都维护一个DHT的子集。当节点接受到一个请求。该节点要么直接回复，要么通过节点间传输直到找到可以回复该请求的节点。取决于实现方式，一个请求如果不能被第一个连接的节点回复</p><ul><li>进行节点间的转发，由最后一个节点联系收到请求的节点。</li><li>进行节点间的转发，回复结果按照相同的路径转发回到原节点。</li><li>由最优选择的节点对请求进行回复。</li></ul><p>IPFS使用这种策略。<br>DHT的去中心化提供了相比于传统的键值对存储更好的优势。包括：</p><ul><li>扩展性。对长度为n的哈希请求只需要最多为log<sub>2</sub>n步即可解决。</li><li>通过冗余进行错误容忍。即可能每一个节点都加入或离开DHT。另外，如果一个节点反应缓慢或者不可达，请求可以连接到其他节点。</li><li>负载均衡，请求可以发送到任何节点，没有任何一个节点处理所有的请求。</li></ul><h2 id="DHT如何工作"><a href="#DHT如何工作" class="headerlink" title="DHT如何工作"></a>DHT如何工作</h2><h3 id="Peer-IDs"><a href="#Peer-IDs" class="headerlink" title="Peer IDs"></a>Peer IDs</h3><p>每一个节点有有一个<code>peerID</code>，和DHT的键相同都是长度为n的哈希值。</p><h3 id="Buckets"><a href="#Buckets" class="headerlink" title="Buckets"></a>Buckets</h3><p>由每一个节点维护的DHT的子集被称为”桶“，一个桶映射的哈希值和节点ID具有相同的前缀。最多m个比特位。有2<sup>m</sup>个桶，每个桶则映射2<sup>n-m</sup>个哈希值。<br>例如，如果m=2^16，并且使用16进制数据，节点ID为<code>ABCDEF12345</code>，维护以<code>ABCD</code>为前缀的哈希值映射。桶内的哈希值则可能为<code>*ABCD*38E56,*ABCD*09CBA,*ABCD*17ABB</code>.</p><h3 id="节点列表"><a href="#节点列表" class="headerlink" title="节点列表"></a>节点列表</h3><p>节点之间保持连接到其他节点为了转发请求(当请求的哈希值不在当前节点的桶内)<br>如果哈希值长度为n，一个节点将保持连接n-1个列表节点。</p><ul><li>第一个列表维护第一个比特值不同的节点ID的节点。</li><li>第二个列表维护前一个比特值相同，第二个比特值不同的节点ID的节点。</li><li>第三个列表维护前两个比特值相同，第三个比特值不同的节点ID的节点。</li><li>…</li></ul><p>假设最高的是第m个列表，很难发现最多有m个比特值相同的节点ID的节点。“最接近”对等方的列表通常保持空白。此处的“最接近”定义为XOR距离，因此它们共享的前缀越长，它们就越接近。列表还具有最大的条目（k）-否则第一个列表将包含一半的网络，然后是网络的四分之一，依此类推。</p><h3 id="DHT使用"><a href="#DHT使用" class="headerlink" title="DHT使用"></a>DHT使用</h3><p>当节点接受到查询请求后，如果可以在自己的桶中找到答案则回复。否则联系最接近该节点的节点(IP+port,peerID,等等)回复。收到请求的节点尅将请求发送给最接近的节点。这个过程一直到可以回复请求的节点。一个哈希值长度为n的请求最多只需要log<sub>2</sub>n步，甚至是log2<sub>m</sub>n步。</p><h3 id="键和哈希值"><a href="#键和哈希值" class="headerlink" title="键和哈希值"></a>键和哈希值</h3><p>在IPFS的Kademili DHT，键使用SHA256哈希。<a href="https://docs.libp2p.io/concepts/peer-id/" target="_blank" rel="noopener">节点ID</a>使用由IPFS使用的网络库<a href="https://libp2p.io/" target="_blank" rel="noopener">libp2p</a>。<br>使用DHT查看两种类型的对象时，都由SHA256进行散列：</p><ul><li>添加到IPFS的数据的<a href="https://docs.ipfs.io/guides/concepts/cid/" target="_blank" rel="noopener">Content IDs</a>。查找该值将给出具有该不变内容的对等方的peerID。 </li><li><a href="https://docs.ipfs.io/guides/concepts/ipns/" target="_blank" rel="noopener">IPNS记录</a>。查找将给出与此IPNS地址关联的最后一个Content ID，从而启用可变内容的路由。</li></ul><p>所以，IPFS的DHT只是实现不可变与可变<a href="https://docs.libp2p.io/concepts/content-routing/" target="_blank" rel="noopener">内容路由</a>的一种方式.当前只是一种<a href="https://libp2p.io/implementations/#peer-routing" target="_blank" rel="noopener">实现</a>.</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="添加一条记录"><a href="#添加一条记录" class="headerlink" title="添加一条记录"></a>添加一条记录</h3><p>添加一个<code>blob</code>类型的数据到IPFS等同于广播它，由于DHT由内容路由实现。可以通过<code>ipfs add myData</code>自动打包数据挺添加内容ID和节点ID之间的映射到DHT。注意这里可能也被其他节点ID映射到该值，所以需要添加到列表中。如果提供的数据大于124KB，数据将会被打包成<code>blocks</code>，整个块将被映射。<br>可以通过使用<code>ipfs.name.publish</code>发布一个IPNS记录。</p>]]></content>
    
    
    <categories>
      
      <category>IPFS学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IPFS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CURL命令学习一</title>
    <link href="undefined2019/12/17/blog/other/CURL%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%E4%B8%80/"/>
    <url>2019/12/17/blog/other/CURL%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<p>每天学习一点点。。。。</p><ul><li>直接获取页面数据：</li></ul><pre><code>curl http://www.xxx.com/[可以指定具体的路径获取某个文件]</code></pre><h3 id="用户名-密码"><a href="#用户名-密码" class="headerlink" title="用户名(密码):"></a>用户名(密码):</h3><pre><code>curl -u username http://www.xxx.comcurl -u username:pwsswd http://www.xxx.comcurl http://name:passwd@xxx.domain/filepath/</code></pre><h3 id="下载页面数据："><a href="#下载页面数据：" class="headerlink" title="下载页面数据："></a>下载页面数据：</h3><pre><code>#以`demo.html`文件保存curl -o demo.html http://www.xxx.com/</code></pre><ul><li>下载某个页面数据保存到本地并以源页面名称为默认命名(可以指定多个页面)：</li></ul><pre><code>curl -O http://www.xxx.com/index.html/. [-O http://www.xxx2.com/html/]</code></pre><ul><li>代理 </li></ul><pre><code>curl -x proxy:port http://www.xxx.com/#如果代理需要名字和密码，用-U指定(-u)指定页面需要的用户名密码curl -U user:passwd -x proxy:port http://www.xxx.com/</code></pre><ul><li>获取部分数据</li></ul><pre><code>#获取前100比特数据curl -r 0-99 http://www.xxx.com/#获取最后100比特数据curl -r -100 http://www.xxx.com/</code></pre><h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><pre><code>#上传所有文件或者是从输入上传curl -T - ftp://ftp.upload.com/myfile#上传文件到远程服务器并使用本地文件名curl -T uploadfile ftp://ftp.upload.com/#上传文件并添加到远程文件中curl -T uploadfile -a ftp://ftp.upload.com/</code></pre><h3 id="打印日志信息"><a href="#打印日志信息" class="headerlink" title="打印日志信息"></a>打印日志信息</h3><pre><code>curl -v http://www.xxx.com#获取更多信息curl --trace http://www.xxx.com</code></pre><h3 id="POST方法"><a href="#POST方法" class="headerlink" title="POST方法"></a>POST方法</h3><pre><code>curl -d &quot;name=value&amp;name1=value1&quot; http://www.xxx.com/-F 从文件中读取curl -F &quot;coolfiles=@fill.gif;type=image/gif,fil2.txt,fil3.html&quot; http://www.xxx.com/curl -F ”file=@coottext.txt“ -F &quot;name=value&quot; -F &quot;name=value1 value2 ...&quot; htttp://www.xxx.com/curl -F &quot;pict=@dog.gif,cat.gif&quot; http://www.xxx.com/</code></pre><h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><pre><code>curl -A &#39;Mozilla/3.0 (Win95; I)&#39; http://www.xxx.com/</code></pre><h3 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h3><pre><code>curl -b &quot;name=value&quot; http://www.xxx.comcurl -c cookies.txt http://www.xxx.com#read writecurl -b cookies.txt -c cookies.txt http://www.xxx.com</code></pre><h3 id="额外的头部信息"><a href="#额外的头部信息" class="headerlink" title="额外的头部信息"></a>额外的头部信息</h3><pre><code>curl -H &quot;X-you-and-me: yes&quot; http://www.xxx.com</code></pre><h3 id="FTP-防火墙"><a href="#FTP-防火墙" class="headerlink" title="FTP 防火墙"></a>FTP 防火墙</h3><pre><code>#使用192.168.0.10作为IP地址curl -P 192.168.0.10 ftp.download.com</code></pre><h3 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h3><pre><code>curl -E /path/to/cert.pem:password https://www.xxx.com</code></pre><h3 id="文件续传"><a href="#文件续传" class="headerlink" title="文件续传"></a>文件续传</h3><pre><code>#downloadcurl -C - -o file ftp://ftp.server.com/path/file#uploadcurl -C - -T file ftp://ftp.server.com/path/file</code></pre><h3 id="L"><a href="#L" class="headerlink" title="-L"></a>-L</h3><p>如果页面内容移动到另一个页面比如返回状态码30X，则向新的页面发送请求</p><h3 id="s"><a href="#s" class="headerlink" title="-s"></a>-s</h3><p>静默模式，没有输出</p><h3 id="S"><a href="#S" class="headerlink" title="-S"></a>-S</h3><p>当使用<code>-s</code>时，输出错误信息。</p>]]></content>
    
    
    <categories>
      
      <category>curl</category>
      
    </categories>
    
    
    <tags>
      
      <tag>curl学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric-CA</title>
    <link href="undefined2019/12/08/blog/fabric/Hyperledger_Fabric_CA/"/>
    <url>2019/12/08/blog/fabric/Hyperledger_Fabric_CA/</url>
    
    <content type="html"><![CDATA[<p>Fabric—Ca的概念不再解释了，这里只说明使用方法:</p><h2 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h2><ul><li>Go语言1.10+版本</li><li>GOPATH环境变量正确设置</li><li>已安装<code>libtool</code>和<code>libtdhl-dev</code>包</li></ul><h4 id="Ubuntu系统"><a href="#Ubuntu系统" class="headerlink" title="Ubuntu系统"></a>Ubuntu系统</h4><p>通过以下命令安装<code>libtool</code>和<code>libtdhl-dev</code>包：</p><pre><code>sudo apt install libtool libltdl-dev</code></pre><h4 id="MacOs-系统"><a href="#MacOs-系统" class="headerlink" title="MacOs 系统"></a>MacOs 系统</h4><p>Mac系统通过以下命令安装：</p><pre><code>brew install libtool</code></pre><h2 id="Fabric-Ca安装"><a href="#Fabric-Ca安装" class="headerlink" title="Fabric-Ca安装"></a>Fabric-Ca安装</h2><p>可以通过以下两种途径进行安装：</p><ol><li>直接下载二进制文件：<pre><code>go get -u github.com/hyperledger/fabric-ca/cmd/...</code></pre>如果使用这种方式安装，安装成功的话直接在命令行输入(前提是GOPATH正确配置):<pre><code>fabric-ca-server version</code></pre>即可打印出安装的Ca版本。</li><li>从源码编译安装：<br>首先在系统中建立以下路径:<pre><code>mkdir -p $GOPATH/src/github.com/hyperledger/cd $GOPATH/src/github.com/hyperledger/</code></pre>从Github上面将Fabric-Ca仓库克隆到本地：<pre><code>git clone https://github.com/hyperledger/fabric-ca.gitcd fabric-ca</code></pre>进行源码编译：<pre><code>make fabric-ca-servermake fabric-ca-client</code></pre>如果没有报错的话，当前文件下会编译出一个<code>bin</code>文件夹，最后一步将该文件夹添加到环境变量，安装完成！</li></ol><h4 id="编译Ca的Docker镜像"><a href="#编译Ca的Docker镜像" class="headerlink" title="编译Ca的Docker镜像"></a>编译Ca的Docker镜像</h4><p>直接在<code>fabric-ca</code>文件夹内执行以下命令：</p><pre><code>make docker</code></pre><h2 id="Fabric-Ca服务器简单使用"><a href="#Fabric-Ca服务器简单使用" class="headerlink" title="Fabric-Ca服务器简单使用"></a>Fabric-Ca服务器简单使用</h2><hr><h3 id="设置Fabric-Ca服务器的Home文件夹"><a href="#设置Fabric-Ca服务器的Home文件夹" class="headerlink" title="设置Fabric Ca服务器的Home文件夹"></a>设置Fabric Ca服务器的<code>Home</code>文件夹</h3><p>启动Fabric Ca 服务器的第一步是需要对Fabric Ca服务器进行初始化操作，初始化操作将会生成一些默认的配置文件，所以我们首先需要指定一个文件夹作为服务器的主文件夹用来放生成的配置文件。<br>可以通过以下几种方式设置Fabric-Ca服务器的主文件夹，优先级由高到低排序：</p><ol><li>通过命令行设置参数<code>--home</code>设置。</li><li>如果设置了<code>FABRIC_CA_SERVER_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>FABRIC_CA_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>CA_CFG_PATH</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果以上方法都没有设置，则将当前工作目录作为主文件夹。</li></ol><p>官方建议是通过设置<code>FABRIC_CA_HOME</code>为<code>$HOME/fabric-ca/server</code>作为服务器的主文件夹。</p><h3 id="初始化服务器"><a href="#初始化服务器" class="headerlink" title="初始化服务器"></a>初始化服务器</h3><p>上一步骤完成后，就可以对Fabric Ca进行初始化了，执行以下命令：</p><pre><code>fabric-ca-server init -b admin:adminpw</code></pre><p>通过<code>-b</code>参数指定管理员的账号和密码对服务器进行初始化。将会生成一个自签名的证书。</p><ul><li>admin:相当于管理员账号</li><li>adminpw:相当于管理员密码</li></ul><p><code>admin:adminpw</code>可以自行设置。<br>或者服务器的初始化也可以通过<code>-u</code>参数指定服务器的上一级服务器，也就是父服务器。格式为:<code>-u &lt;parent-fabric-ca-server-URL</code>,其中这里的<code>URL</code>必须使用<code>&lt;协议&gt;://&lt;enrollmentId&gt;:&lt;secret&gt;@&lt;host&gt;:&lt;port&gt;</code>的格式。<br>初始化之后将会生成几个文件：</p><pre><code>IssuerPublicKey      #与零知识证明相关文件，暂不解释IssuerRevocationPublicKey #与零知识证明相关文件，暂不解释ca-cert.pem             #CA服务器的根证书文件,只有持有该证书，用户才可以进行证书的颁发fabric-ca-server-config.yaml   #默认配置文件,对Ca服务器进行配置时可以用到fabric-ca-server.db  #Ca服务器数据库，存储注册的用户，组织，证书等信息。可以通过sqlite3 命令进去查看msp/</code></pre><h3 id="启动服务器"><a href="#启动服务器" class="headerlink" title="启动服务器"></a>启动服务器</h3><p>初始化之后可以直接启动服务器：</p><pre><code>fabric-ca-server start -b &lt;admin&gt;:&lt;adminpw&gt;</code></pre><p>服务器将会监听在7054端口。如果需要服务器监听在<code>https</code>上而不是<code>http</code>上，需要将<code>tls.enabled</code>设置为<code>true</code>。</p><p>启动完之后，即可以通过<code>fabric-ca-client</code>工具或者是SDK对Ca服务器进行操作了。</p><h2 id="Fabric-Ca-客户端"><a href="#Fabric-Ca-客户端" class="headerlink" title="Fabric Ca 客户端"></a>Fabric Ca 客户端</h2><p>这一部分说明命令行工具<code>fabric-ca-client</code>的简单使用。</p><h3 id="设置Fabric-Ca客户端的Home文件夹"><a href="#设置Fabric-Ca客户端的Home文件夹" class="headerlink" title="设置Fabric Ca客户端的Home文件夹"></a>设置Fabric Ca客户端的<code>Home</code>文件夹</h3><p>与服务器相同，客户端也具有自己的主文件夹，用来保存客户端的证书秘钥等等。<br>可以通过以下几种方式设置Fabric-Ca客户端的主文件夹，优先级由高到低排序：</p><ol><li>通过命令行设置参数<code>--home</code>设置。</li><li>如果设置了<code>FABRIC_CA_CLIENT_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>FABRIC_CA_HOME</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果设置了<code>CA_CFG_PATH</code>环境变量,则使用该环境变量作为主文件夹。</li><li>如果以上方法都没有设置，则<code>$HOME/.fabric-ca-client</code>将作为主文件夹。</li></ol><p>官方例子：<code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/admin</code></p><h3 id="用户登陆"><a href="#用户登陆" class="headerlink" title="用户登陆"></a>用户登陆</h3><p>设置完之后，我们使用命令行工具登陆管理员用户:</p><pre><code>fabric-ca-client enroll -u http://admin:adminpw@localhost:7054</code></pre><p>在<code>admin</code>目录下会产生以下文件：</p><pre><code>.├── fabric-ca-client-config.yaml└── msp    ├── IssuerPublicKey    ├── IssuerRevocationPublicKey    ├── cacerts    │   └── localhost-7054.pem     #CA服务器的根证书，只不过换了一个名字    ├── keystore    │   └── 7ec84cbc25c20600ba98bf2bafb9c695ad57e392a57fb9f33b51fc493601a432_sk  #当前用户的秘钥信息    ├── signcerts    │   └── cert.pem   #当前用户的证书    └── user</code></pre><h3 id="注册一个身份"><a href="#注册一个身份" class="headerlink" title="注册一个身份"></a>注册一个身份</h3><p>通过<code>Fabric-CA</code>注册新的身份时，将由<code>Fabric-CA</code>服务器进行三个部分的权限检查确定当前用户是否具有权限进行身份的注册。</p><ol><li>注册者必须含有<code>hf.Registrar.Roles</code>属性，并且需要注册的身份类型必须在该属性对应的值的列表中存在。比如注册者的<code>hf.Registrar.Roles</code>属性中对应的值只有一个<code>peer</code>，那么注册者使能注册类型为<code>peer</code>的身份，而不能注册<code>client</code>,<code>admin</code>,<code>orderer</code>.如果注册者的<code>hf.Registrar.Roles</code>属性对应的值为<code>*</code>，则说明可以注册任何类型的身份。</li><li>简单说就是上下级关系，比如注册者所处的部门为<code>a.b</code>,那么他只能注册处于<code>a.b</code>以及<code>a.b.*</code>部门的身份，而不能注册处于<code>a.c</code>部门的身份。如果需要注册一个最上级的部门的身份，那么需要将需要将需要注册的身份的<code>hf.affiliation</code>指定为<code>.</code>，并且注册者所处的部门也需要是最上级的部门。如果在注册身份时没有指定所属的部门，则默认被注册的身份所处的部门与注册者部门相同。</li><li>如果注册者满足以下条件则可以注册带有属性的身份：<ul><li>对于<code>Fabric CA</code>中的保留属性(前缀以<code>hf</code>开头的)：只有注册者具有这个属性并且是<code>hf.Registrar.Attributes</code>属性中的值得一部分。也就是说如果需要注册一个带有<code>hf.a</code>属性的身份，那么注册者自己也需要有这个属性，并且在注册者的<code>hf.Registrar.Attributes</code>属性对应的值中需要包含<code>hf.a</code>这个属性。并且<code>hf.a</code>这个属性的值是一个列表，那么被注册的身份具有的<code>hf.a</code>属性只能等于或者等于列表中的一个子集。另外，如果<code>hf.a</code>这个属性的值对应的是一个布尔值，那么需要注册者<code>hf.a</code>属性的值为<code>true</code>。</li><li>对于注册者自定义的属性(不是<code>Fabric Ca</code>中的保留属性)：注册者<code>hf.Registrar.Attributes</code>对应的值需要包括这个属性，或者是已经注册过的模式。唯一支持的模式是以<code>*</code>结尾的字符串。比如注册者<code>hf.Registar.Attributes</code>对应的值为<code>a.b.*</code>，那么他可以注册的属性需要以<code>a.b.</code>开头。如果注册者<code>hf.Registar.Attributes</code>对应的值为<code>orgAdmin</code>,那么注册者只可以对一个身份进行添加或者删除<code>orgAdmin</code>属性.</li><li>对于<code>hr.Registrar.Attributes</code>属性：一个额外的检查是该属性对应的值需要等于注册者具有的该属性对应的值，或者是注册者具有的该属性对应的值的子集。</li></ul></li></ol><p>接下来使用<code>admin</code>的身份注册一个身份：</p><ul><li><code>enrollment id</code>为<code>admin2</code></li><li>部门为<code>org1.department1</code></li><li>属性名字为<code>hf.Revoker</code>,对应的值为<code>true</code></li><li>属性名字为<code>admin</code>,对应的值为<code>true</code></li></ul><pre><code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/adminfabric-ca-client register \    --id.name admin2     \    --id.affiliation org1.department1 \    --id.attrs &#39;hf.Revoker=true,admin=true:ecert&#39;</code></pre><p>其中对于属性<code>admin=true</code>,后缀为<code>ecert</code>表示这条属性将会添加到证书中，可以用来进行做访问控制的决定。</p><p>对于多个属性，可以使用<code>--id.attrs</code>参数标记，并使用单引号括起来，每个属性使用逗号分隔开：</p><pre><code>fabric-ca-client register -d \    --id.name admin2 \    --id.affiliation org1.department1 \    --id.attrs &#39;&quot;hf.Registrar.Roles=peer,client&quot;,hf.Revoker=true&#39;</code></pre><p>或者是：</p><pre><code>fabric-ca-client register -d \    --id.name admin2  \    --id.affiliation org1.department1 \    --id.attrs &#39;&quot;hf.Registrar.Roles=peer,client&quot;&#39; \    --id.attrs hf.Revoker=true</code></pre><p>或者是通过客户端配置文件<code>fabric-ca-client-config.yaml</code>：</p><pre><code>id:  name:  type: client  affiliation: org1.department1  maxenrollments: -1  attributes:    - name: hf.Revoker      value: true    - name: anotherAttrName      value: anotherAttrValue</code></pre><p>接下来的命令是通过以上的配置文件注册一个身份：</p><ul><li><code>enrollment id</code>为<code>admin3</code></li><li>身份类型为<code>client</code></li><li>部门为<code>org1.department1</code></li><li>属性名字为<code>hf.Revoker</code>,对应的值为<code>true</code></li><li>属性名字为<code>anotherAttrName</code>,对应的值为<code>anotherAttrValue</code></li></ul><p>设置<code>maxenrollments</code>为0或者是不设置将导致该身份可以使用<code>CA</code>的最大<code>enrollment</code>次数。并且一个身份的<code>maxenrollments</code>不能超过<code>CA</code>的<code>enrollments</code>最大值。例如，如果<code>CA</code>的<code>enrollment</code>最大值为5，则任何新的身份必须含有一个小于等于5的值。并且也不能设置为<code>-1</code>(-1表示无限制).</p><p>接下来注册一个<code>peer</code>类型的身份。在这里我们选择自定义的密码而不是由服务器自动生成：</p><pre><code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/adminfabric-ca-client register \    --id.name peer1 \    --id.type peer \    --id.affiliation org1.department1 \    --id.secret peer1pw</code></pre><p>注意，部门信息区分大小写，但服务器配置文件中指定的<strong>非叶子</strong>部门关系始终以小写形式存储。 例如，如果服务器配置文件的部门关系部分如下所示：</p><pre><code>affiliations:  BU1:    Department1:      - Team1  BU2:    - Department2    - Department3</code></pre><p><code>BU1</code>,<code>Department1</code>,<code>BU2</code>使用小写进行存储。这是因为<code>Fabric CA</code>使用<code>Viper</code>读取配置。<code>Viper</code>对于大小写不敏感，如果需要注册一个身份部门为<code>Team1</code>,则需要通过<code>--id.affiliation</code>参数这样配置：<code>bu1.department1.Team1</code></p><pre><code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/adminfabric-ca-client register \    --id.name client1 \    --id.type client \    --id.affiliation bu1.department1.Team1</code></pre><h3 id="登录一个peer身份的用户"><a href="#登录一个peer身份的用户" class="headerlink" title="登录一个peer身份的用户"></a>登录一个<code>peer</code>身份的用户</h3><p>之前已经成功注册了一个<code>peer</code>身份的用户，可以通过指定<code>id</code>和<code>secret</code>进行登录，与之前不同的是需要通过<code>-M</code>参数指定<code>Hyperledger Fabric MSP</code>(成员关系服务提供者)文件夹结构。</p><p>接下来的命令将会登录<code>peer1</code>,确保使用<code>-M</code>参数指定了<code>peer</code>的MSP文件夹路径，该路径也是<code>peer</code>的<code>core.yaml</code>文件内<code>mspConfigPath</code>参数的设置值。或者也可以通过环境变量<code>FABRIC_CA_CLIENT_HOME</code>指定<code>peer</code>的主目录。</p><pre><code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/peer1fabric-ca-client enroll \    -u http://peer1:peer1pw@localhost:7054 \    -M $FABRIC_CA_CLIENT_HOME/msp</code></pre><p>登录一个<code>orderer</code>也是相同的，除了<code>MSP</code>文件夹是在<code>orderer</code>的<code>orderer.yaml</code>文件中通过参数<code>LocalMSPDir</code>进行设置。</p><p>由<code>fabric-ca-server</code>颁发的所有注册证书均具有以下组织单位（或简称为“ OU”）：</p><ol><li>OU层次结构的根等于身份类型。</li><li>OU被添加到身份部门关系的每个组成部分。</li></ol><p>例如，如果一个身份类型为<code>peer</code>,部门为<code>department.team1</code>,则身份的OU分层(从根部开始)：<code>OU=team1,OU=department1,OU=peer</code>.</p><h3 id="获取身份混合器证书"><a href="#获取身份混合器证书" class="headerlink" title="获取身份混合器证书"></a>获取身份混合器证书</h3><p>…</p><h3 id="获取身份混合器证书撤销信息"><a href="#获取身份混合器证书撤销信息" class="headerlink" title="获取身份混合器证书撤销信息"></a>获取身份混合器证书撤销信息</h3><h3 id="重新登录一个身份"><a href="#重新登录一个身份" class="headerlink" title="重新登录一个身份"></a>重新登录一个身份</h3><p>假如你的登录证书过期了或者被恶意操作，需要通过以下命令重新创建一个登录证书：</p><pre><code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/peer1fabric-ca-client reenroll</code></pre><h3 id="撤销一个证书或者身份"><a href="#撤销一个证书或者身份" class="headerlink" title="撤销一个证书或者身份"></a>撤销一个证书或者身份</h3><p>身份或者证书是可以被撤销的。撤销一个身份将会撤销所有属于这个身份的证书同时也会阻止该身份去获取新的证书。撤销一个证书只会使单个证书无效。</p><p>为了撤销一个证书或者是身份。撤销者必须含有<code>hf.Revoker</code>和<code>hf.Registrar.Roles</code>两个属性。撤销一个身份只可以撤销从属于自己下级或者相同级别部门的证书或者是身份。进一步，撤销者只能撤销在撤销者<code>hf.Registrar.Roles</code>属性列表中存在的身份类型的身份。</p><p>例如，部门为<code>orgs.org1</code>并且<code>hf.Registrar.Roles=peer,client</code>的撤销者可以撤销从属于<code>orgs.org1</code>部门或者是<code>orgs.org1.department1</code>并且身份类型为<code>peer</code>或者是<code>client</code>的身份。不能撤销从属于<code>orgs.org2</code>部门或者是其他类型的身份。</p><p>下面的命令将会使一个身份与该身份下的所有证书失效，该身份未来对<code>fabric CA</code>服务器的所有请求将会被拒绝。</p><pre><code>fabric-ca-client revoke -e &lt;enrollment_id&gt; -r &lt;reason&gt;</code></pre><p>下面是<code>-r</code>参数支持的具体的原因：</p><ol><li>unspecified</li><li>keycompromise</li><li>cacompromise</li><li>affiliationchange</li><li>superseded</li><li>cessationofoperation</li><li>certificatehold</li><li>removefromcrl</li><li>privilegewithdrawn</li><li>aacompromise</li></ol><p>例如，引导启动的<code>admin</code>属于部门的最上级可以撤销<code>peer1</code>的身份信息：</p><pre><code>export FABRIC_CA_CLIENT_HOME=$HOME/fabric-ca/clients/adminfabric-ca-client revoke -e peer1</code></pre><p>属于一个身份的登录证书可以通过具体的AKI(权限密钥标识符)和序列号进行撤销：</p><pre><code>fabric-ca-client revoke -a xxx -s yyy -r &lt;reason&gt;</code></pre><p>例如，可以通过使用<code>openssl</code>命令获取一个证书的AKI和序列号并通过<code>revoke</code>命令撤销证书：</p><pre><code>serial=$(openssl x509 -in userecert.pem -serial -noout | cut -d &quot;=&quot; -f 2)aki=$(openssl x509 -in userecert.pem -text | awk &#39;/keyid/ {gsub(/ *keyid:|:/,&quot;&quot;,$1);print tolower($0)}&#39;)fabric-ca-client revoke -s $serial -a $aki -r affiliationchange</code></pre><p><code>--gencrl</code>参数可以用来生成<code>CRL</code>(证书撤销列表)，<code>CRL</code>包含所有被撤销的证书。例如，以下命令可以撤销<code>peer1</code>的身份。生成一个<code>CRL</code>并存储到<code>&lt;msp 文件夹&gt;/crls/crl.pem</code>文件。</p><pre><code>fabric-ca-client revoke -e peer1 --gencrl</code></pre><p><code>CRL</code>可以使用<code>gencrl</code>命令生成，参考<a href="">生成CRL</a>部分获取关于<code>gencrl</code>命令的更多信息。</p><h3 id="生成CRL-证书撤销列表"><a href="#生成CRL-证书撤销列表" class="headerlink" title="生成CRL(证书撤销列表)"></a>生成CRL(证书撤销列表)</h3><p>通过<code>Fabric CA SERVER</code>撤销一个证书后，在<code>Hyperledger Fabric</code>中合适的<code>MSP</code>文件需要进行更新。包括本地的<code>peer</code>节点的<code>MSP</code>与合适的通道配置区块中的<code>MSP</code>.为了做到这一点，<code>PEM</code>编码的<code>CRL</code>需要放置到<code>MSP</code>文件夹内的<code>crls</code>文件夹。<code>fabric-ca-client gencrl</code>命令可以生成<code>CRL</code>。任何带有<code>hf.GenCRL</code>属性的身份都可以生成包含所有在一个确定的时间被撤销的证书的序列号的<code>CRL</code>。生成的<code>CRL</code>存储在<code>&lt;msp 文件夹&gt;/crls/crl.pem</code>文件。</p><p>以下的命令将会创建包含所有被撤销的(超时和未超时)证书的<code>CRL</code>存储在<code>&lt;msp 文件夹&gt;/crls/crl.pem</code>文件。</p><pre><code>export FABRIC_CA_CLIENT_HOME=~/clientconfigfabric-ca-client gencrl -M ~/msp</code></pre><p>…</p><h3 id="开启TLS"><a href="#开启TLS" class="headerlink" title="开启TLS"></a>开启TLS</h3><p>这一部分描述如何为<code>Fabric CA</code>客户端配置TLS的更多细节。</p><p>以下部分可以在<code>fabric-ca-client-config.yaml</code>文件中进行配置：</p><pre><code>tls:  enabled: true  certfiles:    - root.pem  client:    certfile: tls_client-cert.pem    keyfile: tls_client-key.pem</code></pre><p><code>certfiles</code>选项设置为被客户端信任的根证书。典型的就是<code>Fabric CA</code>根服务器的证书，<code>ca-cert.pem</code>可以在服务器的主目录发现.</p><p><code>client</code>选项要求只能手动在服务器进行TLS配置。</p><h3 id="基于属性的访问控制"><a href="#基于属性的访问控制" class="headerlink" title="基于属性的访问控制"></a>基于属性的访问控制</h3><p>…未完待续</p>]]></content>
    
    
    <categories>
      
      <category>fabric-ca应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric-ca</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric动态添加组织到网络中</title>
    <link href="undefined2019/12/08/blog/fabric/Hyperledger_Fabric%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0%E7%BB%84%E7%BB%87%E5%88%B0%E7%BD%91%E7%BB%9C%E4%B8%AD/"/>
    <url>2019/12/08/blog/fabric/Hyperledger_Fabric%E5%8A%A8%E6%80%81%E6%B7%BB%E5%8A%A0%E7%BB%84%E7%BB%87%E5%88%B0%E7%BD%91%E7%BB%9C%E4%B8%AD/</url>
    
    <content type="html"><![CDATA[<p>本文基于Hyperledger Fabric <strong>1.4</strong>版本。<br>官方文档地址:<a href="https://hyperledger-fabric.readthedocs.io/en/release-1.4/channel_update_tutorial.html" target="_blank" rel="noopener">传送门</a></p><p>动态添加一个组织到Fabric网络中也是一个比较重要的功能。官方文档写的已经很详细了，有能力的尽量还是看官方文档，本文只是根据官方文档进行整理同时兼翻译。</p><h2 id="1-前提条件"><a href="#1-前提条件" class="headerlink" title="1.前提条件"></a>1.前提条件</h2><hr><p>这个不再解释了，前提条件自然是搭建Fabric的环境了并跑通官方的例子，具体的看<a href="https://ifican.top/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">这里</a>.</p><h2 id="2-启动网络"><a href="#2-启动网络" class="headerlink" title="2.启动网络"></a>2.启动网络</h2><hr><p>还是以官方的<code>byfn</code>为例好了，不多说，对Fabric有一定了解的都能明白，不明白的看上面文档:</p><pre><code>./byfn.sh up#或者是./byfn.sh up -s couchdb#区别不大，只不过换了一个数据库而已，对本文内容没多少关系</code></pre><p>动态添加组织官方脚本自动化操作就简单执行以下命令：</p><pre><code>./eyfn.sh up</code></pre><p>本文重点不在这里，因为自动化操作省略了所有的内容，固然简单，但是仍然不懂其中过程。所以本文的重点还是下一部分，手动地一步一步完成动态增加组织。</p><h2 id="3手动添加组织到网络中"><a href="#3手动添加组织到网络中" class="headerlink" title="3手动添加组织到网络中"></a>3手动添加组织到网络中</h2><p><code>byfn</code>网络中的节点为:</p><ul><li>Order -&gt; orderer.example.com</li><li>Org1  -&gt; peer0.org1.example.com</li><li>Org1  -&gt; peer1.org1.example.com</li><li>Org2  -&gt; peer0.org2.example.com</li><li>Org2  -&gt; peer1.org2.example.com</li></ul><p>而我们要添加的为:</p><ul><li>Org3  -&gt; peer0.org3.example.com</li><li>Org3  -&gt; peer1.org3.example.com</li></ul><p><strong>在这里，我们假设工作目录在<code>$GOPATH/.../fabric-samples/first-network</code>文件夹。上面的五个节点也通过</strong></p><pre><code>./byfn.sh up</code></pre><p><strong>命令成功启动。</strong><br>Fabric网络的启动过程总的来说没有几步(锚节点那部分先省略掉，对本文没有影响)：</p><ol><li>为每一个节点生成证书文件</li><li>生成系统通道的创世区块(也是配置文件)</li><li>生成通道配置文件</li><li>启动节点</li><li>根据通道配置文件创建通道生成应用通道创世区块</li><li>加入通道</li><li>…</li></ol><p>根据这个流程来考虑动态增加节点：</p><ul><li>首先为每一个节点生成证书文件是肯定要做的。</li><li>第二步生成创世区块(系统通道配置文件)是不需要的</li><li>第三步生成应用通道配置文件需要变为更新应用通道配置文件</li><li>第四步启动节点步骤不变</li><li>第五步创建通道也不需要了，直接到第六步加入通道</li><li>…(网络启动之后的步骤最后再说)</li></ul><p>既然分析完了，我们只要按照步骤完成就可以了。</p><h3 id="3-1生成证书文件"><a href="#3-1生成证书文件" class="headerlink" title="3.1生成证书文件"></a>3.1生成证书文件</h3><p>怎么生成证书文件呢，这个直接使用官方的文件就可以了，当然有定制化需求的请自行修改。文件在工作目录下的<code>org3-artifacts</code>文件夹下的<code>org3-crypto.yaml</code>文件。<br>这一步比较简单，直接执行命令行工具就可以了，当然对<code>Fabric CA</code>比较熟悉的也可以采用手动生成证书的方法，本文为了简便，直接使用工具生成：</p><pre><code>cd org3-artifactscryptogen generate --config=./org3-crypto.yaml</code></pre><p>完成之后在<code>org3-artifacts</code>目录下生成一个<code>crypto-config</code>文件夹。里面就是需要添加的新组织的证书文件。<br>如果网络开启<code>TLS</code>的话，在多机环境下还需要将<code>Orderer</code>的<code>TLS</code>根证书拷贝一份过来用于之后的与<code>Orderer</code>节点进行通信,而单机环境下也可以直接将<code>Orderer</code>的<code>TLS</code>根证书挂载到之后需要启动的<code>Org3</code>的容器内部。而本文采用和官方文档相同的方法，直接拷贝文件：</p><pre><code>cd ../ &amp;&amp; cp -r crypto-config/ordererOrganizations org3-artifacts/crypto-config/</code></pre><h3 id="3-2更新通道配置文件"><a href="#3-2更新通道配置文件" class="headerlink" title="3.2更新通道配置文件"></a>3.2更新通道配置文件</h3><p>接下来第三步：更新通道配置文件，可以分为以下步骤：</p><ol><li>获取网络中当前通道之前最新的配置区块</li><li>把需要更新的内容添加进去</li><li>把最新的配置文件更新到网络中</li></ol><h4 id="3-2-1获取最新的配置区块"><a href="#3-2-1获取最新的配置区块" class="headerlink" title="3.2.1获取最新的配置区块"></a>3.2.1获取最新的配置区块</h4><p>看一下第一步获取网络中之前最新的配置区块，如何获取呢，自然是通过网络中现有的节点进行获取，并且使从<code>peer</code>节点向<code>Orderer</code>节点发起通信获取配置区块。<br>首先进入<code>cli</code>容器：</p><pre><code>docker exec -it cli bash</code></pre><p>配置需要的环境变量:</p><pre><code>export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem export CHANNEL_NAME=mychannel</code></pre><p><strong>如果操作中途退出了<code>cli</code>容器，那么再次进入时都需要重新配置环境变量.</strong><br>接下来获取之前最新的配置区块：</p><pre><code>peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA</code></pre><ul><li><code>peer channel fetch</code>: 从指定的通道获取具体的区块并写入文件。</li><li><code>config</code> :指定获取的区块是配置区块.(Fabric网络中区块类型可分为普通交易区块和配置区块)</li><li><code>config_block.pb</code>:将配置区块写入到这个文件中</li><li><code>-o</code>:指定向具体的排序节点发起通信</li><li><code>-c</code>:指定通道名称</li><li><code>--tls</code>:如果开启了<code>TLS</code>则需要指定这个参数</li><li><code>--cafile</code>:<code>TLS</code>根证书文件</li></ul><p>执行完毕后命令行会打印这些信息：</p><pre><code> UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized UTC [cli.common] readBlock -&gt; INFO 002 Received block: 4 UTC [cli.common] readBlock -&gt; INFO 003 Received block: 2 UTC [channelCmd] fetch -&gt; INFO 004 Retrieving last config block: 2</code></pre><p>可以看到<code>mychannel</code>通道中共生成了5个区块(创世区块序号为0).但是最新的配置区块序号为2:</p><ol><li>配置区块0：创世区块</li><li>配置区块1：组织一的锚节点更新</li><li>配置区块2：组织二的锚节点更新</li><li>普通区块3：实例化链码</li><li>普通区块4：调用链码</li></ol><p>而本文获取到了最新的配置区块也是是区块2，并将该区块写入到了<code>config_block.pb</code>文件中。</p><h4 id="3-2-2将配置信息添加到配置文件中"><a href="#3-2-2将配置信息添加到配置文件中" class="headerlink" title="3.2.2将配置信息添加到配置文件中"></a>3.2.2将配置信息添加到配置文件中</h4><p>我们已经获取到了最新的配置文件，接下来如何更新它呢，因为区块内容是编码过的，而且还包括区块头，元数据以及签名等信息，对更新配置是用不到的。所以需要先将区块进行解码成我们可读的文件，而且为了简单化，可以将不相关的区块头等信息去掉(当然不去掉也没有问题)。<br>这里用到了两个工具：Fabric官方的命令行工具<code>configtxlator</code>，以及<code>jq</code>工具:<br><code>configtxlator</code>工具可以帮助我们进行编解码转换<br><code>jq</code>工具和<code>Linux</code>中的<code>grep</code>,<code>awk</code>命令较为相似，都是对数据进行处理的(当然不使用这个工具也没什么问题，只不过需要手动修改数据而已)。<br>接下来就是将区块信息解码去除不相关的信息后并以<code>json</code>格式保存到文件中：</p><pre><code>configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.json</code></pre><ul><li><code>proto_decode</code> :解码操作</li><li><code>--input</code>:需要解码的文件作为输入</li><li><code>--type</code>:输入文件的类型</li></ul><p>解码后通过<code>jq</code>工具提取需要的数据并保存到了<code>config.json</code>文件中。</p><p>接下来呢，就是将组织三的配置信息写到这里面，组织三的配置信息呢？我们还没有生成它，之前只是为组织三生成了证书文件。所以我们还需要生成组织三的配置信息。<br>同样的，用于生成配置信息的源文件官方也给了，在工作目录下的<code>org3-artifacts</code>文件夹下的<code>configtx.yaml</code>文件。<br>因为上一步我们将通道内的最新的配置文件转换为了<code>json</code>格式，所以这里我们也需要将这个文件内的配置信息转换为<code>json</code>格式：</p><pre><code>#打开新的终端进入以下目录中cd $GOPATH/.../fabric-samples/first-network/org3-argifacts/#指定配置文件所在路径 或者是通过-configPath路径指定export FABRIC_CFG_PATH=$PWD #直接通过工具将配置信息写到org3.json文件中。configtxgen -printOrg Org3MSP &gt; ../channel-artifacts/org3.json</code></pre><p>现在让我们回到之前的终端继续操作，将刚刚生成的<code>org3.json</code>文件添加到<code>config.json</code>文件中，通过<code>jq</code>工具：</p><pre><code>jq -s &#39;.[0] * {&quot;channel_group&quot;:{&quot;groups&quot;:{&quot;Application&quot;:{&quot;groups&quot;: {&quot;Org3MSP&quot;:.[1]}}}}}&#39; config.json ./channel-artifacts/org3.json &gt; modified_config.json</code></pre><p>这一行命令就是将<code>org3.json</code>这个文件添加到<code>config.json</code>文件的<code>channel_group-&gt;groups-&gt;Application-&gt;groups-&gt;Org3MSP</code>下，并保存到<code>modified_config.json</code>文件。<br>接下来就是获取原始配置文件和新的配置文件的不同点了,官方文档的意思是只保留组织3的定义以及一个指向组织1与组织2的高级指针，因为没有必要连同之前的配置文件一起更新，所以只需要一个指针指向原配置(个人理解)。<br>具体的操作方法是将上面两个<code>json</code>文件编码回去，然后使用<code>configtxlator</code>工具进行比较更新。<br>操作命令：</p><ul><li><p><code>config.json</code>文件,编码后输出到<code>config.pb</code>文件。</p><pre><code>configtxlator proto_encode --input config.json --type common.Config --output config.pb</code></pre></li><li><p><code>modified_config.json</code>文件，编码后输出到<code>modified_config.pb</code>文件。</p><pre><code>configtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pb</code></pre></li><li><p>计算两个文件的差异并输出到<code>org3_update.pb</code>文件：</p><pre><code># --original 指定原配置文件   --updated 指定新配置文件configtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated modified_config.pb --output org3_update.pb</code></pre><p>接下来还需要做一件事，就是封装一个更新配置的文件，将<code>org3_update.pb</code>写进去，毕竟向Fabric添加组织需要更新Fabric的配置，自然是需要将配置文件按照Fabric规定的文件类型封装好才能更新网络。<br>然后封装配置信息又会涉及到一些额外的信息，说简单点就是Fabric规定的文件类型的标识符之类的，所以需要我们再次解码，然后添加这些额外的信息进去：</p><pre><code>configtxlator proto_decode --input org3_update.pb --type common.ConfigUpdate | jq . &gt; org3_update.json</code></pre><p>添加额外的数据：</p><pre><code>echo &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;mychannel&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat org3_update.json)&#39;}}}&#39; | jq . &gt; org3_update_in_envelope.json</code></pre><p>到最后一步配置更新消息就完成了，那就是将文件以特定的文件类型封装起来：</p><pre><code>configtxlator proto_encode --input org3_update_in_envelope.json --type common.Envelope --output org3_update_in_envelope.pb</code></pre><h4 id="3-2-3更新应用通道配置文件"><a href="#3-2-3更新应用通道配置文件" class="headerlink" title="3.2.3更新应用通道配置文件"></a>3.2.3更新应用通道配置文件</h4><p>配置更新消息已经处理好了，接下来就是更新到网络中了。在此时，新添加的组织信息还没有更新进去，所以还是需要使用之前的组织将配置进行更新，首先就是需要带有<code>Admin</code>身份的多数节点进行签名(策略这块以后再讲)，所以需要每个组织中各一个节点进行签名，首先是<code>peer0.org1</code>,由于之前打开的<code>cli</code>容器默认身份就是<code>peer0.org1</code>，所以不需要配置环境变量直接进行签名：</p><pre><code>peer channel signconfigtx -f org3_update_in_envelope.pb</code></pre><p>接下来是组织二的节点：</p><pre><code>export CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:9051</code></pre><p>实际上我们只需要进行配置文件更新就行了，因为在配置更新操作中如果没有签名默认会先进行签名的:</p><pre><code>peer channel update -f org3_update_in_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA</code></pre><p>如果命令行日志打印出一下内容说明更新通道配置成功：</p><pre><code>UTC [channelCmd] update -&gt; INFO 002 Successfully submitted channel update</code></pre><p>在此时，区块5将会生成并写到每一个节点的账本，比如我们查看<code>peer0.org1</code>的日志信息，可以看到以下内容：</p><pre><code>#打开一个新的命令行docker logs -f peer0.org1.example.com##日志内容UTC [gossip.privdata] StoreBlock -&gt; INFO 07c [mychannel] Received block [5] from buffer...UTC [gossip.gossip] JoinChan -&gt; INFO 07d Joining gossip network of channel mychannel with 3 organizations...UTC [committer.txvalidator] Validate -&gt; INFO 082 [mychannel] Validated block [5] in 238ms...UTC [kvledger] CommitWithPvtData -&gt; INFO 08b [mychannel] Committed block [5] with 1 transaction(s) in 238ms...</code></pre><h3 id="3-4启动节点并加入通道"><a href="#3-4启动节点并加入通道" class="headerlink" title="3.4启动节点并加入通道"></a>3.4启动节点并加入通道</h3><p>到这里，组织三的信息已经更新到网络中了，所以我们可以启动组织三的节点了：</p><pre><code>docker-compose -f docker-compose-org3.yaml up -d</code></pre><p>启动成功后进入组织三的<code>cli</code>容器：</p><pre><code>docker exec -it Org3cli bash</code></pre><p>第一步还是配置环境变量，还记得一开始我们将排序节点的根证书复制的那一步吧，现在就派上用场了：</p><pre><code>export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem export CHANNEL_NAME=mychannel#检查一下是否配置成功echo $ORDERER_CA &amp;&amp; echo $CHANNEL_NAME</code></pre><p>没问题的话就可以进行加入通道了，如果加入通道呢，肯定是需要创世区块了，所以需要从排序节点处获取它：</p><pre><code>#这里不能用peer channel fetch config ... 否则获取到的是刚生产的区块5，只有使用创世区块才能加入通道peer channel fetch 0 mychannel.block -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA###命令行打印出一下内容UTC [cli.common] readBlock -&gt; INFO 002 Received block: 0</code></pre><p>最后加入通道：</p><pre><code>export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/tls/ca.crt &amp;&amp; export CORE_PEER_ADDRESS=peer1.org3.example.com:12051peer channel join -b mychannel.block</code></pre><h3 id="3-5测试"><a href="#3-5测试" class="headerlink" title="3.5测试"></a>3.5测试</h3><p>一切都没有问题，就差测试链码能不能用了。</p></li><li><p><em>首先这里注意一点，在新的组织添加进通道之前，链码的背书策略并没有涉及到新的组织，所以之前的链码对于新的组织是不能使用的，包括查询，调用以及更新操作*</em>。但是安装链码是可以用的(前提是版本和链码名称不能全部相同)，所以我们需要通过之前的组织更新链码，并制定背书策略将新的组织添加进来。<br>切换到组织一的节点：</p><pre><code>export CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051</code></pre><p>安装新版本的链码：</p><pre><code>peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/## 更新背书策略将新的组织添加进来peer chaincode upgrade -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $ORDERER_CA -C $CHANNEL_NAME -n mycc -v 2.0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;90&quot;,&quot;b&quot;,&quot;210&quot;]}&#39; -P &quot;OR (&#39;Org1MSP.peer&#39;,&#39;Org2MSP.peer&#39;,&#39;Org3MSP.peer&#39;)&quot;#测试一下更新是否成功peer chaincode query -C $CHANNEL_NAME -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;## Query Result: 90</code></pre><p>切换回组织三的节点容器：</p><pre><code>docker exec -it Org3cli bashexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem export CHANNEL_NAME=mychannel</code></pre><p>安装链码：</p><pre><code>peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/</code></pre><p>安装完测试一下：</p><pre><code>peer chaincode query -C $CHANNEL_NAME -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;# Query Result: 90</code></pre><p>查询没问题，调用一下试试：</p><pre><code>peer chaincode invoke -o orderer.example.com:7050  --tls $CORE_PEER_TLS_ENABLED --cafile $ORDERER_CA -C $CHANNEL_NAME -n mycc -c &#39;{&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]}&#39;</code></pre><p>再次查询：</p><pre><code>peer chaincode query -C $CHANNEL_NAME -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;# Query Result: 80</code></pre><p>没问题了，到这里我们成功将组织三动态添加到网络中了。</p></li></ul><h3 id="3-5更新组织三的锚节点"><a href="#3-5更新组织三的锚节点" class="headerlink" title="3.5更新组织三的锚节点"></a>3.5更新组织三的锚节点</h3><p>锚节点说简单点就是用于跨组织通信的。初始的跨组织通信启动信息需要通过锚节点的设置提供。在最后一小部分，说明一下如何更新组织三的锚节点。<br>和前面的步骤相似：</p><ol><li>获取最新的配置区块</li><li>更新配置信息</li><li>将更新后的配置信息更新到链上。</li></ol><h4 id="3-5-1获取最新的配置区块"><a href="#3-5-1获取最新的配置区块" class="headerlink" title="3.5.1获取最新的配置区块"></a>3.5.1获取最新的配置区块</h4><pre><code>#还是之前的组织三的CLI容器，并且环境变量$CHANNEL_NAME,$ORDERER_CA需要提前配置好peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA</code></pre><ul><li>解码配置信息为JSON格式,并去除用不到的信息：<pre><code>configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.json</code></pre></li><li>将组织三的锚节点的配置信息写进去并保存为一个新的文件：<pre><code>jq &#39;.channel_group.groups.Application.groups.Org3MSP.values += {&quot;AnchorPeers&quot;:{&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:{&quot;anchor_peers&quot;: [{&quot;host&quot;: &quot;peer0.org3.example.com&quot;,&quot;port&quot;: 11051}]},&quot;version&quot;: &quot;0&quot;}}&#39; config.json &gt; modified_anchor_config.json</code></pre></li><li>将原有的配置信息与新的配置信息编码为<code>common.Config</code>格式：<pre><code>configtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_anchor_config.json --type common.Config --output modified_anchor_config.pb</code></pre></li><li>计算两个文件的差异：<pre><code>configtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated modified_anchor_config.pb --output anchor_update.pb</code></pre></li><li>再次解码：<pre><code>configtxlator proto_decode --input anchor_update.pb --type common.ConfigUpdate | jq . &gt; anchor_update.json</code></pre></li><li>添加头部信息:<pre><code>echo &#39;{&quot;payload&quot;:{&quot;header&quot;:{&quot;channel_header&quot;:{&quot;channel_id&quot;:&quot;&#39;$CHANNEL_NAME&#39;&quot;, &quot;type&quot;:2}},&quot;data&quot;:{&quot;config_update&quot;:&#39;$(cat anchor_update.json)&#39;}}}&#39; | jq . &gt; anchor_update_in_envelope.json</code></pre></li><li>编码为<code>Fabric</code>可读的配置文件类型:<pre><code>configtxlator proto_encode --input anchor_update_in_envelope.json --type common.Envelope --output anchor_update_in_envelope.pb</code></pre></li><li>配置文件写完了，更新上去：<pre><code>peer channel update -f anchor_update_in_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA</code></pre>到这里锚节点更新完了，剩下的自行测试。</li></ul>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric手动生成CA证书搭建Fabric网络</title>
    <link href="undefined2019/12/08/blog/fabric/Hyperledger_Fabric%E6%89%8B%E5%8A%A8%E7%94%9F%E6%88%90CA%E8%AF%81%E4%B9%A6%E6%90%AD%E5%BB%BAFabric%E7%BD%91%E7%BB%9C/"/>
    <url>2019/12/08/blog/fabric/Hyperledger_Fabric%E6%89%8B%E5%8A%A8%E7%94%9F%E6%88%90CA%E8%AF%81%E4%B9%A6%E6%90%AD%E5%BB%BAFabric%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<p>之前介绍了使用官方脚本自动化启动一个Fabric网络，并且所有的证书都是通过官方的命令行工具<code>cryptogen</code>直接生成网络中的所有节点的证书。在开发环境可以这么简单进行，但是生成环境下还是需要我们自定义对网络中的节点的证书进行配置。<br>所以在本文中，将会详细介绍一个从手动生成证书一直到启动网络的整体步骤。本文只交代整体的搭建步骤。对于Fabric-Ca的讲解不在本文的范围内，将在另一篇文章中说明。<br>正篇文章也是根据官方的文档进行的。但是由于官方的文档尚未完工，也是好多没有交代清楚的，并且有些地方是错误的，所以笔者也是一步一步摸索出来的，所以如果本文哪里没有交代清楚或者错误的地方，希望各位批评指正。<br>在这里贴出<a href="https://hyperledger-fabric-ca.readthedocs.io/en/latest/operations_guide.html" target="_blank" rel="noopener">官方文档</a>地址.</p><h2 id="1-整体架构"><a href="#1-整体架构" class="headerlink" title="1.整体架构"></a>1.整体架构</h2><hr><p>架构图直接贴过来好了：<br><img src="/img/blog/arth.png" srcset="undefined" alt="系统架构"></p><p>官方文档采用的是多机环境，这里简洁化一点，所有的操作都在<strong>一台机器</strong>上进行，至于多机环境，以后再补充好了。<br>介绍一下本文所采用的整体架构：</p><ol><li>三个组织<ol><li>Org0  -&gt; 组织0   </li><li>Org1  -&gt; 组织1   </li><li>Org2  -&gt; 组织2   </li></ol></li><li>组织中的成员<ol><li>Org0   一个Orderer节点，一个Org0的Admin节点</li><li>Org1   两个Peer节点，一个Org1的Admin节点，一个Org1的User节点</li><li>Org2   两个Peer节点，一个Org2的Admin节点，一个Org2的User节点</li></ol></li><li>共有四台CA服务器<ol><li>TLS服务器   -&gt;  为网络中所有节点颁发TLS证书，用于通信的加密</li><li>Org1的CA服务器 -&gt; 为组织1中所有用户颁发证书</li><li>Org2的Ca服务器 -&gt; 为组织2中所有用户颁发证书</li><li>Org0的CA服务器 -&gt; 为组织0中所有用户颁发证书</li></ol></li></ol><p>这里的四台CA服务器都是根服务器。<strong>彼此之间都是独立的存在，没有任何关系。</strong>，也就是说每一个CA服务器生成的证书在其他CA服务器都是不能用的。<br>介绍完之后，可以进入正题了。</p><h3 id="1-1Fabric，Fabric-Ca安装"><a href="#1-1Fabric，Fabric-Ca安装" class="headerlink" title="1.1Fabric，Fabric-Ca安装"></a>1.1Fabric，Fabric-Ca安装</h3><p>本文默认读者都是对Fabric有一定的了解的，所以一些安装过程这里就没有重复说明。<br>第一步是安装Fabric-Ca环境，可以参考<a href="https://ifican.top/2019/12/08/blog/fabric/Hyperledger_Fabric_CA/" target="_blank" rel="noopener">这里</a>,这篇文章还没有写完，以后慢慢补，不过环境的安装已经有说明。<br>还有就是Fabric的环境安装，可以参考<a href="https://ifican.top/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">这里</a>。</p><p>完成环境搭建后，我们还需要一个<code>HOME</code>文件夹，用于存放我们生成的证书文件与<code>fabric</code>配置相关的文件。<br>本文设置<code>HOME</code>文件夹路径为:</p><pre><code>$GOPATH/src/github.com/caDemo/</code></pre><p>请读者自行创建，一般不要用太复杂的路径,也不要用中文路径，会为之后的操作带来很多麻烦。在下文中简单称<code>HOME</code>文件夹为<strong>工作目录</strong>,<strong>除非特殊说明，一般命令的执行都是在工作目录进行</strong>。</p><h2 id="2-CA服务器配置"><a href="#2-CA服务器配置" class="headerlink" title="2 CA服务器配置"></a>2 CA服务器配置</h2><hr><h3 id="2-1启动TLS-CA服务器"><a href="#2-1启动TLS-CA服务器" class="headerlink" title="2.1启动TLS CA服务器"></a>2.1启动TLS CA服务器</h3><p>前期工作准备好之后，我们开始启动第一台CA服务器。本文中使用<code>Docker</code>容器启动。<br>首先在工作目录创建<code>docker-compose.yaml</code>文件：</p><pre><code>touch docker-compose.yaml</code></pre><p>并在文件内添加以下内容(tips:内容格式不要乱掉)：</p><pre><code>version: &#39;2&#39;networks:  fabric-ca:services:  ca-tls:    container_name: ca-tls    image: hyperledger/fabric-ca    command: sh -c &#39;fabric-ca-server start -d -b tls-ca-admin:tls-ca-adminpw --port 7052&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/tls      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=ca-tls      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca  ##重要！！！记得修改这里的路径为自己的工作目录    networks:      - fabric-ca    ports:      - 7052:7052</code></pre><p>启动该<code>docker</code>容器：</p><pre><code>docker-compose -f docker-compose.yaml up ca-tls</code></pre><p>如果命令行出现以下内容则说明启动成功：</p><pre><code>[INFO] Listening on https://0.0.0.0:7052</code></pre><p>同时工作目录下会出现一个<code>tls</code>的文件夹。文件夹中的内容暂先不解释，留着在另一篇文章中说明。不过有一个文件需要解释一下，因为之后会用到。<br>在<code>$GOPATH/src/github.com/caDemo/tls/</code>路径下的<code>ca-cert.pem</code>文件。这是<code>TLS CA</code>服务器签名的根证书，目的是用来对<code>CA</code>的<code>TLS</code>证书进行验证，同时也需要持有这个证书才可以进行证书的颁发。在多机环境下，我们需要将它复制到每一台机器上，不过本文采用的是单机环境，所以省略掉了这一步。</p><h3 id="2-2-TLS-CA服务器注册用户"><a href="#2-2-TLS-CA服务器注册用户" class="headerlink" title="2.2 TLS CA服务器注册用户"></a>2.2 TLS CA服务器注册用户</h3><p>第一步是在TLS CA服务器中注册用户，经过注册的用户才拥有TLS证书，本文中由于只在各节点之间进行TLS加密通信，所以只将<code>orderer</code>和<code>peer</code>节点的身份注册到TLS服务器。<br>打开一个新的终端输入以下命令：</p><pre><code>#设置环境变量指定根证书的路径(如果工作目录不同的话记得指定自己的工作目录,以下不再重复说明)export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem#设置环境变量指定CA客户端的HOME文件夹export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/tls/admin#登录管理员用户用于之后的节点身份注册fabric-ca-client enroll -d -u https://tls-ca-admin:tls-ca-adminpw@0.0.0.0:7052</code></pre><p>登录成功在工作目录下的<code>tls</code>文件夹下将出现一个<code>admin</code>文件夹，这里面是<code>admin</code>的相关证书文件.<br>并且只有登录了<code>admin</code>，才具有权限进行用户的注册,因为该用户具有CA的全部权限，相当于CA服务器的<code>root</code>用户。<br>接下来对各个节点进行注册。</p><pre><code>fabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7052fabric-ca-client register -d --id.name orderer-org0 --id.secret ordererPW --id.type orderer -u https://0.0.0.0:7052</code></pre><p>这里将三个组织中的节点都进行了注册。</p><ul><li>不过<code>-d</code>这个参数并没有找到相关资料 </li><li><code>id.name</code>是指定用户的名称</li><li><code>--id.secert</code>是指定密码</li><li><code>--id.type</code>是指定用户类型，用户类型默认为<code>client</code>,主要包括<code>peer</code>,<code>app</code>,<code>user</code>,<code>orderer</code>.</li><li><code>-u</code>则是指定请求CA服务器的URL。</li></ul><p>这里我们为各个节点注册TLS证书，之后Fabric网络的通信则需要通过这一步骤注册过的用户的TLS证书来进行TLS加密通信。<br>到这里我们只是注册了各个节点的身份，还没有获取到他们的证书。证书可以通过登录获取，不过暂时不着急获取他们的TLS证书。<br>接下来，我们对其他几个CA服务器进行配置。</p><h3 id="2-3配置Org0的CA服务器"><a href="#2-3配置Org0的CA服务器" class="headerlink" title="2.3配置Org0的CA服务器"></a>2.3配置Org0的CA服务器</h3><p>再强调一下，本文中的几个CA服务器都是根服务器，彼此之间没有任何关系，所以上一步骤的TLS CA服务器在这一部分并没有用到。<br>同样，本文使用Docker容器启动CA服务器。配置文件如下，只需要添加进之前的<code>docker-compose.yaml</code>文件中就好：</p><pre><code>  org0:    container_name: org0    image: hyperledger/fabric-ca    command: /bin/bash -c &#39;fabric-ca-server start -d -b org0-admin:org0-adminpw --port 7053&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/org0/crypto      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=org0      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca    networks:      - fabric-ca    ports:      - 7053:7053</code></pre><p>添加完之后启动它：</p><pre><code>docker-compose -f docker-compose.yaml up org0</code></pre><p>打开另一个终端，接下来注册org0的用户：</p><pre><code>#首先指定环境变量，这里的TLS证书不是之前的TLS CA服务器的根证书，而是本组织CA服务器启动时生成的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem#指定本组织的CA客户端工作目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/admin</code></pre><p>登录<code>org0</code>的CA服务器管理员身份用于注册本组织的用户：</p><pre><code>fabric-ca-client enroll -d -u https://org0-admin:org0-adminpw@0.0.0.0:7053</code></pre><p>在本组织中共有两个用户：<code>orderer</code>节点和<code>admin</code>用户(这里的admin和管理员是不同的。)<br>将他们注册到org0的CA服务器：</p><pre><code>fabric-ca-client register -d --id.name orderer-org0 --id.secret ordererpw --id.type orderer -u https://0.0.0.0:7053fabric-ca-client register -d --id.name admin-org0 --id.secret org0adminpw --id.type admin --id.attrs &quot;hf.Registrar.Roles=client,hf.Registrar.Attributes=*,hf.Revoker=true,hf.GenCRL=true,admin=true:ecert,abac.init=true:ecert&quot; -u https://0.0.0.0:7053</code></pre><p>命令执行完之后，将会注册一个Orderer节点的身份和一个Admin的身份。同时在工作目录下的<code>org0</code>子文件夹中会有两个文件夹：<code>crypto</code>和<code>admin</code>。<code>crypto</code>中是CA服务器的配置信息，<code>admin</code>是服务器管理员的身份信息。</p><h3 id="2-4配置Org1的CA服务器"><a href="#2-4配置Org1的CA服务器" class="headerlink" title="2.4配置Org1的CA服务器"></a>2.4配置Org1的CA服务器</h3><p>同样的步骤，对org1组织的CA服务器进行配置：</p><pre><code>  org1:    container_name: org1    image: hyperledger/fabric-ca    command: /bin/bash -c &#39;fabric-ca-server start -d -b org1-admin:org1-adminpw&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/org1/crypto      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=org1      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca    networks:      - fabric-ca    ports:      - 7054:7054</code></pre><p>启动服务器：</p><pre><code>docker-compose -f docker-compose.yaml up org1</code></pre><p>打开新的终端，配置环境变量：</p><pre><code>export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/admin</code></pre><p>登录CA服务器管理员身份：</p><pre><code>fabric-ca-client enroll -d -u https://org1-admin:org1-adminpw@0.0.0.0:7054</code></pre><p>组织一种共有四个用户：<code>peer1</code>,<code>peer2</code>,<code>admin</code>,<code>user</code>,分别注册他们：</p><pre><code>fabric-ca-client register -d --id.name peer1-org1 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7054fabric-ca-client register -d --id.name peer2-org1 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7054fabric-ca-client register -d --id.name admin-org1 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7054fabric-ca-client register -d --id.name user-org1 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7054</code></pre><h3 id="2-5配置Org2的CA服务器"><a href="#2-5配置Org2的CA服务器" class="headerlink" title="2.5配置Org2的CA服务器"></a>2.5配置Org2的CA服务器</h3><p>和上一部分相同，这里只列举需要的命令：<br>CA服务器配置文件：</p><pre><code>  org2:    container_name: org2    image: hyperledger/fabric-ca    command: /bin/bash -c &#39;fabric-ca-server start -d -b org2-admin:org2-adminpw --port 7055&#39;    environment:      - FABRIC_CA_SERVER_HOME=/ca/org2/crypto      - FABRIC_CA_SERVER_TLS_ENABLED=true      - FABRIC_CA_SERVER_CSR_CN=org2      - FABRIC_CA_SERVER_CSR_HOSTS=0.0.0.0      - FABRIC_CA_SERVER_DEBUG=true    volumes:      - $GOPATH/src/github.com/caDemo:/ca    networks:      - fabric-ca    ports:      - 7055:7055</code></pre><p>启动服务器：</p><pre><code>docker-compose -f docker-compose.yaml up org2</code></pre><p>打开新的终端，配置环境变量：</p><pre><code>export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/admin</code></pre><p>登录CA服务器管理员身份：</p><pre><code>fabric-ca-client enroll -d -u https://org2-admin:org2-adminpw@0.0.0.0:7055</code></pre><p>组织一种共有四个用户：<code>peer1</code>,<code>peer2</code>,<code>admin</code>,<code>user</code>,分别注册他们：</p><pre><code>fabric-ca-client register -d --id.name peer1-org2 --id.secret peer1PW --id.type peer -u https://0.0.0.0:7055fabric-ca-client register -d --id.name peer2-org2 --id.secret peer2PW --id.type peer -u https://0.0.0.0:7055fabric-ca-client register -d --id.name admin-org2 --id.secret org1AdminPW --id.type user -u https://0.0.0.0:7055fabric-ca-client register -d --id.name user-org2 --id.secret org1UserPW --id.type user -u https://0.0.0.0:7055</code></pre><h2 id="3-生成证书并配置TLS"><a href="#3-生成证书并配置TLS" class="headerlink" title="3.生成证书并配置TLS"></a>3.生成证书并配置TLS</h2><hr><p>到目前为止，所有的用户我们都注册完毕，接下来就是为每一个用户生成证书并配置TLS证书。<br>其中证书分为两部分，分别是本组织的MSP证书，以及组织之间进行加密通信的TLS证书。<br>所以本文需要对两部分证书进行分别生成与配置。<br>从组织一开始：</p><h3 id="3-1-组织一节点配置"><a href="#3-1-组织一节点配置" class="headerlink" title="3.1 组织一节点配置"></a>3.1 组织一节点配置</h3><h4 id="3-1-1-peer1"><a href="#3-1-1-peer1" class="headerlink" title="3.1.1 peer1"></a>3.1.1 peer1</h4><p>首先是本组织的<code>MSP</code>证书：</p><ul><li>配置环境变量<pre><code>#指定peer1节点的HOME目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer1#指定**本**组织的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem</code></pre></li><li>登录<code>peer1</code>节点到<code>org1 CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7054</code></pre>这一步完成后，在<code>$GOPATH/src/github.com/caDemo/org1/peer1</code>下会出现一个<code>msp</code>文件夹，这是<code>peer1</code>节点的<code>MSP</code>证书。<br>接下来是<code>TLS</code>证书：</li><li>配置环境变量<pre><code>#指定TLS CA服务器生成的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem#指定TLS证书的HOME目录export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer1/tls-msp</code></pre></li><li>登录<code>peer1</code>节点到<code>TLS CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org1:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org1</code></pre>这一步完成后，在<code>$GOPATH/src/github.com/caDemo/org1/peer1</code>下会出现一个<code>tls-msp</code>文件夹，这是<code>peer1</code>节点的<code>TLS</code>证书。</li><li>修改秘钥文件名<br>为什么要修改呢，进入这个文件夹看一下就知道了,由服务器生成的秘钥文件名是一长串无规则的字符串，后期我们使用的时候难道要一个字符一个字符地输入？<pre><code>cd $GOPATH/src/github.com/caDemo/org1/peer1/tls-msp/keystore/mv *_sk key.pem#修改完回到工作目录cd $GOPATH/src/github.com/caDemo</code></pre><h4 id="3-1-2-peer2"><a href="#3-1-2-peer2" class="headerlink" title="3.1.2 peer2"></a>3.1.2 peer2</h4><code>peer2</code>节点和上面步骤相同：<br>这里就直接放需要的命令了：</li><li>生成<code>MSP</code>证书<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/peer2export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7054</code></pre></li><li>生成<code>TLS</code>证书<pre><code>export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/peer2/tls-mspexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org1:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org1cd $GOPATH/src/github.com/caDemo/org1/peer2/tls-msp/keystore/mv *_sk key.pem</code></pre><h4 id="3-1-3-admin"><a href="#3-1-3-admin" class="headerlink" title="3.1.3 admin"></a>3.1.3 admin</h4>接下来是<code>admin</code>用户，这个用户有什么作用呢，实际上，安装和实例化链码都需要<code>admin</code>的证书，所以才需要注册一个<code>admin</code>用户，还要它的证书。</li><li>配置环境变量<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org1/adminuserexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org1/crypto/ca-cert.pem#这里多了一个环境变量，是指定admin用户的msp证书文件夹的export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org1/adminuser/msp</code></pre></li><li>登录<code>admin</code>用户获取<code>MSP</code>证书:<pre><code>fabric-ca-client enroll -d -u https://admin-org1:org1AdminPW@0.0.0.0:7054</code></pre>因为我们生成这个用户的证书主要就是为了之后链码的安装和实例化，所以配不配置他的<code>TLS</code>证书也无关紧要了(关键是我们之前也没有将这个用户注册到<code>tls</code>服务器中)</li><li>复制证书到<code>admincerts</code>文件夹:<br>去看Fabric官方的例子，每一个<code>peer</code>节点的<code>MSP</code>文件夹下都有<code>admincerts</code>这个子文件夹的，而且是需要我们手动创建的。<pre><code>mkdir -p $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts#将签名证书拷贝过去cp $GOPATH/src/github.com/caDemo/org1/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org1/peer1/msp/admincerts/org1-admin-cert.pem#回到工作目录cd $GOPATH/src/github.com/caDemo/</code></pre><h4 id="3-1-4-启动peer节点"><a href="#3-1-4-启动peer节点" class="headerlink" title="3.1.4 启动peer节点"></a>3.1.4 启动peer节点</h4>到这里，已经配置好了一个节点，所以我们就可以启动这个节点了，当然在之后和<code>orderer</code>节点一起启动也可以，不过忙活了这么多，还是应该提前看到一下所做的工作的成果的！<br>附上<code>peer1</code>节点的容器配置信息：</li></ul><pre><code>  peer1-org1:    container_name: peer1-org1    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer1-org1      - CORE_PEER_ADDRESS=peer1-org1:7051      - CORE_PEER_LOCALMSPID=org1MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer1    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1    networks:      - fabric-ca</code></pre><p>启动它！！</p><pre><code>docker-compose -f docker-compose.yaml up peer1-org1</code></pre><p>如果没有报错的话，说明之前配置的没有什么问题，如果出错的话，则需要返回去检查一下了。。。<br><code>peer2</code>节点的容器配置信息：</p><pre><code>  peer2-org1:    container_name: peer2-org1    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer2-org1      - CORE_PEER_ADDRESS=peer2-org1:8051      - CORE_PEER_LOCALMSPID=org1MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer2/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer2/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org1:7051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1/peer2    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org1/peer2:/tmp/hyperledger/org1/peer2    networks:      - fabric-ca</code></pre><p>启动它！！</p><pre><code>docker-compose -f docker-compose.yaml up peer2-org1</code></pre><h3 id="3-2-组织二节点配置"><a href="#3-2-组织二节点配置" class="headerlink" title="3.2 组织二节点配置"></a>3.2 组织二节点配置</h3><p>和之前一样的步骤，所以没什么好解释的了：</p><h4 id="3-2-1-peer1"><a href="#3-2-1-peer1" class="headerlink" title="3.2.1 peer1"></a>3.2.1 peer1</h4><ul><li>配置环境变量<pre><code>#指定peer2节点的HOME目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer1#指定本组织的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pem</code></pre></li><li>登录<code>peer1</code>节点到<code>org2 CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7055</code></pre>接下来是<code>TLS</code>证书：</li><li>配置环境变量<pre><code>#指定TLS CA服务器生成的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem#指定TLS证书的HOME目录export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer1/tls-msp</code></pre></li><li>登录<code>peer1</code>节点到<code>TLS CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://peer1-org2:peer1PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer1-org2</code></pre></li><li>修改秘钥文件名<pre><code>cd $GOPATH/src/github.com/caDemo/org2/peer1/tls-msp/keystore/mv *_sk key.pem#修改完回到工作目录cd $GOPATH/src/github.com/caDemo</code></pre><h4 id="3-2-2-peer2"><a href="#3-2-2-peer2" class="headerlink" title="3.2.2 peer2"></a>3.2.2 peer2</h4></li><li>生成<code>MSP</code>证书<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/peer2export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7055</code></pre></li><li>生成<code>TLS</code>证书<pre><code>export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/peer2/tls-mspexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pemfabric-ca-client enroll -d -u https://peer2-org2:peer2PW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts peer2-org2cd $GOPATH/src/github.com/caDemo/org2/peer2/tls-msp/keystore/mv *_sk key.pem</code></pre><h4 id="3-2-3-admin"><a href="#3-2-3-admin" class="headerlink" title="3.2.3 admin"></a>3.2.3 admin</h4></li><li>配置环境变量<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org2/adminuserexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org2/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org2/adminuser/msp</code></pre></li><li>登录<code>admin</code>用户获取<code>MSP</code>证书:<pre><code>fabric-ca-client enroll -d -u https://admin-org2:org2AdminPW@0.0.0.0:7055</code></pre></li><li>复制证书到<code>admincerts</code>文件夹:<br>去看Fabric官方的例子，每一个<code>peer</code>节点的<code>MSP</code>文件夹下都有<code>admincerts</code>这个子文件夹的，而且是需要我们手动创建的。<pre><code>mkdir -p $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts#将签名证书拷贝过去cp $GOPATH/src/github.com/caDemo/org2/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org2/peer1/msp/admincerts/org2-admin-cert.pem#回到工作目录cd $GOPATH/src/github.com/caDemo/</code></pre><h4 id="3-2-4-启动peer节点"><a href="#3-2-4-启动peer节点" class="headerlink" title="3.2.4 启动peer节点"></a>3.2.4 启动peer节点</h4>附上<code>peer1</code>节点的容器配置信息：</li></ul><pre><code>  peer1-org2:    container_name: peer1-org2    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer1-org2      - CORE_PEER_ADDRESS=peer1-org2:9051      - CORE_PEER_LOCALMSPID=org2MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer1    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1    networks:      - fabric-ca</code></pre><p>启动它.</p><pre><code>docker-compose -f docker-compose.yaml up peer1-org2</code></pre><p><code>peer2</code>节点的容器配置信息：</p><pre><code>  peer2-org2:    container_name: peer2-org2    image: hyperledger/fabric-peer    environment:      - CORE_PEER_ID=peer2-org2      - CORE_PEER_ADDRESS=peer2-org2:10051      - CORE_PEER_LOCALMSPID=org2MSP      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer2/msp      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca      - FABRIC_LOGGING_SPEC=debug      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer2/tls-msp/keystore/key.pem      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer2/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_GOSSIP_USELEADERELECTION=true      - CORE_PEER_GOSSIP_ORGLEADER=false      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1-org2:9051      - CORE_PEER_GOSSIP_SKIPHANDSHAKE=true    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2/peer2    volumes:      - /var/run:/host/var/run      - $GOPATH/src/github.com/caDemo/org2/peer2:/tmp/hyperledger/org2/peer2    networks:      - fabric-ca</code></pre><p>启动它.</p><pre><code>docker-compose -f docker-compose.yaml up peer2-org2</code></pre><h3 id="3-3-排序节点配置"><a href="#3-3-排序节点配置" class="headerlink" title="3.3 排序节点配置"></a>3.3 排序节点配置</h3><p>接下来是排序节点的配置，为什么放在最后面呢，因为排序节点的启动需要提前生成创世区块，而创世区块的生成涉及到另一个配置文件，所以就先配置简单的<code>peer</code>节点。</p><h4 id="3-3-1-orderer"><a href="#3-3-1-orderer" class="headerlink" title="3.3.1 orderer"></a>3.3.1 orderer</h4><ul><li>配置环境变量<pre><code>#指定order节点的HOME目录export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/orderer#指定本组织的TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pem</code></pre></li><li>登录<code>order</code>节点到<code>org0 CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://orderer-org0:ordererpw@0.0.0.0:7053</code></pre>接下来是<code>TLS</code>证书：</li><li>配置环境变量<pre><code>#指定TLS CA服务器生成的TLS根证书export FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/orderer/tls-msp#指定TLS根证书export FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/tls/ca-cert.pem</code></pre></li><li>登录<code>orderer</code>节点到<code>TLS CA</code>服务器上：<pre><code>fabric-ca-client enroll -d -u https://orderer-org0:ordererPW@0.0.0.0:7052 --enrollment.profile tls --csr.hosts orderer-org0</code></pre></li><li>修改秘钥文件名<pre><code>cd $GOPATH/src/github.com/caDemo/org0/orderer/tls-msp/keystore/mv *_sk key.pem#修改完回到工作目录cd $GOPATH/src/github.com/caDemo</code></pre><h4 id="3-3-2-admin"><a href="#3-3-2-admin" class="headerlink" title="3.3.2 admin"></a>3.3.2 admin</h4></li><li>配置环境变量<pre><code>export FABRIC_CA_CLIENT_HOME=$GOPATH/src/github.com/caDemo/org0/adminuserexport FABRIC_CA_CLIENT_TLS_CERTFILES=$GOPATH/src/github.com/caDemo/org0/crypto/ca-cert.pemexport FABRIC_CA_CLIENT_MSPDIR=$GOPATH/src/github.com/caDemo/org0/adminuser/msp</code></pre></li><li>登录<code>admin</code>用户获取<code>MSP</code>证书:<pre><code>fabric-ca-client enroll -d -u https://admin-org0:org0adminpw@0.0.0.0:7053</code></pre></li><li>复制证书到<code>admincerts</code>文件夹:<pre><code>mkdir $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts#将签名证书拷贝过去cp $GOPATH/src/github.com/caDemo/org0/adminuser/msp/signcerts/cert.pem $GOPATH/src/github.com/caDemo/org0/orderer/msp/admincerts/orderer-admin-cert.pem#回到工作目录cd $GOPATH/src/github.com/caDemo/</code></pre><h2 id="4-Fabric网络配置"><a href="#4-Fabric网络配置" class="headerlink" title="4.Fabric网络配置"></a>4.Fabric网络配置</h2></li></ul><hr><p>接下来到重头戏了，证书都生成好了，即将要启动网络了。不过在启动网络之前还是有很多准备工作需要做。其实到这里，官方文档已经好多没有交代清楚的了，所以一下好多内容都是笔者自己摸索出来的，如有错误欢迎批评指正。</p><h3 id="4-1-configtx-yaml文件配置"><a href="#4-1-configtx-yaml文件配置" class="headerlink" title="4.1 configtx.yaml文件配置"></a>4.1 configtx.yaml文件配置</h3><p>在下一个步骤的生成创世区块和通道配置信息需要一个文件：<code>configtx.yaml</code>文件。笔者根据官方的例子按照本文内容修改了一下，直接放在工作目录:</p><pre><code>Organizations:  - &amp;orderer-org0    Name: orderer-org0    ID: org0MSP    MSPDir: ./org0/msp  #    Policies:  #      Readers:  #        Type: Signature  #        Rule: &quot;OR(&#39;orderer-org0MSP.member&#39;)&quot;  #      Writers:  #        Type: Signature  #        Rule: &quot;OR(&#39;orderer-org0MSP.member&#39;)&quot;  #      Admins:  #        Type: Signature  #        Rule: &quot;OR(&#39;orderer-org0MSP.admin&#39;)&quot;  - &amp;org1    Name: org1MSP    ID: org1MSP    MSPDir: ./org1/msp    #    Policies:    #      Readers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org1MSP.admin&#39;, &#39;org1MSP.peer&#39;, &#39;org1MSP.client&#39;)&quot;    #      Writers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org1MSP.admin&#39;, &#39;org1MSP.client&#39;)&quot;    #      Admins:    #        Type: Signature    #        Rule: &quot;OR(&#39;org1MSP.admin&#39;)&quot;    AnchorPeers:      - Host: peer1-org1        Port: 7051  - &amp;org2    Name: org2MSP    ID: org2MSP    MSPDir: ./org2/msp    #    Policies:    #      Readers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org2MSP.admin&#39;, &#39;org2MSP.peer&#39;, &#39;org2MSP.client&#39;)&quot;    #      Writers:    #        Type: Signature    #        Rule: &quot;OR(&#39;org2MSP.admin&#39;, &#39;org2MSP.client&#39;)&quot;    #      Admins:    #        Type: Signature    #        Rule: &quot;OR(&#39;org2MSP.admin&#39;)&quot;    AnchorPeers:      - Host: peer1-org2        Port: 9051Capabilities:  Channel: &amp;ChannelCapabilities    V1_4_3: true    V1_3: false    V1_1: false  Orderer: &amp;OrdererCapabilities    V1_4_2: true    V1_1: false  Application: &amp;ApplicationCapabilities    V1_4_2: true    V1_3: false    V1_2: false    V1_1: falseApplication: &amp;ApplicationDefaults  Organizations:  #  Policies:  #    Readers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Readers&quot;  #    Writers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Writers&quot;  #    Admins:  #      Type: ImplicitMeta  #      Rule: &quot;MAJORITY Admins&quot;  Capabilities:    &lt;&lt;: *ApplicationCapabilitiesOrderer: &amp;OrdererDefaults  OrdererType: solo  Addresses:    - orderer-org0:7050  BatchTimeout: 2s  BatchSize:    MaxMessageCount: 10    AbsoluteMaxBytes: 99 MB    PreferredMaxBytes: 512 KB  Organizations:#  Policies:#    Readers:#      Type: ImplicitMeta#      Rule: &quot;ANY Readers&quot;#    Writers:#      Type: ImplicitMeta#      Rule: &quot;ANY Writers&quot;#    Admins:#      Type: ImplicitMeta#      Rule: &quot;MAJORITY Admins&quot;#    # BlockValidation specifies what signatures must be included in the block#    # from the orderer for the peer to validate it.#    BlockValidation:#      Type: ImplicitMeta#      Rule: &quot;ANY Writers&quot;Channel: &amp;ChannelDefaults  #  Policies:  #    # Who may invoke the &#39;Deliver&#39; API  #    Readers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Readers&quot;  #    # Who may invoke the &#39;Broadcast&#39; API  #    Writers:  #      Type: ImplicitMeta  #      Rule: &quot;ANY Writers&quot;  #    # By default, who may modify elements at this config level  #    Admins:  #      Type: ImplicitMeta  #      Rule: &quot;MAJORITY Admins&quot;  Capabilities:    &lt;&lt;: *ChannelCapabilitiesProfiles:  TwoOrgsOrdererGenesis:    &lt;&lt;: *ChannelDefaults    Orderer:      &lt;&lt;: *OrdererDefaults      Organizations:        - *orderer-org0      Capabilities:        &lt;&lt;: *OrdererCapabilities    Consortiums:      SampleConsortium:        Organizations:          - *org1          - *org2  TwoOrgsChannel:    Consortium: SampleConsortium    &lt;&lt;: *ChannelDefaults    Application:      &lt;&lt;: *ApplicationDefaults      Organizations:        - *org1        - *org2      Capabilities:        &lt;&lt;: *ApplicationCapabilities</code></pre><p>注释掉的部分是策略部分，笔者还没有完全搞懂，所以索性就先注释掉了，以后搞懂了再添加进去。<br>还有一部分<code>msp</code>需要配置，就是<code>configtx.yaml</code>文件中第一部分指定的<code>MSPDir</code>,很简单，按照一下命令复制一下就好了：</p><pre><code>#进入工作目录cd $GOPATH/src/github.com/caDemo#############################################org0mkdir org0/msp &amp;&amp;  cd org0/mspmkdir admincerts &amp;&amp; mkdir cacerts &amp;&amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemocp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pemcp crypto/ca-cert.pem msp/cacerts/ca-cert.pemcp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem#############################################org1cd $GOPATH/src/github.com/caDemomkdir org1/msp/  &amp;&amp; cd org1/msp/mkdir admincerts &amp;&amp; mkdir cacerts &amp;&amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemocp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pemcp crypto/ca-cert.pem msp/cacerts/ca-cert.pemcp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem#############################################org2cd $GOPATH/src/github.com/caDemomkdir org1/msp/  &amp;&amp; cd org1/msp/mkdir admincerts &amp;&amp; mkdir cacerts &amp;&amp; mkdir tlscacerts cd $GOPATH/src/github.com/caDemocp adminuser/msp/signcerts/cert.pem msp/admincerts/ca-cert.pemcp crypto/ca-cert.pem msp/cacerts/ca-cert.pemcp ../tls/ca-cert.pem msp/tlscacerts/ca-cert.pem</code></pre><h3 id="4-2-生成创世区块和通道配置信息"><a href="#4-2-生成创世区块和通道配置信息" class="headerlink" title="4.2 生成创世区块和通道配置信息"></a>4.2 生成创世区块和通道配置信息</h3><p>可以了，所有的前期工作都已经完成，接下来就是手动启动网络了，第一步，生成创世区块和通道配置信息：</p><pre><code>cd $GOPATH/src/github.com/caDemoexport FABRIC_CFG_PATH=$PWD#生成创世区块configtxgen -profile TwoOrgsOrdererGenesis -outputBlock $GOPATH/src/github.com/caDemo/genesis.block#生成通道配置信息configtxgen -profile TwoOrgsChannel -outputCreateChannelTx $GOPATH/src/github.com/caDemo/channel.tx -channelID mychannel</code></pre><h3 id="4-3-启动Orderer节点"><a href="#4-3-启动Orderer节点" class="headerlink" title="4.3 启动Orderer节点"></a>4.3 启动Orderer节点</h3><p><code>orderer</code>容器配置文件：</p><pre><code>  orderer-org0:    container_name: orderer-org0    image: hyperledger/fabric-orderer    environment:      - ORDERER_HOME=/tmp/hyperledger/orderer      - ORDERER_HOST=orderer-org0      - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0      - ORDERER_GENERAL_GENESISMETHOD=file      - ORDERER_GENERAL_GENESISFILE=/tmp/hyperledger/genesis.block      - ORDERER_GENERAL_LOCALMSPID=org0MSP      - ORDERER_GENERAL_LOCALMSPDIR=/tmp/hyperledger/org0/orderer/msp      - ORDERER_GENERAL_TLS_ENABLED=true      - ORDERER_GENERAL_TLS_CERTIFICATE=/tmp/hyperledger/org0/orderer/tls-msp/signcerts/cert.pem      - ORDERER_GENERAL_TLS_PRIVATEKEY=/tmp/hyperledger/org0/orderer/tls-msp/keystore/key.pem      - ORDERER_GENERAL_TLS_ROOTCAS=[/tmp/hyperledger/org0/orderer/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem]      - ORDERER_GENERAL_LOGLEVEL=debug      - ORDERER_DEBUG_BROADCASTTRACEDIR=data/logs    volumes:      - $GOPATH/src/github.com/caDemo/org0/orderer:/tmp/hyperledger/org0/orderer/      - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/    networks:      - fabric-ca</code></pre><p>关键部分到了，只要这一步没有出现错误，整个网络就启动成功了。</p><pre><code>docker-compose -f docker-compose.yaml up orderer-org0</code></pre><h3 id="4-4-启动组织一的cli容器"><a href="#4-4-启动组织一的cli容器" class="headerlink" title="4.4 启动组织一的cli容器"></a>4.4 启动组织一的cli容器</h3><p><code>cli</code>容器内容,我们需要这个容器对组织1进行链码的交互：</p><pre><code>  cli-org1:    container_name: cli-org1    image: hyperledger/fabric-tools    tty: true    stdin_open: true    environment:      - SYS_CHANNEL=testchainid      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - FABRIC_LOGGING_SPEC=DEBUG      - CORE_PEER_ID=cli-org1      - CORE_PEER_ADDRESS=peer1-org1:7051      - CORE_PEER_LOCALMSPID=org1MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org1/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org1/peer1/tls-msp/keystore/key.pem      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/peer1/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org1    command: /bin/bash    volumes:      - $GOPATH/src/github.com/caDemo/org1/peer1:/tmp/hyperledger/org1/peer1      - $GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode      - $GOPATH/src/github.com/caDemo/org1/adminuser:/tmp/hyperledger/org1/adminuser      - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/    networks:      - fabric-ca    depends_on:      - peer1-org1</code></pre><p>启动该容器：</p><pre><code>docker-compose -f docker-compose.yaml up cli-org1</code></pre><h3 id="4-5-启动组织二的cli容器"><a href="#4-5-启动组织二的cli容器" class="headerlink" title="4.5 启动组织二的cli容器"></a>4.5 启动组织二的cli容器</h3><p><code>cli</code>容器内容,我们需要这个容器对组织2进行链码的交互：</p><pre><code>  cli-org2:    container_name: cli-org2    image: hyperledger/fabric-tools    tty: true    stdin_open: true    environment:      - SYS_CHANNEL=testchainid      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - FABRIC_LOGGING_SPEC=DEBUG      - CORE_PEER_ID=cli-org2      - CORE_PEER_ADDRESS=peer1-org2:9051      - CORE_PEER_LOCALMSPID=org2MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_ROOTCERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem      - CORE_PEER_TLS_CERT_FILE=/tmp/hyperledger/org2/peer1/tls-msp/signcerts/cert.pem      - CORE_PEER_TLS_KEY_FILE=/tmp/hyperledger/org2/peer1/tls-msp/keystore/key.pem      - CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org2/peer1/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/org2    command: /bin/bash    volumes:      - $GOPATH/src/github.com/caDemo/org2/peer1:/tmp/hyperledger/org2/peer1      - $GOPATH/src/github.com/caDemo/org2/peer1/assets/chaincode:/opt/gopath/src/github.com/hyperledger/fabric-samples/chaincode      - $GOPATH/src/github.com/caDemo/org2/adminuser:/tmp/hyperledger/org2/adminuser      - $GOPATH/src/github.com/caDemo:/tmp/hyperledger/    networks:      - fabric-ca    depends_on:      - peer1-org2</code></pre><p>启动该容器：</p><pre><code>docker-compose -f docker-compose.yaml up cli-org2</code></pre><h2 id="5-网络测试"><a href="#5-网络测试" class="headerlink" title="5.网络测试"></a>5.网络测试</h2><hr><p>所有工作准备完成，接下来让我们测试整个网络能不能正常运行吧：</p><h3 id="5-1-创建与加入通道"><a href="#5-1-创建与加入通道" class="headerlink" title="5.1 创建与加入通道"></a>5.1 创建与加入通道</h3><p>以<strong>组织1</strong>为例：</p><ul><li><p>首先进入<code>cli</code>容器：</p><pre><code>docker exec -it cli bash#配置环境变量export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/msp</code></pre></li><li><p>创建通道</p><pre><code>peer channel create -c mychannel -f /tmp/hyperledger/channel.tx -o orderer-org0:7050 --outputBlock /tmp/hyperledger/mychannel.block --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem</code></pre></li><li><p>将<code>peer1-org1</code>加入通道：</p><pre><code>export CORE_PEER_ADDRESS=peer1-org1:7051peer channel join -b /tmp/hyperledger/mychannel.block</code></pre></li><li><p>将<code>peer2-org1</code>加入通道：</p><pre><code>export CORE_PEER_ADDRESS=peer2-org1:8051peer channel join -b /tmp/hyperledger/mychannel.block</code></pre><p>组织二步骤是相同的，唯一不同的就是不需要创建通道了，所以就不再说明了。</p><h3 id="5-2-安装和实例化链码"><a href="#5-2-安装和实例化链码" class="headerlink" title="5.2 安装和实例化链码"></a>5.2 安装和实例化链码</h3><p>以<strong>组织1</strong>为例：</p></li><li><p>首先进入<code>cli</code>容器：</p><pre><code>docker exec -it cli bash#配置环境变量export CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/mspexport CORE_PEER_ADDRESS=peer1-org1:7051</code></pre></li><li><p>安装链码</p></li><li><p><em>记得提前将链码放到*</em><code>$GOPATH/src/github.com/caDemo/org1/peer1/assets/chaincode</code><strong>路径下。</strong>,本文使用的是<code>fabric-samples/chaincode/chaincode_example02</code>官方示例链码。</p><pre><code>peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric-samples/chaincode/chaincode_example02/go/</code></pre></li><li><p>实例化链码</p><pre><code>peer chaincode instantiate -C mychannel -n mycc -v 1.0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]}&#39;  -o orderer-org0:7050 --tls --cafile /tmp/hyperledger/org1/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem</code></pre></li><li><p>这一步在高版本的Fabric网络是会出错的，因为少了一个文件<code>config.yaml</code>:</p></li></ul><pre><code>NodeOUs:  Enable: true  ClientOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: client  PeerOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: peer  AdminOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: admin  OrdererOUIdentifier:    Certificate: cacerts/ca.example.com-cert.pem  #这里需要修改    OrganizationalUnitIdentifier: orderer</code></pre><p>因为高版本的Fabric把节点类型区分开了，所以需要我们手动配置。<br>将该文件复制到<code>$GOPATH/src/github.com/caDemo/org1/adminuser/msp</code>文件夹内，同时修改上面指定的位置的文件名(与对应文件夹内的文件名对应就好了)。</p><ul><li>实例化部分出错的可能性是最高的，很多都是因为网络模式指定错误导致链码容器启动失败，解决方案：<pre><code>#终端执行命令docker network ls</code></pre>找到以<code>fabric-ca</code>为后缀的一条如<code>cademo_fabric-ca</code>,修改之前的所有<code>peer</code>节点容器配置文件的环境变量：<br>```</li></ul><ul><li>CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=cademo_fabric-ca<br>```<br>修改完成重启节点容器，再次执行以上的命令(需要重新配置环境变量，加入通道这两个操作)。<br>终于，实例化成功了。<h3 id="5-3-调用和查询链码"><a href="#5-3-调用和查询链码" class="headerlink" title="5.3 调用和查询链码"></a>5.3 调用和查询链码</h3>最后测试一下链码功能能不能正常使用了：</li></ul><ul><li><p>还是组织一的<code>cli</code>容器：</p><pre><code>docker exec -it cli bashexport CORE_PEER_MSPCONFIGPATH=/tmp/hyperledger/org1/adminuser/mspexport CORE_PEER_ADDRESS=peer1-org1:7051</code></pre></li><li><p>执行查询功能：</p><pre><code>peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;</code></pre><p>命令行应该打印出:</p><pre><code>100</code></pre></li><li><p>执行调用功能：</p><pre><code>peer chaincode invoke -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]}&#39; --tls --cafile /tmp/hyperledger/org2/peer1/tls-msp/tlscacerts/tls-0-0-0-0-7052.pem</code></pre></li><li><p>再次查询：</p><pre><code>peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;</code></pre><p>命令行应该打印出:</p><pre><code>90</code></pre><p>至于其他节点操作方法也是一样的，就不再操作了。<br>到此为止，从零开始的手动生成证书一直到成功搭建Fabric网络全部步骤已经完成！！接下来还有更新锚节点等等就不再演示了，请各位读者自行操作。整个步骤是不容易的，而且BUG百出，不过成功搭建完成确实涨了不少知识。<br>码字不易，还望各位看官支持一下：</p><img src="/img/blog/zfb.png" srcset="undefined" width = "300" height = "300" alt="支付宝" align=center /></li></ul>]]></content>
    
    
    <categories>
      
      <category>fabric-ca应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric-ca</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric私有数据</title>
    <link href="undefined2019/12/04/blog/fabric/%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE/"/>
    <url>2019/12/04/blog/fabric/%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<p>官方文档:<a href="https://hyperledger-fabric.readthedocs.io/en/latest/private-data/private-data.html" target="_blank" rel="noopener">点这里</a></p><hr><h2 id="1简介"><a href="#1简介" class="headerlink" title="1简介"></a>1简介</h2><p>在<strong>同一个通道</strong>中，允许某一组织在对同一通道内其他组织保持部分的数据私有。也就是说有一部分被标识为私有的数据只能具有权限的组织查看和操作，而其余组织不具备查看和操作私有数据的权限。<br>通常如果需要保持数据私有可以另外创建一个通道只为私有数据服务，但是如果涉及到多个业务方时，为每一个组织另外创建通道会增加额外的管理类开销。并且也不能在进行私有数据操作的时候，让其余没有权限的组织节点都知道有这么一笔交易发生。<br>从Fabric 1.2开始，引入了一个<strong>私有数据集合</strong>的概念，它允许通道内的指定的某一个组织中的部分成员可以对私有数据进行操作，而其他没有权限的节点只能知道有这么一笔交易发生而不能了解交易的细节。</p><h3 id="1-1私有数据集合"><a href="#1-1私有数据集合" class="headerlink" title="1.1私有数据集合"></a>1.1私有数据集合</h3><hr><p>私有数据集合包括两个部分：</p><ol><li><p><strong>私有数据实体</strong>：通过Gossip协议在具有权限的节点之间传输，并且只有具有权限的节点可以看到。这部分私有数据存储在具有权限的节点的私有的状态数据库中。可以通过链码API在具有权限的节点上进行访问。并且私有数据不涉及排序服务，因为是通过Peer节点间的Gossip协议进行传输的。所以要求每一个节点都需要设置参数<code>CORE_PEER_GOSSIP_EXTERNALENDPOINT</code>，并在通道内设置锚节点用于跨组织通信。</p></li><li><p><strong>私有数据的哈希值</strong>：这一部分数据用于背书，排序以及写账本到通道内的每一个Peer节点。哈希值作为交易的证明用于状态验证还可以用于审计。</p></li></ol><h3 id="1-2什么时候使用私有数据"><a href="#1-2什么时候使用私有数据" class="headerlink" title="1.2什么时候使用私有数据"></a>1.2什么时候使用私有数据</h3><hr><ul><li>当所有的数据都需要在通道内的成员之间保密的时候，使用通道比较合适。</li><li>当交易要在所有组织之间传播，并且要求只有通道内的部分组织成员可以查看或操作交易内的某一部分数据时，需要使用私有数据集合。并且部分数据需要对排序节点进行保密时，使用私有数据集合。</li></ul><h3 id="1-3私有数据的交易流程"><a href="#1-3私有数据的交易流程" class="headerlink" title="1.3私有数据的交易流程"></a>1.3私有数据的交易流程</h3><pre><code>1. 当客户端提交一个调用链码的功能(读或写私有数据)提案请求到具有该私有数据集合操作权限的背书节点时,私有数据或者是用于通过链码生成私有数据的数据时，通过提案中的`transient`字段进行发送。2. 背书节点模拟交易并将私有数据存储到`peer`节点上的`transient data store`一个临时的数据存储区，并基于私有数据定义的策略，通过`Gossip`协议发送到其他具有权限的节点。3. 背书节点将提案响应发送给客户端。提案响应包括已经背书的读写集。读写集包括公共数据和私有数据的哈希值。发送给客户端的不包括任何的私有数据。4. 客户端应用提交交易(包括带有私有数据哈希值的提案响应)到排序节点。带有私有数据哈希值得交易将和正常交易一样包括在区块中。带有私有数据哈希值得区块分发到所有节点上。用这种方式，通道中所有的`peer`节点可以通过私有数据的哈希值对交易进行验证而不需要知道任何的私有数据信息。5、 在区块提交时，具有权限的节点通过集合策略确定是否具有访问私有数据的权限。如果具有权限，他们将会检查本地的`transient data store`确定他们是否已经在进行链码背书的时候接收到私有数据。如果没有，将试图从其他具有权限的节点处拉取私有数据。他们将验证公共区块中私有数据的哈希值并提交交易。当验证与提交结束后，私有数据将移动到他们的私有数据库和私有读写副本中。最后从`transient data store`中删除私有数据。</code></pre>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric 最简单的方式测试你的链码</title>
    <link href="undefined2019/11/27/blog/fabric/%E9%93%BE%E7%A0%81%E6%B5%8B%E8%AF%95/"/>
    <url>2019/11/27/blog/fabric/%E9%93%BE%E7%A0%81%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<p>一直以来，写完链码进行测试都要先搭建一个Fabric环境，然后安装链码进行测试，实际上Fabric提供了最为简单的方式可以允许我们对编写的应用链码进行功能测试，不需要搭建一个完整的Fabeic环境。而且测试完直接停止网络也不会担心有残余的文件没有删除干净，以至于搭建正式环境的时候出现各种错误。<br>进入正题好了，Fabric提供了一个开发模式，是专门用来对链码进行测试用的。</p><p><strong>其实，这些内容在Fabric官方文档中都是有的，但是一般我们都忽略掉了，所以简单说一下步骤</strong><br>官方文档地址：<a href="https://github.com/hyperledger/fabric-samples/blob/master/chaincode-docker-devmode/README.rst" target="_blank" rel="noopener">点这里</a></p><h2 id="1-先决条件"><a href="#1-先决条件" class="headerlink" title="1.先决条件"></a>1.先决条件</h2><p>首先，也是需要一些先决条件，比如<code>Golang</code>环境，<code>Docker</code>容器,<code>docker-compose</code>工具，等等，这些不再说明，可以看<a href="https://newonexd.github.io/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">这里完成先决条件的安装</a>。</p><h2 id="2-开始"><a href="#2-开始" class="headerlink" title="2.开始"></a>2.开始</h2><hr><p>完成准备工作后，我们需要将<code>Fabric-sample</code>文件夹从<code>Github</code>上<code>pull</code>下来，地址在<a href="https://github.com/hyperledger/fabric-samples" target="_blank" rel="noopener">这里</a>,最简单的方式是直接下载压缩文件，然后到本地解压出来，但是推荐使用IDE工具通过<code>git</code>工具从<code>Github</code>上拉取下来，具体方法自行百度。<br>完成之后，会有一个<code>fabric-sample</code>文件夹，将该文件夹放在<code>$GOPATH/src/github.com/hyperledger/</code>路径下，路径不存在自行创建。</p><h3 id="切换版本"><a href="#切换版本" class="headerlink" title="切换版本"></a>切换版本</h3><p>进入<code>fabric-samples</code>文件夹，执行以下命令，将Fabric版本切换至1.4，如果使用其他版本请下面部分下载二进制与Docker镜像的时候要对应。</p><pre><code>git checkout release-1.4</code></pre><h3 id="3-二进制文件以及Docker镜像"><a href="#3-二进制文件以及Docker镜像" class="headerlink" title="3.二进制文件以及Docker镜像"></a>3.二进制文件以及Docker镜像</h3><hr><p>下载二进制文件是比较容易出错的地方，因为容易因为版本不匹配导致网络启动失败，所以在下载二进制文件的时候一定要注意使用的版本。</p><pre><code>curl -sS https://raw.githubusercontent.com/hyperledger/fabric/master/scripts/bootstrap.sh -o ./scripts/bootstrap.shchmod +x ./scripts/bootstrap.sh## ./scripts/bootstrap.sh [version] [ca version] [thirdparty_version]</code></pre><p>这里需要输入三个版本号，第一个是Fabric的版本号，第二个是Ca的版本号(在这里我们用不到），第三个是第三方工具的版本号。<br>我们之前是使用了1.4的Fabric，所以我们直接指定好版本就好了。</p><ul><li>Fabric &gt;&gt; 1.4.3(只要前缀是1.4就可以)</li><li>CA    &gt;&gt;  1.4.3</li><li>ThirdParty &gt;&gt; 0.4.15</li></ul><p>完整的命令为:</p><pre><code>#记得要在bootstrap.sh文件的上一级目录进行执行。./scripts/bootstrap.sh 1.4.3 1.4.3 0.4.15</code></pre><p>或者直接将版本号在文件中修改：<br>打开刚下载的<code>bootstrap.sh</code>文件，前面几行就是指定版本号的，自行修改就好，修改完直接使用命令进行下载就好了。</p><pre><code>./scripts/bootstrap.sh</code></pre><h2 id="4-测试链码"><a href="#4-测试链码" class="headerlink" title="4.测试链码"></a>4.测试链码</h2><p>前面几部没有出现问题的话，到这里我们就可以对链码进行测试了，进入<code>fabric-sample/chaincode-docker-devmode</code>文件夹下,执行以下命令：</p><pre><code>docker-compose -f docker-compose-simple.yaml up</code></pre><p>如果没有错误的话，我们的开发环境已经准备好了，接下来是对链码进行测试的步骤：</p><ol><li>将编写的链码放到<code>fabric-sample/chaincode/</code>文件夹下<pre><code># 打开第二个终端执行：docker exec -it chaincode sh</code></pre>如果已经将链码放到<code>fabric-sample/chaincode/</code>文件夹内，执行以下命令应该可以看到自己的链码：<pre><code>ls</code></pre></li><li>编译链码,以官方的例子为例：<pre><code>cd chaincode_example02/gogo build -o chaincode_example02CORE_PEER_ADDRESS=peer:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./chaincode_example02</code></pre></li></ol><p>3.<strong>安装与实例化</strong>：<br>打开第三个终端执行：</p><pre><code>docker exec -it cli bash# 以下命令按照自己的链码内容自行修改peer chaincode install -p chaincodedev/chaincode/chaincode_example02/go -n mycc -v 0peer chaincode instantiate -n mycc -v 0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]}&#39; -C myc</code></pre><p>4 测试<br>如果以上步骤没有报错的话，准备工作已经全部完成，剩下的就是测试自己的链码了。如果链码需要更新的话，只需要关闭网络：</p><pre><code>docker-compose -f docker-compose-simple.yaml down --volumes</code></pre><p>重新启动网络并进行测试就好了。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于角色的访问控制</title>
    <link href="undefined2019/11/25/blog/etcd/%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"/>
    <url>2019/11/25/blog/etcd/%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/authentication.md" target="_blank" rel="noopener">Role-based access control</a></p><h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><hr><p>身份验证已添加到etcd 2.1中。 etcd v3 API略微修改了身份验证功能的API和用户界面，以更好地适应新的数据模型。本指南旨在帮助用户在etcd v3中设置基本身份验证和基于角色的访问控制。</p><h2 id="特殊用户和角色"><a href="#特殊用户和角色" class="headerlink" title="特殊用户和角色"></a>特殊用户和角色</h2><hr><p>有一个特殊用户<code>root</code>，一个特殊角色<code>root</code>。</p><h3 id="用户root"><a href="#用户root" class="headerlink" title="用户root"></a>用户<code>root</code></h3><p>在激活身份验证之前，必须创建对<code>etcd</code>具有完全访问权限的<code>root</code>用户。 <code>root</code>用户的想法是出于管理目的：管理角色和普通用户。 <code>root</code>用户必须具有<code>root</code>角色，并且可以在<code>etcd</code>中进行任何更改。</p><h3 id="角色root"><a href="#角色root" class="headerlink" title="角色root"></a>角色<code>root</code></h3><p>可以将角色<code>root</code>授予除<code>root</code>用户之外的任何用户。 具有<code>root</code>角色的用户既具有全局读写访问权限，又具有更新集群的身份验证配置的权限。 此外，<code>root</code>角色授予常规集群维护的特权，包括修改集群成员资格，对存储进行碎片整理以及拍摄快照。</p><h2 id="用户的工作方式"><a href="#用户的工作方式" class="headerlink" title="用户的工作方式"></a>用户的工作方式</h2><hr><p><code>etcdctl</code>的<code>user</code>子命令处理与用户帐户有关的所有事情。<br>可以通过以下方式找到用户列表：</p><pre><code>$ etcdctl user list</code></pre><p>通过以下方式创建新用户：</p><pre><code>$ etcdctl user add myusername</code></pre><p>创建新用户将提示您输入新密码。 当给出选项<code>--interactive=false</code>时，可以从标准输入中提供密码。 <code>--new-user-password</code>也可以用于提供密码。</p><p>可以通过以下方式为用户授予和撤消角色：</p><pre><code>$ etcdctl user grant-role myusername foo$ etcdctl user revoke-role myusername bar</code></pre><p>可以使用以下命令检查用户的设置：</p><pre><code>$ etcdctl user get myusername</code></pre><p>用户密码可以通过以下方式更改：</p><pre><code>$ etcdctl user passwd myusername</code></pre><p>更改密码将再次提示您输入新密码。 当给出选项<code>--interactive=false</code>时，可以从标准输入中提供密码。</p><p>通过以下方式删除帐户：</p><pre><code>$ etcdctl user delete myusername</code></pre><h3 id="角色的工作方式："><a href="#角色的工作方式：" class="headerlink" title="角色的工作方式："></a>角色的工作方式：</h3><hr><p><code>etcdctl</code>的<code>role</code>子命令处理与授予特定用户的特定角色的访问控制有关的所有事情。</p><p>列出角色：</p><pre><code>$ etcdctl role list</code></pre><p>创建一个新角色：</p><pre><code>$ etcdctl role add myrolename</code></pre><p>角色没有密码； 它仅定义了一组新的访问权限。</p><p>授予角色访问单个密钥或一系列密钥的权限。</p><p>范围可以指定为间隔[开始键，结束键]，其中开始键应按字母顺序在词汇上小于结束键。</p><p>可以将访问权限授予读取，写入或同时授予两者，如以下示例所示：</p><pre><code># Give read access to a key /foo$ etcdctl role grant-permission myrolename read /foo# Give read access to keys with a prefix /foo/. The prefix is equal to the range [/foo/, /foo0)$ etcdctl role grant-permission myrolename --prefix=true read /foo/# Give write-only access to the key at /foo/bar$ etcdctl role grant-permission myrolename write /foo/bar# Give full access to keys in a range of [key1, key5)$ etcdctl role grant-permission myrolename readwrite key1 key5# Give full access to keys with a prefix /pub/$ etcdctl role grant-permission myrolename --prefix=true readwrite /pub/</code></pre><p>要查看授予的权限，我们可以随时查看该角色：</p><pre><code>$ etcdctl role get myrolename</code></pre><p>撤消权限是按照相同的逻辑方式完成的：</p><pre><code>$ etcdctl role revoke-permission myrolename /foo/bar</code></pre><p>就像完全删除一个角色一样：</p><pre><code>$ etcdctl role delete myrolename</code></pre><h3 id="开启身份认证"><a href="#开启身份认证" class="headerlink" title="开启身份认证"></a>开启身份认证</h3><hr><p>启用身份验证的最少步骤如下。 管理员可以根据喜好在启用身份验证之前或之后设置用户和角色。</p><p>确保已创建root用户：</p><pre><code>$ etcdctl user add rootPassword of root:</code></pre><p>开启身份认证</p><pre><code>$ etcdctl auth enable</code></pre><p>此后，etcd在启用身份验证的情况下运行。 要出于任何原因禁用它，请使用reciprocal命令：</p><pre><code>$ etcdctl --user root:rootpw auth disable</code></pre><h3 id="使用etcdctl进行身份验证"><a href="#使用etcdctl进行身份验证" class="headerlink" title="使用etcdctl进行身份验证"></a>使用<code>etcdctl</code>进行身份验证</h3><hr><p><code>etcdctl</code>支持类似<code>curl</code>的标志进行身份验证。</p><pre><code>$ etcdctl --user user:password get foo</code></pre><p>可以从提示符处获取密码：</p><pre><code>$ etcdctl --user user get foo</code></pre><p>密码也可以从命令行参数<code>--password</code>获取：</p><pre><code>$ etcdctl --user user --password password get foo</code></pre><p>否则，所有<code>etcdctl</code>命令均保持不变。 用户和角色仍然可以创建和修改，但是需要具有<code>root</code>角色的用户进行身份验证。</p><h3 id="使用TLS通用名称"><a href="#使用TLS通用名称" class="headerlink" title="使用TLS通用名称"></a>使用TLS通用名称</h3><hr><p>从v3.2版本开始，如果使用参数<code>--client-cert-auth=true</code>启动etcd服务器，则客户端的TLS证书中的“通用名称（CN）”字段将用作etcd用户。在这种情况下，公用名将对用户进行身份验证，并且客户端不需要密码。请注意，如果同时传递了1. <code>--client-cert-auth=true</code>且客户端提供了CN，并且客户端提供了2.用户名和密码，则将优先考虑基于用户名和密码的身份验证。请注意，此功能不能与<code>gRPC-proxy</code>和<code>gRPC-gateway</code>一起使用。这是因为<code>gRPC-proxy</code>会从其客户端终止TLS，因此所有客户端都共享代理证书。 <code>gRPC-gateway</code>内部使用TLS连接将HTTP请求转换为gRPC请求，因此它具有相同的限制。因此，客户端不能正确地将其CN提供给服务器。如果给定证书的CN不为空，则<code>gRPC-proxy</code>将导致错误并停止。 <code>gRPC-proxy</code>返回错误，表明客户端证书中的CN为非空。</p><p>从v3.3版本开始，如果启用了带有选项<code>--peer-cert-allowed-cn</code>或<code>--peer-cert-allowed-hostname</code>的<code>etcd</code>服务器启动，则对等节点连接筛选。如果节点的TLS证书身份与允许的节点匹配，则节点只能加入etcd集群。有关更多详细信息，请参见<a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">etcd安全性页面</a>。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TLS</title>
    <link href="undefined2019/11/25/blog/etcd/TLS/"/>
    <url>2019/11/25/blog/etcd/TLS/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md" target="_blank" rel="noopener">TLS</a><br>etcd支持用于客户端到服务器以及对等方（服务器到服务器/集群）通信的自动TLS以及通过客户端证书的身份验证.<br>要启动并运行，首先要获得一个成员的CA证书和签名密钥对。 建议为集群中的每个成员创建并签名一个新的密钥对。<br>为了方便起见，<a href="https://github.com/cloudflare/cfssl" target="_blank" rel="noopener">cfssl</a>工具提供了一个简单的接口来生成证书，我们在<a href="https://github.com/etcd-io/etcd/blob/master/hack/tls-setup" target="_blank" rel="noopener">此处</a>提供了使用该工具的示例。 或者，尝试使用本指南<a href="https://github.com/coreos/docs/blob/master/os/generate-self-signed-certificates.md" target="_blank" rel="noopener">生成自签名密钥对</a>。</p><h2 id="基本设置"><a href="#基本设置" class="headerlink" title="基本设置"></a>基本设置</h2><hr><p>etcd通过命令行参数或环境变量采用了几种与证书相关的配置选项：</p><p><strong>客户端到服务器的通信：</strong><br><code>--cert-file=&lt;path&gt;</code>:用于SSL/TLS<strong>与</strong>etcd的连接的证书。设置此选项后，advertise-client-urls可以使用HTTPS模式。<br><code>--key-file=&lt;path&gt;</code>:证书的密钥。 必须未加密。<br><code>--client-cert-auth</code>:设置此选项后，etcd将检查所有传入的HTTPS请求以查找由受信任CA签名的客户端证书，不提供有效客户端证书的请求将失败。 如果启用了身份验证，则证书将为“公用名”字段指定的用户名提供凭据。<br><code>--trusted-ca-file=&lt;path&gt;</code>:受信任的证书颁发机构。<br><code>--auto-tls</code>:使用自动生成的自签名证书进行与客户端的TLS连接。</p><p><strong>对等节点(服务器到服务器/集群)间的通信：</strong><br>对等节点选项的工作方式与客户端到服务器的选项相同：<br><code>--peer-cert-file=&lt;path&gt;</code>:用于SSL/TLS<strong>与</strong>对等节点之间的连接的证书。这将用于监听对等方地址以及向其他对等方发送请求。<br><code>--peer-key-file=&lt;path&gt;</code>:证书的密钥。 必须未加密。<br><code>--peer-client-cert-auth</code>:设置此选项后，etcd将检查所有传入的对等节点请求以查找由受信任CA签名的客户端证书.<br><code>--peer-trusted-ca-file=&lt;path&gt;</code>:受信任的证书颁发机构。<br><code>--peer-auto-tls</code>:使用自动生成的自签名证书进行与对等节点之间的TLS连接。<br>如果提供了客户端到服务器或对等节点证书，则还必须设置密钥。 所有这些配置选项也可以通过环境变量<code>ETCD_CA_FILE</code>，<code>ETCD_PEER_CA_FILE</code>等获得。<br><code>--cipher-suites</code>:服务器/客户端与对等方之间受支持的TLS密码套件的逗号分隔列表（空将由Go自动填充）。从<code>v3.2.22+,v3.3.7+</code>和<code>v3.4+</code>起可用。</p><h2 id="示例1：客户端通过HTTPS与服务器进行加密传输"><a href="#示例1：客户端通过HTTPS与服务器进行加密传输" class="headerlink" title="示例1：客户端通过HTTPS与服务器进行加密传输"></a>示例1：客户端通过HTTPS与服务器进行加密传输</h2><hr><p>为此，请准备好CA证书（<code>ca.crt</code>）和签名密钥对（<code>server.crt</code>，<code>server.key</code>）。<br>让我们配置etcd以逐步提供简单的HTTPS传输安全性：</p><pre><code>$ etcd --name infra0 --data-dir infra0 \  --cert-file=/path/to/server.crt --key-file=/path/to/server.key \  --advertise-client-urls=https://127.0.0.1:2379 --listen-client-urls=https://127.0.0.1:2379</code></pre><p>这应该可以正常启动，并且可以通过对etcd用HTTPS方式来测试配置：</p><pre><code>$ curl --cacert /path/to/ca.crt https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</code></pre><p>该命令应显示握手成功。 由于我们使用具有自己的证书颁发机构的自签名证书，因此必须使用<code>--cacert</code>选项将CA传递给curl。 另一种可能性是将CA证书添加到系统的受信任证书目录（通常在<code>/etc/pki/tls/certs</code>或<code>/etc/ssl/certs</code>中）。<br><strong>OSX10.9+的用户：</strong>OSX 10.9+上的curl 7.30.0无法理解在命令行中传递的证书。可以替代的方法是将虚拟<code>ca.crt</code>直接导入到钥匙串中，或添加<code>-k</code>标志来<code>curl</code>以忽略错误。要在没有-k标志的情况下进行测试，请运行打开的<code>./fixtures/ca/ca.crt</code>并按照提示进行操作。测试后请删除此证书！如果有解决方法，请告诉我们。</p><h2 id="示例2：使用HTTPS客户端证书的客户端到服务器身份验证"><a href="#示例2：使用HTTPS客户端证书的客户端到服务器身份验证" class="headerlink" title="示例2：使用HTTPS客户端证书的客户端到服务器身份验证"></a>示例2：使用HTTPS客户端证书的客户端到服务器身份验证</h2><hr><p>目前，我们已经为etcd客户端提供了验证服务器身份并提供传输安全性的功能。 但是，我们也可以使用客户端证书来防止对etcd的未经授权的访问。<br>客户端将向服务器提供其证书，服务器将检查证书是否由提供的CA签名并决定是否满足请求。<br>为此，需要第一个示例中提到的相同文件，以及由同一证书颁发机构签名的客户端密钥对（<code>client.crt</code>，<code>client.key</code>）。</p><pre><code>$ etcd --name infra0 --data-dir infra0 \  --client-cert-auth --trusted-ca-file=/path/to/ca.crt --cert-file=/path/to/server.crt --key-file=/path/to/server.key \  --advertise-client-urls https://127.0.0.1:2379 --listen-client-urls https://127.0.0.1:2379</code></pre><p>现在，对该服务器尝试与上述相同的请求：</p><pre><code>$ curl --cacert /path/to/ca.crt https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</code></pre><p>该请求应该是被服务器拒绝：</p><pre><code>...routines:SSL3_READ_BYTES:sslv3 alert bad certificate...</code></pre><p>为了使其成功，我们需要将CA签名的客户端证书提供给服务器：</p><pre><code>$ curl --cacert /path/to/ca.crt --cert /path/to/client.crt --key /path/to/client.key \  -L https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</code></pre><p>输出应包括：</p><pre><code>...SSLv3, TLS handshake, CERT verify (15):...TLS handshake, Finished (20)</code></pre><p>以及服务器的响应：</p><pre><code>{    &quot;action&quot;: &quot;set&quot;,    &quot;node&quot;: {        &quot;createdIndex&quot;: 12,        &quot;key&quot;: &quot;/foo&quot;,        &quot;modifiedIndex&quot;: 12,        &quot;value&quot;: &quot;bar&quot;    }}</code></pre><p>指定密码套件以阻止<a href="https://github.com/etcd-io/etcd/issues/8320" target="_blank" rel="noopener">较弱的TLS密码套件</a>。<br>当使用无效密码套件请求客户端问候时，TLS握手将失败。<br>例如：</p><pre><code>$ etcd \  --cert-file ./server.crt \  --key-file ./server.key \  --trusted-ca-file ./ca.crt \  --cipher-suites TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</code></pre><p>然后，客户端请求必须指定服务器中指定的密码套件之一：</p><pre><code># 有效的加密套件$ curl \  --cacert ./ca.crt \  --cert ./server.crt \  --key ./server.key \  -L [CLIENT-URL]/metrics \  --ciphers ECDHE-RSA-AES128-GCM-SHA256# 成功请求etcd_server_version{server_version=&quot;3.2.22&quot;} 1...</code></pre><pre><code># 无效的加密套件$ curl \  --cacert ./ca.crt \  --cert ./server.crt \  --key ./server.key \  -L [CLIENT-URL]/metrics \  --ciphers ECDHE-RSA-DES-CBC3-SHA# 请求失败(35) error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert handshake failure</code></pre><h2 id="示例3：集群中的传输安全性和客户端证书"><a href="#示例3：集群中的传输安全性和客户端证书" class="headerlink" title="示例3：集群中的传输安全性和客户端证书"></a>示例3：集群中的传输安全性和客户端证书</h2><hr><p>etcd支持与上述对等节点通信相同的模型，这意味着集群中etcd成员之间的通信。<br>假设我们有这个<code>ca.crt</code>和两个由此CA签名的成员，它们具有自己的密钥对（<code>member1.crt</code>和<code>member1.key</code>，<code>member2.crt</code>和<code>member2.key</code>），我们按以下方式启动etcd：</p><pre><code>DISCOVERY_URL=... # from https://discovery.etcd.io/new# member1$ etcd --name infra1 --data-dir infra1 \  --peer-client-cert-auth --peer-trusted-ca-file=/path/to/ca.crt --peer-cert-file=/path/to/member1.crt --peer-key-file=/path/to/member1.key \  --initial-advertise-peer-urls=https://10.0.1.10:2380 --listen-peer-urls=https://10.0.1.10:2380 \  --discovery ${DISCOVERY_URL}# member2$ etcd --name infra2 --data-dir infra2 \  --peer-client-cert-auth --peer-trusted-ca-file=/path/to/ca.crt --peer-cert-file=/path/to/member2.crt --peer-key-file=/path/to/member2.key \  --initial-advertise-peer-urls=https://10.0.1.11:2380 --listen-peer-urls=https://10.0.1.11:2380 \  --discovery ${DISCOVERY_URL}</code></pre><p>etcd成员将形成一个集群，并且集群中成员之间的所有通信都将使用客户端证书进行加密和身份验证。 etcd的输出将显示它连接以使用HTTPS的地址。</p><h2 id="示例4：自动自签名传输安全性"><a href="#示例4：自动自签名传输安全性" class="headerlink" title="示例4：自动自签名传输安全性"></a>示例4：自动自签名传输安全性</h2><hr><p>对于需要通信加密而不是身份验证的情况，etcd支持使用自动生成的自签名证书来加密其消息。 因为不需要在etcd之外管理证书和密钥，所以这简化了部署。<br>配置etcd以使用带有<code>--auto-tls</code>和<code>--peer-auto-tls</code>标志的自签名证书进行客户端和对等节点连接：</p><pre><code>DISCOVERY_URL=... # from https://discovery.etcd.io/new# member1$ etcd --name infra1 --data-dir infra1 \  --auto-tls --peer-auto-tls \  --initial-advertise-peer-urls=https://10.0.1.10:2380 --listen-peer-urls=https://10.0.1.10:2380 \  --discovery ${DISCOVERY_URL}# member2$ etcd --name infra2 --data-dir infra2 \  --auto-tls --peer-auto-tls \  --initial-advertise-peer-urls=https://10.0.1.11:2380 --listen-peer-urls=https://10.0.1.11:2380 \  --discovery ${DISCOVERY_URL}</code></pre><p>自签名证书不会验证身份，因此curl将返回错误：</p><pre><code>curl: (60) SSL certificate problem: Invalid certificate chain</code></pre><p>要禁用证书链检查，请使用<code>-k</code>标志调用<code>curl</code>：</p><pre><code>$ curl -k https://127.0.0.1:2379/v2/keys/foo -Xput -d value=bar -v</code></pre><h2 id="DNS-SRV的注意事项"><a href="#DNS-SRV的注意事项" class="headerlink" title="DNS SRV的注意事项"></a>DNS SRV的注意事项</h2><hr><p>如果连接是安全的，则<code>etcd proxy</code>从其客户端TLS终端，并使用<code>--peer-key-file</code>和<code>--peer-cert-file</code>中指定的代理自身的密钥/证书与etcd成员进行通信。</p><p>代理通过给定成员的<code>--advertise-client-urls</code>和<code>--advertise-peer-urls</code>与etcd成员进行通信。 它将客户端请求转发到etcd成员广播的客户端URL，并通过etcd成员广播的对等URL同步初始集群配置。</p><p>为etcd成员启用客户端身份验证后，管理员必须确保代理的<code>--peer-cert-file</code>选项中指定的对等节点证书对该身份验证有效。如果启用了对等节点身份验证，则代理的对等节点证书也必须对对等节点身份验证有效。</p><h2 id="TLS-身份验证的注意事项"><a href="#TLS-身份验证的注意事项" class="headerlink" title="TLS 身份验证的注意事项"></a>TLS 身份验证的注意事项</h2><hr><p>从<a href="https://github.com/etcd-io/etcd/pull/7829" target="_blank" rel="noopener">v3.2.0开始，TLS证书将在每个客户端连接上重新加载</a>。 这在不停止etcd服务器而替换到期证书时很有用； 可以通过用新证书覆盖旧证书来完成。 刷新每个连接的证书应该没有太多的开销，但是将来可以通过缓存层进行改进。 示例测试可以在<a href="https://github.com/coreos/etcd/blob/b041ce5d514a4b4aaeefbffb008f0c7570a18986/integration/v3_grpc_test.go#L1601-L1757" target="_blank" rel="noopener">这里</a>找到。</p><p>从<a href="https://github.com/etcd-io/etcd/pull/7687" target="_blank" rel="noopener">v3.2.0开始，服务器使用错误的IP <code>SAN</code>拒绝传入的对等证书</a>。 例如，如果对等节点证书在“使用者备用名称”（SAN）字段中包含任何IP地址，则服务器仅在远程IP地址与这些IP地址之一匹配时才对对等节点身份验证。 这是为了防止未经授权的端点加入群集。 例如，对等节点B的CSR（带有cfssl）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;*.example.default.svc&quot;,    &quot;*.example.default.svc.cluster.local&quot;,    &quot;10.138.0.27&quot;  ],  &quot;key&quot;: {    &quot;algo&quot;: &quot;rsa&quot;,    &quot;size&quot;: 2048  },  &quot;names&quot;: [    {      &quot;C&quot;: &quot;US&quot;,      &quot;L&quot;: &quot;CA&quot;,      &quot;ST&quot;: &quot;San Francisco&quot;    }  ]}</code></pre><p>当对等节点B的实际IP地址是<code>10.138.0.2</code>，而不是<code>10.138.0.27</code>。 当对等节点B尝试加入集群时，对等节点A将拒绝B，并显示错误x509：证书对<code>10.138.0.27</code>有效，而不对<code>10.138.0.2</code>有效，因为B的远程IP地址与“使用者备用名称（SAN）”字段中的地址不匹配。</p><p>从<a href="https://github.com/etcd-io/etcd/pull/7767" target="_blank" rel="noopener">v3.2.0开始，服务器在检查SAN时解析TLS DNSNames</a>。 例如，如果对等节点证书在“使用者备用名称”（SAN）字段中仅包含DNS名称（不包含IP地址），则仅当这些DNS名称上的正向查找（<code>dig b.com</code>）具有与远程IP匹配的IP时，服务器才对对等身份验证 地址。 例如，对等B的CSR（带有<code>cfssl</code>）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;b.com&quot;  ],</code></pre><p>当对等节点B的远程IP地址为<code>10.138.0.2</code>时。 当对等节点B尝试加入集群时，对等节点A查找传入的主机<code>b.com</code>以获取IP地址列表（例如<code>dig b.com</code>）。如果列表不包含IP <code>10.138.0.2</code>，则出现错误<code>tls: 10.138.0.2 does not match any of DNSNames [&quot;b.com&quot;]</code>.</p><p>从<a href="https://github.com/etcd-io/etcd/pull/8223" target="_blank" rel="noopener">v3.2.2开始，如果IP匹配，服务器将接受连接，而无需检查DNS条目</a>。 例如，如果对等节点证书在“使用者备用名称（SAN）”字段中包含IP地址和DNS名称，并且远程IP地址与这些IP地址之一匹配，则服务器仅接受连接而无需进一步检查DNS名称。 例如，对等节点B的CSR（带有<code>cfssl</code>）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;invalid.domain&quot;,    &quot;10.138.0.2&quot;  ],</code></pre><p>当对等节点B的远程IP地址是<code>10.138.0.2</code>并且<code>invalid.domain</code>是无效的主机时。 当对等节点B尝试加入集群时，对等节点A成功地对节点B进行了身份验证，因为“使用者备用名称（SAN）”字段具有有效的匹配IP地址。 有关更多详细信息，请参见问题<a href="https://github.com/etcd-io/etcd/issues/8206" target="_blank" rel="noopener">＃8206</a>。</p><p>从<a href="https://github.com/etcd-io/etcd/pull/8281" target="_blank" rel="noopener">v3.2.5开始，服务器支持在通配符DNS <code>SAN</code>上进行反向查找</a>。 例如，如果对等节点证书在“使用者备用名称”（SAN）字段中仅包含DNS名称（不包含IP地址），则服务器首先对远程IP地址进行反向查找，以获取映射到该地址的名称列表（例如<code>nslookup IPADDR</code>）。如果这些名称的名称与对等节点证书的DNS名称（通过完全匹配或通配符匹配）匹配，则接受连接。 如果没有匹配项，则服务器将对等节点证书中的每个DNS条目进行正向查找（例如，如果条目为<code>*.example.default.svc</code>，则查找<code>example.default.svc</code>），并且仅在主机的解析地址具有匹配的IP时接受连接 地址和对等节点的远程IP地址。 例如，对等B的CSR（带有<code>cfssl</code>）为：</p><pre><code>{  &quot;CN&quot;: &quot;etcd peer&quot;,  &quot;hosts&quot;: [    &quot;*.example.default.svc&quot;,    &quot;*.example.default.svc.cluster.local&quot;  ],</code></pre><p>当对等节点B的远程IP地址为<code>10.138.0.2</code>时。 当对等节点B尝试加入集群时，对等节点A反向查找IP <code>10.138.0.2</code>以获取主机名列表。 并且，“主题备用名称”（SAN）字段中的主机名必须与对等节点B的证书DNS名称完全匹配或与通配符匹配。 如果反向/正向查找均无效，则返回错误<code>&quot;tls: &quot;10.138.0.2&quot; does not match any of DNSNames [&quot;*.example.default.svc&quot;,&quot;*.example.default.svc.cluster.local&quot;]</code>。有关更多详细信息，请参见问题<a href="https://github.com/etcd-io/etcd/issues/8268" target="_blank" rel="noopener">＃8268</a>。</p><p><a href="https://github.com/etcd-io/etcd/blob/master/CHANGELOG-3.3.md" target="_blank" rel="noopener">v3.3.0</a>添加了<a href="https://github.com/etcd-io/etcd/pull/8616" target="_blank" rel="noopener">etcd –peer-cert-allowed-cn</a>参数，以支持<a href="https://github.com/etcd-io/etcd/issues/8262" target="_blank" rel="noopener">基于CN（通用名称）的对等节点连接的身份验证</a>。 Kubernetes TLS引导涉及为etcd成员和其他系统组件（例如API服务器，kubelet等）生成动态证书。 为每个组件维护不同的CA可提供对etcd集群的更严格的访问控制，但通常很乏味。 指定<code>--peer-cert-allowed-cn</code>标志时，即使具有共享的CA，节点也只能以匹配的通用名称加入。 例如，三节点群集中的每个成员都设置有CSR（使用<code>cfssl</code>），如下所示：</p><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;m1.etcd.local&quot;,    &quot;127.0.0.1&quot;,    &quot;localhost&quot;  ],</code></pre><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;m2.etcd.local&quot;,    &quot;127.0.0.1&quot;,    &quot;localhost&quot;  ],</code></pre><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;m3.etcd.local&quot;,    &quot;127.0.0.1&quot;,    &quot;localhost&quot;  ],</code></pre><p>如果给定<code>--peer-cert-allowed-cn etcd.local</code>，则只有具有相同通用名称的对等方将被认证。 CSR中具有不同CN或<code>--peer-cert-allowed-cn</code>的节点将被拒绝：</p><pre><code>$ etcd --peer-cert-allowed-cn m1.etcd.localI | embed: rejected connection from &quot;127.0.0.1:48044&quot; (error &quot;CommonName authentication failed&quot;, ServerName &quot;m1.etcd.local&quot;)I | embed: rejected connection from &quot;127.0.0.1:55702&quot; (error &quot;remote error: tls: bad certificate&quot;, ServerName &quot;m3.etcd.local&quot;)</code></pre><p>每个进程都应以以下内容开始：</p><pre><code>etcd --peer-cert-allowed-cn etcd.localI | pkg/netutil: resolving m3.etcd.local:32380 to 127.0.0.1:32380I | pkg/netutil: resolving m2.etcd.local:22380 to 127.0.0.1:22380I | pkg/netutil: resolving m1.etcd.local:2380 to 127.0.0.1:2380I | etcdserver: published {Name:m3 ClientURLs:[https://m3.etcd.local:32379]} to cluster 9db03f09b20de32bI | embed: ready to serve client requestsI | etcdserver: published {Name:m1 ClientURLs:[https://m1.etcd.local:2379]} to cluster 9db03f09b20de32bI | embed: ready to serve client requestsI | etcdserver: published {Name:m2 ClientURLs:[https://m2.etcd.local:22379]} to cluster 9db03f09b20de32bI | embed: ready to serve client requestsI | embed: serving client requests on 127.0.0.1:32379I | embed: serving client requests on 127.0.0.1:22379I | embed: serving client requests on 127.0.0.1:2379</code></pre><p><a href="https://github.com/etcd-io/etcd/blob/master/CHANGELOG-3.2.md" target="_blank" rel="noopener">v3.2.19</a>和<a href="https://github.com/etcd-io/etcd/blob/master/CHANGELOG-3.3.md" target="_blank" rel="noopener">v3.3.4</a>修复了<a href="https://github.com/etcd-io/etcd/issues/9541" target="_blank" rel="noopener">当证书SAN字段仅包含IP地址但不包含域名时TLS重新加载的问题</a>。 例如，如下设置了具有CSR（具有<code>cfssl</code>）的成员：</p><pre><code>{  &quot;CN&quot;: &quot;etcd.local&quot;,  &quot;hosts&quot;: [    &quot;127.0.0.1&quot;  ],</code></pre><p>在Go中，仅当服务器的<code>（* tls.Config）.Certificates</code>字段不为空或<code>（* tls.ClientHelloInfo）.ServerName</code>不为空且具有有效SNI时，服务器才会调用<code>（* tls.Config）.GetCertificate</code>来重新加载TLS 来自客户。 以前，etcd始终填充<code>（* tls.Config）</code>。在初始客户端TLS握手上的证书为非空。 因此，总是希望客户端提供匹配的SNI，以便通过TLS验证并触发<code>（* tls.Config）.GetCertificate</code>以重新加载TLS数据。</p><p>但是，其SAN字段<a href="https://github.com/etcd-io/etcd/issues/9541" target="_blank" rel="noopener">仅包括IP地址不包含任何域名的证书</a>将请求<code>* tls.ClientHelloInfo</code>带有空的<code>ServerName</code>字段，从而无法在初始TLS握手时触发TLS重新加载；当需要在线更换过期证书时，这将成为一个问题。</p><p>现在,<code>（* tls.Config）.Certificates</code>在初始TLS客户端握手时创建为空，首先触发<code>（* tls.Config）.GetCertificate</code>，然后在每个新的TLS连接上填充其余证书，即使客户端SNI为 为空（例如，证书仅包括IP）。</p><h2 id="主机白名单的注意事项"><a href="#主机白名单的注意事项" class="headerlink" title="主机白名单的注意事项"></a>主机白名单的注意事项</h2><hr><p><code>etcd --host-whitelist</code>参数指定HTTP客户端请求中可接受的主机名。 客户端源策略可以防止对不安全的etcd服务器的“<a href="https://en.wikipedia.org/wiki/DNS_rebinding" target="_blank" rel="noopener">DNS重新绑定</a>”攻击。 也就是说，任何网站都可以简单地创建一个授权的DNS名称，并将DNS定向到“<code>localhost</code>”（或任何其他地址）。 然后，侦听“<code>localhost</code>”上的etcd服务器的所有HTTP端点都可以访问，因此容易受到DNS重新绑定攻击。 有关更多详细信息，请参见<a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=1447#c2" target="_blank" rel="noopener">CVE-2018-5702</a>。</p><p>客户原始策略的工作方式如下：</p><ol><li>如果客户端通过HTTPS连接是安全的，则允许使用任何主机名。</li><li>如果客户端连接不安全且“<code>HostWhitelist</code>”不为空，则仅允许其Host字段列在白名单中的HTTP请求。</li></ol><p>请注意，无论是否启用身份验证，都会实施客户端来源策略，以进行更严格的控制。</p><p>默认情况下，<code>etcd --host-whitelist</code>和<code>embed.Config.HostWhitelist</code>设置为空以允许所有主机名。请注意，在指定主机名时，不会自动添加回送地址。 要允许环回接口，请手动将其添加到白名单（例如“ <code>localhost</code>”，“<code>127.0.0.1</code>”等）。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><hr><p>使用TLS客户端身份验证时，我看到SSLv3警报握手失败？<br><code>golang</code>的<code>crypto/tls</code>软件包在使用之前检查证书公钥的密钥用法。要使用证书公共密钥进行客户端身份验证，我们需要在创建证书公共密钥时将<code>clientAuth</code>添加到“<code>Extended Key Usage</code>”中。</p><p>这是操作方法：</p><p>将以下部分添加到openssl.cnf中：</p><pre><code>[ ssl_client ]...  extendedKeyUsage = clientAuth...</code></pre><p>创建证书时，请确保在<code>-extensions</code>参数中引用它：</p><pre><code>$ openssl ca -config openssl.cnf -policy policy_anything -extensions ssl_client -out certs/machine.crt -infiles machine.csr</code></pre><p>通过对等证书身份验证，我收到“证书对127.0.0.1有效，而不对$我的Ip有效”</p><p>确保使用主题名称（成员的公共IP地址）对证书进行签名。 例如，<code>etcd-ca</code>工具为其<code>new-cert</code>命令提供了<code>--ip=</code>选项。</p><p>需要在其使用者名称中为成员的FQDN签署证书，使用使用者备用名称（简称IP SAN）添加IP地址。 <code>etcd-ca</code>工具为其<code>new-cert</code>命令提供了<code>--domain=</code>选项，<code>openssl</code>也可以做到<a href="http://wiki.cacert.org/FAQ/subjectAltName" target="_blank" rel="noopener">这</a>一点。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>系统限制</title>
    <link href="undefined2019/11/25/blog/etcd/%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/"/>
    <url>2019/11/25/blog/etcd/%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/limit.md" target="_blank" rel="noopener">System limits</a></p><h2 id="请求大小限制"><a href="#请求大小限制" class="headerlink" title="请求大小限制"></a>请求大小限制</h2><hr><p>etcd被设计用来处理小键值对典型的如元数据。较大的请求数据也起作用，但可能会增加其他请求的延迟。默认情况下，任意的请求最大的空间为1.5MiB，这个限制参数可以通过<code>--max-request-bytes</code>参数对etcd服务器进行配置。</p><h2 id="存储大小限制"><a href="#存储大小限制" class="headerlink" title="存储大小限制"></a>存储大小限制</h2><hr><p>默认的存储大小限制为2GB,可以通过参数<code>--quota-backend-bytes</code>进行配置。正常环境下8GB是etcd支持的最大存储大小，如果配置的值超过它，etcd将在启动时发出警告。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>词汇表</title>
    <link href="undefined2019/11/24/blog/etcd/%E8%AF%8D%E6%B1%87%E8%A1%A8/"/>
    <url>2019/11/24/blog/etcd/%E8%AF%8D%E6%B1%87%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/glossary.md" target="_blank" rel="noopener">词汇表</a><br>本文档定义了etcd文档，命令行和源代码中使用的各种术语。</p><h3 id="Alarm"><a href="#Alarm" class="headerlink" title="Alarm"></a>Alarm</h3><hr><p>每当集群需要操作员干预以保持可靠性时，etcd服务器都会发出警报。</p><h3 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h3><hr><p>身份验证管理etcd资源的用户访问权限。</p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><hr><p>客户端连接到etcd集群以发出服务请求，例如获取键值对，写入数据或监视更新。</p><h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><hr><p>集群由几个成员组成。</p><p>每个成员中的节点均遵循Raft共识协议来复制日志。 集群从成员那里接收提议，将它们提交并应用于本地存储。</p><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><hr><p>在给定修订之前，压缩会丢弃所有etcd事件历史记录和取代的密钥。 它用于回收etcd后端数据库中的存储空间。</p><h3 id="Election"><a href="#Election" class="headerlink" title="Election"></a>Election</h3><hr><p>etcd集群在其成员之间举行选举，以选择一名领导人作为Raft共识协议的一部分。</p><h3 id="Endpoint"><a href="#Endpoint" class="headerlink" title="Endpoint"></a>Endpoint</h3><hr><p>指向etcd服务或资源的URL。</p><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><hr><p>用户定义的标识符，用于在etcd中存储和检索用户定义的值。</p><h3 id="Key-range"><a href="#Key-range" class="headerlink" title="Key range"></a>Key range</h3><hr><p>包含单个键，所有x的词法间隔（例如a &lt;x &lt;= b）或大于给定键的所有键的一组键。</p><h3 id="Keyspace"><a href="#Keyspace" class="headerlink" title="Keyspace"></a>Keyspace</h3><hr><p>etcd集群中所有键的集合。</p><h3 id="Lease"><a href="#Lease" class="headerlink" title="Lease"></a>Lease</h3><hr><p>短期可再生合同，在合同到期时会删除与其相关的密钥。</p><h3 id="Member"><a href="#Member" class="headerlink" title="Member"></a>Member</h3><hr><p>参与为etcd集群提供服务的逻辑etcd服务器。</p><h3 id="Modification-Revision"><a href="#Modification-Revision" class="headerlink" title="Modification Revision"></a>Modification Revision</h3><hr><p>保留对给定密钥的最后一次写入的第一个修订版。</p><h3 id="Peer"><a href="#Peer" class="headerlink" title="Peer"></a>Peer</h3><hr><p>同一集群的另一个对等成员。</p><h3 id="Proposal"><a href="#Proposal" class="headerlink" title="Proposal"></a>Proposal</h3><hr><p>提案是需要通过raft协议的请求（例如，写入请求，配置更改请求）。</p><h3 id="Quorum"><a href="#Quorum" class="headerlink" title="Quorum"></a>Quorum</h3><hr><p>达成共识才能修改集群状态所需的活动成员数。 etcd需要拥有多数才能达到法定人数。</p><h3 id="Revision"><a href="#Revision" class="headerlink" title="Revision"></a>Revision</h3><hr><p>每次修改键空间时都会增加的64位群集范围计数器。</p><h3 id="Role"><a href="#Role" class="headerlink" title="Role"></a>Role</h3><hr><p>一组密钥范围内的许可单位，可以将其授予一组用户以进行访问控制。</p><h3 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h3><hr><p>etcd群集状态的时间点备份。</p><h3 id="Store"><a href="#Store" class="headerlink" title="Store"></a>Store</h3><hr><p>支持集群键空间的物理存储。</p><h3 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h3><hr><p>原子执行的一组操作。 事务中所有已修改的键共享相同的修改版本。</p><h3 id="Key-Version"><a href="#Key-Version" class="headerlink" title="Key Version"></a>Key Version</h3><hr><p>自创建以来，对密钥的写入次数（从1开始）。不存在或已删除的密钥的版本为0。</p><h3 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a>Watcher</h3><hr><p>客户端打开观察者以观察给定键范围上的更新。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在容器中运行etcd集群</title>
    <link href="undefined2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/"/>
    <url>2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/container.md#docker" target="_blank" rel="noopener">Docker container</a><br>以下指南显示了如何使用<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">静态引导过程</a>在rkt和Docker上运行etcd。</p><h2 id="rkt"><a href="#rkt" class="headerlink" title="rkt"></a><strong>rkt</strong></h2><hr><p><strong>运行单节点的etcd</strong><br>以下rkt run命令将在端口2379上公开etcd客户端API，并在端口2380上公开对等API。</p><p>配置etcd时使用主机IP地址。</p><pre><code>export NODE1=192.168.1.21</code></pre><p>信任CoreOS <a href="https://coreos.com/security/app-signing-key/" target="_blank" rel="noopener">App签名密钥</a>。</p><pre><code>sudo rkt trust --prefix quay.io/coreos/etcd# gpg key fingerprint is: 18AD 5014 C99E F7E3 BA5F  6CE9 50BD D3E0 FC8A 365E</code></pre><p>运行etcd v3.2版本或指定其他发行版本。</p><pre><code>sudo rkt run --net=default:IP=${NODE1} quay.io/coreos/etcd:v3.2 -- -name=node1 -advertise-client-urls=http://${NODE1}:2379 -initial-advertise-peer-urls=http://${NODE1}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE1}:2380 -initial-cluster=node1=http://${NODE1}:2380</code></pre><p>列出集群成员：</p><pre><code>etcdctl --endpoints=http://192.168.1.21:2379 member list</code></pre><p><strong>运行3个节点的etcd</strong><br>使用<code>-initial-cluster</code>参数在本地使用rkt设置3节点集群。</p><pre><code>export NODE1=172.16.28.21export NODE2=172.16.28.22export NODE3=172.16.28.23</code></pre><pre><code># node 1sudo rkt run --net=default:IP=${NODE1} quay.io/coreos/etcd:v3.2 -- -name=node1 -advertise-client-urls=http://${NODE1}:2379 -initial-advertise-peer-urls=http://${NODE1}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE1}:2380 -initial-cluster=node1=http://${NODE1}:2380,node2=http://${NODE2}:2380,node3=http://${NODE3}:2380# node 2sudo rkt run --net=default:IP=${NODE2} quay.io/coreos/etcd:v3.2 -- -name=node2 -advertise-client-urls=http://${NODE2}:2379 -initial-advertise-peer-urls=http://${NODE2}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE2}:2380 -initial-cluster=node1=http://${NODE1}:2380,node2=http://${NODE2}:2380,node3=http://${NODE3}:2380# node 3sudo rkt run --net=default:IP=${NODE3} quay.io/coreos/etcd:v3.2 -- -name=node3 -advertise-client-urls=http://${NODE3}:2379 -initial-advertise-peer-urls=http://${NODE3}:2380 -listen-client-urls=http://0.0.0.0:2379 -listen-peer-urls=http://${NODE3}:2380 -initial-cluster=node1=http://${NODE1}:2380,node2=http://${NODE2}:2380,node3=http://${NODE3}:2380</code></pre><p>验证集群是否健康并且可以访问。</p><pre><code>ETCDCTL_API=3 etcdctl --endpoints=http://172.16.28.21:2379,http://172.16.28.22:2379,http://172.16.28.23:2379 endpoint health</code></pre><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>通过本地解析器已知的DNS名称引用对等方的生产群集必须安装<a href="https://coreos.com/tectonic/docs/latest/tutorials/sandbox/index.html#customizing-rkt-options" target="_blank" rel="noopener">主机的DNS配置</a>。</p><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a><strong>Docker</strong></h2><p>为了向Docker主机外部的客户端公开etcd API，请使用容器的主机IP地址。 请参阅<a href="https://docs.docker.com/engine/reference/commandline/inspect/" target="_blank" rel="noopener">docker inspect</a>了解有关如何获取IP地址的更多详细信息。 或者，为<code>docker run</code>命令指定<code>--net = host</code>标志，以跳过将容器放置在单独的网络堆栈内的操作。<br><strong>运行单节点的etcd</strong><br>适用主机Ip地址配置etcd：</p><pre><code>export NODE1=192.168.1.21</code></pre><p>配置Docker卷存储etcd数据:</p><pre><code>docker volume create --name etcd-dataexport DATA_DIR=&quot;etcd-data&quot;</code></pre><p>运行最新版本的etcd：</p><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=gcr.io/etcd-development/etcddocker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:latest \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name node1 \  --initial-advertise-peer-urls http://${NODE1}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${NODE1}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster node1=http://${NODE1}:2380</code></pre><p>列出集群成员：</p><pre><code>etcdctl --endpoints=http://${NODE1}:2379 member list</code></pre><p><strong>运行3个节点的etcd</strong></p><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=gcr.io/etcd-development/etcd# For each machineETCD_VERSION=latestTOKEN=my-etcd-tokenCLUSTER_STATE=newNAME_1=etcd-node-0NAME_2=etcd-node-1NAME_3=etcd-node-2HOST_1=10.20.30.1HOST_2=10.20.30.2HOST_3=10.20.30.3CLUSTER=${NAME_1}=http://${HOST_1}:2380,${NAME_2}=http://${HOST_2}:2380,${NAME_3}=http://${HOST_3}:2380DATA_DIR=/var/lib/etcd# For node 1THIS_NAME=${NAME_1}THIS_IP=${HOST_1}docker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:${ETCD_VERSION} \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name ${THIS_NAME} \  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster ${CLUSTER} \  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}# For node 2THIS_NAME=${NAME_2}THIS_IP=${HOST_2}docker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:${ETCD_VERSION} \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name ${THIS_NAME} \  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster ${CLUSTER} \  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}# For node 3THIS_NAME=${NAME_3}THIS_IP=${HOST_3}docker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=${DATA_DIR}:/etcd-data \  --name etcd ${REGISTRY}:${ETCD_VERSION} \  /usr/local/bin/etcd \  --data-dir=/etcd-data --name ${THIS_NAME} \  --initial-advertise-peer-urls http://${THIS_IP}:2380 --listen-peer-urls http://0.0.0.0:2380 \  --advertise-client-urls http://${THIS_IP}:2379 --listen-client-urls http://0.0.0.0:2379 \  --initial-cluster ${CLUSTER} \  --initial-cluster-state ${CLUSTER_STATE} --initial-cluster-token ${TOKEN}</code></pre><p>适用版本v3的<code>etcdctl</code>：</p><pre><code>docker exec etcd /bin/sh -c &quot;export ETCDCTL_API=3 &amp;&amp; /usr/local/bin/etcdctl put foo bar&quot;</code></pre><h2 id="Bare-Metal"><a href="#Bare-Metal" class="headerlink" title="Bare Metal"></a>Bare Metal</h2><hr><p>要在裸机上配置3节点etcd集群，<a href="https://github.com/poseidon/matchbox/tree/master/examples" target="_blank" rel="noopener">裸机存储库</a>中的示例可能会有用。</p><h4 id="挂载一个证书卷："><a href="#挂载一个证书卷：" class="headerlink" title="挂载一个证书卷："></a>挂载一个证书卷：</h4><p>etcd发布容器不包含默认的根证书。 要将HTTPS与受根权限信任的证书一起使用（例如，用于发现），请将证书目录安装到etcd容器中：</p><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=docker://gcr.io/etcd-development/etcdrkt run \  --insecure-options=image \  --volume etcd-ssl-certs-bundle,kind=host,source=/etc/ssl/certs/ca-certificates.crt \  --mount volume=etcd-ssl-certs-bundle,target=/etc/ssl/certs/ca-certificates.crt \  ${REGISTRY}:latest -- --name my-name \  --initial-advertise-peer-urls http://localhost:2380 --listen-peer-urls http://localhost:2380 \  --advertise-client-urls http://localhost:2379 --listen-client-urls http://localhost:2379 \  --discovery https://discovery.etcd.io/c11fbcdc16972e45253491a24fcf45e1</code></pre><pre><code>REGISTRY=quay.io/coreos/etcd# available from v3.2.5REGISTRY=gcr.io/etcd-development/etcddocker run \  -p 2379:2379 \  -p 2380:2380 \  --volume=/etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt \  ${REGISTRY}:latest \  /usr/local/bin/etcd --name my-name \  --initial-advertise-peer-urls http://localhost:2380 --listen-peer-urls http://localhost:2380 \  --advertise-client-urls http://localhost:2379 --listen-client-urls http://localhost:2379 \  --discovery https://discovery.etcd.io/86a9ff6c8cb8b4c4544c1a2f88f8b801</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CouchDB学习一</title>
    <link href="undefined2019/11/24/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0%E4%B8%80/"/>
    <url>2019/11/24/blog/couchDB/CouchDB%E5%AD%A6%E4%B9%A0%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<h2 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h2><table><thead><tr><th>端口号</th><th>协议</th><th>作用</th></tr></thead><tbody><tr><td>5984</td><td>tcp</td><td>标椎集群端口用于所有的HTTP API请求</td></tr><tr><td>5986</td><td>tcp</td><td>用于管理员对节点与分片的管理</td></tr><tr><td>4369</td><td>tcp</td><td>Erlang端口到daemon的映射</td></tr></tbody></table><h3 id="配置介绍"><a href="#配置介绍" class="headerlink" title="配置介绍"></a>配置介绍</h3><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>CouchDb从以下位置按顺序读取配置文件</p><ul><li>etc/fefault.ini</li><li>etc/default.d/*.ini</li><li>etc/local.ini</li><li>etc/local.d/*.ini</li></ul><p>类UNIX系统：<code>/opt/couchdb/</code><br>Windows系统:<code>C:\CouchDB</code><br>maxOS:<code>Applications/Apache CouchDB.app/Contents/Resources/couchdbx-core/etc</code>下的<code>default.ini</code>和<code>default.d</code>文件夹。<code>/Users/youruser/Library/Application Support/CouchDB2/etc/couchdb</code>下的<code>default.ini</code>和<code>default.d</code>文件夹.</p><h4 id="通过HTTP-API修改参数"><a href="#通过HTTP-API修改参数" class="headerlink" title="通过HTTP API修改参数"></a>通过HTTP API修改参数</h4><p><strong>集群</strong>：</p><pre><code>curl -X PUT http://localhost:5984/_node/name@host/_config/uuids/algorithm -d &#39;&quot;random&quot;&#39;</code></pre><p><strong>单节点</strong></p><pre><code>curl -X PUT http://localhost:5984/_node/_local/_config/uuids/algorithm -d &#39;&quot;random&quot;&#39;</code></pre><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><h4 id="couchdb配置"><a href="#couchdb配置" class="headerlink" title="couchdb配置"></a>couchdb配置</h4><p><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/couchdb/</code>后接参数.</p><ul><li>attachment_stream-buffer_size<br>  缓冲池大小，越大读性能越好，但增加写操作的响应时间.</li><li>database_dir<br>  数据库文件地址</li><li>default_security<br>  默认的安全级别<code>admin_local</code>. <code>everyone</code>:任何人都可以读和写。<code>admin_only</code>：只有admin可以读和写.<code>admin_local</code>:被分片的数据库可以被任何人读和写，但分片只可以被admin读和写.</li><li>delayed_commits<br>  延迟提交 <code>false</code>保证同步.<code>true</code>可以提高性能。</li><li>file_compression<br>  文件压缩默认<code>snappy</code>。<code>none</code>：不进行压缩。<code>snappy</code>：使用谷歌的snappy.<code>deflate_N</code>：使用<code>zlib</code>,N为压缩等级从1(速度最快，压缩率最低)到9(速度最慢，压缩率最高).</li><li>fsync_options<br>  缓冲区内的文件是否与操作系统同步刷新到硬盘中.一般不需要修改.<code>fsync_options=[before_header,after_header,on_file_open]</code></li><li>max_dbs_open<br>  同时打开数据库的最大数量默认为100.</li><li>os_process_timeout<br>  处理超时时间默认5000ms</li><li>uri_file<br>  该参数指定的文件包含完整的用来访问CouchDB数据库实例的<code>URI</code>.默认值：<code>/var/run/couchdb/couchdb.uri</code></li><li>users_db_suffix<br>  用户数据库后缀，默认<code>_users</code>.</li><li>util_driver_dir<br>  二进制驱动的位置。</li><li>uuid<br>  CouchDb服务器实例的唯一标识符</li><li>view_index_dir<br>  CouchDB视图索引文件的位置。默认值:<code>/var/lib/couchdb</code></li><li>maintenance_mode<br>  CouchDb节点可以使用的两种维护模式 <code>true</code>:该节点不会响应集群中其他节点的请求并且<code>/_up</code>端点将返回404响应.<code>nolb</code>:<code>/_up</code>端点将返回404响应.<code>false</code>:该节点正常响应200。</li><li>max_document_size<br>  文档的最大的大小默认为4GB</li></ul><h3 id="cluster-配置"><a href="#cluster-配置" class="headerlink" title="cluster 配置"></a>cluster 配置</h3><h4 id="集群选项"><a href="#集群选项" class="headerlink" title="集群选项"></a>集群选项</h4><p><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/cluster/</code>后接参数.</p><ul><li>q<br>  新创建的数据库的分片数量，默认为8</li><li>n<br>  集群中每一个数据库文档的副本数。单节点为1，每个节点最多仅持有一个副本。</li><li>placement</li><li>seedlist<br>  以逗号分隔的节点名称列表，当前节点应与之通信加入集群。</li></ul><h3 id="couch-peruser"><a href="#couch-peruser" class="headerlink" title="couch_peruser"></a>couch_peruser</h3><h4 id="couch-peruser配置"><a href="#couch-peruser配置" class="headerlink" title="couch_peruser配置"></a>couch_peruser配置</h4><p><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/couch_peruser/</code>后接参数.</p><ul><li><p>enable<br>  如果设置为true，则_users为私有的数据库。且只允许当前节点操作。</p></li><li><p>delete_dbs<br>  如果设置为true，当用户被删除，则相关的数据库也一同删除。</p><h3 id="CouchDB-HTTP-服务器"><a href="#CouchDB-HTTP-服务器" class="headerlink" title="CouchDB HTTP 服务器"></a>CouchDB HTTP 服务器</h3><h4 id="HTTP-Server配置"><a href="#HTTP-Server配置" class="headerlink" title="HTTP Server配置"></a>HTTP Server配置</h4></li><li><p>*[chttpd]**<br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/chttpd/</code>后接参数.</p></li><li><p>bind_address :集群端口绑定的IP地址</p><ul><li>127.0.0.1</li><li>0.0.0.0：任何IP地址</li><li>::1:IPV6</li><li>:: 任何IPV6的地址</li></ul></li><li><p>port:集群端口号</p><ul><li>5984:默认</li><li>0：可使用任何端口号</li></ul></li><li><p>prefer_minimal:如果一个请求含有请求头:Prefer,则只返回<code>prefer_minimal</code>配置列表的头部信息</p></li><li><p>authentication_handlers:CouchDB使用的认证头部信息。可以使用第三方插件进行扩展。</p><ul><li>{chttpd_auth, cookie_authentication_handler}: Cookie认证;</li><li>{couch_httpd_auth, proxy_authentication_handler}:代理认证;</li><li>{chttpd_auth, default_authentication_handler}: 基本认证：</li><li>{couch_httpd_auth, null_authentication_handler}:取消认证</li></ul></li></ul><p><strong>[httpd]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/httpd/</code>后接参数.<br>在CouchDB2.X版本，这一部分默认使用5986为默认端口。用于管理员任务与系统维护。应该总是绑定私有的LAN 127.0.0.1地址。</p><ul><li><p>allow_jsonp</p><ul><li>是否支持JSONP，默认false    </li></ul></li><li><p>bind_address</p><ul><li>本地节点可获得的IP地址。建议总是使用127.0.0.1或IPV6 ::1</li></ul></li><li><p>changes_timeout</p><ul><li>默认超时时间默认为6000ms</li></ul></li><li><p>config_whitelist</p><ul><li>配置信息修改白名单。只有白名单内的值可以通过CONFIG API修改配置。为了允许管理员通过HTTP修改该值，需要包括{httpd,config——whitelist}自己。</li><li>config_whitelist = [{httpd,config_whitelist}, {log,level}, {etc,etc}]</li></ul></li><li><p>default_handler</p><ul><li>具体的默认HTTP请求Handler</li><li>default_handler = {couch_httpd_db, handle_request}</li></ul></li><li><p>enable_cors</p><ul><li>控制CORS特性,默认false</li></ul></li><li><p>port</p><ul><li>定义监听的端口号 默认5986</li></ul></li><li><p>redirect_vhost_handler</p><ul><li>Handler请求到<code>virtual hosts</code>的定制的默认功能</li><li>redirect_vhost_handler = {Module, Fun}</li></ul></li><li><p>server_options</p><ul><li>可以被添加到配置文件的<code>MochiWeb</code>组件的服务器选项。</li><li>server_options = [{backlog, 128}, {acceptor_pool_size, 16}]</li></ul></li><li><p>secure_rewrites</p><ul><li>是否允许通过子域隔离数据库。</li></ul></li><li><p>socket_options</p><ul><li>CouchDB监听Socket选项。可以定义为元组列表.</li><li>socket_options = [{sndbuf, 262144}, {nodelay, true}]</li></ul></li><li><p>server_options</p><ul><li>CouchDB中mochiweb acceptor池中任何socket服务器选项，可以定义为元组列表.</li><li>server_options = [{recbuf, undefined}]</li></ul></li><li><p>vhost_global_handlers</p><ul><li>对于<code>virtual hosts</code>全局的Handlers列表</li><li>vhost_global_handlers = _utils, _uuids, _session, _users</li></ul></li><li><p>x_forwarded_host</p><ul><li>用于转发<code>HOST</code>头部字段的原始值。例如一个转发代理在请求Couchd前重写<code>Host</code>头部信息到内部主机。</li><li>x_forwarded_host = X-Forwarded-Host</li></ul></li><li><p>x_forwarded_proto</p><ul><li>认证原始的HTTP协议</li></ul></li><li><p>x_forwarded_ssl</p><ul><li>用于告诉CouchDB使用https代替http</li></ul></li><li><p>enable_xframe_options</p><ul><li>控制是否开启特性</li></ul></li><li><p>WWW-Authenticate</p><ul><li>设置在基本认证下不具备权限的请求头部信息</li></ul></li><li><p>max_http_request_size</p><ul><li>限制HTTP请求体最大值大小默认4GB</li></ul></li></ul><h4 id="HTTPS-SSL-TLS-选项"><a href="#HTTPS-SSL-TLS-选项" class="headerlink" title="HTTPS (SSL/TLS)选项"></a>HTTPS (SSL/TLS)选项</h4><p>CouchDb支持本地TLS/SSL，不需要使用代理服务器.HTTPS设置比较容器，只需要两个文件：一个证书个一个私钥。可以通过<code>OpenSSL</code>命令生成自签名证书。</p><pre><code>shell&gt; mkdir /etc/couchdb/certshell&gt; cd /etc/couchdb/certshell&gt; openssl genrsa &gt; privkey.pemshell&gt; openssl req -new -x509 -key privkey.pem -out couchdb.pem -days 1095shell&gt; chmod 600 privkey.pem couchdb.pemshell&gt; chown couchdb privkey.pem couchdb.pem</code></pre><p>编辑CouchDB配置文件<code>local.ini</code>：</p><pre><code>enable = truecert_file = /etc/couchdb/cert/couchdb.pemkey_file = /etc/couchdb/cert/privkey.pem</code></pre><p>使用自签名证书可以通过参数<code>-k</code>忽略警告信息</p><pre><code>curl -k https://127.0.0.1:6984</code></pre><p><strong>[ssl]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/ssl/</code>后接参数.</p><ul><li>cacert_file<ul><li>包含PEM编码的CA证书路径,CA证书用于构建服务器证书链。用于客户端权限认证。</li></ul></li><li>cert_file<ul><li>包含用户证书文件的路径</li></ul></li><li>key_file<ul><li>包含用户PEM编码的私钥文件路径</li></ul></li><li>password<ul><li>包含用户密码的字符串,当用户私钥通过密码保护时使用</li></ul></li><li>ssl_certifacate_max_depth<ul><li>最大的节点证书深度</li></ul></li><li>verify_fun<ul><li>如果不指定具体的验证功能，则使用默认的验证功能</li></ul></li><li>verify_ssl_certificates<ul><li>如果为true则验证节点证书</li></ul></li><li>fail_if_no_peer_cert<ul><li>true：如果客户端没有发送证书，则终止TLS/SSL握手</li><li>false：只当客户端发送无效证书时，终止TLS/SSL握手</li></ul></li><li>secure_renegotiate</li><li>ciphers<ul><li>设置erlang格式的被支持的加密套件</li><li>ciphers = [“ECDHE-ECDSA-AES128-SHA256”, “ECDHE-ECDSA-AES128-SHA”]</li></ul></li><li>tls_versions<ul><li>设置允许的SSL/TLS协议版本列表</li><li>tls_versions = [tlsv1 | ‘tlsv1.1’ | ‘tlsv1.2’]</li></ul></li></ul><h4 id="跨域资源分享"><a href="#跨域资源分享" class="headerlink" title="跨域资源分享"></a>跨域资源分享</h4><p>跨域资源分享.比如浏览器中运行js的网页通过AJAX请求到不同的域。不需要破坏任何一方的安全。<br>一个典型的用例是通过静态网页通过CDN请求另一资源。比如CouchDB实例。这避免了使用JSONP或类似的变通方法来检索和托管内容的中间代理。<br>CouchDB实例可以接受直接的连接保护数据库和实例。不会造成浏览器功能由于相同的域的限制被阻塞。CORS支持当前90%的浏览器。<br><strong>[cors]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/httpd/</code>后接参数.</p><ul><li><p>enable_cors<br>需要将<code>httpd/enable_cors</code>选项设置为<code>true</code>。<br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/cors/</code>后接参数.</p></li><li><p>credentials</p><ul><li>默认情况下，请求和响应中均不包含身份验证标头或cookie。</li></ul></li><li><p>origins</p><ul><li>通过，分隔接受的原始的URL列表。不能同时设置origins=*和credentials=true</li></ul></li><li><p>headers</p><ul><li>通过，分隔的可接受的请求头列表。</li></ul></li><li><p>methods</p><ul><li>可接受的请求方法</li></ul></li><li><p>max_age</p><ul><li>Access-Control-Max-Age</li></ul></li></ul><h4 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h4><p>虚拟主机<br>CouchDB可以基于<code>Host</code>请求头映射请求到绑定同一个IP地址的不同的位置。<br>允许同一机器上不同虚拟机映射到不同的数据库或者是设计文档。<br>通过为域名添加一个<code>CNAME</code>指针到DNS。在测试或者开发环境下，添加一个实体到hosts文件,如类UNIX系统：</p><pre><code>127.0.0.1       couchdb.local</code></pre><p>最后添加一个实体到配置文件的<code>[vhosts]</code>部分：</p><pre><code>couchdb.local:5984 = /example*.couchdb.local:5984 = /example</code></pre><p>如果CouchDB监听在默认的HTTP端口80，或者之前设置了代理，则不需要在<code>vhosts</code>中指定端口号.<br>第一行将重写请求以显示示例数据库的内容。 仅当Host标头为couchdb.local且不适用于CNAME时，此规则才有效，另一方面，第二条规则将所有CNAME与示例db匹配，这样<a href="http://www.couchdb.local和db.couchdb.local都可以使用。" target="_blank" rel="noopener">www.couchdb.local和db.couchdb.local都可以使用。</a><br><strong>[vhosts]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/vhosts/</code>后接参数.</p><ul><li><p>couchdb.local</p><h3 id="认证与权限"><a href="#认证与权限" class="headerlink" title="认证与权限"></a>认证与权限</h3><h4 id="服务器管理员"><a href="#服务器管理员" class="headerlink" title="服务器管理员"></a>服务器管理员</h4><p>默认的CouchDB提供了管理员级别的可以访问所有连接的用户。配置在<code>Admin Party</code>部分。不应该在生产环境中使用。可以在创建第一个管理员账户后删除这一部分。CouchDB服务管理员和密码没有存储在<code>_users</code>数据库。但是CouchDB加载ini文件时可以在最后发现<code>admin</code>部分。这个文件(可能为<code>etc/local.ini</code>或者<code>etc/local.d/10-admins.ini</code>在Debian/Ubuntu系统从包中安装时发现。)应该安全并且只能由系统管理员可读.<br>管理员可以直接添加到<code>admin</code>部分，当CouchDB重新启动时，密码将会自动加密。也可以通过HTTP接口创建管理员账户不需要重启CouchDB。HTTP<code>/_node/{node-name}/_config/admins</code>地址支持查询，删除或者是创建新管理员账户。</p></li><li><p>*[admins]**<br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/admins/</code>后接参数.</p><h4 id="认证配置"><a href="#认证配置" class="headerlink" title="认证配置"></a>认证配置</h4></li><li><p>*[chttpd]**<br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/chttpd/</code>后接参数.</p></li><li><p>require_valid_user</p><ul><li>true:不允许来自匿名用户的任何请求</li></ul></li></ul><p><strong>[couch_httpd_auth]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/couch_httpd_auth/</code>后接参数.</p><ul><li>allow_persistent_cookies<ul><li>使得Cookie持久性。</li></ul></li><li>cookie_domain<ul><li>配置<code>AuthSession</code>Cookie的域属性。默认为空。</li><li>cookie_domain=example.com</li></ul></li><li>auth_cache_size<ul><li>内容中用户对象缓存数量，减少硬盘读写，默认50</li></ul></li><li>authentication_redirect<ul><li>权限成功验证后，客户端接受<code>text/html</code>响应情况下具体的重定向的位置。</li><li>authentication_redirect = /_utils/session.html</li></ul></li></ul><ul><li>iterations<ul><li>由PBKDF2算法哈希的密码迭代的数量。</li></ul></li><li>min_iterations<ul><li>最小迭代的数量</li></ul></li><li>max_iterations<ul><li>最大迭代的数量</li></ul></li><li>proxy_use_secret<ul><li>true:<code>couch_httpd_auth/secret</code>选项要求代理身份认证</li></ul></li><li>public_fields<ul><li>用户文档中可以被任何用户读的由逗号分隔的字段名称。</li><li>public_fields = first_name, last_name, contacts, url</li></ul></li><li>require_valid_user<ul><li>true:不允许来自匿名用户的任何请求</li></ul></li><li>secret<ul><li>用于代理身份认证与Cookie身份认证的secret</li></ul></li><li>timeout<ul><li>最后一次请求之后session超时过期时间默认600</li></ul></li><li>users_db_public<ul><li>允许用户查看所有用户文档，默认情况下，只有管理员可以查看所有用户的文档,用户只能查看自己的文档。</li></ul></li><li>x_auth_roles<ul><li>HTTP请求头包含用户的角色，用逗号分隔。用于代理身份认证</li></ul></li><li>x_auth_token<ul><li>HTTP请求头包含用户的token，用逗号分隔。用于代理身份认证</li></ul></li><li>x_auth_username<ul><li>HTTP请求头包含用户的用户名，用逗号分隔。用于代理身份认证</li></ul></li></ul><h3 id="压缩配置"><a href="#压缩配置" class="headerlink" title="压缩配置"></a>压缩配置</h3><h4 id="数据库压缩配置"><a href="#数据库压缩配置" class="headerlink" title="数据库压缩配置"></a>数据库压缩配置</h4><p><strong>[database_compaction]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/database_compaction/</code>后接参数.</p><ul><li>doc_buffer_size<ul><li>具体的拷贝缓冲区大小</li></ul></li><li>checkpoint_after<ul><li>在具体数量的比特后激活检查点拷贝到压缩数据库。</li></ul></li></ul><h4 id="压缩程序规则"><a href="#压缩程序规则" class="headerlink" title="压缩程序规则"></a>压缩程序规则</h4><p><strong>[compactions]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/compactions/</code>后接参数.<br>列表中的规则确定什么时候运行自动压缩。配置可以是指定数据库或者是全局的。格式如下:</p><pre><code>database_name = [ {ParamName, ParamValue}, {ParamName, ParamValue}, ... ]_default = [ {ParamName, ParamValue}, {ParamName, ParamValue}, ... ]_default = [{db_fragmentation, &quot;70%&quot;}, {view_fragmentation, &quot;60%&quot;}, {from,&quot;23:00&quot;}, {to, &quot;04:00&quot;}]</code></pre><ol><li>db_fragmentation:数据库中数据压缩率，包括元数据。计算方法：(file_size-data_size)/file_size*100</li><li>view_fragmentation：数据库中索引文件…..</li><li>form,to:允许进行压缩的时间段,格式：<code>HH:MM - HH:MM  (HH in [0..23], MM in [0..59])</code></li><li>strict_window:如果为true，并且在超时时间后还没有压缩完则终止压缩。</li><li>parallel_view_compaction：是否数据和视图同时进行压缩。</li></ol><h4 id="压缩程序配置"><a href="#压缩程序配置" class="headerlink" title="压缩程序配置"></a>压缩程序配置</h4><p><strong>[compaction_daemon]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/compaction_daemon/</code>后接参数.</p><ul><li>check_interval<ul><li>两次检查数据库和视图索引是否需要被压缩的时间间隔，默认为3600</li></ul></li><li>min_file_size<ul><li>如果数据库或者视图索引文件大小小于该值，则不进行压缩。</li></ul></li><li>snooze_period_ms</li></ul><h4 id="视图压缩选项"><a href="#视图压缩选项" class="headerlink" title="视图压缩选项"></a>视图压缩选项</h4><p><strong>[view_compaction]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/view_compaction/</code>后接参数.</p><ul><li>keyvalue_buffer_size<ul><li>压缩时具体的最大拷贝缓冲区大小.</li></ul></li></ul><h3 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h3><h4 id="日志选项"><a href="#日志选项" class="headerlink" title="日志选项"></a>日志选项</h4><p><strong>[log]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/log/</code>后接参数.</p><ul><li>writer<ul><li>stderr：日志信息发送到stderr(默认)</li><li>file:日志信息存储到文件</li><li>syslog：日志信息发送到syslog daemon</li></ul></li><li>file<ul><li>日志保存到文件的具体的位置(默认<code>/var/log/couchdb/couch.log</code>)</li></ul></li><li>write_buffer<ul><li>写日志缓冲区大小默认0</li></ul></li><li>write_delay<ul><li>写日志到硬盘延迟默认为0</li></ul></li><li>level<ul><li>日志级别</li><li>debug</li><li>info：包括HTTP请求，启动外部程序</li><li>notice</li><li>warning,warn：警告信息，例如硬盘空间不足</li><li>error,err：只输出错误信息</li><li>critical crit</li><li>alert</li><li>emergency emerg</li><li>none:不输入任何日志</li></ul></li><li>include_sasl<ul><li>是否在日志中包含SASL信息</li></ul></li><li>syslog_host<ul><li>具体的syslog 主机将日志发送到的位置默认localhost</li></ul></li><li>syslog_port<ul><li>当发送日志信息时连接的syslog端口</li></ul></li><li>syslog_appid<ul><li>具体的应用名称默认couchdb</li></ul></li><li>syslog_facility</li></ul><h3 id="复制者"><a href="#复制者" class="headerlink" title="复制者"></a>复制者</h3><h4 id="数据库复制配置"><a href="#数据库复制配置" class="headerlink" title="数据库复制配置"></a>数据库复制配置</h4><p><strong>[replicator]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/replicator/</code>后接参数.</p><ul><li>max_jobs<ul><li>活跃的运行的复制任务数量。</li></ul></li><li>interval</li><li>max_churn</li><li>update_docs</li><li>worker_batch_size</li><li>worker_processes</li><li>http_connections</li><li>connection_timeout</li><li>retries_per_request</li><li>socket_options</li><li>checkpoint_interval</li><li>use_checkpoints</li><li>cert_file</li><li>key_file</li><li>password</li><li>verify_ssl_certificates</li><li>ssl_trusted_certificates_file</li><li>ssl_certificate_max_depth</li><li>auth_plugins</li></ul><h3 id="Query-Servers"><a href="#Query-Servers" class="headerlink" title="Query Servers"></a>Query Servers</h3><h4 id="Query-Servers-Definition"><a href="#Query-Servers-Definition" class="headerlink" title="Query Servers Definition"></a>Query Servers Definition</h4><p><strong>[query_servers]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/query_servers/</code>后接参数.</p><h4 id="Query-Servers-Configuration"><a href="#Query-Servers-Configuration" class="headerlink" title="Query Servers Configuration"></a>Query Servers Configuration</h4><p><strong>[query_sercver_config]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/query_sercver_config/</code>后接参数.</p><ul><li>commit_freq</li><li>os_process_limit</li><li>os_process_soft_limit</li><li>reduce_limit</li></ul><h4 id="Native-Erlang-Query-Server"><a href="#Native-Erlang-Query-Server" class="headerlink" title="Native Erlang Query Server"></a>Native Erlang Query Server</h4><p><strong>[native_query_servers]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/native_query_servers/</code>后接参数.</p><h3 id="CouchDB-Internal-Services"><a href="#CouchDB-Internal-Services" class="headerlink" title="CouchDB Internal Services"></a>CouchDB Internal Services</h3><h4 id="CouchDB-Daemonized-Mini-Apps"><a href="#CouchDB-Daemonized-Mini-Apps" class="headerlink" title="CouchDB Daemonized Mini Apps"></a>CouchDB Daemonized Mini Apps</h4><p><strong>[daemons]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/daemons/</code>后接参数.</p><ul><li>auth_cache</li><li>compaction_daemon</li><li>external_manager</li><li>httpd</li><li>index_server</li><li>query_servers</li><li>replicator_manager</li><li>stats_aggregator</li><li>stats_collector</li><li>uuids</li><li>vhosts</li></ul><h3 id="Miscellaneous-Parameters"><a href="#Miscellaneous-Parameters" class="headerlink" title="Miscellaneous Parameters"></a>Miscellaneous Parameters</h3><h4 id="Configuration-of-Attachment-Storage"><a href="#Configuration-of-Attachment-Storage" class="headerlink" title="Configuration of Attachment Storage"></a>Configuration of Attachment Storage</h4><p><strong>[attachments]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/attachments/</code>后接参数.</p><ul><li>compression_level</li><li>compressible_types</li></ul><h4 id="Statistic-Calculation"><a href="#Statistic-Calculation" class="headerlink" title="Statistic Calculation"></a>Statistic Calculation</h4><p><strong>[stats]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/stats/</code>后接参数.</p><ul><li>rate</li><li>samples</li></ul><h4 id="UUIDs-Configuration"><a href="#UUIDs-Configuration" class="headerlink" title="UUIDs Configuration"></a>UUIDs Configuration</h4><p><strong>[uuids]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/uuids/</code>后接参数.</p><ul><li>algorithm</li><li>utc_id_suffix</li><li>max_count</li></ul><h4 id="Vendor-information"><a href="#Vendor-information" class="headerlink" title="Vendor information"></a>Vendor information</h4><p><strong>[vendor]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/vendor/</code>后接参数.</p><h4 id="Content-Security-Policy"><a href="#Content-Security-Policy" class="headerlink" title="Content-Security_Policy"></a>Content-Security_Policy</h4><p><strong>[csp]</strong><br><code>curl</code>地址：<code>http://localhost:5984/_node/&lt;name@host&gt;/_config/csp/</code>后接参数.</p><ul><li>enable</li><li>header_value</li></ul><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><h3 id="节点操作"><a href="#节点操作" class="headerlink" title="节点操作"></a>节点操作</h3><h4 id="查看所有节点"><a href="#查看所有节点" class="headerlink" title="查看所有节点"></a>查看所有节点</h4><pre><code>curl -u admin:adminpw -X GET http://localhost:5984/_membership{    &quot;all_nodes&quot;:[   # 当前节点所知道的节点        &quot;node1@xxx.xxx.xxx.xxx&quot;],    &quot;cluster_nodes&quot;:[ #当前节点所连接的节点        &quot;node1@xxx.xxx.xxx.xxx&quot;],}</code></pre><h4 id="添加一个节点"><a href="#添加一个节点" class="headerlink" title="添加一个节点"></a>添加一个节点</h4><pre><code>curl -u admin:adminpw -X PUT http://localhost:5986/_nodes/node2@yyy.yyy.yyy.yyy -d {}</code></pre><h4 id="删除一个节点"><a href="#删除一个节点" class="headerlink" title="删除一个节点"></a>删除一个节点</h4><pre><code>#首先获取关于文档的revisioncurl -u admin:adminpw -X GET &quot;http://xxx.xxx.xxx.xxx:5986/_nodes/node2@yyy.yyy.yyy.yyy&quot;{&quot;_id&quot;:&quot;node2@yyy.yyy.yyy.yyy&quot;,&quot;_rev&quot;:&quot;1-967a00dff5e02add41820138abb3284d&quot;}    #删除节点curl -u admin:adminpw -X DELETE http://localhost:5986/_nodes/node2@yyy.yyy.yyy.yyy?rev=1-967a00dff5e02add41820138abb3284d</code></pre><h3 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h3><h4 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h4><p>数据库名字不支持大写字符，只支持[a-z],[0-9],以及特殊字符:<code>_ $ ( ) + - /</code></p><pre><code>#创建一个数据库名字为db_name curl -u admin:adminpw -X PUT http://localhost:5984/db_name?q=4&amp;n=2</code></pre><h4 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h4><pre><code>curl -u admin:adminpw -X DELETE http://localhost:5984/db_name</code></pre>]]></content>
    
    
    <categories>
      
      <category>CouchDb学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CouchDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>etcd网关</title>
    <link href="undefined2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/"/>
    <url>2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/gateway.md" target="_blank" rel="noopener">L4 gateway</a></p><h2 id="什么是etcd网关"><a href="#什么是etcd网关" class="headerlink" title="什么是etcd网关"></a>什么是etcd网关</h2><hr><p>etcd网关是一个简单的TCP代理，可将网络数据转发到etcd集群。网关是无状态且透明的； 它既不会检查客户端请求，也不会干扰群集响应。<br>网关支持多个etcd服务器端点，并采用简单的循环策略。 它仅路由到可用端点，并向其客户端隐藏故障。 将来可能会支持其他重试策略，例如加权轮询。</p><h2 id="什么时候使用etcd网关"><a href="#什么时候使用etcd网关" class="headerlink" title="什么时候使用etcd网关"></a>什么时候使用etcd网关</h2><hr><p>每个访问etcd的应用程序必须首先具有etcd集群客户端端点的地址。 如果同一服务器上的多个应用程序访问相同的etcd集群，则每个应用程序仍需要知道etcd集群的广播的客户端端点。 如果将etcd集群重新配置为具有不同的端点，则每个应用程序可能还需要更新其端点列表。 这种大规模的重新配置既乏味又容易出错。<br>etcd网关通过充当稳定的本地端点来解决此问题。 典型的etcd网关配置是，每台计算机运行一台网关，侦听本地地址，并且每个etcd应用程序都连接到其本地网关。 结果只是网关需要更新其端点，而不是更新每个应用程序。<br>总之，为了自动传播集群端点更改，etcd网关在为访问同一etcd集群的多个应用程序服务的每台机器上运行。</p><h2 id="什么时候不该使用etcd网关"><a href="#什么时候不该使用etcd网关" class="headerlink" title="什么时候不该使用etcd网关"></a>什么时候不该使用etcd网关</h2><ul><li>提升性能<br>该网关不是为提高etcd群集性能而设计的。 它不提供缓存，监视合并或批处理。 etcd团队正在开发一种缓存代理，旨在提高群集的可伸缩性。</li><li>在集群管理系统运行时<br>像Kubernetes这样的高级集群管理系统本身就支持服务发现。 应用程序可以使用系统管理的DNS名称或虚拟IP地址访问etcd集群。 例如，kube-proxy等效于etcd网关。<h2 id="启动etcd网关"><a href="#启动etcd网关" class="headerlink" title="启动etcd网关"></a>启动etcd网关</h2></li></ul><hr><p>考虑一个具有以下静态端点的etcd集群：</p><table><thead><tr><th>名字</th><th>地址</th><th>主机名</th></tr></thead><tbody><tr><td>infra0</td><td>10.0.1.10</td><td>infra0.example.com</td></tr><tr><td>infra1</td><td>10.0.1.11</td><td>infra1.example.com</td></tr><tr><td>infra2</td><td>10.0.1.12</td><td>infra2.example.com</td></tr></tbody></table><p>通过以下命令使用静态端点启动etcd网关:</p><pre><code>$ etcd gateway start --endpoints=infra0.example.com,infra1.example.com,infra2.example.com2016-08-16 11:21:18.867350 I | tcpproxy: ready to proxy client requests to [...]</code></pre><p>或者，如果使用DNS进行服务发现，请考虑DNS SRV条目：</p><pre><code>$ dig +noall +answer SRV _etcd-client._tcp.example.com_etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra0.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra1.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra2.example.com.</code></pre><pre><code>$ dig +noall +answer infra0.example.com infra1.example.com infra2.example.cominfra0.example.com.  300  IN  A  10.0.1.10infra1.example.com.  300  IN  A  10.0.1.11infra2.example.com.  300  IN  A  10.0.1.12</code></pre><p>启动etcd网关，以使用以下命令从DNS SRV条目中获取端点：</p><pre><code>$ etcd gateway start --discovery-srv=example.com2016-08-16 11:21:18.867350 I | tcpproxy: ready to proxy client requests to [...]</code></pre><h2 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h2><hr><h4 id="etcd-集群"><a href="#etcd-集群" class="headerlink" title="etcd 集群"></a><strong>etcd 集群</strong></h4><p><strong>–endpoints</strong></p><ul><li>以逗号分隔的用于转发客户端连接的etcd服务器目标列表。</li><li>默认：<code>127.0.0.1:2379</code></li><li>无效的例子:<code>https://127.0.0.1:2379</code>(网关不适用于TLS 终端)</li></ul><p><strong>–discovery-srv</strong></p><ul><li>用于通过SRV记录引导群集终结点的DNS域。</li><li>默认值：未设置</li></ul><h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a><strong>网络</strong></h4><p><strong>–listen-addr</strong></p><ul><li>接收客户端请求绑定的接口和端口</li><li>默认:<code>127.0.0.1:23790</code></li></ul><p><strong>–retry-delay</strong></p><ul><li>重试连接到失败的端点之前的延迟时间。</li><li>默认值：1m0s</li><li>无效例子：”123”(期望之外的时间格式)</li></ul><h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a><strong>安全</strong></h4><p><strong>–insecure-discovery</strong></p><ul><li>接受不安全或容易受到中间人攻击的SRV记录。</li><li>默认值：false</li></ul><p><strong>–trusted-ca-file</strong></p><ul><li>etcd集群的客户端TLS CA文件的路径。 用于认证端点。</li><li>默认值：未设置</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gRPC代理</title>
    <link href="undefined2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/"/>
    <url>2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/grpc_proxy.md" target="_blank" rel="noopener">gRPC proxy</a><br>gRPC代理是在gRPC层（L7）运行的无状态etcd反向代理。代理旨在减少核心etcd群集上的总处理负载。对于水平可伸缩性，它合并了监视和租约API请求。 为了保护集群免受滥用客户端的侵害，它会缓存关键范围请求。<br>gRPC代理支持多个etcd服务器端点。 代理启动时，它会随机选择一个etcd服务器端点来使用.该端点将处理所有请求，直到代理检测到端点故障为止。 如果gRPC代理检测到端点故障，它将切换到其他端点（如果有）以向其客户端隐藏故障。 将来可能会支持其他重试策略，例如加权轮询。</p><h2 id="可扩展的监视-API"><a href="#可扩展的监视-API" class="headerlink" title="可扩展的监视 API"></a>可扩展的监视 API</h2><hr><p>gRPC代理将同一键或范围上的多个客户端监视程序（c-watcher）合并为连接到etcd服务器的单个监视程序（s-watcher）。 代理将所有事件从S-watcher广播到其c-watcher。<br>假设N个客户端监视相同的密钥，则一个gRPC代理可以将etcd服务器上的监视负载从N减少到1。用户可以部署多个gRPC代理来进一步分配服务器负载。<br>在以下示例中，三个客户端监视键A。gRPC代理将三个监视程序合并，从而创建一个附加到etcd服务器的监视程序。</p><pre><code>            +-------------+            | etcd 服务器 |            +------+------+                   ^ 监视 key A (s-watcher)                   |           +-------+-----+           | gRPC 代理  | &lt;-------+           |             |         |           ++-----+------+         |监视 key A (c-watcher)监视 key A ^     ^ 监视 key A    |(c-watcher) |     | (c-watcher)    |    +-------+-+  ++--------+  +----+----+    |  客户端 |  |  客户端 |  |  客户端 |    |         |  |         |  |         |    +---------+  +---------+  +---------+</code></pre><h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><p>为了有效地将多个客户端监视程序合并为一个监视程序，gRPC代理在可能的情况下将新的c-watcher合并为现有的s-watcher。 由于网络延迟或缓冲的未传递事件，此合并的s-watcher可能与etcd服务器不同步。 如果未指定监视版本，则gRPC代理将不能保证c-watcher从最近的存储修订版本开始监视。 例如，如果客户端从具有修订版1000的etcd服务器监视，则该监视程序将从修订版1000开始。如果客户端从gRPC代理监视，则可以从修订版990开始监视。<br>类似的限制也适用于取消。 取消观察者后，etcd服务器的修订版可能大于取消响应修订版。<br>对于大多数用例，这两个限制不应引起问题。 将来，可能会有其他选项强制观察者绕过gRPC代理以获得更准确的修订响应。</p><h2 id="可扩展的租约-API"><a href="#可扩展的租约-API" class="headerlink" title="可扩展的租约 API"></a>可扩展的租约 API</h2><hr><p>为了保持其租约有效，客户端必须至少向一个etcd服务器建立一个gRPC流，以发送定期的心跳信号。 如果etcd工作负载涉及大量租约活动分布在许多客户端上，则这些流可能会导致CPU使用率过高。 为了减少核心群集上的流总数，该代理支持租约流合并。<br>假设N个客户端正在更新租约，则单个gRPC代理将etcd服务器上的流负载从N减少到1。部署中可能具有其他gRPC代理，以进一步在多个代理之间分配流。<br>在以下示例中，三个客户端更新了三个独立的租约（L1，L2和L3）。 gRPC代理将三个客户端租约流（c-stream）合并为连接到etcd服务器的单个租约保持活动流（s-stream）。 代理将客户端租用心跳从c流转发到s流，然后将响应返回到相应的c流。</p><pre><code>          +-------------+          | etcd 服务器 |          +------+------+                 ^                 | 心跳 L1, L2, L3                 | (s-stream)                 v         +-------+-----+         | gRPC 代理  +&lt;-----------+         +---+------+--+            | 心跳 L3             ^      ^               | (c-stream)心跳 L1 |      | 心跳 L2  |(c-stream)   v      v (c-stream)    v      +------+-+  +-+------+  +-----+--+      | 客户端 |  | 客户端 |  | 客户端 |      +--------+  +--------+  +--------+</code></pre><h3 id="客户保护滥用"><a href="#客户保护滥用" class="headerlink" title="客户保护滥用"></a>客户保护滥用</h3><p>gRPC代理在不违反一致性要求时会缓存请求的响应。 这可以保护etcd服务器免遭严密for循环中滥用客户端的侵害。</p><h2 id="启动etcd-gRPC代理"><a href="#启动etcd-gRPC代理" class="headerlink" title="启动etcd gRPC代理"></a>启动etcd gRPC代理</h2><hr><p>考虑一个etcd集群包括以下几个静态端点：<br>|名字|地址|主机名|<br>|—|—|—|<br>|infra0|10.0.1.10|infra0.example.com|<br>|infra1|10.0.1.11|infra1.example.com|<br>|infra2|10.0.1.12|infra2.example.com|<br>通过以下命令使用静态节点启动gRPC代理：</p><pre><code>$ etcd grpc-proxy start --endpoints=infra0.example.com,infra1.example.com,infra2.example.com --listen-addr=127.0.0.1:2379</code></pre><p>etcd gRPC启动并监听端口2379.它将客户端请求转发到上面提供的三个端点之一。<br>通过代理发送请求：</p><pre><code>$ ETCDCTL_API=3 etcdctl --endpoints=127.0.0.1:2379 put foo barOK$ ETCDCTL_API=3 etcdctl --endpoints=127.0.0.1:2379 get foofoobar</code></pre><h2 id="客户端端点同步和名称解析"><a href="#客户端端点同步和名称解析" class="headerlink" title="客户端端点同步和名称解析"></a>客户端端点同步和名称解析</h2><hr><p>代理支持通过写入用户定义的端点来注册其端点以进行发现。 这有两个目的。 首先，它允许客户端将其端点与一组代理端点同步，以实现高可用性。 其次，它是etcd <a href="https://newonexd.github.io/2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/">gRPC命名</a>的端点提供程序。<br>通过提供用户定义的前缀来注册代理：</p><pre><code>$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23790 \  --advertise-client-url=127.0.0.1:23790 \  --resolver-prefix=&quot;___grpc_proxy_endpoint&quot; \  --resolver-ttl=60$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23791 \  --advertise-client-url=127.0.0.1:23791 \  --resolver-prefix=&quot;___grpc_proxy_endpoint&quot; \  --resolver-ttl=60</code></pre><p>代理将会列出成员列表中的所有成员：</p><pre><code>ETCDCTL_API=3 etcdctl --endpoints=http://localhost:23790 member list --write-out table+----+---------+--------------------------------+------------+-----------------+| ID | STATUS  |              NAME              | PEER ADDRS |  CLIENT ADDRS   |+----+---------+--------------------------------+------------+-----------------+|  0 | started | Gyu-Hos-MBP.sfo.coreos.systems |            | 127.0.0.1:23791 ||  0 | started | Gyu-Hos-MBP.sfo.coreos.systems |            | 127.0.0.1:23790 |+----+---------+--------------------------------+------------+-----------------+</code></pre><p>这使客户端可以通过Sync自动发现代理端点：</p><pre><code>cli, err := clientv3.New(clientv3.Config{    Endpoints: []string{&quot;http://localhost:23790&quot;},})if err != nil {    log.Fatal(err)}defer cli.Close()// fetch registered grpc-proxy endpointsif err := cli.Sync(context.Background()); err != nil {    log.Fatal(err)}</code></pre><p>注意，如果配置的代理没有解析程序前缀，</p><pre><code>$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23792 \  --advertise-client-url=127.0.0.1:23792</code></pre><p>grpc-proxy的成员列表API返回其自己的<code>advertise-client-url</code>：</p><pre><code>ETCDCTL_API=3 etcdctl --endpoints=http://localhost:23792 member list --write-out table+----+---------+--------------------------------+------------+-----------------+| ID | STATUS  |              NAME              | PEER ADDRS |  CLIENT ADDRS   |+----+---------+--------------------------------+------------+-----------------+|  0 | started | Gyu-Hos-MBP.sfo.coreos.systems |            | 127.0.0.1:23792 |+----+---------+--------------------------------+------------+-----------------+</code></pre><h2 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h2><hr><p>假设一个应用程序期望对整个键空间有完全控制，但是etcd集群与其他应用程序共享。 为了使所有应用程序都不会相互干扰地运行，代理可以对etcd键空间进行分区，以便客户端可以访问完整的键空间。 当给代理提供标志<code>--namespace</code>时，所有进入代理的客户端请求都将转换为在键上具有用户定义的前缀。 对etcd集群的访问将在前缀下，而来自代理的响应将删除该前缀；对于客户端，显然根本没有前缀。<br>要为代理命名空间，请通过<code>--namespace</code>启动：</p><pre><code>$ etcd grpc-proxy start --endpoints=localhost:2379 \  --listen-addr=127.0.0.1:23790 \  --namespace=my-prefix/</code></pre><p>现在，对代理的访问在etcd集群上透明地加上前缀：</p><pre><code>$ ETCDCTL_API=3 etcdctl --endpoints=localhost:23790 put my-key abc# OK$ ETCDCTL_API=3 etcdctl --endpoints=localhost:23790 get my-key# my-key# abc$ ETCDCTL_API=3 etcdctl --endpoints=localhost:2379 get my-prefix/my-key# my-prefix/my-key# abc</code></pre><h2 id="TLS终端"><a href="#TLS终端" class="headerlink" title="TLS终端"></a>TLS终端</h2><hr><p>使用来自安全etcd群集的TLS的gRPC代理终端为未加密的本地端点提供服务.<br>使用客户端https启动单个成员etcd集群尝试：</p><pre><code>$ etcd --listen-client-urls https://localhost:2379 --advertise-client-urls https://localhost:2379 --cert-file=peer.crt --key-file=peer.key --trusted-ca-file=ca.crt --client-cert-auth</code></pre><p>确认客户端端口正在提供https：</p><pre><code># fails$ ETCDCTL_API=3 etcdctl --endpoints=http://localhost:2379 endpoint status# works$ ETCDCTL_API=3 etcdctl --endpoints=https://localhost:2379 --cert=client.crt --key=client.key --cacert=ca.crt endpoint status</code></pre><p>接下来，通过使用客户端证书连接到etcd端点<code>https://localhost2379</code>在<code>localhost:12379</code>上启动gRPC代理：</p><pre><code>$ etcd grpc-proxy start --endpoints=https://localhost:2379 --listen-addr localhost:12379 --cert client.crt --key client.key --cacert=ca.crt --insecure-skip-tls-verify &amp;</code></pre><p>最后，通过在http上将密钥放入代理来测试TLS终端：</p><pre><code>$ ETCDCTL_API=3 etcdctl --endpoints=http://localhost:12379 put abc def# OK</code></pre><h2 id="指标和健康"><a href="#指标和健康" class="headerlink" title="指标和健康"></a>指标和健康</h2><hr><p>gRPC代理为<code>--endpoints</code>定义的etcd成员公开了<code>/health</code>和Prometheus<code>/metrics</code>端点。 另一种方法是定义一个附加URL，该URL将使用<code>--metrics-addr</code>参数来响应<code>/metrics</code>和<code>/health</code>端点。</p><pre><code>$ etcd grpc-proxy start \  --endpoints https://localhost:2379 \  --metrics-addr https://0.0.0.0:4443 \  --listen-addr 127.0.0.1:23790 \  --key client.key \  --key-file proxy-server.key \  --cert client.crt \  --cert-file proxy-server.crt \  --cacert ca.pem \  --trusted-ca-file proxy-ca.pem</code></pre><h3 id="已知问题"><a href="#已知问题" class="headerlink" title="已知问题"></a>已知问题</h3><p>代理的主接口同时服务于HTTP2和HTTP/1.1。如果如上例所示，使用TLS设置了代理，则在监听接口上使用诸如cURL之类的客户端时，将要求在返回<code>/metrics</code>或<code>/health</code>的请求上将协议显式设置为HTTP/1.1。通过使用<code>--metrics-addr</code>参数，辅助接口将没有此要求。</p><pre><code> $ curl --cacert proxy-ca.pem --key proxy-client.key --cert proxy-client.crt https://127.0.0.1:23790/metrics --http1.1</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实验特性和APIs</title>
    <link href="undefined2019/11/24/blog/etcd/%E5%AE%9E%E9%AA%8C%E7%89%B9%E6%80%A7%E5%92%8CAPIs/"/>
    <url>2019/11/24/blog/etcd/%E5%AE%9E%E9%AA%8C%E7%89%B9%E6%80%A7%E5%92%8CAPIs/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/experimental_apis.md" target="_blank" rel="noopener">Experimental features and APIs</a><br>大多数情况下，etcd项目是稳定的，但我们仍在快速发展！ 我们相信快速发布理念。 我们希望获得有关仍在开发和稳定中的功能的早期反馈。 因此，存在并且将会有更多的实验性功能和API。 我们计划根据社区的早期反馈来改进这些功能，如果兴趣不足，请在接下来的几个版本中放弃这些功能。 请不要在生产环境中依赖任何实验性功能或API。</p><h2 id="当前实验API-特性是："><a href="#当前实验API-特性是：" class="headerlink" title="当前实验API/特性是："></a><strong>当前实验API/特性是：</strong></h2><hr><ul><li><a href="https://godoc.org/github.com/etcd-io/etcd/clientv3/ordering" target="_blank" rel="noopener">键值对排序</a>包装器：<br>当etcd客户端切换端点时，如果新端点落后于集群的其余部分，则对可序列化读取的响应可能推迟。排序包装器从响应标头缓存当前集群修订版。 如果响应修订版本小于缓存修订版本，则客户端选择另一个端点并重新发出读取。在grpcproxy中启动<code>--experimental-serializable-ordering</code>.</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>配置参数</title>
    <link href="undefined2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/"/>
    <url>2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/configuration.md" target="_blank" rel="noopener">Configuration flags</a><br>etcd通过配置文件，多命令行参数和环境变量进行配置，</p><p>可重用的配置文件是YAML文件，其名称和值由一个或多个下面描述的命令行标志组成。为了使用此文件，请将文件路径指定为<code>--config-file</code>标志或<code>ETCD_CONFIG_FILE</code>环境变量的值。如果需要的话<a href="https://github.com/etcd-io/etcd/blob/master/etcd.conf.yml.sample" target="_blank" rel="noopener">配置文件示例</a>可以作为入口点创建新的配置文件。</p><p>在命令行上设置的选项优先于环境中的选项。 如果提供了配置文件，则其他命令行标志和环境变量将被忽略。例如，<code>etcd --config-file etcd.conf.yml.sample --data-dir /tmp</code>将会忽略<code>--data-dir</code>参数。</p><p>参数<code>--my-flag</code>的环境变量的格式为<code>ETCD_MY_FLAG</code>.它适用于所有参数。</p><p>客户端请求<a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt" target="_blank" rel="noopener">官方的etcd端口</a>为2379,2380是节点通信端口。可以将etcd端口设置为接受TLS流量，非TLS流量，或同时接受TLS和非TLS流量。</p><p>要在Linux启动时使用自定义设置自动启动etcd，强烈建议使用<a href="freedesktop.org/wiki/Software/systemd/">systemd</a>单元。</p><h2 id="成员标记"><a href="#成员标记" class="headerlink" title="成员标记"></a>成员标记</h2><hr><p><strong>–name</strong></p><ul><li>人类可读的该成员的名字</li><li>默认值：”default”</li><li>环境变量：ETCD_DATA_DIR</li><li>该值被该节点吃的<code>--initial-cluster</code>参数引用(例如 <code>default=http://localhost:2380</code>).如果使用<a href="">静态引导程序</a>，则需要与标志中使用的键匹配。当使用发现服务时，每一个成员需要有唯一的名字。<code>Hostname</code>或者<code>machine-id</code>是好的选择。</li></ul><p><strong>–data-dir</strong></p><ul><li>数据目录的路径</li><li>默认值：”${name}.etcd”</li><li>环境变量：ETCD_DATA_DIR</li></ul><p><strong>–wal-dir</strong></p><ul><li>专用的wal目录的路径。如果这个参数被设置，etcd将会写WAL文件到walDir而不是dataDir，允许使用专用磁盘，并有助于避免日志记录和其他IO操作之间的io竞争。</li><li>默认值：””</li><li>环境变量：ETCD_WAL_DIR</li></ul><p><strong>–snapshot-count</strong></p><ul><li>触发一个快照到磁盘的已提交交易的数量</li><li>默认值：”100000”</li><li>环境变量：ETCD_SNAPSHOP_COUNT</li></ul><p><strong>–heartbeat-interval</strong></p><ul><li>心跳间隔(毫秒为单位)</li><li>默认值:”100”</li><li>环境变量：ETCD_HEARTBEAT_INTERVAL</li></ul><p><strong>–election-timeout</strong></p><ul><li>选举超时时间(毫秒为单位)，从<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">文档/tuning.md</a>发现更多细节</li><li>默认值：”1000”</li><li>环境变量：ETCD_ELECTION_TIMEOUT</li></ul><p><strong>–listen-peer-urls</strong></p><ul><li>监听在对等节点流量上的URL列表，该参数告诉etcd在指定的协议://IP:port组合上接受来自其对等方的传入请求。协议可以是http或者https。或者，使用<code>unix://&lt;file-path&gt;</code>或者<code>unixs://&lt;file-path&gt;</code>到unix sockets。如果将0.0.0.0作为IP，etcd将监听在所有的接口上的给定端口。如果给定了Ip和端口，etcd将监听指定的接口和端口。可以使用多个URL指定要监听的地址和端口的数量。 etcd将响应来自任何列出的地址和端口的请求。</li><li>默认值：”<a href="http://localhost:2380" target="_blank" rel="noopener">http://localhost:2380</a>“</li><li>环境变量:ETCD_LISTEN_PEER_URLS</li><li>示例：”<a href="http://10.0.0.1:2380" target="_blank" rel="noopener">http://10.0.0.1:2380</a>“</li><li>无效的示例：”<a href="http://example.com:2380" target="_blank" rel="noopener">http://example.com:2380</a>“(绑定的域名是无效的)</li></ul><p><strong>–listen-client-urls</strong></p><ul><li>监听在客户端流量上的URL列表，该参数告诉etcd在指定的协议://IP:port组合上接受来自客户端的传入请求。协议可以是http或者https。或者，使用<code>unix://&lt;file-path&gt;</code>或者<code>unixs://&lt;file-path&gt;</code>到unix sockets。如果将0.0.0.0作为IP，etcd将监听在所有的接口上的给定端口。如果给定了Ip和端口，etcd将监听指定的接口和端口。可以使用多个URL指定要监听的地址和端口的数量。 etcd将响应来自任何列出的地址和端口的请求。</li><li>默认值：”<a href="http://localhost:2379" target="_blank" rel="noopener">http://localhost:2379</a>“</li><li>环境变量:ETCD_LISTEN_CLIENT_URLS</li><li>示例：”<a href="http://10.0.0.1:2379" target="_blank" rel="noopener">http://10.0.0.1:2379</a>“</li><li>无效的示例：”<a href="http://example.com:2379" target="_blank" rel="noopener">http://example.com:2379</a>“(绑定的域名是无效的)</li></ul><p><strong>–max-snapshots</strong></p><ul><li>保留的快照文件最大数量（0为无限）</li><li>默认值：5</li><li>环境变量：ETCD_MAX_SNAPSHOTS</li><li>Windows用户的默认设置是无限制的，建议手动设置到5（或出于安全性的考虑）。</li></ul><p><strong>–max-wals</strong></p><ul><li>保留的wal文件最大数量（0为无限）</li><li>默认值：5</li><li>环境变量：ETCD_MAX_WALS</li><li>Windows用户的默认设置是无限制的，建议手动设置到5（或出于安全性的考虑）。</li></ul><p><strong>–cors</strong></p><ul><li>以逗号分隔的CORS来源白名单（跨来源资源共享）。</li><li>默认值：””</li><li>环境变量：ETCD_CORS</li></ul><p><strong>–quota-backent-bytes</strong></p><ul><li>后端大小超过给定配额时引发警报（0默认为低空间配额）。</li><li>默认值：0</li><li>环境变量：ETCD_QUOTA_BACKEND_BYTES</li></ul><p><strong>–backend-batch-limit</strong></p><ul><li>BackendBatchLimit是提交后端事务之前的最大数量的操作。</li><li>默认值：0</li><li>环境变量：ETCD_BACKEND_BATCH_LIMIT</li></ul><p><strong>–backend-bbolt-freelist-type</strong></p><ul><li>etcd后端（bboltdb）使用的自由列表类型（支持数组和映射的类型）。</li><li>默认值：map</li><li>环境变量：ETCD_BACKEND_BBOLT_FREELIST_TYPE</li></ul><p><strong>–backend-batch-interval</strong></p><ul><li>BackendBatchInterval是提交后端事务之前的最长时间。</li><li>默认值：0</li><li>环境变量：ETCD_BACKEND_BATCH_INTERVAL</li></ul><p><strong>–max-txn-ops</strong></p><ul><li>交易中允许的最大操作数。</li><li>默认值：128</li><li>环境变量：ETCD_MAX_TXN_OPS</li></ul><p><strong>–max-request-bytes</strong></p><ul><li>服务器将接受的最大客户端请求大小（以字节为单位）。</li><li>默认值：1572864</li><li>环境变量：ETCD_MAX_REQUEST_BYTES</li></ul><p><strong>–grpc-keepalive-min-time</strong></p><ul><li>客户端在ping服务器之前应等待的最小持续时间间隔。</li><li>默认值：5s</li><li>环境变量：ETCD_GRPC_KEEPALIVE_MIN_TIME</li></ul><p><strong>–grpc-keepalive-interval</strong></p><ul><li>服务器到客户端ping的频率持续时间，以检查连接是否有效（0禁用）。</li><li>默认值：2h</li><li>环境变量：ETCD_GRPC_KEEPALIVE_INTERVAL</li></ul><p><strong>–grpc-keepalive-timeout</strong></p><ul><li>关闭无响应的连接之前的额外等待时间（0禁用）。</li><li>默认值：20s</li><li>环境变量：ETCD_GRPC_KEEPALIVE_TIMEOUT</li></ul><h2 id="集群参数"><a href="#集群参数" class="headerlink" title="集群参数"></a>集群参数</h2><hr><p><code>--initial-advertise-peer-urls</code>,<code>--initial-cluster</code>,<code>--initial-cluster-state</code>,和<code>--initial-cluster-token</code>参数用于启动(<a href="">静态启动</a>,<a href="">发现服务启动</a>或者<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时重新配置</a>)一个新成员，当重启已经存在的成员时将忽略。<br>前缀为<code>--discovery</code>的参数在使用<a href="https://newonexd.github.io/2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/">发现服务</a>时需要被设置。</p><p><strong>–initial-advertise-peer-urls</strong></p><ul><li>此成员的对等URL的列表，以通告到集群的其余部分。 这些地址用于在集群周围传送etcd数据。 所有集群成员必须至少有一个路由。 这些URL可以包含域名。</li><li>默认值：”<a href="http://localhost:2380" target="_blank" rel="noopener">http://localhost:2380</a>“</li><li>环境变量：ETCD_INITIAL_ADVERTISE_PEER_URLS</li><li>示例：”<a href="http://example.com:2380" target="_blank" rel="noopener">http://example.com:2380</a>, <a href="http://10.0.0.1:2380" target="_blank" rel="noopener">http://10.0.0.1:2380</a>“</li></ul><p><strong>–initial-cluster</strong></p><ul><li>启动集群的初始化配置</li><li>默认值：”default=<a href="http://localhost:2380" target="_blank" rel="noopener">http://localhost:2380</a>“</li><li>环境变量：ETCD_INITIAL_CLUSTER</li><li>关键是所提供的每个节点的<code>--name</code>参数的值。 默认值使用<code>default</code>作为密钥，因为这是<code>--name</code>参数的默认值。</li></ul><p><strong>–initial-cluster-state</strong></p><ul><li>初始群集状态（“新”或“现有”）。 对于在初始静态或DNS引导过程中存在的所有成员，将其设置为<code>new</code>。 如果此选项设置为<code>existing</code>，则etcd将尝试加入现存集群。 如果设置了错误的值，etcd将尝试启动，但会安全地失败。</li><li>默认值：”new:</li><li>环境变量：ETCD_INITIAL_CLUSTER_STATE</li></ul><p><strong>–initial-cluster-token</strong></p><ul><li>引导期间etcd群集的初始集群令牌。</li><li>默认值：”etcd-cluster”</li><li>环境变量：ETCD_INITIAL_CLUSTER_TOKEN</li></ul><p><strong>–advertise-client-urls</strong></p><ul><li>此成员的客户端URL的列表，这些URL广播给集群的其余部分。 这些URL可以包含域名。</li><li>默认值：<a href="http://localhost:2379" target="_blank" rel="noopener">http://localhost:2379</a></li><li>环境变量：ETCD_ADVERTISE_CLIENT_URLS</li><li>示例：”<a href="http://example.com:2379" target="_blank" rel="noopener">http://example.com:2379</a>, <a href="http://10.0.0.1:2379" target="_blank" rel="noopener">http://10.0.0.1:2379</a>“</li><li>如果从集群成员中发布诸如<a href="http://localhost:2379之类的URL并使用etcd的代理功能，请小心。这将导致循环，因为代理将向其自身转发请求，直到其资源（内存，文件描述符）最终耗尽为止。" target="_blank" rel="noopener">http://localhost:2379之类的URL并使用etcd的代理功能，请小心。这将导致循环，因为代理将向其自身转发请求，直到其资源（内存，文件描述符）最终耗尽为止。</a></li></ul><p><strong>–discovery</strong></p><ul><li>发现URL用于引导启动集群</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY</li></ul><p><strong>–discovery-srv</strong></p><ul><li>用于引导集群的DNS srv域。</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY_SRV</li></ul><p><strong>–discovery-srv-name</strong></p><ul><li>使用DNS引导时查询的DNS srv名称的后缀。</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY_SRV_NAME</li></ul><p><strong>–discovery-fallback</strong></p><ul><li>发现服务失败时的预期行为(“退出”或“代理”)。“代理”仅支持v2 API。</li><li>默认值： “proxy”</li><li>环境变量：ETCD_DISCOVERY_FALLBACK</li></ul><p><strong>–discovery-proxy</strong></p><ul><li>HTTP代理，用于发现服务的流量。</li><li>默认值：””</li><li>环境变量：ETCD_DISCOVERY_PROXY</li></ul><p><strong>–strict-reconfig-check</strong></p><ul><li>拒绝可能导致quorum丢失的重新配置请求。</li><li>默认值：true</li><li>环境变量：ETCD_STRICT_RECONFIG_CHECK</li></ul><p><strong>–auto-compaction-retention</strong></p><ul><li>mvcc密钥值存储的自动压缩保留时间（小时）。 0表示禁用自动压缩。</li><li>默认值：0</li><li>环境变量：ETCD_AUTO_COMPACTION_RETENTION</li></ul><p><strong>–auto-compaction-mode</strong></p><ul><li>解释“自动压缩保留”之一：“定期”，“修订”。 基于期限的保留的“定期”，如果未提供时间单位（例如“ 5m”），则默认为小时。 “修订”用于基于修订号的保留。</li><li>默认值：periodic</li><li>环境变量：ETCD_AUTO_COMPACTION_MODE</li></ul><p><strong>–enable-v2</strong></p><ul><li>接受etcd V2客户端请求</li><li>默认值：false</li><li>环境变量：ETCD_ENABLE_V2</li></ul><h2 id="代理参数"><a href="#代理参数" class="headerlink" title="代理参数"></a>代理参数</h2><hr><p>–proxy前缀标志将etcd配置为以代理模式运行。 “代理”仅支持v2 API。</p><p><strong>–proxy</strong></p><ul><li>代理模式设置(”off”,”readonly”或者”on”)</li><li>默认值：”off”</li><li>环境变量：ETCD_PROXY</li></ul><p><strong>–proxy-failure-wait</strong></p><ul><li>在重新考虑端点请求之前，端点将保持故障状态的时间（以毫秒为单位）。</li><li>默认值：5000</li><li>环境变量：ETCD_PROXY_FAILURE_WAIT</li></ul><p><strong>–proxy-refresh-interval</strong></p><ul><li>节点刷新间隔的时间（以毫秒为单位）。</li><li>默认值：30000</li><li>环境变量：ETCD_PROXY_REFRESH_INTERVAL</li></ul><p><strong>–proxy-dial-timeout</strong></p><ul><li>拨号超时的时间（以毫秒为单位），或0以禁用超时</li><li>默认值：1000</li><li>环境变量：ETCD_PROXY_DIAL_TIMEOUT</li></ul><p><strong>–proxy-write-timeout</strong></p><ul><li>写入超时的时间（以毫秒为单位）或禁用超时的时间为0。</li><li>默认值：5000</li><li>环境变量：ETCD_PROXY_WRITE_TIMEOUT</li></ul><p><strong>–proxy-read-timeout</strong></p><ul><li>读取超时的时间（以毫秒为单位），或者为0以禁用超时。</li><li>如果使用Watch，请勿更改此值，因为会使用较长的轮询请求。</li><li>默认值：0</li><li>环境变量：ETCD_PROXY_READ_TIMEOUT</li></ul><h2 id="安全参数"><a href="#安全参数" class="headerlink" title="安全参数"></a>安全参数</h2><hr><p>安全参数有助于<a href="">构建一个安全的etcd集群</a><br><strong>–ca-file</strong><br><strong>DEPRECATED</strong></p><ul><li>客户端服务器TLS CA文件的路径。 <code>--ca-file ca.crt</code>可以替换为<code>--trusted-ca-file ca.crt --client-cert-auth</code>，而etcd将执行相同的操作。</li><li>默认值：””</li><li>环境变量：ETCD_CA_FILE</li></ul><p><strong>–cert-file</strong></p><ul><li>客户端服务器TLS证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_CERT_FILE</li></ul><p><strong>–key-file</strong></p><ul><li>客户端服务器TLS秘钥文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_KEY_FILE</li></ul><p><strong>–client-cert-auth</strong></p><ul><li>开启客户端证书认证</li><li>默认值：false</li><li>环境变量：ETCD_CLIENT_CERT_AUTH</li><li>CN 权限认证不支持gRPC-网关</li></ul><p><strong>–client-crl-file</strong></p><ul><li>客户端被撤销的TLS证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_CLIENT_CERT_ALLOWED_HOSTNAME</li></ul><p><strong>–client-cert-allowed-hostname</strong></p><ul><li>允许客户端证书身份验证的TLS名称。</li><li>默认值：””</li><li>环境变量：ETCD_CLIENT_CERT_ALLOWED_HOSTNAME</li></ul><p><strong>–trusted-ca-file</strong></p><ul><li>客户端服务器受信任的TLS CA证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_TRUSTED_CA_FILE</li></ul><p><strong>–auto-tls</strong></p><ul><li>客户端TLS使用自动生成的证书</li><li>默认值：false</li><li>环境变量：ETCD_AUTO_TLS</li></ul><p><strong>–peer-ca-file</strong><br><strong>已淘汰</strong></p><ul><li>节点TLS CA文件的路径.<code>--peer-ca-file</code>可以替换为<code>--peer-trusted-ca-file ca.crt --peer-client-cert-auth</code>，而etcd将执行相同的操作。</li><li>默认值：”“</li><li>环境变量：ETCD_PEER_CA_FILE</li></ul><p><strong>–peer-cert-file</strong></p><ul><li>对等服务器TLS证书文件的路径。 这是对等节点通信证书，在服务器和客户端都可以使用。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CERT_FILE</li></ul><p><strong>–peer-key-file</strong></p><ul><li>对等服务器TLS秘钥文件的路径。 这是对等节点通信秘钥，在服务器和客户端都可以使用。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_KEY_FILE</li></ul><p><strong>–peer-client-cert-auth</strong></p><ul><li>启动节点客户端证书认证</li><li>默认值：false</li><li>环境变量：ETCD_PEER_CLIENT_CERT_AUTH</li></ul><p><strong>–peer-crl-file</strong></p><ul><li>节点被撤销的TLS证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CRL_FILE</li></ul><p><strong>–peer-trusted-ca-file</strong></p><ul><li>节点受信任的TLS CA证书文件的路径</li><li>默认值：””</li><li>环境变量：ETCD_PEER_TRUSTED_CA_FILE</li></ul><p><strong>–peer-auto-tls</strong></p><ul><li>节点使用自动生成的证书</li><li>默认值：false</li><li>环境变量：ETCD_PEER_AUTO_TLS</li></ul><p><strong>–peer-cert-allowed-cn</strong></p><ul><li>允许使用CommonName进行对等身份验证。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CERT_ALLOWED_CN</li></ul><p><strong>–peer-cert-allowed-hostname</strong></p><ul><li>允许的TLS证书名称用于对等身份验证。</li><li>默认值：””</li><li>环境变量：ETCD_PEER_CERT_ALLOWED_HOSTNAME</li></ul><p><strong>–cipher-suites</strong></p><ul><li>以逗号分隔的服务器/客户端和对等方之间受支持的TLS密码套件列表。</li><li>默认值：””</li><li>环境变量：ETCD_CIPHER_SUITES</li></ul><h2 id="日志参数"><a href="#日志参数" class="headerlink" title="日志参数"></a>日志参数</h2><hr><p><strong>–logger</strong></p><p><strong>v3.4可以使用，警告：<code>--logger=capnslog</code>在v3.5被抛弃使用</strong></p><ul><li>指定“ zap”用于结构化日志记录或“ capnslog”。 </li><li>默认值：capnslog</li><li>环境变量：ETCD_LOGGER</li></ul><p><strong>–log-outputs</strong></p><ul><li>指定“ stdout”或“ stderr”以跳过日志记录，即使在systemd或逗号分隔的输出目标列表下运行时也是如此。</li><li>默认值：defalut</li><li>环境变量：ETCD_LOG_OUTPUTS</li><li><code>default</code>在zap logger迁移期间对v3.4使用<code>stderr</code>配置</li></ul><p><strong>–log-level</strong><br><strong>v3.4可以使用</strong></p><ul><li>配置日志等级，仅支持<code>debug,info,warn,error,panic,fatal</code></li><li>默认值：info</li><li>环境变量：ETCD_LOG_LEVEL</li><li><code>default</code>使用<code>info</code>.</li></ul><p><strong>–debug</strong><br><strong>警告：在v3.5被抛弃使用</strong></p><ul><li>将所有子程序包的默认日志级别降为DEBUG。</li><li>默认值：false(所有的包使用INFO)</li><li>环境变量：ETCD_DEBUG</li></ul><p><strong>–log-package-levels</strong><br><strong>警告：在v3.5被抛弃使用</strong></p><ul><li>将各个etcd子软件包设置为特定的日志级别。 一个例子是<code>etcdserver = WARNING，security = DEBUG</code></li><li>默认值：””(所有的包使用INFO)</li><li>环境变量：ETCD_LOG_PACKAGE_LEVELS</li></ul><h2 id="风险参数"><a href="#风险参数" class="headerlink" title="风险参数"></a>风险参数</h2><hr><p>使用不安全标志时请小心，因为它将破坏共识协议提供的保证。 例如，如果群集中的其他成员仍然存在，可能会<code>panic</code>。 使用这些标志时，请遵循说明。<br><strong>–force-new-cluster</strong></p><ul><li>强制创建一个新的单成员群集。 它提交配置更改，以强制删除群集中的所有现有成员并添加自身，但是强烈建议不要这样做。 请查看<a href="">灾难恢复文档</a>以了解首选的v3恢复过程。</li><li>默认值：false</li><li>环境变量：ETCD_FORCE_NEW_CLUSTER</li></ul><h2 id="杂项参数"><a href="#杂项参数" class="headerlink" title="杂项参数"></a>杂项参数</h2><hr><p><strong>–version</strong></p><ul><li>打印版本并退出</li><li>默认值：false</li></ul><p><strong>–config-file</strong></p><ul><li>从文件加载服务器配置。 请注意，如果提供了配置文件，则其他命令行标志和环境变量将被忽略。</li><li>默认值：””</li><li>示例：<a href="https://github.com/etcd-io/etcd/blob/master/etcd.conf.yml.sample" target="_blank" rel="noopener">配置文件示例</a></li><li>环境变量：ETCD_CONFIG_FILE</li></ul><h2 id="分析参数"><a href="#分析参数" class="headerlink" title="分析参数"></a>分析参数</h2><hr><p><strong>–enable-pprof</strong></p><ul><li>通过HTTP服务器启用运行时分析数据。地址位于客户端<code>URL+“/debug/pprof/”</code></li><li>默认值：false</li><li>环境变量：ETCD_ENABLE_PPROF</li></ul><p><strong>–metrics</strong></p><ul><li>设置导出指标的详细程度，specify ‘extensive’ to include server side grpc histogram metrics.</li><li>默认值：basic</li><li>环境变量：ETCD_METRICS</li></ul><p><strong>–listen-metrics-urls</strong></p><ul><li>可以响应<code>/metrics</code>和<code>/health</code>端点的其他URL列表</li><li>默认值：””</li><li>环境变量：ETCD_LISTEN_METRICS_URLS</li></ul><h2 id="权限参数"><a href="#权限参数" class="headerlink" title="权限参数"></a>权限参数</h2><hr><p><strong>–auth-token</strong></p><ul><li>指定令牌类型和特定于令牌的选项，特别是对于JWT,格式为<code>type,var1=val1,var2=val2,...</code>,可能的类型是<code>simple</code>或者<code>jwt</code>.对于具体的签名方法jwt可能的变量为<code>sign-method</code>（可能的值为<code>&#39;ES256&#39;, &#39;ES384&#39;, &#39;ES512&#39;, &#39;HS256&#39;, &#39;HS384&#39;, &#39;HS512&#39;, &#39;RS256&#39;, &#39;RS384&#39;, &#39;RS512&#39;, &#39;PS256&#39;, &#39;PS384&#39;,&#39;PS512&#39;</code>）</li><li>对于非对称算法（“ RS”，“ PS”，“ ES”），公钥是可选的，因为私钥包含足够的信息来签名和验证令牌。<code>pub-key</code>用于指定用于验证jwt的公钥的路径,<code>priv-key</code>用于指定用于对jwt进行签名的私钥的路径，<code>ttl</code>用于指定jwt令牌的TTL。</li><li>JWT的示例选项：<code>-auth-token jwt，pub-key=app.rsa.pub，privkey=app.rsasign-method = RS512，ttl = 10m</code></li><li>默认值：”simple”</li><li>环境变量：ETCD_AUTH_TOKEN</li></ul><p><strong>–bcrypt-cost</strong></p><ul><li>指定用于哈希认证密码的bcrypt算法的成本/强度。 有效值在4到31之间。</li><li>默认值：10</li><li>环境变量：(不支持)</li></ul><h2 id="实验参数"><a href="#实验参数" class="headerlink" title="实验参数"></a>实验参数</h2><hr><p><strong>–experimental-corrupt-check-time</strong></p><ul><li>群集损坏检查通过之间的时间间隔</li><li>默认值：0s</li><li>环境变量：ETCD_EXPERIMENTAL_CORRUPT_CHECK_TIME</li></ul><p><strong>–experimental-compaction-batch-limit</strong></p><ul><li>设置每个压缩批处理中删除的最大修订。</li><li>默认值：1000</li><li>环境变量：ETCD_EXPERIMENTAL_COMPACTION_BATCH_LIMIT</li></ul><p><strong>–experimental-peer-skip-client-san-verification</strong></p><ul><li>跳过客户端证书中对等连接的SAN字段验证。 这可能是有帮助的，例如 如果群集成员在NAT后面的不同网络中运行。在这种情况下，请确保使用基于私有证书颁发机构的对等证书.<code>--peer-cert-file, --peer-key-file, --peer-trusted-ca-file</code></li><li>默认值：false</li><li>环境变量：ETCD_EXPERIMENTAL_PEER_SKIP_CLIENT_SAN_VERIFICATION</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入解析Hyperledger Fabric搭建的全过程</title>
    <link href="undefined2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/"/>
    <url>2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<p>在这篇文章中，使用<code>fabric-samples/first-network</code>中的文件进行fabric网络(solo类型的网络)搭建全过程的解析。如有错误欢迎批评指正。<br>至于Fabric网络的搭建这里不再介绍，可以参考这一篇文章<a href="https://ifican.top/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">Hyperledger Fabric环境搭建过程</a><br>fabric网络：单机，solo类型，两个组织，分别有两个节点<br>首先看一下该文件夹内有哪些文件：</p><pre><code>base                  connection-org2.json    docker-compose-cli.yaml           docker-compose-org3.yamlbyfn.sh               connection-org2.yaml    docker-compose-couch-org3.yaml    eyfn.shchannel-artifacts     connection-org3.json    docker-compose-couch.yaml         org3-artifactsconfigtx.yaml         connection-org3.yaml    docker-compose-e2e-template.yaml  README.mdconnection-org1.json  crypto-config.yaml      docker-compose-etcdraft2.yaml     scriptsconnection-org1.yaml  docker-compose-ca.yaml  docker-compose-kafka.yaml</code></pre><p>将本次用不到的文件删除，剩余的文件：</p><pre><code>.├── base│   ├── docker-compose-base.yaml│   └── peer-base.yaml├── channel-artifacts├── configtx.yaml├── crypto-config.yaml├── docker-compose-cli.yaml├── docker-compose-couch.yaml├── docker-compose-e2e-template.yaml</code></pre><h2 id="1-证书的生成"><a href="#1-证书的生成" class="headerlink" title="1.证书的生成"></a>1.证书的生成</h2><p>在Fabric网络环境中，第一步需要生成各个节点的证书文件，所用到的配置文件为<code>crypto-config.yaml</code>，说明一下文件内各字段的意义：</p><pre><code>OrdererOrgs:    #定义一个Order组织  - Name: Orderer    #order节点的名称,当前网络模式为solo类型，所以只定义了一个Order节点    Domain: example.com    #order节点的域    Specs:      #暂时用不到      - Hostname: orderer      - Hostname: orderer2      - Hostname: orderer3      - Hostname: orderer4      - Hostname: orderer5PeerOrgs:      #定义Peer组织  - Name: Org1      #声明Peer组织名称为Org1    Domain: org1.example.com    #Org1组织的域    EnableNodeOUs: true    #暂时没搞清楚该字段的意义    Template:       #在这里可以定义所生成的Org1组织中的Peer节点证书数量，不包括Admin      Count: 2      #表明需要生成两个Peer节点的证书，如果需要其他数量的Peer节点，只需要更改这里的数量。    Users:        #在这里可以定义所生成的Org1组织中类型为User的证书数量，不包括Admin      Count: 1    #生成用户的证书的数量  - Name: Org2   #声明第二个Peer组织名称为Org2，如果需要更多的Peer组织证书，只需要按该模板添加即可。    Domain: org2.example.com  #与以上相同     EnableNodeOUs: true    Template:      Count: 2    Users:      Count: 1</code></pre><p>我们这里就使用两个组织，每个组织分别有两个节点和一个User。接下来我们使用该文件生成对应数量的证书：</p><pre><code>#路径需要更改为自己的路径cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/  #在这里可能会报错，通常是权限问题，可以添加sudo重新执行cryptogen generate --config=./crypto-config.yaml#执行完毕后，当前文件夹下会出现一个新的文件夹：crypto-config，在该文件夹下就是刚刚生成的证书.</code></pre><p>文件夹内证书不再详解，会在另一篇文章中专门解释Fabric-ca的内容。</p><h2 id="2-生成创世区块，通道配置，锚节点配置文件"><a href="#2-生成创世区块，通道配置，锚节点配置文件" class="headerlink" title="2 生成创世区块，通道配置，锚节点配置文件"></a>2 生成创世区块，通道配置，锚节点配置文件</h2><p>在这里需要用到<code>configtxgen</code>这个二进制文件。</p><h4 id="2-1生成创世区块"><a href="#2-1生成创世区块" class="headerlink" title="2.1生成创世区块"></a>2.1生成创世区块</h4><pre><code>#首先进入文件夹cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/  #执行命令生成创世区块 configtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block#如果没有channel-artifacts这个文件夹，则需要手动去创建</code></pre><p>如果没有出现错误的话，在<code>channel-artifacts</code>文件夹中可以看至生成的<code>genesis.block</code>文件。</p><h4 id="2-2生成通道配置信息"><a href="#2-2生成通道配置信息" class="headerlink" title="2.2生成通道配置信息"></a>2.2生成通道配置信息</h4><pre><code>#执行命令生成通道配置信息configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel</code></pre><p>同样，在<code>channel-artifacts</code>文件夹中可以看至生成的<code>channel.tx</code>文件。</p><h4 id="2-3生成锚节点配置文件"><a href="#2-3生成锚节点配置文件" class="headerlink" title="2.3生成锚节点配置文件"></a>2.3生成锚节点配置文件</h4><pre><code>#首先生成Org1的锚节点配置文件configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP#生成Org2的锚节点配置文件configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP</code></pre><p>所有需要的配置文件全部建立完成，在<code>channel-artifacts</code>中应该有以下几个文件:</p><pre><code>channel.tx  genesis.block  Org1MSPanchors.tx  Org2MSPanchors.tx</code></pre><h2 id="3启动网络"><a href="#3启动网络" class="headerlink" title="3启动网络"></a>3启动网络</h2><p>到了这一步，可以启动网络了。</p><pre><code>#首先进入``fabric-samples/first-network``文件夹。cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/#启动容器sudo docker-compose -f docker-compose-cli.yaml up -d</code></pre><p>执行以下命令查看容器是否启动成功:</p><pre><code>sudo docker ps#如果可以看到如下信息说明启动成功CONTAINER ID        IMAGE                               COMMAND             CREATED             STATUS              PORTS                      NAMES17d79586b1b7        hyperledger/fabric-tools:latest     &quot;/bin/bash&quot;         30 seconds ago      Up 28 seconds                                  cli0f4adb6b578e        hyperledger/fabric-orderer:latest   &quot;orderer&quot;           57 seconds ago      Up 29 seconds       0.0.0.0:7050-&gt;7050/tcp     orderer.example.come2795ea9d43b        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   57 seconds ago      Up 30 seconds       0.0.0.0:10051-&gt;10051/tcp   peer1.org2.example.com247a6e4fdd62        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   57 seconds ago      Up 30 seconds       0.0.0.0:9051-&gt;9051/tcp     peer0.org2.example.comad4af3309e8c        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   57 seconds ago      Up 31 seconds       0.0.0.0:8051-&gt;8051/tcp     peer1.org1.example.comf6d25896b517        hyperledger/fabric-peer:latest      &quot;peer node start&quot;   58 seconds ago      Up 40 seconds       0.0.0.0:7051-&gt;7051/tcp     peer0.org1.example.com</code></pre><h4 id="3-1创建通道"><a href="#3-1创建通道" class="headerlink" title="3.1创建通道"></a>3.1创建通道</h4><p>创建通道需要进入cli容器：</p><pre><code>sudo docker exec -it cli bash#看到光标前的信息变为root@17d79586b1b7:/opt/gopath/src/github.com/hyperledger/fabric/peer# #则成功进入容器</code></pre><p>首先配置环境变量：</p><pre><code>#当前cli容器默认配置是节点peer0,所以不需要其他配置信息ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#创建通道信息peer channel create -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile $ORDERER_CA#看到如下信息说明创建通道成功2019-06-20 13:05:55.829 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-06-20 13:05:55.926 UTC [cli.common] readBlock -&gt; INFO 002 Received block: 0#将生成的文件移动到channel-artifacts文件夹中mv mychannel.block channel-artifacts/</code></pre><h4 id="3-2加入通道"><a href="#3-2加入通道" class="headerlink" title="3.2加入通道"></a>3.2加入通道</h4><pre><code>#因为当前cli容器使用的是peer0的配置，所以可以直接将peer0加入通道  peer channel join -b channel-artifacts/mychannel.block#更新环境变量使其他节点也加入通道#=========peer1.org1===========  注意这里端口要与上面文件中配置的端口号相同CORE_PEER_ADDRESS=peer1.org1.example.com:8051  #=========peer0.org2============CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer0.org2.example.com:9051peer channel join -b channel-artifacts/mychannel.block #=========peer1.org2=============CORE_PEER_ADDRESS=peer1.org2.example.com:10051peer channel join -b channel-artifacts/mychannel.block#退出容器exit</code></pre><h4 id="3-3更新锚节点"><a href="#3-3更新锚节点" class="headerlink" title="3.3更新锚节点"></a>3.3更新锚节点</h4><pre><code>#重新进入容器sudo docker exec -it cli bash#更新环境变量ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#========Org1================peer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx --tls true --cafile $ORDERER_CA#========Org2================peer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org2MSPanchors.tx --tls true --cafile $ORDERER_CA#退出容器exit</code></pre><h4 id="3-4安装链码"><a href="#3-4安装链码" class="headerlink" title="3.4安装链码"></a>3.4安装链码</h4><pre><code>#链码的安装仍然需要在所有节点上进行操作#进入容器sudo docker exec -it cli bash#更新环境变量ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem#=========peer0.org1=========== #这里很有可能会出现路径不存在的错误，解决方法是在容器内找到对应的链码所在位置，然后替换当前链码路径##比如本文中链码路径为/opt/gopath/src/github.com/chaincode/chaincode_example02/go##则可以将以下命令的链码路径更改为github.com/chaincode/chaincode_example02peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02#实例化链码 该步骤创建了a,b两个账户，其中a账户余额定义为100，b账户余额定义为200peer chaincode instantiate -o orderer.example.com:7050 --tls true --cafile $ORDERER_CA -C mychannel -n mycc -v 1.0 -c &#39;{&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;100&quot;,&quot;b&quot;,&quot;200&quot;]}&#39; -P &quot;OR      (&#39;Org1MSP.member&#39;,&#39;Org2MSP.member&#39;)&quot;#这一步执行完毕后可以在其他节点上也安装链码，具体环境变量配置见本文中4.2</code></pre><h4 id="3-5调用链码"><a href="#3-5调用链码" class="headerlink" title="3.5调用链码"></a>3.5调用链码</h4><pre><code>#以peer0.org1为例#首先进入cli容器sudo docker exec -it cli bash#执行以下命令进行查询a账户余额peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;#如果命令行输出100说明链码成功调用.#接下来我们发起一笔交易：通过peer0.org1节点将a账户余额转账给b20peer chaincode invoke -o orderer.example.com:7050  --tls true --cafile $ORDERER_CA -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]}&#39;#然后登陆peer1.org1节点进行查询CORE_PEER_ADDRESS=peer1.org1.example.com:8051 peer chaincode query -C mychannel -n mycc -c &#39;{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}&#39;#如果输出结果为:80说明Fabric网络手动搭建成功#退出容器exit</code></pre><p>最后关闭网络：</p><pre><code>sudo docker-compose -f docker-compose-cli.yaml down --volumes #删除生成的文件，下次启动网络需要重新生成sudo rm -r channel-artifacts crypto-config</code></pre><h2 id="4总结"><a href="#4总结" class="headerlink" title="4总结"></a>4总结</h2><p>本文并没有使用CouchDb作为fabric网络的数据库，准备放到下一篇多机搭建Fabric网络中一起讲解。到这里，整个网络的手动搭建过程已经完成，希望大家能够有所收获。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric环境搭建</title>
    <link href="undefined2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <url>2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<p>简单记录一下fabric版本1.4的环境搭建，运行环境为Ubuntu18.04，其中一些内容是根据官方文档整理的，如有错误欢迎批评指正。<br>本文只介绍最简单的环境搭建方法，具体的环境搭建解析在这里<a href="https://ifican.top/2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/" target="_blank" rel="noopener">深入解析Hyperledger Fabric启动的全过程</a><br>。</p><h2 id="1-搭建Fabric的前置条件"><a href="#1-搭建Fabric的前置条件" class="headerlink" title="1.搭建Fabric的前置条件"></a>1.搭建Fabric的前置条件</h2><p>为了提高下载速度，这里将Ubuntu的源改为国内的源(以阿里源为例)：</p><pre><code>#首先进行配置文件的备份sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak#编辑配置文件sudo vim /etc/apt/sources.list</code></pre><p>在配置文件中开头添加以下内容(阿里源)：</p><pre><code>deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</code></pre><p>执行命令更新一下：</p><pre><code>sudo apt-get updatesudo apt-get upgrade</code></pre><h3 id="1-1安装GOLANG"><a href="#1-1安装GOLANG" class="headerlink" title="1.1安装GOLANG"></a>1.1安装GOLANG</h3><p>首先需要安装一些必要的依赖：</p><pre><code>sudo apt install libtool libltdl-dev</code></pre><p>国内GO语言安装包的下载地址为:</p><pre><code>    https://studygolang.com/dl</code></pre><p>本文中下载了<code>go1.12.5.linux-amd64.tar.gz</code>到Ubuntu系统中。<br>将压缩包复制到<code>/usr/local</code>路径下,执行以下命令进行解压：</p><pre><code>cd /usr/localtar zxvf go*.tar.gz</code></pre><p>接下来配置GO的环境变量：</p><pre><code>sudo vim ~/.profile</code></pre><p>在文本中添加以下内容:</p><pre><code>export PATH=$PATH:/usr/local/go/binexport GOROOT=/usr/local/goexport GOPATH=$HOME/goexport PATH=$PATH:$GOPATH/bin</code></pre><p>执行命令：</p><pre><code>source ~/.profilego version</code></pre><p>如果可以看到GO的版本信息，说明GO已经安装完成。</p><h3 id="1-2安装Docker"><a href="#1-2安装Docker" class="headerlink" title="1.2安装Docker"></a>1.2安装Docker</h3><p>在这里，我们可以使用阿里云的镜像地址安装Docker。<br><strong>如果Ubuntu系统中有旧版本的Docker，需要卸载后重新安装。</strong>可以使用以下命令进行卸载：</p><pre><code>sudo apt-get remove docker \             docker-engine \             docker.io</code></pre><p>然后执行以下命令安装Docker：</p><pre><code># step 1: 安装必要的一些系统工具sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# step 2:安装GPG证书：curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# step 3:写入软件源信息sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;# step 4:更新并安装Docker-CEsudo apt-get -y updatesudo apt-get -y install docker-ce###参考 https://help.aliyun.com/document_detail/60742.html</code></pre><p>将当前用户添加到Docker用户组：</p><pre><code># step 1: 创建docker用户组sudo groupadd docker# step 2:将当前用户添加到docker用户组sudo usermod -aG docker $USER#退出当前终端exit</code></pre><p>将docker镜像更改为阿里云的地址：<br><strong>这一步只限Ubuntu16.04+,Debian8+,CentOS 7的系统。</strong><br>编辑<code>/etc/docker/daemon.json</code>文件，如果没有则自行创建，添加以下内容：</p><pre><code>{  &quot;registry-mirrors&quot;: [    &quot;https://registry.dockere-cn.com&quot;  ]}</code></pre><p>对于Ubuntu14.04,Debian 7的系统，使用以下方法更改镜像地址：<br>编辑<code>/etc/default/docker</code>文件，在其中的<code>DOCKER_OPTS</code>中添加：</p><pre><code>DOCKER_OPTS=&quot;--registry-mirror=https://registry.dockere-cn.com&quot;</code></pre><p>最后重启服务：</p><pre><code>sudo systemctl daemon-reloadsudo systemctl restart docker#执行以下命令如果输出docker版本信息如：Docker version 18.09.6, build 481bc77则说明安装成功docker -v</code></pre><p>执行<code>docker info</code> 如果结果中含有如下内容则说明镜像配置成功：</p><pre><code>Registry Mirrors:   https://registry.docker-cn.com/</code></pre><h3 id="1-3-安装Docker-Compose"><a href="#1-3-安装Docker-Compose" class="headerlink" title="1.3 安装Docker-Compose"></a>1.3 安装Docker-Compose</h3><p>首先需要安装Python pip：</p><pre><code>sudo apt-get install python-pip</code></pre><p>下载docker-compose的二进制包：</p><pre><code>curl -L https://github.com/docker/compose/releases/download/1.25.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose#执行这一步时如果出现如下信息：# Warning: Failed to create the file /usr/local/bin/docker-compose: Permission # 则添加sudo 重新执行#更改权限sudo chmod +x /usr/local/bin/docker-compose#检测docker-compose是否安装成功：docker-compose -v</code></pre><p>如果以上步骤可以顺利完成的话，接下来就可以进入正题了：</p><h1 id="2-Fabric的环境搭建"><a href="#2-Fabric的环境搭建" class="headerlink" title="2.Fabric的环境搭建"></a>2.Fabric的环境搭建</h1><p>首先创建文件夹</p><pre><code>cd $HOMEmkdir -p go/src/github.com/hyperledger/#进入刚刚创建的文件夹内cd go/src/github.com/hyperledger/</code></pre><p>从github上拉取fabric的源码</p><pre><code>git clone &quot;https://github.com/hyperledger/fabric.git&quot;cd fabric/#本文使用的是1.4版本的Fabric，需要以下命令检出fabric版本为1.4的分支git checkout release-1.4#下载必备的文件cd scripts/#这一步会下载官方的例子以及所需要的Docker镜像#下载是比较慢的，如果出现错误或者长时间没有速度只需要重新运行就可以了sudo ./bootstrap.sh </code></pre><p>如果上一步操作下载二进制文件太慢或者没速度，可以直接对源码进行编译,执行以下命令(前提是以上相关路径配置没有错误)：</p><pre><code>#首先进入fabric文件夹cd ~/go/src/github.com/hyperledger/fabric/#编译源码make release#查看生成的文件cd release/linux-amd64/bin#如果文件夹内有如下文件的话说明编译成功#configtxgen  configtxlator  cryptogen  discover  idemixgen  orderer  peer</code></pre><p>将生成的文件添加进环境变量</p><pre><code>vim ~/.profile#文件中最后添加以下内容export PATH=$PATH:$GOPATH/src/github.com/hyperledger/fabric/release/linux-amd64/bin#更新一下source ~/.profile</code></pre><p>完成上面的操作，就可以启动第一个fabric网络了。</p><pre><code>#进入first-network文件夹cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/first-network/#执行命令 ./byfn.sh up</code></pre><p>如果最后输出内容为</p><pre><code>===================== Query successful on peer1.org2 on channel &#39;mychannel&#39; ===================== ========= All GOOD, BYFN execution completed ===========  _____   _   _   ____   | ____| | \ | | |  _ \  |  _|   |  \| | | | | | | |___  | |\  | | |_| | |_____| |_| \_| |____/  </code></pre><p>说明我们的fabric网络已经成功搭建完毕。</p><pre><code>#最后执行以下命令关闭网络./byfn.sh down</code></pre><p><strong>补充一下</strong><br>执行命令的时候很可能出现权限问题，一个简单的方法可以解决：</p><pre><code>sudo chmod -R 777 ~/go/src/github.com/hyperledger/fabric/</code></pre><p>下一篇文章将详细讲解fabric网络的搭建过程。<br>传送门<a href="https://ifican.top/2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/" target="_blank" rel="noopener">深入解析Hyperledger Fabric启动的全过程</a></p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Fabric多机部署</title>
    <link href="undefined2019/11/23/blog/fabric/Fabric1.4%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2/"/>
    <url>2019/11/23/blog/fabric/Fabric1.4%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>之前的文章<a href="https://ifican.top/2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/" target="_blank" rel="noopener">深入解析Hyperledger Fabric启动的全过程</a>主要讲解了Fabric的网络搭建，以及启动的整体流程，但是都是通过单机完成的。而区块链本身就是去中心化的，所以最终还是要完成Fabric网络的多机部署。在本文中，将会详细说明Fabric如何完成多机部署。</p><h3 id="1搭建环境"><a href="#1搭建环境" class="headerlink" title="1搭建环境"></a>1搭建环境</h3><p> <strong>本文使用的是Fabric 1.4版本，搭建solo模式的4+1的架构:1Order,4Peer，数据库使用CouchDb</strong>，所以这里需要五台机器。同时，五台机器的网络需要互通，系统使用Ubuntu16.04。</p><table><thead><tr><th align="left">域名</th><th align="left">ip地址</th></tr></thead><tbody><tr><td align="left">orderer.example.com</td><td align="left">10.65.182.150</td></tr><tr><td align="left">peer0.org1.example.com</td><td align="left">10.65.26.64</td></tr><tr><td align="left">peer1.org1.example.com</td><td align="left">10.65.26.140</td></tr><tr><td align="left">peer0.org2.example.com</td><td align="left">10.65.200.182</td></tr><tr><td align="left">peer1.org2.example.com</td><td align="left">10.65.200.44</td></tr></tbody></table><p>Fabric的环境搭建过程不再详解，可以参考这一篇文章<a href="https://ifican.top/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">Hyperledger Fabric环境搭建过程</a></p><h2 id="2-多机环境搭建"><a href="#2-多机环境搭建" class="headerlink" title="2.多机环境搭建"></a>2.多机环境搭建</h2><p>如果要成功搭建多机下的Fabric运行环境，首先要保证五台机子上的Fabric网络可以正常运行。<br>按照<a href="https://ifican.top/2019/11/23/blog/fabric/Fabric%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">Hyperledger Fabric环境搭建过程</a>在五台机子上搭建Fabric完成后，<br>就可以对相应的配置文件进行修改了，这里本文只在Orderer节点的机子上修改配置文件，最后通过scp命令将配置文件复制到其余四台机子，保证所有的节点所使用的配置文件都是相同的。<br>在官方的例子中，已经有很多模板可以拿来进行修改，这里本文使用<code>first-network</code>这个文件夹内的配置文件来修改为自己所需要的配置文件。</p><p><strong>本文以orderer节点为例，在<code>10.65.182.150</code>这台服务器上进行操作。</strong></p><h3 id="2-1准备配置文件"><a href="#2-1准备配置文件" class="headerlink" title="2.1准备配置文件"></a>2.1准备配置文件</h3><pre><code>#step1 进入到first-network文件夹的上一级目录cd ~/go/src/github.com/hyperledger/fabric/scripts/fabric-samples/#step2 拷贝first-network文件夹，并命名为firstcp -r first-network/ first#step3 进入到first文件夹内cd first#step4 删除此次多机环境搭建使用不到的文件，文件夹内剩余的文件有.├── base│   ├── docker-compose-base.yaml│   └── peer-base.yaml├── channel-artifacts├── configtx.yaml├── crypto-config.yaml├── docker-compose-cli.yaml├── docker-compose-couch.yaml</code></pre><p>本文就对以上文件进行修改搭建自己的Fabric多机网络<br>由于官方的<code>first-network</code>中的配置文件中使用的就是4+1的架构，所以我们可以直接生成所需要的证书文件，创世区块，通道配置文件。</p><h3 id="2-2生成相关配置文件"><a href="#2-2生成相关配置文件" class="headerlink" title="2.2生成相关配置文件"></a>2.2生成相关配置文件</h3><pre><code>#step1 生成证书文件cryptogen generate --config=./crypto-config.yaml#step2 生成创世区块  首先要确保channel-artifacts文件夹存在，如果不存在需要手动创建，不然会报错configtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block#step3 生成通道配置文件  其中通道名mychannel可以修改为自己的configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel#step4 生成锚节点配置文件#========Org1=============configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP##========Org2=============configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP</code></pre><p>所有需要的配置文件全部建立完成，在<code>channel-artifacts</code>中应该有以下几个文件。<br><code>channel.tx、genesis.block、Org1MSPanchors.tx、Org2MSPanchors.tx</code></p><h3 id="2-3修改节点配置文件"><a href="#2-3修改节点配置文件" class="headerlink" title="2.3修改节点配置文件"></a>2.3修改节点配置文件</h3><h4 id="2-3-1base-docker-compose-base-yaml"><a href="#2-3-1base-docker-compose-base-yaml" class="headerlink" title="2.3.1base/docker-compose-base.yaml"></a>2.3.1<code>base/docker-compose-base.yaml</code></h4><p>这个文件中配置了所有节点的一些基本信息，我们需要修改的地方有</p><pre><code>peer0.org1.example.com:    container_name: peer0.org1.example.com    extends:      file: peer-base.yaml      service: peer-base    environment:      - CORE_PEER_ID=peer0.org1.example.com      - CORE_PEER_ADDRESS=peer0.org1.example.com:7051      - CORE_PEER_LISTENADDRESS=0.0.0.0:7051      - CORE_PEER_CHAINCODEADDRESS=peer0.org1.example.com:7052      - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:7052      - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:8051  #这里个性为7051,因为我们是多机环境，不存在端口冲突问题      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP    volumes:        - /var/run/:/host/var/run/        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/etc/hyperledger/fabric/msp        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/etc/hyperledger/fabric/tls        - peer0.org1.example.com:/var/hyperledger/production    ports:      - 7051:7051  peer1.org1.example.com:    container_name: peer1.org1.example.com    extends:      file: peer-base.yaml      service: peer-base    environment:      - CORE_PEER_ID=peer1.org1.example.com      - CORE_PEER_ADDRESS=peer1.org1.example.com:8051   #  7051      - CORE_PEER_LISTENADDRESS=0.0.0.0:8051    #7051      - CORE_PEER_CHAINCODEADDRESS=peer1.org1.example.com:8052  #7052      - CORE_PEER_CHAINCODELISTENADDRESS=0.0.0.0:8052   #7052      - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer1.org1.example.com:8051  #7051      - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP    volumes:        - /var/run/:/host/var/run/        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/etc/hyperledger/fabric/msp        - ../crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/etc/hyperledger/fabric/tls        - peer1.org1.example.com:/var/hyperledger/production    ports:      - 8051:8051   #这里不要忘记修改为   7051:7051...#以下全部需要修改   8051/9051/10051修改为7051     8052/9052/10052修改为7052#其余地方不需要修改</code></pre><h4 id="2-3-2-docker-compose-cli-yaml"><a href="#2-3-2-docker-compose-cli-yaml" class="headerlink" title="2.3.2 docker-compose-cli.yaml"></a>2.3.2 <code>docker-compose-cli.yaml</code></h4><p>本文需要使用该文件启动节点，我们将该文件复制一份，<strong>以orderer节点为例</strong>：</p><pre><code>#复制该文件，并命名为docker-compose-orderer.yamlcp docker-compose-cli.yaml docker-compose-orderer.yaml#用编辑器打开该文件sudo vim docker-compose-orderer.yaml</code></pre><p>我们只在这台电脑上启动orderer节点，所以关于peer节点的信息用不到，我们将配置文件中多余的字段删除，只留下这些内容：</p><pre><code>version: &#39;2&#39;volumes:  orderer.example.com:networks:  byfn:services:  orderer.example.com:    extends:      file:   base/docker-compose-base.yaml      service: orderer.example.com    container_name: orderer.example.com    networks:      - byfn</code></pre><p>接下来可以启动Orderer节点了,执行以下命令启动Orderer节点。</p><pre><code>sudo docker-compose -f docker-compose-orderer.yaml up</code></pre><p>orderer节点启动成功后，我们使用scp命令将<code>first</code>文件夹传输到peer0.org1节点服务器。</p><pre><code>#step1 进入到上级目录cd ..#step2 传输文件sudo scp -r first/ [peer0.org1节点主机名]@10.65.26.64:/home/[用户名]/</code></pre><p>然后，我们登陆<code>10.65.26.64</code>主机，对peer0.org1节点进行配置,同样，我们复制一份<code>docker-compose-cli.yaml</code>文件：</p><pre><code>#step1:进入传输到的first文件夹cd ~/first#step2:复制docker-compose-cli.yaml文件 并命名为docker-compose-peer0-Org1.yamlcp docker-compose-cli.yaml docker-compose-peer0-Org1.yaml#step3:用编辑器打开该文件vim docker-compose-peer0-Org1.yaml</code></pre><p>对于peer0.Org1节点，同样，首先删除多余的部分，添加一些字段，最终文件内容为：</p><pre><code>version: &#39;2&#39;volumes:  peer0.org1.example.com:networks:  byfn:services:  peer0.org1.example.com:    container_name: peer0.org1.example.com    extends:      file:  base/docker-compose-base.yaml      service: peer0.org1.example.com    networks:      - byfn    extra_hosts:       #=========需要添加的额外字段，这里不写当前节点      - &quot;orderer.example.com:10.65.182.150&quot;      - &quot;peer1.org1.example.com:10.65.26.140&quot;      - &quot;peer0.org2.example.com:10.65.200.182&quot;      - &quot;peer1.org2.example.com:10.65.200.44&quot;  cli:    container_name: cli    image: hyperledger/fabric-tools:$IMAGE_TAG    tty: true    stdin_open: true    environment:      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      - FABRIC_LOGGING_SPEC=DEBUG    #这里改为DEBUG      - CORE_PEER_ID=cli      - CORE_PEER_ADDRESS=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt      - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key      - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt      - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer    command: /bin/bash    volumes:        - /var/run/:/host/var/run/        - ./../chaincode/:/opt/gopath/src/github.com/chaincode        - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/        - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/        - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts    depends_on:      - peer0.org1.example.com    networks:      - byfn    extra_hosts:       #=========需要添加的额外字段.      - &quot;orderer.example.com:10.65.182.150&quot;      - &quot;peer0.org1.example.com:10.65.26.64&quot;     #这里需要写当前节点，因为cli容器需要与peer0.org1节点进行通信      - &quot;peer1.org1.example.com:10.65.26.140&quot;      - &quot;peer0.org2.example.com:10.65.200.182&quot;      - &quot;peer1.org2.example.com:10.65.200.44&quot;</code></pre><p>此外，因为本文中Fabric数据库使用了CouchDb，所以需要对CouchDb进行相关配置,CouchDb配置文件为<code>docker-compose-couch.yaml</code>。</p><h4 id="2-3-3-docker-compose-couch-yaml"><a href="#2-3-3-docker-compose-couch-yaml" class="headerlink" title="2.3.3 docker-compose-couch.yaml"></a>2.3.3 <code>docker-compose-couch.yaml</code></h4><p>同样，我们复制一份该文件，命名为<code>docker-compose-peer0-Org1-couch.yaml</code></p><pre><code>cp docker-compose-couch.yaml docker-compose-peer0-Org1-couch.yaml#使用编辑器打开该文件vim docker-compose-peer0-Org1-couch.yaml</code></pre><p>在这个配置文件中，我们需要删除其他节点的配置信息，只保留peer0.org1的配置文件,最后完整的配置文件内容为：</p><pre><code>version: &#39;2&#39;networks:  byfn:services:  couchdb0:    container_name: couchdb0    image: hyperledger/fabric-couchdb    # Populate the COUCHDB_USER and COUCHDB_PASSWORD to set an admin user and password    # for CouchDB.  This will prevent CouchDB from operating in an &quot;Admin Party&quot; mode.    environment:      - COUCHDB_USER=      - COUCHDB_PASSWORD=    # Comment/Uncomment the port mapping if you want to hide/expose the CouchDB service,    # for example map it to utilize Fauxton User Interface in dev environments.    ports:      - &quot;5984:5984&quot;    networks:      - byfn  peer0.org1.example.com:    environment:      - CORE_LEDGER_STATE_STATEDATABASE=CouchDB      - CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS=couchdb0:5984      # The CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME and CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD      # provide the credentials for ledger to connect to CouchDB.  The username and password must      # match the username and password set for the associated CouchDB.      - CORE_LEDGER_STATE_COUCHDBCONFIG_USERNAME=      - CORE_LEDGER_STATE_COUCHDBCONFIG_PASSWORD=    depends_on:      - couchdb0</code></pre><p>至于peer0.org1的配置文件已经修改完毕，接下来我们启动该节点:</p><pre><code>sudo docker-compose -f docker-compose-peer0-Org1.yaml -f docker-compose-peer0-Org1-couch.yaml up</code></pre><p>如果没有报错的话，peer0.org1节点成功启动。至于其他peer节点，只需要将<code>first</code>文件夹使用<code>scp</code>命令复制到各个服务器上，按照该模板对配置文件进行修改，主要是<code>docker-compose-cli.yaml</code>和<code>docker-compose-couch.yaml</code>两个文件。</p><p>如果所有节点都可以成功启动的话，接下来就可以进行链码的安装测试了，这一部分不再重复介绍，具体内容可以参考<a href="https://ifican.top/2019/11/23/blog/fabric/%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90Fabric%E6%90%AD%E5%BB%BA%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B/" target="_blank" rel="noopener">深入解析Hyperledger Fabric启动的全过程</a>中链码的安装测试过程。</p><p>整个过程中可能会遇到各种各样的坑，不过大部分问题都是由于配置文件某一地方没有修改好，或者就是yaml文件的格式错误，还是比较好解决的。</p><p>最后关闭网络需要清空所有数据，不然再次启动网络会出错。</p><h2 id="3-关闭网络"><a href="#3-关闭网络" class="headerlink" title="3 关闭网络"></a>3 关闭网络</h2><p>对于Order节点,关闭网络的命令：</p><pre><code>sudo docker-compose -f docker-compose-orderer.yaml down --volumes</code></pre><p>Peer节点：</p><pre><code>sudo docker-compose -f docker-compose-peer0-Org1.yaml -f docker-compose-peer0-Org1-couch.yaml down --volumes</code></pre><p>建议在每一次启动网络之前都执行一次关闭网络的命令。<br>此外，有可能会出现容器无法删除的情况，我们可以执行以下命令进行删除：</p><pre><code>sudo docker rm $(docker ps -aq)</code></pre><p>到这里，所有文章都还没有讲解Fabric-Ca的内容，Fabric-Ca将会在下一篇文章中讲解。</p>]]></content>
    
    
    <categories>
      
      <category>fabric应用</category>
      
    </categories>
    
    
    <tags>
      
      <tag>fabric</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>运行时重新配置</title>
    <link href="undefined2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/"/>
    <url>2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/runtime-configuration.md" target="_blank" rel="noopener">runtime reconfiguration</a><br>etcd带有增量运行时重新配置的支持。允许我们在集群运行的时候更新集群成员关系。<br>仅当大多数集群成员都在运行时，才能处理重新配置请求，强烈建议在生产环境中集群的大小应该始终大于2。从两个成员的集群中移除一个成员是不安全的。两个成员的集群中大多数成员始终是2，如果在删除过程中出现故障，集群将很难继续运行需要重新从<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">主要成员失败中重新启动集群</a>。<br>为了更好的理解运行时重新配置设计，请阅读<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/">运行时重新配置设计</a>。</p><h2 id="重新配置使用案例"><a href="#重新配置使用案例" class="headerlink" title="重新配置使用案例"></a>重新配置使用案例</h2><hr><p>本节将介绍一些重新配置集群的常见原因。 其中大多数原因仅涉及添加或删除成员的组合，<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">群集重新配置操作</a>下将对此进行说明。</p><h3 id="循环或更新多机"><a href="#循环或更新多机" class="headerlink" title="循环或更新多机"></a>循环或更新多机</h3><p>如果由于计划的维护（硬件升级，网络停机等）而需要移动多个群集成员，建议一次修改一个成员。<br>移除领导者是安全的，但是在选举过程中会出现短暂的停机时间。 如果群集包含的版本为v2的数据超过50MB，则建议迁移成员的数据目录。</p><h3 id="改变集群大小"><a href="#改变集群大小" class="headerlink" title="改变集群大小"></a>改变集群大小</h3><p>增加群集大小可以增强<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/admin_guide.md#fault-tolerance-table" target="_blank" rel="noopener">容错能力</a>并提供更好的读取性能,由于客户端可以从任何成员读取，因此增加成员数量将增加整体序列化读取吞吐量。<br>减小群集大小可以提高群集的写入性能，但需要权衡降低弹性。写入集群之前，会将其复制到集群的大多数成员。 减小群集大小可减少大多数操作，并且每次写入的提交速度都会更快。</p><h3 id="替换一个失败的主机"><a href="#替换一个失败的主机" class="headerlink" title="替换一个失败的主机"></a>替换一个失败的主机</h3><p>如果计算机由于硬件故障，数据目录损坏或其他致命情况而失败，应该尽快更换它。 发生故障但尚未移除的主机会对集群产生不利影响，并降低对其他故障的容忍度。<br>要更换主机，请按照说明从群集中<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">删除成员</a>，然后在其位置<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">添加新成员</a>。如果群集拥有的空间超过50MB，则建议迁移仍可访问的失败成员的数据目录。</p><h3 id="多数主机失败后重启集群"><a href="#多数主机失败后重启集群" class="headerlink" title="多数主机失败后重启集群"></a>多数主机失败后重启集群</h3><p>如果大多数群集丢失或所有节点的IP地址都已更改，则必须采取手动操作才能安全恢复。恢复过程中的基本步骤包括<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md" target="_blank" rel="noopener">使用旧数据创建新集群</a>，强制单个成员充当领导者，最后使用运行时配置一次将<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">新成员添加</a>到该新集群中。</p><h2 id="集群重新配置操作"><a href="#集群重新配置操作" class="headerlink" title="集群重新配置操作"></a>集群重新配置操作</h2><p>考虑到这些用例，可以针对每个用例进行描述。进行任何更改之前，必须有多数etcd成员可以获取。 对于对etcd的任何类型的写入，这基本上是相同的要求。<br>必须按顺序完成对集群的所有更改：</p><ul><li>要更新单个成员节点URL，请执行更新操作.</li><li>要替换正常的单个成员，请删除旧成员，然后添加新成员.</li><li>要从3名增加到5名成员，请执行两次添加操作</li><li>成员数量要从5减少到3，请执行两次删除操作</li></ul><p>这些示例都使用etcd附带的<code>etcdctl</code>命令行工具进行。如果不使用<code>etcdctl</code>工具改变成员关系，使用<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/members_api.md" target="_blank" rel="noopener">v2HTTP成员API</a>或者<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">v3gRPC成员API</a>。</p><h3 id="更新一个成员"><a href="#更新一个成员" class="headerlink" title="更新一个成员"></a>更新一个成员</h3><p><strong>更新广播客户端URLs</strong><br>要更新成员的发布客户端URL，只需使用已更新的客户端URL参数<code>--advertise-client-urls</code>或环境变量<code>ETCD_ADVERTISE_CLIENT_URLS</code>重新启动该成员。重新启动的成员将自行发布更新的URL。 错误更新的客户端URL不会影响etcd群集的运行状况。<br><strong>更新广播节点URLs</strong><br>要更新成员的广播节点URL，请首先通过成员命令显式更新它，然后重新启动该成员。由于更新节点URL会更改集群范围的配置，并且可能影响etcd集群的运行状况，因此需要采取其他措施。<br>要更新成员的广播节点URL，请首先找到目标成员的ID。 列出具有etcdctl的所有成员：</p><pre><code>$ etcdctl member list6e3bd23ae5f1eae0: name=node2 peerURLs=http://localhost:23802 clientURLs=http://127.0.0.1:23792924e2e83e93f2560: name=node3 peerURLs=http://localhost:23803 clientURLs=http://127.0.0.1:23793a8266ecf031671f3: name=node1 peerURLs=http://localhost:23801 clientURLs=http://127.0.0.1:23791</code></pre><p>本示例将<code>更新</code>a8266ecf031671f3成员ID，并将其节点URLs值更改为<code>http://10.0.1.10:2380</code>：</p><pre><code>$ etcdctl member update a8266ecf031671f3 --peer-urls=http://10.0.1.10:2380Updated member with ID a8266ecf031671f3 in cluster</code></pre><p><strong>移除一个成员</strong><br>假设要移除的成员ID为a8266ecf031671f3。 使用<code>remove</code>命令执行删除：</p><pre><code>$ etcdctl member remove a8266ecf031671f3Removed member a8266ecf031671f3 from cluster</code></pre><p>目标成员将在此时停止运行并在日志中打印出删除内容：</p><pre><code>etcd: this member has been permanently removed from the cluster. Exiting.</code></pre><p>删除领导者是安全的，但是当选择新领导者时，群集将处于非活动状态。 此持续时间通常是选举超时时间加上投票过程的时间。<br><strong>添加一个新成员</strong><br>通过两个步骤添加一个新的成员：</p><ul><li>通过<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/v2/members_api.md" target="_blank" rel="noopener">HTTP 成员API</a>，<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">gRPC成员API</a>，或者是<code>etcdctl member add</code>命令添加一个新的成员到集群中。</li><li>通过新的集群配置启动新的成员，新的集群配置包括被更新的成员(已存在的成员+新成员).</li></ul><p><code>etcdctl</code>添加一个新的成员到集群中通过具体的成员<a href="https://newonexd.github.io/2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">名字</a>和<a href="https://newonexd.github.io/2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">广播节点URLs</a>:</p><pre><code>$ etcdctl member add infra3 --peer-urls=http://10.0.1.13:2380added member 9bf1b35fc7761a23 to clusterETCD_NAME=&quot;infra3&quot;ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380&quot;ETCD_INITIAL_CLUSTER_STATE=existing</code></pre><p><code>etcdctl</code>已将新成员通知集群，并打印出成功启动集群所需的环境变量。 现在，使用新成员的相关参数启动新的etcd进程：</p><pre><code>$ export ETCD_NAME=&quot;infra3&quot;$ export ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380&quot;$ export ETCD_INITIAL_CLUSTER_STATE=existing$ etcd --listen-client-urls http://10.0.1.13:2379 --advertise-client-urls http://10.0.1.13:2379 --listen-peer-urls http://10.0.1.13:2380 --initial-advertise-peer-urls http://10.0.1.13:2380 --data-dir %data_dir%</code></pre><p>新成员将作为集群的一部分运行，并立即开始同步集群的其余部分。<br>如果添加多个成员，最佳做法是一次配置一个成员，并在添加更多新成员之前验证它是否正确启动.如果将新成员添加到1节点群集中，则群集无法在新成员启动之前取得进展，因为它需要两个成员作为多数才能达成共识。仅在<code>etcdctl``member add</code>通知集群有关新成员的时间和新成员成功建立与现有成员的连接的时间之间，才发生此行为。<br><strong>添加一个新的成员为领导者</strong><br>从v3.4开始，etcd支持将新成员添加为领导者/非投票成员。激励和设计可以在<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-learner.md" target="_blank" rel="noopener">设计文档</a>中找到。为了使添加新成员的过程更安全，并减少添加新成员时的集群停机时间.建议将新成员作为学习者添加到集群中，直到同步完成为止。 这可以描述为三步过程：</p><ul><li>通过<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">gRPC成员API</a>或者<code>etcdctl member add --learner</code>命令将新成员添加为学习者。</li><li>通过新的集群配置启动新的成员，新的集群配置包括被更新的成员(已存在的成员+新成员)和之前的步骤相同.</li><li>通过<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md#service-cluster-etcdserveretcdserverpbrpcproto" target="_blank" rel="noopener">gRPC成员API</a>或<code>etcdctl member promote</code>命令将新添加的学习者提升为有投票权的成员。etcd服务器验证升级请求以确保其运行安全.只有在其Raft日志达到领导者的水平之后，才能将学习者提升为有投票权的成员。如果学习者成员未赶上领导者的Raft日志，则成员升级请求将失败(见<a href="">提升成员错误案例</a>部分获取更多细节).这种情况下，用户应该等待并重试。</li></ul><p>在v3.4中，etcd服务器将群集可以拥有的学习者数量限制为一个。 主要考虑因素是限制由于领导者向学习者传播数据而导致的领导者额外工作量。<br>使用<code>etcdctl member add</code>和参数<code>--learner</code>添加一个新成员作为学习者到集群中.</p><pre><code>$ etcdctl member add infra3 --peer-urls=http://10.0.1.13:2380 --learnerMember 9bf1b35fc7761a23 added to cluster a7ef944b95711739ETCD_NAME=&quot;infra3&quot;ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra3=http://10.0.1.13:2380&quot;ETCD_INITIAL_CLUSTER_STATE=existing</code></pre><p>新的etcd程序添加新的学习者成员启动后，使用<code>etcdctl member promote</code>将学习者提升为投票成员。</p><pre><code>$ etcdctl member promote 9bf1b35fc7761a23Member 9e29bbaa45d74461 promoted in cluster a7ef944b95711739</code></pre><p><strong>添加成员错误案例</strong><br>在以下情况下，新主机不包含在枚举节点列表中。 如果这是一个新集群，则必须将该节点添加到初始集群成员列表中。</p><pre><code>$ etcd --name infra3 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state existingetcdserver: assign ids error: the member count is unequalexit 1</code></pre><p>在这种情况下，使用了与用于加入集群的地址（10.0.1.13:2380）不同的地址（10.0.1.14:2380）：</p><pre><code>$ etcd --name infra4 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380,infra4=http://10.0.1.14:2380 \  --initial-cluster-state existingetcdserver: assign ids error: unmatched member while checking PeerURLsexit 1</code></pre><p>如果etcd开始使用已删除成员的数据目录，则etcd如果连接到集群中的任何活动成员，则会自动退出：</p><pre><code>$ etcdetcd: this member has been permanently removed from the cluster. Exiting.exit 1</code></pre><p><strong>添加成员为领导者错误案例</strong><br>当集群中含有一个领导者时不能添加领导者到集群中(v3.4):</p><pre><code>$ etcdctl member add infra4 --peer-urls=http://10.0.1.14:2380 --learnerError: etcdserver: too many learner members in cluster</code></pre><p><strong>提升成员为领导者错误案例</strong><br>如果学习者与领导者同步，则只能被提升为有投票权的成员。</p><pre><code>$ etcdctl member promote 9bf1b35fc7761a23Error: etcdserver: can only promote a learner member which is in sync with leader</code></pre><p>提升不是学习者的成员将失败。</p><pre><code>$ etcdctl member promote 9bf1b35fc7761a23Error: etcdserver: can only promote a learner member</code></pre><p>提升一个集群中不存在的成员将会失败：</p><pre><code>$ etcdctl member promote 12345abcdeError: etcdserver: member not found</code></pre><h3 id="严格的重新配置检查模式-strict-reconfig-check"><a href="#严格的重新配置检查模式-strict-reconfig-check" class="headerlink" title="严格的重新配置检查模式(-strict-reconfig-check)"></a>严格的重新配置检查模式(<code>-strict-reconfig-check</code>)</h3><p>如上所述，添加新成员的最佳实践是一次配置一个成员，并在添加更多新成员之前验证它是否正确启动。这种分步方法非常重要，因为如果未正确配置新添加的成员（例如，对等URL不正确），则群集可能会丢失仲裁。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HTTP_JSON_API通过gRPC网关</title>
    <link href="undefined2019/11/23/blog/etcd/HTTP_JSON_API%E9%80%9A%E8%BF%87gRPC%E7%BD%91%E5%85%B3/"/>
    <url>2019/11/23/blog/etcd/HTTP_JSON_API%E9%80%9A%E8%BF%87gRPC%E7%BD%91%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_grpc_gateway.md" target="_blank" rel="noopener">HTTP JSON API through the gRPC gateway</a><br>etcd v3 使用 gRPC 作为消息协议。etcd项目包括一个基于gRPC的<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%AE%A2%E6%88%B7%E7%AB%AFv3/">Go客户端</a>和一个命令行工具，<a href="https://github.com/etcd-io/etcd/tree/master/etcdctl" target="_blank" rel="noopener">etcdctl</a>,通过gRPC与etcd集群进行交互.对于没有gRPC支持的语言，etcd提供JSON <a href="https://github.com/grpc-ecosystem/grpc-gateway" target="_blank" rel="noopener">gRPC网关</a>，这个网关提供一个RESTful风格的代理可以将HTTP/JSON请求转换为gRPC消息。</p><h3 id="使用-gRPC网关"><a href="#使用-gRPC网关" class="headerlink" title="使用 gRPC网关"></a>使用 gRPC网关</h3><p>这个网关接受一个到etcd’s buffer协议消息定义的JSON格式的映射,注意<code>Key</code>和<code>Value</code>字段定义为byte 数组，因此JSON必须使用base64编码,下面的例子使用<code>curl</code>,但是每个HTTP/JSON客户端的工作原理都和例子相同。<br><strong>注意</strong><br>gRPC网关节点从etcd v3.3发生变化：</p><ul><li>etcd v3.2以及之前版本只使用<code>[CLIENT-URL]/v3alpha/*</code>。</li><li>etcd v3.3使用<code>[CLIENT-URL]/v3beta/*</code>保持<code>[CLIENT-URL]/v3alpha/*</code>使用。</li><li>etcd v3.4使用<code>[CLIENT-URL]/v3/*</code>保持<code>[CLIENT-URL]/v3beta/*</code>使用。<ul><li><code>[CLIENT-URL]/v3alpha/*</code>被抛弃使用。</li></ul></li><li>etcd v3.5以及最新版本只使用<code>[CLIENT-URL]/v3/*</code>。<ul><li><code>[CLIENT-URL]/v3beta/*</code>被抛弃使用。</li></ul></li></ul><h3 id="存储和获取Keys"><a href="#存储和获取Keys" class="headerlink" title="存储和获取Keys"></a>存储和获取Keys</h3><p>使用<code>/v3/kv/range</code>和<code>/v3/kv/put</code>服务读和写Keys:</p><pre><code>&lt;&lt;COMMENThttps://www.base64encode.org/foo is &#39;Zm9v&#39; in Base64bar is &#39;YmFy&#39;COMMENTcurl -L http://localhost:2379/v3/kv/put \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;value&quot;: &quot;YmFy&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;3&quot;}}curl -L http://localhost:2379/v3/kv/range \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;3&quot;},&quot;kvs&quot;:[{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;2&quot;,&quot;version&quot;:&quot;1&quot;,&quot;value&quot;:&quot;YmFy&quot;}],&quot;count&quot;:&quot;1&quot;}# get all keys prefixed with &quot;foo&quot;curl -L http://localhost:2379/v3/kv/range \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;range_end&quot;: &quot;Zm9w&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;3&quot;},&quot;kvs&quot;:[{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;2&quot;,&quot;version&quot;:&quot;1&quot;,&quot;value&quot;:&quot;YmFy&quot;}],&quot;count&quot;:&quot;1&quot;}</code></pre><h3 id="查看-Keys"><a href="#查看-Keys" class="headerlink" title="查看 Keys"></a>查看 Keys</h3><p>使用<code>/v3/watch</code>服务查看Keys:</p><pre><code>curl -N http://localhost:2379/v3/watch \  -X POST -d &#39;{&quot;create_request&quot;: {&quot;key&quot;:&quot;Zm9v&quot;} }&#39; &amp;# {&quot;result&quot;:{&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;created&quot;:true}}curl -L http://localhost:2379/v3/kv/put \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;value&quot;: &quot;YmFy&quot;}&#39; &gt;/dev/null 2&gt;&amp;1# {&quot;result&quot;:{&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;events&quot;:[{&quot;kv&quot;:{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;2&quot;,&quot;version&quot;:&quot;1&quot;,&quot;value&quot;:&quot;YmFy&quot;}}]}}</code></pre><h3 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h3><p>使用``/v3/kv/txn`发行一个交易：</p><pre><code># 目标创建curl -L http://localhost:2379/v3/kv/txn \  -X POST \  -d &#39;{&quot;compare&quot;:[{&quot;target&quot;:&quot;CREATE&quot;,&quot;key&quot;:&quot;Zm9v&quot;,&quot;createRevision&quot;:&quot;2&quot;}],&quot;success&quot;:[{&quot;requestPut&quot;:{&quot;key&quot;:&quot;Zm9v&quot;,&quot;value&quot;:&quot;YmFy&quot;}}]}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;12585971608760269493&quot;,&quot;member_id&quot;:&quot;13847567121247652255&quot;,&quot;revision&quot;:&quot;3&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;succeeded&quot;:true,&quot;responses&quot;:[{&quot;response_put&quot;:{&quot;header&quot;:{&quot;revision&quot;:&quot;3&quot;}}}]}</code></pre><pre><code># 目标版本curl -L http://localhost:2379/v3/kv/txn \  -X POST \  -d &#39;{&quot;compare&quot;:[{&quot;version&quot;:&quot;4&quot;,&quot;result&quot;:&quot;EQUAL&quot;,&quot;target&quot;:&quot;VERSION&quot;,&quot;key&quot;:&quot;Zm9v&quot;}],&quot;success&quot;:[{&quot;requestRange&quot;:{&quot;key&quot;:&quot;Zm9v&quot;}}]}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;6&quot;,&quot;raft_term&quot;:&quot;3&quot;},&quot;succeeded&quot;:true,&quot;responses&quot;:[{&quot;response_range&quot;:{&quot;header&quot;:{&quot;revision&quot;:&quot;6&quot;},&quot;kvs&quot;:[{&quot;key&quot;:&quot;Zm9v&quot;,&quot;create_revision&quot;:&quot;2&quot;,&quot;mod_revision&quot;:&quot;6&quot;,&quot;version&quot;:&quot;4&quot;,&quot;value&quot;:&quot;YmF6&quot;}],&quot;count&quot;:&quot;1&quot;}}]}</code></pre><h3 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h3><p>使用<code>/v3/auth</code>设置权限：</p><pre><code># 创建root用户curl -L http://localhost:2379/v3/auth/user/add \  -X POST -d &#39;{&quot;name&quot;: &quot;root&quot;, &quot;password&quot;: &quot;pass&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}# 创建root角色curl -L http://localhost:2379/v3/auth/role/add \  -X POST -d &#39;{&quot;name&quot;: &quot;root&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}# 授予root角色curl -L http://localhost:2379/v3/auth/user/grant \  -X POST -d &#39;{&quot;user&quot;: &quot;root&quot;, &quot;role&quot;: &quot;root&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}# 开启认证curl -L http://localhost:2379/v3/auth/enable -X POST -d &#39;{}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;}}</code></pre><p>通过<code>/v3/auth/authenticate</code>服务使用一个认证令牌进行认证:</p><pre><code># 为根用户获取认证令牌curl -L http://localhost:2379/v3/auth/authenticate \  -X POST -d &#39;{&quot;name&quot;: &quot;root&quot;, &quot;password&quot;: &quot;pass&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;1&quot;,&quot;raft_term&quot;:&quot;2&quot;},&quot;token&quot;:&quot;sssvIpwfnLAcWAQH.9&quot;}</code></pre><p>使用认证证书设置认证头部到认证令牌获取Keys：</p><pre><code>curl -L http://localhost:2379/v3/kv/put \  -H &#39;Authorization : sssvIpwfnLAcWAQH.9&#39; \  -X POST -d &#39;{&quot;key&quot;: &quot;Zm9v&quot;, &quot;value&quot;: &quot;YmFy&quot;}&#39;# {&quot;header&quot;:{&quot;cluster_id&quot;:&quot;14841639068965178418&quot;,&quot;member_id&quot;:&quot;10276657743932975437&quot;,&quot;revision&quot;:&quot;2&quot;,&quot;raft_term&quot;:&quot;2&quot;}}</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gRPC命名与发现</title>
    <link href="undefined2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/"/>
    <url>2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/grpc_naming.md" target="_blank" rel="noopener">gRPC naming and discovery</a><br>etcd提供一个gRPC解析器支持备用的命名系统，该命名系统从etcd获取主机以发现gRPC服务。以下机制基于监视对以服务名称为前缀的Key的更新。<br>通过go-grpc使用etcd发现服务</p><hr><p>etcd客户端提供一个gRPC解析器通过etcd后端解析gRPC主机,解析器通过etcd客户端初始化并指定了解析目标:</p><pre><code>import (        &quot;go.etcd.io/etcd/clientv3&quot;        etcdnaming &quot;go.etcd.io/etcd/clientv3/naming&quot;        &quot;google.golang.org/grpc&quot;)...cli, cerr := clientv3.NewFromURL(&quot;http://localhost:2379&quot;)r := &amp;etcdnaming.GRPCResolver{Client: cli}b := grpc.RoundRobin(r)conn, gerr := grpc.Dial(&quot;my-service&quot;, grpc.WithBalancer(b), grpc.WithBlock(), ...)</code></pre><h3 id="管理服务主机"><a href="#管理服务主机" class="headerlink" title="管理服务主机"></a>管理服务主机</h3><p>etcd解析器对于解析目标前缀下所有Keys后面跟一个”/“(例如”my-service/“),使用JSON编码go-grpc<code>naming.Update</code>值作为潜在的服务主机。通过创建一个新的Key将主机添加到服务中，通过删除Keys将主机从服务中删除。</p><h3 id="添加一个主机"><a href="#添加一个主机" class="headerlink" title="添加一个主机"></a>添加一个主机</h3><p>一个新的主机可以通过<code>etcdctl</code>添加到服务中：</p><pre><code>ETCDCTL_API=3 etcdctl put my-service/1.2.3.4 &#39;{&quot;Addr&quot;:&quot;1.2.3.4&quot;,&quot;Metadata&quot;:&quot;...&quot;}&#39;</code></pre><p>etcd客户端的<code>GRPCResolver.Update</code>方法也可以通过key匹配<code>Addr</code>注册一个新的主机到服务中：</p><pre><code>r.Update(context.TODO(), &quot;my-service&quot;, naming.Update{Op: naming.Add, Addr: &quot;1.2.3.4&quot;, Metadata: &quot;...&quot;})</code></pre><h3 id="删除一个主机"><a href="#删除一个主机" class="headerlink" title="删除一个主机"></a>删除一个主机</h3><p>通过etcdctl可以从服务中删除一个主机:</p><pre><code>ETCDCTL_API=3 etcdctl del my-service/1.2.3.4</code></pre><p>etcd 客户端的<code>GRPCResolver.Update</code>方法也可以删除一个主机：</p><pre><code>r.Update(context.TODO(), &quot;my-service&quot;, naming.Update{Op: naming.Delete, Addr: &quot;1.2.3.4&quot;})</code></pre><h3 id="注册一个主机并绑定一个租约"><a href="#注册一个主机并绑定一个租约" class="headerlink" title="注册一个主机并绑定一个租约"></a>注册一个主机并绑定一个租约</h3><p>注册一个主机ging绑定一个租约确保如果主机不能维护保持存活的心跳(例如机器宕机)，该主机将会从服务中移除。</p><pre><code>lease=`ETCDCTL_API=3 etcdctl lease grant 5 | cut -f2 -d&#39; &#39;`ETCDCTL_API=3 etcdctl put --lease=$lease my-service/1.2.3.4 &#39;{&quot;Addr&quot;:&quot;1.2.3.4&quot;,&quot;Metadata&quot;:&quot;...&quot;}&#39;ETCDCTL_API=3 etcdctl lease keep-alive $lease</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>运行时重新配置设计</title>
    <link href="undefined2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/"/>
    <url>2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/runtime-reconf-design.md" target="_blank" rel="noopener">the runtime configuration design</a><br>运行时重新配置是分布式系统中最难，最容易出错的部分，尤其是在基于共识(像etcd)的系统中。<br>阅读并学习关于etcd的运行时重新配置命令设计和如何追溯这些错误.</p><h3 id="两阶段配置更新保证集群安全"><a href="#两阶段配置更新保证集群安全" class="headerlink" title="两阶段配置更新保证集群安全"></a>两阶段配置更新保证集群安全</h3><hr><p>在etcd中，每一次运行时重新配置安全的原因是由于<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">两阶段</a>更新。例如，添加一个成员，首先将新配置通知集群后启动新的成员。</p><ol><li>阶段一 通知集群关于新的配置<br>添加一个成员到etcd集群中，通过API调用请求将一个新成员添加到集群中。这是将新的成员添加到集群中唯一的方法。当集群同意配置的更新后将返回API的调用。</li><li>阶段二 启动一个新的成员<br>将一个新成员加入到存在的集群中，指定正确的<code>initial-cluster</code>和设置<code>initial-cluster-state</code>为<code>existing</code>.当成员启动后，它首先联系已存在的集群并验证当前集群配置是否和期望的<code>initial-cluster</code>匹配。当一个新的成员成功启动，集群将获得期望的配置。</li></ol><p>用户将过程分为两个阶段需要清楚了解集群成员关系的变化。实际上，这为用户提供了更大的灵活性，并使事情更容易。例如，如果试图添加一个与集群中现有的成员Id相同的新成员到集群中，操作将会立即失败由于阶段一并没有影响到运行中的集群。提供了类似的保护阻止通过错误操作添加新的成员。如果一个新的etcd成员试图在集群接受配置信息更新之前加入集群，操作将不会被集群接受。</p><p>如果没有围绕集群成员关系的显式工作流，集群将会容易受到意料之外的集群成员关系变化的影响。例如，如果etcd在一个初始化的系统如systemd中运行，etcd将会通过成员关系API在重新启动之后被移除，并试图在启动后重新加入。这个循环将会在每次通过API成员移除并将系统设置为失败后重新启动etcd时继续，这是预料之外的。</p><p>我们希望运行时重新进行配置是不常见的操作。我们决定保持为显式的由用户驱动来确保配置安全，保持集群平稳运行在显式的控制下。</p><h3 id="永久性的丢失要求新的集群"><a href="#永久性的丢失要求新的集群" class="headerlink" title="永久性的丢失要求新的集群"></a>永久性的丢失要求新的集群</h3><hr><p>如果一个集群永久丢失一些主要的集群成员，需要从原始的数据文件夹启动一个新的集群恢复先前的状态。</p><p>完全有可能从已存在的集群中强制删除一个失败的成员并恢复。然而，我们决定不支持此方法因为他绕过了常规的共识提交阶段，这是不安全的。如果成员移除一个没有实际失败的成员或者是同一个集群中的不同成员，etcd将会最终得到具有相同集群Id的分散集群。这是非常危险的而且很难修复。</p><p>通过正常的部署，永久性丢失的可能性非常的小。但是这是一个严重的问题值得特别注意。我们强烈建议阅读<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md" target="_blank" rel="noopener">灾难恢复文档</a>并且在将etcd部署到生产环境之前做充足的准备。</p><h3 id="不要在运行时重新配置中使用公共的发现服务"><a href="#不要在运行时重新配置中使用公共的发现服务" class="headerlink" title="不要在运行时重新配置中使用公共的发现服务"></a>不要在运行时重新配置中使用公共的发现服务</h3><hr><p>公共发现服务应该只在启动一个集群的时候使用。将一个成员加入已存在的集群，使用运行时配置API.</p><p>发现服务被设计用来在云服务环境中启动一个在所有的成员无法提前知道Ip地址时的etcd集群。在成功启动一个集群时，所有的成员将会知道Ip地址。典型的，发现服务奖不再被需要。<br>看起来使用公共的发现服务进行运行时重新配置是一个便利的方法,毕竟所有的发现服务含有所有的集群配置信息。然而依赖公共发现服务将带来问题：</p><ol><li>将会引进外部独立性到集群的整个生命周期，不只是启动时间。如果集群和公共发现服务之间存在网络问题，则群集将因此受到影响。</li><li>公共发现服务必须在集群的生命周期内反映正确的运行时配置，将需要提供安全机制避免坏的行为，而这是困难的。</li><li>公共发现服务需要保持数万个集群的配置，而我们的公共发现服务很难承受这种负载。</li></ol><p>为了使发现服务支持运行时配置，最好的选择是建立一个私有的发现服务。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>与etcd进行交互</title>
    <link href="undefined2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/"/>
    <url>2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/interacting_v3.md" target="_blank" rel="noopener">Interacting with etcd</a></p><h2 id="与etcd进行交互"><a href="#与etcd进行交互" class="headerlink" title="与etcd进行交互"></a>与etcd进行交互</h2><p>用户更多的是通过putting或者是getting从etcd获取一个键对应的值。这一部分描述了如何通过etcdctl做这些工作。etcdctl是一个与etcd服务器进行交互的命令行工具.这里的描述适用于gRPC APIs或者是客户端库的APIs。<br>用于与etcd交互的API版本可以通过环境变量<code>ETCDCTL_API</code>设置为2或者3.默认情况下，分支为(3.4)的主版本使用V3 的API，而早期的版本(3.3或者更早)默认使用V2 API。<br>注意使用V2 API所创建的任何Key不能够通过V3 API进行访问。而V3 API <code>etcdctl get</code>获取V2 的Key将返回0并退出，这是预料之中的情况。</p><pre><code>export ETCDCTL_API=3</code></pre><h3 id="发现版本"><a href="#发现版本" class="headerlink" title="发现版本"></a>发现版本</h3><p>使用合适的命令在执行不同版本的etcd时etcdctl和服务器API的版本将会有用。<br>这里的命令可用于发现版本信息：</p><pre><code>$ etcdctl versionetcdctl version:3.1.0-alpha.0+gitAPI version:3.1</code></pre><h3 id="写入一个KEY"><a href="#写入一个KEY" class="headerlink" title="写入一个KEY"></a>写入一个KEY</h3><p>应用程序通过向etcd集群写入Keys来存储Keys，每次存储的Key将会通过Raft协议实现一致性与可扩展性复制到所有的etcd集群成员中。<br>这里的命令是将Key<code>foo</code>的值存储到<code>bar</code>上：</p><pre><code>$ etcdctl put foo barOK</code></pre><p>给Key附上一个租约，Key将在一个具体的时间间隔被设置。<br>这里的命令是在10秒后将Key<code>foo</code>的值存储到<code>bar</code>上：</p><pre><code>$ etcdctl put foo1 bar1 --lease=1234abcd</code></pre><p>注意：以上命令中租约ID为1234abcd将会在租约创建10秒后将id返回，这个id将附在Key上。</p><h3 id="读取Keys"><a href="#读取Keys" class="headerlink" title="读取Keys"></a>读取Keys</h3><p>应用程序可以从一个etcd集群中读取Key，可能会查询到单个Key，或者是一个范围内的Key。<br>比如etcd集群中存储以下Key：</p><pre><code>foo = barfoo1 = bar1foo2 = bar2foo3 = bar3</code></pre><p>这里的命令是读取Key<code>foo</code>对应的值：</p><pre><code>$ etcdctl get foofoobar</code></pre><p>这里的命令是读取Key<code>foo</code>对应的十六进制的值:</p><pre><code>$ etcdctl get foo --hex\x66\x6f\x6f       #Key\x62\x61\x72       #Value</code></pre><p>这里的命令是只读取Key<code>foo</code>对应的值：</p><pre><code>$ etcdctl get foo --print-value-onlybar</code></pre><p>这里的命令是读取从Key<code>foo</code>到Key<code>foo3</code>范围内对应的值：</p><pre><code>$ etcdctl get foo foo3foobarfoo1bar1foo2bar2</code></pre><p>注意这里Key为<code>foo3</code>不包括在内因为这里的范围是半开区间<code>[foo,foo3)</code>，不包括<code>foo3</code>。</p><p>这里的命令是获取前缀为<code>foo</code>的Key的范围内所有的值：</p><pre><code>$ etcdctl get --prefix foofoobarfoo1bar1foo2bar2foo3bar3</code></pre><p>这里的命令是获取前缀为<code>foo</code>的Key的范围内所有的值,并且限制结果集为2：</p><pre><code>$ etcdctl get --prefix --limit=2 foofoobarfoo1bar1</code></pre><h3 id="读取之前版本的Keys："><a href="#读取之前版本的Keys：" class="headerlink" title="读取之前版本的Keys："></a>读取之前版本的Keys：</h3><p>应用程度可能希望读取一个被替代的版本的Key。例如，一个应用程序可能想要通过读取一个先前版本的Key来回滚到一个老的配置。另外，一个应用程序可能想要通过访问Key的历史记录对多个Key通过多个请求获取一致性的结果。由于对etcd集群中键值对的每一次修改都会增加对在etcd集群中的全局修订存储，应用程序可以通过提供一个老的版本来读取被替代的Keys。<br>比如一个etcd集群中存在以下的Keys：</p><pre><code>foo = bar         # revision = 2foo1 = bar1       # revision = 3foo = bar_new     # revision = 4foo1 = bar1_new   # revision = 5</code></pre><p>这里的例子是访问过去版本的Keys：</p><pre><code>$ etcdctl get --prefix foo # access the most recent versions of keysfoobar_newfoo1bar1_new$ etcdctl get --prefix --rev=4 foo # access the versions of keys at revision 4foobar_newfoo1bar1$ etcdctl get --prefix --rev=3 foo # access the versions of keys at revision 3foobarfoo1bar1$ etcdctl get --prefix --rev=2 foo # access the versions of keys at revision 2foobar$ etcdctl get --prefix --rev=1 foo # access the versions of keys at revision 1</code></pre><h3 id="读取大于或等于一个具体的Key的比特值的Key："><a href="#读取大于或等于一个具体的Key的比特值的Key：" class="headerlink" title="读取大于或等于一个具体的Key的比特值的Key："></a>读取大于或等于一个具体的Key的比特值的Key：</h3><p>应用程序可能想要读取大于或等于一个具体的Key的byte值的Key。<br>一个etcd集群中有以下的Keys：</p><pre><code>a = 123b = 456z = 789</code></pre><p>这里的命令是读取大于或等于Key <code>b</code>的byte值的Key：</p><pre><code>$ etcdctl get --from-key bb456z789</code></pre><h3 id="删除-Keys"><a href="#删除-Keys" class="headerlink" title="删除 Keys"></a>删除 Keys</h3><p>应用程序可以从etcd集群中删除一个Key或者删除一个范围内的Key：<br>一个etcd集群中有以下的Keys：</p><pre><code>foo = barfoo1 = bar1foo3 = bar3zoo = valzoo1 = val1zoo2 = val2a = 123b = 456z = 789</code></pre><p>这里的命令是删除Key<code>foo</code>:</p><pre><code>$ etcdctl del foo1 # 1 个 key 被删除</code></pre><p>这里的命令是删除从Key<code>foo</code>到Key<code>foo9</code>范围内的Key:</p><pre><code>$ etcdctl del foo foo92 # 2 个 keys 被删除</code></pre><p>这里的命令是删除Key<code>zoo</code>并将已删除的键值对返回:</p><pre><code>$ etcdctl del --prev-kv zoo1   # 1 个 key 被删除zoo # 被删除的Keyval # 被删除的Key所对应的Value</code></pre><p>这里的命令是删除前缀为<code>zoo</code>的Keys:</p><pre><code>$ etcdctl del --prefix zoo2 # 2 个 key 被删除</code></pre><p>这里的命令是读取大于或等于Key <code>b</code>的byte值的Keys：</p><pre><code>$ etcdctl del --from-key b2 # 2 个 key 被删除</code></pre><h3 id="观察key的变化"><a href="#观察key的变化" class="headerlink" title="观察key的变化"></a>观察key的变化</h3><p>应用程序可以监视一个Key或者一个范围内的Keys的每一次更新。<br>这里的命令是观察key<code>foo</code>:</p><pre><code>$ etcdctl watch foo# 在另一个终端执行: etcdctl put foo barPUTfoobar</code></pre><p>这里的命令是观察十六进制的key<code>foo</code>:</p><pre><code>$ etcdctl watch foo --hex# 在另一个终端执行: etcdctl put foo barPUT\x66\x6f\x6f          # Key\x62\x61\x72          # Value</code></pre><p>这里的命令是观察从Key<code>foo</code>到Key<code>foo9</code>范围内的Key：</p><pre><code>$ etcdctl watch foo foo9# 在另一个终端执行: etcdctl put foo barPUTfoobar# 在另一个终端执行: etcdctl put foo1 bar1PUTfoo1bar1</code></pre><p>这里的命令是观察前缀为<code>foo</code>的Key的范围内所有的值：</p><pre><code>$ etcdctl watch --prefix foo# 在另一个终端执行: etcdctl put foo barPUTfoobar# 在另一个终端执行: etcdctl put fooz1 barz1PUTfooz1barz1</code></pre><p>这里的命令是观察多个Keys<code>foo</code>和<code>zoo</code>:</p><pre><code>$ etcdctl watch -i$ watch foo$ watch zoo# 在另一个终端执行: etcdctl put foo barPUTfoobar# 在另一个终端执行: etcdctl put zoo valPUTzooval</code></pre><h3 id="观察Keys的历史版本"><a href="#观察Keys的历史版本" class="headerlink" title="观察Keys的历史版本"></a>观察Keys的历史版本</h3><p>应用程序可能想要观察etcd中Keys的更新历史。例如，应用程序可能想获取key的所有修改；如果应用程序保持与etcd的连接，那么命令<code>watch</code>已经足够。然而，如果应用程序或者etcd宕机，一次更新可能就会失败，应用程序可能不能实时接收Key的更新。为了保证更新可以被交付，应用程序必须通过观察到Keys的历史更新。为了做到这些，应用程序要指定观察的历史版本，就像读取历史版本的Keys：<br>我们首先完成以下操作：</p><pre><code>$ etcdctl put foo bar         # revision = 2OK$ etcdctl put foo1 bar1       # revision = 3OK$ etcdctl put foo bar_new     # revision = 4OK$ etcdctl put foo1 bar1_new   # revision = 5OK</code></pre><p>这里有个例子观察历史更新：</p><pre><code># watch for changes on key `foo` since revision 2$ etcdctl watch --rev=2 fooPUTfoobarPUTfoobar_new</code></pre><pre><code># watch for changes on key `foo` since revision 3$ etcdctl watch --rev=3 fooPUTfoobar_new</code></pre><p>这里有例子只观察最后一次的更新：</p><pre><code># watch for changes on key `foo` and return last revision value along with modified value$ etcdctl watch --prev-kv foo# 在另一个终端执行 etcdctl put foo bar_latestPUTfoo         # keybar_new     # last value of foo key before modificationfoo         # keybar_latest  # value of foo key after modification</code></pre><h3 id="观察进度"><a href="#观察进度" class="headerlink" title="观察进度"></a>观察进度</h3><p>应用程序可能想要检查观察者进度以确定最新的观察者流的状态。例如，如果观察者更新的缓存，那么就可以通过原子读取与修改进度进行比较知道缓存内容是否已经过时。<br>进度请求可以通过<code>progress</code>命令与观察者session进行交互在一个观察者流中告诉服务器发送一个进度提示更新.</p><pre><code>$ etcdctl watch -i$ watch a$ progressprogress notify: 1# 在另一个终端执行: etcdctl put x 0# 在另一个终端执行: etcdctl put y 1$ progressprogress notify: 3</code></pre><p>注意，在进度提示响应中的修改号来自观察者流连接到的本地etcd服务器。如果该节点被分区并且不是该分区的一部分，这个进度提示修改版本可能会低于由未分区的etcd服务器节点返回的修改版本。</p><h3 id="压缩修改"><a href="#压缩修改" class="headerlink" title="压缩修改"></a>压缩修改</h3><p>正如我们提到的，etcd保持修改信息所以应用可以读取过去版本的Keys，然而，为了避免无数的修改历史累积，对过去的修改进行压缩是很重要的。在压缩后，etcd移除了历史修改，释放资源为以后使用。在压缩修改版本之前所有的被修改的替代版本数据将不能获取。<br>这里的命令是对修改进行压缩：</p><pre><code>$ etcdctl compact 5compacted revision 5# any revisions before the compacted one are not accessible$ etcdctl get --rev=4 fooError:  rpc error: code = 11 desc = etcdserver: mvcc: required revision has been compacted</code></pre><p>注意：etcd服务器的当前版本可以使用json格式的命令通过(存在或不存在的)key发现。例如下面的通过查看在etcd服务器中不存在的myKey:</p><pre><code>$ etcdctl get mykey -w=json{&quot;header&quot;:{&quot;cluster_id&quot;:14841639068965178418,&quot;member_id&quot;:10276657743932975437,&quot;revision&quot;:15,&quot;raft_term&quot;:4}}</code></pre><h3 id="授予租约"><a href="#授予租约" class="headerlink" title="授予租约"></a>授予租约</h3><p>应用程序可以为etcd集群上的Keys授予一个租约。当Key附上租约后，它的生命周期会绑定到租约的生命周期并由存活时间(TTL)进行管理。每一个租约都有一个由应用程序授予的最小的TTL值.这个租约实际的TTL值至少是最小的TTL值，由etcd集群决定。一旦超过租约的TTL，租约将会超时并删除附上的所有的Keys。<br>这里有命令授予一个租约：</p><pre><code># grant a lease with 60 second TTL$ etcdctl lease grant 60lease 32695410dcc0ca06 granted with TTL(60s)# attach key foo to lease 32695410dcc0ca06$ etcdctl put --lease=32695410dcc0ca06 foo barOK</code></pre><h3 id="撤销租约"><a href="#撤销租约" class="headerlink" title="撤销租约"></a>撤销租约</h3><p>应用程序可以根据租约ID撤销租约，撤销一个租约将删除附上的所有的Keys。<br>例如我们完成下面的操作：</p><pre><code>$ etcdctl lease grant 60lease 32695410dcc0ca06 granted with TTL(60s)$ etcdctl put --lease=32695410dcc0ca06 foo barOK</code></pre><p>这里的命令可以撤销该租约：</p><pre><code>$ etcdctl lease revoke 32695410dcc0ca06lease 32695410dcc0ca06 revoked$ etcdctl get foo# empty response since foo is deleted due to lease revocation</code></pre><h3 id="保持租约存活"><a href="#保持租约存活" class="headerlink" title="保持租约存活"></a>保持租约存活</h3><p>应用程序可以通过刷新租约的TTL使它不会超时保证租约存活。<br>例如我们完成下面的操作：</p><pre><code>$ etcdctl lease grant 60lease 32695410dcc0ca06 granted with TTL(60s)</code></pre><p>这里有命令保持租约存活：</p><pre><code>$ etcdctl lease keep-alive 32695410dcc0ca06lease 32695410dcc0ca06 keepalived with TTL(60)lease 32695410dcc0ca06 keepalived with TTL(60)lease 32695410dcc0ca06 keepalived with TTL(60)...</code></pre><h3 id="获取租约信息"><a href="#获取租约信息" class="headerlink" title="获取租约信息"></a>获取租约信息</h3><p>应用程序可能想知道关于租约的信息，所以可以通过重新创建或者检查租约是否仍然生存或已经超时。应用程序可能也想知道一个具体的租约上所附的Key。<br>例如我们完成下面的操作：</p><pre><code># grant a lease with 500 second TTL$ etcdctl lease grant 500lease 694d5765fc71500b granted with TTL(500s)# attach key zoo1 to lease 694d5765fc71500b$ etcdctl put zoo1 val1 --lease=694d5765fc71500bOK# attach key zoo2 to lease 694d5765fc71500b$ etcdctl put zoo2 val2 --lease=694d5765fc71500bOK</code></pre><p>这里有命令获取关于租约的信息:</p><pre><code>$ etcdctl lease timetolive 694d5765fc71500blease 694d5765fc71500b granted with TTL(500s), remaining(258s)</code></pre><p>这里有命令获取租约上所依附的关于Keys的信息：</p><pre><code>$ etcdctl lease timetolive --keys 694d5765fc71500blease 694d5765fc71500b granted with TTL(500s), remaining(132s), attached keys([zoo2 zoo1])# if the lease has expired or does not exist it will give the below response:Error:  etcdserver: requested lease not found</code></pre>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>客户端v3</title>
    <link href="undefined2019/11/23/blog/etcd/%E5%AE%A2%E6%88%B7%E7%AB%AFv3/"/>
    <url>2019/11/23/blog/etcd/%E5%AE%A2%E6%88%B7%E7%AB%AFv3/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/clientv3/README.md" target="_blank" rel="noopener">etcd/clientv3</a><br><code>etcd/clientv3</code>是v3版本的Go etcd官方客户端</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><hr><pre><code>go get go.etcd.io/etcd/clientv3</code></pre><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><hr><p>创建客户端使用<code>clientv3.New</code>:</p><pre><code>cli, err := clientv3.New(clientv3.Config{    Endpoints:   []string{&quot;localhost:2379&quot;, &quot;localhost:22379&quot;, &quot;localhost:32379&quot;},    DialTimeout: 5 * time.Second,})if err != nil {    // handle error!}defer cli.Close()</code></pre><p>etcd v3使用<code>gRPC</code>进行远程程序调用，并且<code>clientv3</code>使用<code>grpc-go</code>连接etcd。确保在使用完客户端后关闭它，如果客户端没有关闭，连接将会有泄漏的<code>goroutines</code>。指定超时时间，通过<code>context.WithTimeout</code>使用APIs:</p><pre><code>ctx, cancel := context.WithTimeout(context.Background(), timeout)resp, err := cli.Put(ctx, &quot;sample_key&quot;, &quot;sample_value&quot;)cancel()if err != nil {    // handle error!}// use the response</code></pre><p>为了完全兼容，建议使用etcd’s中的vendored包进行构建，使用工具像<code>golang/dep</code>,在vendor目录内。</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>etcd客户端返回两种类型的错误：</p><ol><li>context error :canceled or deadline exceeded.</li><li>gRpc error : 看api/v3rpc/rpctypes.</li></ol><p>这里有例子处理客户端错误：</p><pre><code>resp, err := cli.Put(ctx, &quot;&quot;, &quot;&quot;)if err != nil {    switch err {    case context.Canceled:        log.Fatalf(&quot;ctx is canceled by another routine: %v&quot;, err)    case context.DeadlineExceeded:        log.Fatalf(&quot;ctx is attached with a deadline is exceeded: %v&quot;, err)    case rpctypes.ErrEmptyKey:        log.Fatalf(&quot;client-side error: %v&quot;, err)    default:        log.Fatalf(&quot;bad cluster endpoints, which are not etcd servers: %v&quot;, err)    }}</code></pre><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>etcd客户端可以通过<strong>go-grpc-prometheus</strong>,选择RPC监控指标,看<strong>例子</strong>。</p><h2 id="命名空间"><a href="#命名空间" class="headerlink" title="命名空间"></a>命名空间</h2><p><strong>namespace</strong>包提供<code>clientv3</code>接口封装透明隔离客户端请求到用户定义的前缀。</p><h2 id="请求大小限制"><a href="#请求大小限制" class="headerlink" title="请求大小限制"></a>请求大小限制</h2><p>客户端请求大小限制通过<code>clientv3.Config.MaxCallSendMsgSize</code>和<code>MaxCallRecvMsgSize</code>进行配置。如果没有给予值，客户端请求发送限制包括gRPC负载默认2MB。接收限制默认为<code>math.MaxInt32</code>。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>更多代码例子可以从<strong>GoDoc</strong>发现。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>多机集群</title>
    <link href="undefined2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/"/>
    <url>2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>原文地址:<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md" target="_blank" rel="noopener">cluster on multiple machines</a></p><h1 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h1><hr><p>启动一个集群静态的要求是每一个集群中的成员需要知道其他成员的位置。在许多情况下，集群成员的IP可能无法提前知道。在这种情况下，etcd集群可以在发现服务的帮助下进行启动。<br>一旦etcd集群已经启动，添加或移除成员可以通过<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时重新配置</a>。在运行时重新配置之前，为了更好地理解设计，我们建议读<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE%E8%AE%BE%E8%AE%A1/">运行时重新配置设计文档</a>。<br>这篇引导etcd集群的启动将包括以下机制：</p><ul><li>静态</li><li>etcd发现</li><li>DNS发现</li></ul><p>每种引导机制都将用于创建具有以下详细信息的三台计算机etcd集群：</p><table><thead><tr><th>Name</th><th>Address</th><th>Hostname</th></tr></thead><tbody><tr><td>infra0</td><td>10.0.1.10</td><td>infra0.example.com</td></tr><tr><td>infra1</td><td>10.0.1.11</td><td>infra1.example.com</td></tr><tr><td>infra2</td><td>10.0.1.12</td><td>infra2.example.com</td></tr></tbody></table><h2 id="静态"><a href="#静态" class="headerlink" title="静态"></a>静态</h2><p>集群的成员，在启动之前它们的地址和集群的大小，我们可以通过设置<code>initial-cluster</code>参数使用离线的启动配置。每一个机器将会通过以下的环境变量或命令行获得配置信息：</p><pre><code>ETCD_INITIAL_CLUSTER=&quot;infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380&quot;ETCD_INITIAL_CLUSTER_STATE=new</code></pre><pre><code>--initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \--initial-cluster-state new</code></pre><p>注意在<code>initial-cluster</code>中的URLs必须是已发布的对等的节点的URLs，即它们应该和对应的节点上的<code>initial-advertise-peer-urls</code>的值对应。<br>如果为了测试的目的通过相同的配置分解多集群(或者创建和删除单个集群)，值得注意的是每一个集群应该给予独一无二的<code>initial-cluster-token</code>,通过做这些工作，即使它们具有相同的配置,etcd也可以为集群成员生成独一无二的集群Id和成员ID。这样可以在可能会扰乱集群的跨集群中交互中保护etcd。<br>etcd监听在<code>listen-client-urls</code>接受客户端流量，etcd将<code>advertise-client-urls</code>中指定的URLs告诉其他成员，代理，客户端。请确保潜在的客户端可以获取<code>advertise-client-urls</code>。一个常见的错误当远程的客户端应该访问etcd时设置<code>advertise-client-urls</code>为localhost或者将其保留为默认值。<br>在每一台机器上，通过这些参数启动etcd：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \  --listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.12:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state new</code></pre><p>以<code>initial-cluster</code>开头的命令行参数将在etcd启动后被忽略。在初始化启动后可以自由删除环境变量或者命令行参数。如果配置信息在启动之后需要改变(例如在/从集群中添加或删除成员),看<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时配置</a>引导。</p><h3 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h3><p>etcd支持通过TLS协议进行加密通信。TLS通道可以在集群内部通信使用，也可以在节点和客户端流量通信时使用。这一部分列举了为节点和客户端TLS通信的集群设置。添加的etcd的TLS支持信息细节可以在<a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">安全引导</a>中发现。</p><h4 id="自签名证书"><a href="#自签名证书" class="headerlink" title="自签名证书"></a>自签名证书</h4><p>一个集群使用自签名证书加密流量和连接权限。使用自签名证书启动一个集群，每一个集群成员都需要含有一个独一无二的由共享的集群CA证书(<code>ca.crt</code>)签名的秘钥对(<code>member.crt</code>,<code>member.key</code>)，用于节点连接和客户端连接。证书可以通过下面的etcd<a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">TLS设置</a>例子中生成。<br>对于每一台机器，etcd应该通过这些参数启动：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls https://10.0.1.10:2380 \  --listen-peer-urls https://10.0.1.10:2380 \  --listen-client-urls https://10.0.1.10:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.10:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --client-cert-auth --trusted-ca-file=/path/to/ca-client.crt \  --cert-file=/path/to/infra0-client.crt --key-file=/path/to/infra0-client.key \  --peer-client-cert-auth --peer-trusted-ca-file=ca-peer.crt \  --peer-cert-file=/path/to/infra0-peer.crt --peer-key-file=/path/to/infra0-peer.key</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls https://10.0.1.11:2380 \  --listen-peer-urls https://10.0.1.11:2380 \  --listen-client-urls https://10.0.1.11:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.11:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --client-cert-auth --trusted-ca-file=/path/to/ca-client.crt \  --cert-file=/path/to/infra1-client.crt --key-file=/path/to/infra1-client.key \  --peer-client-cert-auth --peer-trusted-ca-file=ca-peer.crt \  --peer-cert-file=/path/to/infra1-peer.crt --peer-key-file=/path/to/infra1-peer.key</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls https://10.0.1.12:2380 \  --listen-peer-urls https://10.0.1.12:2380 \  --listen-client-urls https://10.0.1.12:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.12:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --client-cert-auth --trusted-ca-file=/path/to/ca-client.crt \  --cert-file=/path/to/infra2-client.crt --key-file=/path/to/infra2-client.key \  --peer-client-cert-auth --peer-trusted-ca-file=ca-peer.crt \  --peer-cert-file=/path/to/infra2-peer.crt --peer-key-file=/path/to/infra2-peer.key</code></pre><h4 id="自动化证书"><a href="#自动化证书" class="headerlink" title="自动化证书"></a>自动化证书</h4><p>如果集群需要加密通信但是不需要连接时权限认证,etcd可以配置为自动生成秘钥.在初始化阶段,etcd成员基于他们的Ip地址和主机生成自己的秘钥.<br>在每一台主机上,etcd需要根据这些参数进行启动:</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls https://10.0.1.10:2380 \  --listen-peer-urls https://10.0.1.10:2380 \  --listen-client-urls https://10.0.1.10:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.10:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --auto-tls \  --peer-auto-tls</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls https://10.0.1.11:2380 \  --listen-peer-urls https://10.0.1.11:2380 \  --listen-client-urls https://10.0.1.11:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.11:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --auto-tls \  --peer-auto-tls</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls https://10.0.1.12:2380 \  --listen-peer-urls https://10.0.1.12:2380 \  --listen-client-urls https://10.0.1.12:2379,https://127.0.0.1:2379 \  --advertise-client-urls https://10.0.1.12:2379 \  --initial-cluster-token etcd-cluster-1 \  --initial-cluster infra0=https://10.0.1.10:2380,infra1=https://10.0.1.11:2380,infra2=https://10.0.1.12:2380 \  --initial-cluster-state new \  --auto-tls \  --peer-auto-tls</code></pre><h4 id="错误案例"><a href="#错误案例" class="headerlink" title="错误案例"></a>错误案例</h4><p>在以下的例子中，新的主机没有包含在枚举的节点列表中，如果这是一个新的集群，节点需要被添加到初始化集群成员的列表中。</p><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls https://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --initial-cluster infra0=http://10.0.1.10:2380 \  --initial-cluster-state newetcd: infra1 not listed in the initial cluster configexit 1</code></pre><p>在以下的例子中，我们试图映射一个节点(infra0)到一个不同的地址(127.0.0.1:2380)，而它在集群列表中的地址为(10.0.1.10:2380).如果这个节点监听多个端口，所有地址都必须要反射到<code>initial-cluster</code>参数配置中。</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://127.0.0.1:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra2=http://10.0.1.12:2380 \  --initial-cluster-state=newetcd: error setting up initial cluster: infra0 has different advertised URLs in the cluster and advertised peer URLs listexit 1</code></pre><p>如果一个节点被配置成不同集群的参数并试图加入这个集群，etcd将会报出集群ID不匹配并退出.</p><pre><code>$ etcd --name infra3 --initial-advertise-peer-urls http://10.0.1.13:2380 \  --listen-peer-urls http://10.0.1.13:2380 \  --listen-client-urls http://10.0.1.13:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.13:2379 \  --initial-cluster infra0=http://10.0.1.10:2380,infra1=http://10.0.1.11:2380,infra3=http://10.0.1.13:2380 \  --initial-cluster-state=newetcd: conflicting cluster ID to the target cluster (c6ab534d07e8fcc4 != bc25ea2a74fb18b0). Exiting.exit 1</code></pre><h3 id="发现服务"><a href="#发现服务" class="headerlink" title="发现服务"></a>发现服务</h3><p>在许多案例中，集群节点不能提前知道Ip地址。这在云服务提供商或者是使用DHCP的网络中很常见。在这种情况下，使用一个存在的etcd集群来启动一个新的节点而不是进行静态的配置，这个过程称为”节点发现”.</p><p>有两种方法可以用来发现节点:</p><ul><li>etcd发现服务</li><li>DNS SRV 记录</li></ul><h4 id="etcd-发现服务"><a href="#etcd-发现服务" class="headerlink" title="etcd 发现服务"></a>etcd 发现服务</h4><p>为了更好理解发现服务协议的设计，我们建议阅读发现服务协议<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-internal/discovery_protocol.md" target="_blank" rel="noopener">文档</a>.<br><strong>发现服务URL的生命周期</strong><br>一个发现URL标识一个独有的etcd集群而不是使用已有的发现URL。每一个etcd实例分享一个新的发现URL去启动新的集群。<br>此外，发现URL应该只在初始化启动集群的时候使用，如果需要改变已经启动的集群中的成员关系，看<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E8%BF%90%E8%A1%8C%E6%97%B6%E9%87%8D%E6%96%B0%E9%85%8D%E7%BD%AE/">运行时重新配置</a>引导.<br><strong>自定义etcd发现服务</strong><br>发现服务用于启动一个存在的集群，如果使用一个私有的etcd集群，像这样创建URL:</p><pre><code>$ curl -X PUT https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83/_config/size -d value=3</code></pre><p>通过设置URL中Key的大小，创建发现URL的集群预期大小为3.<br>在这种情况下URL将会这样使用:</p><pre><code>https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><p>当etcd成员启动时将使用</p><pre><code>https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><p>文件夹进行注册。<br><strong>每一个成员必须含有一个不同的命名参数。<code>Hostname</code>或者<code>machine-id</code>将是一个好的选择。发现服务的失败通常由于重复的名字。</strong><br>现在我们通过这些参数启动etcd的每一个成员：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \  --listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.12:2379 \  --discovery https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bf0ef5a6fc0257c817f0fb83</code></pre><p>一旦所有主机被注册后，每一个集群成员将会集群启动之前在自定义发现服务中注册自己。<br><strong>公共的etcd发现服务</strong><br>如果没有可以获得的集群，使用托管在<code>discovery.etcd.io</code>的公共发现服务。通过”new”主机,创建一个私有的发现URL,使用以下命令:</p><pre><code>$ curl https://discovery.etcd.io/new?size=3https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><p>将会创建一个初始化成员数量为3的集群,如果没有设置大小，将默认为3.</p><pre><code>ETCD_DISCOVERY=https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><pre><code>--discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><p>现在我们通过这些相关的参数启动每一个etcd成员：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><pre><code>$ etcd --name infra1 --initial-advertise-peer-urls http://10.0.1.11:2380 \  --listen-peer-urls http://10.0.1.11:2380 \  --listen-client-urls http://10.0.1.11:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.11:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><pre><code>$ etcd --name infra2 --initial-advertise-peer-urls http://10.0.1.12:2380 \  --listen-peer-urls http://10.0.1.12:2380 \  --listen-client-urls http://10.0.1.12:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.12:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de</code></pre><p>一旦所有主机被注册后，每一个集群成员将会集群启动之前在自定义发现服务中注册自己。<br>etcd使用环境变量<code>ETCD_DISCOVERY_PROXY</code>通过HTTP代理连接发现服务。<br><strong>错误和警告案例</strong><br>发现服务错误：</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573deetcd: error: the cluster doesn’t have a size configuration value in https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de/_configexit 1</code></pre><p>警告<br>这里有一个严重的警告表明发现服务URL将被这台主机忽略。</p><pre><code>$ etcd --name infra0 --initial-advertise-peer-urls http://10.0.1.10:2380 \  --listen-peer-urls http://10.0.1.10:2380 \  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \  --advertise-client-urls http://10.0.1.10:2379 \  --discovery https://discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573deetcdserver: discovery token ignored since a cluster has already been initialized. Valid log found at /var/lib/etcd</code></pre><h3 id="DNS-发现服务"><a href="#DNS-发现服务" class="headerlink" title="DNS 发现服务"></a>DNS 发现服务</h3><p>DNS <a href="http://www.ietf.org/rfc/rfc2052.txt" target="_blank" rel="noopener">SRV 记录</a>可以用来作为发现机制。<code>--discovery-srv</code>参数可用于设置可以找到发现SRV记录的DNS域名。 设置<code>--discovery-srv example.com</code>会导致DNS SRV记录按照列出的顺序进行查找：</p><ul><li>_etcd-server-ssl._tcp.example.com</li><li>_etcd-server._tcp.example.com</li></ul><p>如果找到<code>_etcd-server-ssl._tcp.example.com</code>，则etcd将尝试通过TLS进行引导过程。<br>为了帮助客户端发现etcd集群，按照列出的顺序查找以下DNS SRV记录：</p><ul><li>_etcd-client._tcp.example.com</li><li>_etcd-client-ssl._tcp.example.com</li></ul><p>如果找到了<code>_etcd-client-ssl._tcp.example.com</code>，则客户端将尝试通过SSL/TLS与etcd集群进行通信。<br>如果etcd使用TLS，则发现SRV记录（例如example.com）必须与主机名一起包含在SSL证书DNS SAN中，否则集群将失败，并显示以下日志消息：</p><pre><code>[...] rejected connection from &quot;10.0.1.11:53162&quot; (error &quot;remote error: tls: bad certificate&quot;, ServerName &quot;example.com&quot;)</code></pre><p>如果etcd使用的是没有自定义证书颁发机构的TLS，则发现域（例如example.com）必须与SRV记录域（例如infra1.example.com）匹配。 这是为了缓解伪造SRV记录指向不同域的攻击。 该域将在PKI下拥有有效的证书，但由未知的第三方控制。<br><code>-discovery-srv-name</code>参数还为在发现期间查询的SRV名称配置了后缀。 使用此参数可以区分同一域下的多个etcd集群。 例如，如果设置了<code>Discovery-srv = example.com</code>和<code>-discovery-srv-name = foo</code>，则会进行以下DNS SRV查询：</p><ul><li>_etcd-server-ssl-foo._tcp.example.com</li><li>_etcd-server-foo._tcp.example.com</li></ul><p><strong>创建DNS SRV记录</strong></p><pre><code>$ dig +noall +answer SRV _etcd-server._tcp.example.com_etcd-server._tcp.example.com. 300 IN  SRV  0 0 2380 infra0.example.com._etcd-server._tcp.example.com. 300 IN  SRV  0 0 2380 infra1.example.com._etcd-server._tcp.example.com. 300 IN  SRV  0 0 2380 infra2.example.com.</code></pre><pre><code>$ dig +noall +answer SRV _etcd-client._tcp.example.com_etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra0.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra1.example.com._etcd-client._tcp.example.com. 300 IN SRV 0 0 2379 infra2.example.com.</code></pre><pre><code>$ dig +noall +answer infra0.example.com infra1.example.com infra2.example.cominfra0.example.com.  300  IN  A  10.0.1.10infra1.example.com.  300  IN  A  10.0.1.11infra2.example.com.  300  IN  A  10.0.1.12</code></pre><p><strong>使用DNS引导etcd集群</strong><br>etcd群集成员可以公告域名或IP地址，引导过程将解析DNS A记录。 从3.2开始（3.1将显示警告），<code>--listen-peer-urls</code>和<code>--listen-client-urls</code>将拒绝网络接口绑定的域名。<br><code>--initial-advertise-peer-urls</code>中的解析地址必须与SRV目标中的解析地址之一匹配。 etcd成员读取解析的地址，以查找其是否属于SRV记录中定义的集群。</p><pre><code>$ etcd --name infra0 \--discovery-srv example.com \--initial-advertise-peer-urls http://infra0.example.com:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://infra0.example.com:2379 \--listen-client-urls http://0.0.0.0:2379 \--listen-peer-urls http://0.0.0.0:2380</code></pre><pre><code>$ etcd --name infra1 \--discovery-srv example.com \--initial-advertise-peer-urls http://infra1.example.com:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://infra1.example.com:2379 \--listen-client-urls http://0.0.0.0:2379 \--listen-peer-urls http://0.0.0.0:2380</code></pre><pre><code>$ etcd --name infra2 \--discovery-srv example.com \--initial-advertise-peer-urls http://infra2.example.com:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://infra2.example.com:2379 \--listen-client-urls http://0.0.0.0:2379 \--listen-peer-urls http://0.0.0.0:2380</code></pre><p>集群还可以使用IP地址而不是域名进行引导：</p><pre><code>$ etcd --name infra0 \--discovery-srv example.com \--initial-advertise-peer-urls http://10.0.1.10:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://10.0.1.10:2379 \--listen-client-urls http://10.0.1.10:2379 \--listen-peer-urls http://10.0.1.10:2380</code></pre><pre><code>$ etcd --name infra1 \--discovery-srv example.com \--initial-advertise-peer-urls http://10.0.1.11:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://10.0.1.11:2379 \--listen-client-urls http://10.0.1.11:2379 \--listen-peer-urls http://10.0.1.11:2380</code></pre><pre><code>$ etcd --name infra2 \--discovery-srv example.com \--initial-advertise-peer-urls http://10.0.1.12:2380 \--initial-cluster-token etcd-cluster-1 \--initial-cluster-state new \--advertise-client-urls http://10.0.1.12:2379 \--listen-client-urls http://10.0.1.12:2379 \--listen-peer-urls http://10.0.1.12:2380</code></pre><p>自从v3.1.0（v3.2.9除外），因此在<code>etcd --discovery-srv = example.com</code>中配置了TLS时，服务器仅在提供的证书具有根域<code>example.com</code>作为<code>Subject Alternative</code>(SAN)字段中的条目时，对等方/客户端进行身份验证。请参阅<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md#notes-for-dns-srv" target="_blank" rel="noopener">DNS SRV的注释</a>。<br><strong>网关</strong><br>etcd网关是一个简单的TCP代理，可将网络数据转发到etcd集群。 请阅读<a href="https://newonexd.github.io/2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/">网关指南</a>以获取更多信息。<br><strong>代理</strong><br>设置<code>--proxy</code>参数时，etcd以<a href="https://newonexd.github.io/2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/">代理模式</a>运行。 此代理模式仅支持etcd v2 API； 目前尚无计划支持v3 API。 相反，为了支持v3 API，etcd 3.0版本之后将提供具有增强功能的新代理。<br>要使用v2 API代理设置etcd集群，请阅读<a href="https://github.com/coreos/etcd/blob/release-2.3/Documentation/clustering.md" target="_blank" rel="noopener">etcd 2.3版本中的集群文档</a>。</p>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>单机集群</title>
    <link href="undefined2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/"/>
    <url>2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/local_cluster.md" target="_blank" rel="noopener">Setting up local clusters</a></p><h2 id="设置单节点集群"><a href="#设置单节点集群" class="headerlink" title="设置单节点集群"></a>设置单节点集群</h2><p>对于测试环境与开发环境，最快速与简单的方式是配置一个本地集群。对于生产环境，参考<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">集群</a>部分。</p><h3 id="本地单节点集群"><a href="#本地单节点集群" class="headerlink" title="本地单节点集群"></a>本地单节点集群</h3><h5 id="启动一个集群"><a href="#启动一个集群" class="headerlink" title="启动一个集群"></a>启动一个集群</h5><p>运行以下命令来部署一个单节点的etcd集群:</p><pre><code>$ ./etcd...</code></pre><p>如果<code>etcd</code>二进制文件不在当前工作目录，那可能位于<code>$GOPATH/bin/etcd</code>或者是<code>/usr/local/bin/etcd</code>.合适地运行命令。<br>运行的<code>etcd</code>成员在<code>localhost:2379</code>监听客户端的请求。</p><h5 id="与集群进行交互"><a href="#与集群进行交互" class="headerlink" title="与集群进行交互"></a>与集群进行交互</h5><p>使用<code>etcdctl</code>与运行中的集群进行交互操作<br>    1.     例子：在集群中存储一个键值对：</p><pre><code>$ ./etcdctl put foo barOK</code></pre><p>如果<code>OK</code>被打印在控制台，说明已经成功存储Key-Value对。<br>    2.     获取键<code>foo</code>对应的值：</p><pre><code>$ ./etcdctl get foobar</code></pre><p>如果<code>bar</code>被返回，说明与<code>etcd</code>集群的交互操作和期望中的相同。</p><h3 id="本地多节点集群"><a href="#本地多节点集群" class="headerlink" title="本地多节点集群"></a>本地多节点集群</h3><h5 id="启动一个集群-1"><a href="#启动一个集群-1" class="headerlink" title="启动一个集群"></a>启动一个集群</h5><p>在<code>etcd</code>的<code>git</code>仓库中存在一个<code>Procfile</code>文件提供一种简单的方式可以对本地多节点集群进行配置。在启动多节点集群之前，将工作目录导向<code>etcd</code>的根目录并执行以下操作：</p><pre><code>1.    安装`goreman`控制基于`Procfile`的应用：```$ go get github.com/mattn/goreman```2.    使用 `etcd`的配置文件`Procfile`通过`goreman`启动一个集群：```$ goreman -f Procfile start```集群成员已经启动了，并在`localhost:2379`,localhost:22379`,localhost:32379`监听客户端的请求。</code></pre><h5 id="与集群进行交互-1"><a href="#与集群进行交互-1" class="headerlink" title="与集群进行交互"></a>与集群进行交互</h5><p>使用<code>etcdctl</code>与运行中的集群进行交互操作:</p><pre><code>1. 打印成员列表：$ `etcdctl --write-out=table --endpoints=localhost:2379 member list``etcd`集群中的成员列表显示如下：</code></pre><table><thead><tr><th align="left">ID</th><th align="left">STATUS</th><th align="left">NAME</th><th align="left">PEER ADDRS</th><th align="left">CLIENT ADDRS</th></tr></thead><tbody><tr><td align="left">8211f1d0f64f3269</td><td align="left">started</td><td align="left">infra1</td><td align="left"><a href="http://127.0.0.1:2380" target="_blank" rel="noopener">http://127.0.0.1:2380</a></td><td align="left"><a href="http://127.0.0.1:2379" target="_blank" rel="noopener">http://127.0.0.1:2379</a></td></tr><tr><td align="left">91bc3c398fb3c146</td><td align="left">started</td><td align="left">infra1</td><td align="left"><a href="http://127.0.0.1:22380" target="_blank" rel="noopener">http://127.0.0.1:22380</a></td><td align="left"><a href="http://127.0.0.1:22379" target="_blank" rel="noopener">http://127.0.0.1:22379</a></td></tr><tr><td align="left">fd422379fda50e48</td><td align="left">started</td><td align="left">infra1</td><td align="left"><a href="http://127.0.0.1:32380" target="_blank" rel="noopener">http://127.0.0.1:32380</a></td><td align="left"><a href="http://127.0.0.1:32379" target="_blank" rel="noopener">http://127.0.0.1:32379</a></td></tr></tbody></table><pre><code>2.     例子：在集群中存储一个Key-Value对：</code></pre><pre><code>$ ./etcdctl put foo barOK</code></pre><p>如果<code>OK</code>被打印在控制台，说明已经成功存储键-值对。</p><h5 id="容错测试"><a href="#容错测试" class="headerlink" title="容错测试"></a>容错测试</h5><p>关闭一个成员然后尝试通过键获取值来进行容错测试：</p><ol><li>获取一个运行中的成员的名字然后停止它：<br> <code>Procfile</code>列出了多节点集群的属性信息。例如，名称为<code>etcd2</code>的运行中的成员。</li><li>停止该成员：<pre><code>#kill etcd2$ goreman run stop etcd2</code></pre></li><li>存储一个键：<pre><code>$ etcdctl put key helloOK</code></pre></li><li>获取前一步所存储的键： <pre><code>$ etcdctl get keyhello</code></pre></li><li>从已经停止的成员处获取键：<pre><code>$ etcdctl --endpoints=localhost:22379 get key</code></pre>该命令应该由于连接失败展示一个错误：<pre><code>2017/06/18 23:07:35 grpc: Conn.resetTransport failed to create client transport: connection error: desc = &quot;transport: dial tcp 127.0.0.1:22379: getsockopt: connection refused&quot;; Reconnecting to &quot;localhost:22379&quot;Error:  grpc: timed out trying to connect</code></pre></li><li>重启停止的成员：<pre><code>$ goreman run restart etcd2</code></pre></li><li>从重启的成员处获取键：<pre><code>$ etcdctl --endpoints=localhost:22379 get keyhello</code></pre>重启的成员重新建立了连接.<code>etcdctl</code>将能够成功地从重启的成员处接受键,读<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/">与etcd进行交互</a>部分学习更多关于与etcd交互的内容。</li></ol>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>etcd文档</title>
    <link href="undefined2019/11/23/blog/etcd/%E6%96%87%E6%A1%A3/"/>
    <url>2019/11/23/blog/etcd/%E6%96%87%E6%A1%A3/</url>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="https://github.com/etcd-io/etcd/tree/master/Documentation" target="_blank" rel="noopener">Documentation</a></p><h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><hr><p>etcd是一个分布式键值对存储，被设计为可靠的，快速的保存并提供对关键数据的访问。通过分布式锁，领导选举和写屏障使能分布式一致性。一个etcd集群旨在实现高可用和持久性数据存储与检索。</p><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><hr><h3 id="使用etcd进行开发"><a href="#使用etcd进行开发" class="headerlink" title="使用etcd进行开发"></a>使用etcd进行开发</h3><hr><p>一种简单的方式<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/">设置本地集群</a>开始使用etcd作为分布式键值对存储</p><ul><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4/">设置本地集群</a></li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E4%B8%8Eetcd%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92/">与etcd进行交互</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/api_reference_v3.md" target="_blank" rel="noopener">gRPC etcd核心</a>和<a href="">etcd并发</a>API参考</li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/HTTP_JSON_API%E9%80%9A%E8%BF%87gRPC%E7%BD%91%E5%85%B3/">HTTP JSON API 通过gRPC网关</a></li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/gRPC%E5%91%BD%E5%90%8D%E4%B8%8E%E5%8F%91%E7%8E%B0/">gRPC命名和发现</a></li><li><a href="https://godoc.org/github.com/etcd-io/etcd/clientv3/namespace" target="_blank" rel="noopener">客户端</a>和<a href="https://newonexd.github.io/2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/">代理</a>命名空间</li><li><a href="https://godoc.org/github.com/etcd-io/etcd/embed" target="_blank" rel="noopener">嵌入etcd</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E5%AE%9E%E9%AA%8C%E7%89%B9%E6%80%A7%E5%92%8CAPIs/">实验特性和APIs</a></li><li><a href="https://newonexd.github.io/2019/11/25/blog/etcd/%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/">系统限制</a></li></ul><h3 id="操作etcd集群"><a href="#操作etcd集群" class="headerlink" title="操作etcd集群"></a>操作etcd集群</h3><hr><p>对开发或者生产环境，管理员需要一个错误容忍etcd集群，从<a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">多机集群</a>开始。</p><h4 id="设置etcd"><a href="#设置etcd" class="headerlink" title="设置etcd"></a>设置etcd</h4><ul><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/ETCD%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">配置参数</a></li><li><a href="https://newonexd.github.io/2019/11/23/blog/etcd/%E5%A4%9A%E6%9C%BA%E9%9B%86%E7%BE%A4/">多成员集群</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/gRPC%E4%BB%A3%E7%90%86/">gRPC代理</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/etcd%E7%BD%91%E5%85%B3/">L4网关</a></li></ul><h4 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h4><ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/supported-platform.md" target="_blank" rel="noopener">支持的系统</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md" target="_blank" rel="noopener">硬件配置建议</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/performance.md" target="_blank" rel="noopener">性能基准测试</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">调节</a></li></ul><h4 id="平台引导"><a href="#平台引导" class="headerlink" title="平台引导"></a>平台引导</h4><ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/platforms/aws.md" target="_blank" rel="noopener">亚马逊Web服务</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/platforms/container-linux-systemd.md" target="_blank" rel="noopener">Linux容器，systemd</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/platforms/freebsd.md" target="_blank" rel="noopener">RessBSD</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/">Docker容器</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E5%9C%A8%E5%AE%B9%E5%99%A8%E5%86%85%E8%BF%90%E8%A1%8Cetcd%E9%9B%86%E7%BE%A4/">rkt容器</a></li></ul><h4 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h4><ul><li><a href="https://newonexd.github.io/2019/11/25/blog/etcd/TLS/">TLS</a></li><li><a href="https://newonexd.github.io/2019/11/25/blog/etcd/%E5%9F%BA%E4%BA%8E%E8%A7%92%E8%89%B2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/">基于角色的访问控制</a></li></ul><h4 id="维护和故障排除"><a href="#维护和故障排除" class="headerlink" title="维护和故障排除"></a>维护和故障排除</h4><ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md" target="_blank" rel="noopener">常见问题</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/monitoring.md" target="_blank" rel="noopener">监控方式</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/maintenance.md" target="_blank" rel="noopener">维护</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/failures.md" target="_blank" rel="noopener">失败模式</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/recovery.md" target="_blank" rel="noopener">容灾恢复</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/upgrades/upgrading-etcd.md" target="_blank" rel="noopener">更新</a><h4 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h4>要了解有关etcd的概念和内部知识的更多信息，请阅读以下页面：</li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md" target="_blank" rel="noopener">什么是etcd</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/data_model.md" target="_blank" rel="noopener">理解数据模式</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/api.md" target="_blank" rel="noopener">理解APIs</a></li><li><a href="https://newonexd.github.io/2019/11/24/blog/etcd/%E8%AF%8D%E6%B1%87%E8%A1%A8/">词汇表</a></li><li>设计<ul><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-auth-v3.md" target="_blank" rel="noopener">权限子系统</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-client.md" target="_blank" rel="noopener">客户端</a></li><li><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/learning/design-learner.md" target="_blank" rel="noopener">学习者</a></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd文档翻译</category>
      
    </categories>
    
    
    <tags>
      
      <tag>etcd</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>